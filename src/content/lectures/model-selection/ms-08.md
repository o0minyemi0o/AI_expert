# 정형 데이터 모델 비교

## 왜 정형 데이터 모델 비교가 중요한가

"정형(tabular) 데이터에서는 트리 기반 모델이 신경망을 이긴다"는 ML 커뮤니티의 오래된 경험칙입니다. 하지만 이것이 항상 참일까요? 최근 TabNet, FT-Transformer 등 정형 데이터 전용 신경망이 등장하면서, 이 질문은 더 복잡해졌습니다. Kaggle 대회와 학술 벤치마크에서의 실험 결과를 바탕으로, 각 접근법의 실질적 강점과 한계를 정리합니다.

---

## 1. 정형 데이터의 특성

정형 데이터는 이미지/텍스트와 근본적으로 다른 특성을 가집니다.

| 특성 | 정형 데이터 | 이미지/텍스트 |
|------|-----------|-------------|
| 피처 의미 | 각각 독립적 의미 | 공간/순서 관계 |
| 피처 유형 | 수치+범주 혼합 | 균질적 (픽셀/토큰) |
| 데이터 증강 | 어렵고 위험 | 자연스럽고 효과적 |
| 사전학습 | 거의 없음 | 대규모 가능 (ImageNet, 코퍼스) |
| 전이학습 | 매우 제한적 | 핵심 전략 |

> **핵심 직관**: 이미지/텍스트에서 딥러닝이 성공하는 핵심 이유(공간적 규칙성, 데이터 증강, 사전학습)가 정형 데이터에서는 대부분 적용되지 않습니다. 이것이 트리 모델이 강한 근본적 이유입니다.

---

## 2. 모델 후보군 비교

### XGBoost / LightGBM (트리 기반)

이미 ms-04에서 상세히 다룬 부스팅 모델입니다.

### 로지스틱 회귀 / 선형 모델

해석가능성이 높고, 베이스라인으로 항상 유용합니다.

### TabNet (Google)

- 어텐션 메커니즘으로 피처를 선택적으로 사용 (dl-07 참조)
- 해석가능한 신경망을 표방
- self-supervised 사전학습 가능

### FT-Transformer

- Transformer 아키텍처를 정형 데이터에 적용 (dl-08 참조)
- 각 피처를 토큰으로 변환 후 self-attention

| 모델 | 정확도 (일반) | 학습 속도 | 튜닝 난이도 | 해석성 | GPU 필요 |
|------|-------------|----------|-----------|--------|---------|
| 로지스틱 회귀 | 낮음~중간 | 매우 빠름 | 쉬움 | 매우 높음 | 불필요 |
| XGBoost | 높음 | 빠름 | 중간 | 중간 | 선택적 |
| LightGBM | 높음 | 매우 빠름 | 중간 | 중간 | 선택적 |
| TabNet | 중간~높음 | 느림 | 어려움 | 중간 | 필요 |
| FT-Transformer | 중간~높음 | 매우 느림 | 매우 어려움 | 낮음 | 필요 |

---

## 3. 벤치마크 결과: 트리가 이기는 이유

Grinsztajn et al. (2022) "Why do tree-based models still outperform deep learning on tabular data?"의 핵심 결과를 정리합니다.

### 주요 발견

| 실험 조건 | 트리 기반 | 신경망 | 승자 |
|----------|----------|--------|------|
| 중소 규모 (< 10K) | 우세 | 과적합 | 트리 |
| 중간 규모 (10K~100K) | 우세 | 비슷 | 트리 (근소) |
| 대규모 (> 100K) | 우세~비슷 | 비슷~우세 | 혼합 |
| 범주형 피처 다수 | 우세 | 열세 | 트리 |
| 비관련 피처 포함 | 강건 | 민감 | 트리 |
| 비평활(non-smooth) 타겟 | 우세 | 열세 | 트리 |

```
정형 데이터 모델 선택 플로우:

데이터 크기는?
├── < 10K 샘플
│   ├── 해석 필요 → 로지스틱/Ridge
│   └── 성능 우선 → XGBoost (깊이 제한)
├── 10K ~ 100K
│   ├── 정형만 → XGBoost / LightGBM (거의 항상 최선)
│   └── 정형 + 비정형 → 멀티모달 신경망 고려
├── 100K ~ 1M
│   ├── 범주형 많음 → CatBoost
│   ├── 속도 우선 → LightGBM
│   └── 신경망 시도 가치 → FT-Transformer
└── > 1M
    ├── 정형만 → LightGBM / XGBoost
    └── 멀티모달 → 신경망 (통합 아키텍처)
```

> **핵심 직관**: 트리 기반 모델이 정형 데이터에서 강한 이유는 (1) 비관련 피처에 강건하고, (2) 불규칙한 결정 경계를 잘 포착하며, (3) 범주형 피처를 자연스럽게 처리하기 때문입니다.

---

### 시나리오: 온라인 광고 CTR 예측

대형 광고 플랫폼이 배너 광고의 클릭률(CTR)을 예측하려 합니다. 데이터는 1억 건의 클릭 로그이며, 유저 ID(100만 명), 광고 ID(50만 개), 시간대, 디바이스 유형, 지역 등을 포함합니다. 유저 ID와 광고 ID는 고기수(high-cardinality) 범주형 피처로, 원-핫 인코딩 시 150만 차원이 되어 트리 모델로는 처리가 어렵습니다.

이 상황은 신경망의 엔티티 임베딩이 트리 모델을 이기는 대표적 케이스입니다. 유저 ID와 광고 ID를 각각 32~64차원 임베딩 벡터로 학습하면, "비슷한 유저"와 "비슷한 광고" 간의 관계를 밀집 벡터 공간에서 포착할 수 있습니다. 또한 1억 건이라는 대규모 데이터에서 신경망은 충분한 용량을 활용할 수 있으므로, 트리 모델 대비 AUC 0.01~0.02 정도의 유의미한 개선을 기대할 수 있습니다. 실무에서는 Wide & Deep 또는 DeepFM 아키텍처가 이 용도로 널리 사용됩니다.

### 시나리오: 중소기업 대출 부도 예측

시중은행이 중소기업 대출의 부도 가능성을 예측하려 합니다. 데이터는 3만 건의 기업 재무제표이며, 매출액, 영업이익, 부채비율, 유동비율, 이자보상배율, 업력, 종업원 수 등 20개 피처를 포함합니다. 타겟은 1년 내 부도 여부(이진 분류)입니다.

이 문제는 "XGBoost가 이기는" 전형적인 케이스입니다. 3만 건은 신경망이 충분한 성능을 발휘하기에는 부족하고, 20개 피처는 모두 의미가 명확한 수치형 재무 지표입니다. XGBoost는 별도의 피처 엔지니어링 없이도 피처 간 상호작용(예: 부채비율이 높지만 영업이익도 높은 기업)을 자동으로 포착합니다. 또한 금융 규제상 모델의 판단 근거를 설명해야 하므로, SHAP을 활용한 피처 중요도 분석이 가능한 트리 모델이 실무적으로도 적합합니다.

## 4. 언제 신경망이 정형에서도 유리한가

트리가 항상 이기는 것은 아닙니다. 다음 조건에서는 신경망이 우세할 수 있습니다.

| 조건 | 이유 | 예시 |
|------|------|------|
| 매우 큰 데이터 (>1M) | 신경망의 용량 활용 가능 | 대규모 광고 CTR 예측 |
| 멀티모달 입력 | 정형 + 이미지/텍스트 통합 | 상품 메타데이터 + 이미지 |
| 엔티티 임베딩 | 고기수 범주형 처리 | 수만 개 상점/사용자 ID |
| 자기 지도 학습 가능 | 레이블 없는 데이터 활용 | TabNet 사전학습 |
| End-to-end 학습 필요 | 피처 엔지니어링 최소화 | 빠른 프로토타입 |

```python
# 정형 데이터 모델 비교 실험 코드
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import Ridge
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb
import lightgbm as lgb
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline

X, y = fetch_california_housing(return_X_y=True)
print(f"데이터 크기: {X.shape}")

models = {
    'Ridge':         make_pipeline(StandardScaler(), Ridge()),
    'RandomForest':  RandomForestRegressor(n_estimators=100, random_state=42),
    'XGBoost':       xgb.XGBRegressor(n_estimators=200, max_depth=6,
                                       learning_rate=0.1, random_state=42),
    'LightGBM':      lgb.LGBMRegressor(n_estimators=200, num_leaves=31,
                                         learning_rate=0.1, random_state=42,
                                         verbose=-1),
}

print(f"\n{'모델':18s} {'R² (mean±std)':>15s}")
print("-" * 35)
for name, model in models.items():
    scores = cross_val_score(model, X, y, cv=5, scoring='r2')
    print(f"{name:18s} {scores.mean():.3f} ± {scores.std():.3f}")
```

---

## 5. 실전 권장 전략

```
정형 데이터 실전 전략:

Step 1: 베이스라인
  └── 로지스틱/Ridge로 하한 확인

Step 2: 트리 모델
  └── XGBoost 또는 LightGBM (기본 설정)
      └── 이미 충분한 성능? → 여기서 멈춤

Step 3: 하이퍼파라미터 튜닝
  └── Optuna로 최적화 (ms-09 참조)

Step 4: (필요 시) 신경망 시도
  └── 데이터 > 100K이고 트리 성능이 부족할 때만

Step 5: (대회 등) 앙상블
  └── XGBoost + LightGBM + CatBoost Stacking
```

> **핵심 직관**: 실무에서 정형 데이터의 성능을 높이는 가장 효과적인 방법은 "더 좋은 모델"이 아니라 "더 좋은 피처"를 만드는 것입니다. 모델 탐색에 시간을 쓰기 전에 피처 엔지니어링에 투자하십시오 (ms-06 참조).

---

## 핵심 정리

1. **정형 데이터에서는 트리 기반 모델이 대부분 승리**: XGBoost, LightGBM은 정형 데이터에서 신경망보다 빠르고, 튜닝이 쉽고, 일반적으로 더 정확합니다.
2. **신경망이 유리한 조건은 한정적**: 매우 큰 데이터, 멀티모달 입력, 고기수 범주형 임베딩 등 특수한 조건에서만 신경망이 트리를 이깁니다.
3. **데이터 증강과 사전학습의 부재가 핵심 차이**: 이미지/텍스트에서 딥러닝이 성공하는 두 가지 핵심 요소가 정형 데이터에서는 거의 적용되지 않습니다.
4. **로지스틱 → 트리 → (필요 시) 신경망 순서로 시도**: 단순한 모델부터 시작하여 복잡성을 점진적으로 높이는 것이 가장 효율적인 전략입니다.
5. **모델보다 피처에 투자**: 정형 데이터에서는 모델 선택보다 피처 엔지니어링이 성능에 더 큰 영향을 미치며, 도메인 지식 기반 피처가 가장 강력합니다.
