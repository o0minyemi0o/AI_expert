# 텍스트/자연어 모델 선택

## 왜 NLP 모델 선택이 복잡해졌는가

자연어 처리(NLP)는 LLM의 등장으로 패러다임이 완전히 변했습니다. 불과 5년 전까지만 해도 TF-IDF + 로지스틱 회귀가 텍스트 분류의 표준이었지만, 이제는 BERT fine-tuning이나 GPT 프롬프팅이 경쟁합니다. 문제는 이 세 가지 접근법 모두가 여전히 유효하며, **비용, 정확도, 지연시간의 트레이드오프**에 따라 최적 선택이 달라진다는 것입니다.

---

## 1. NLP 모델 스펙트럼

| 접근법 | 모델 크기 | 학습 데이터 필요 | 정확도 | 비용 | 지연시간 |
|--------|----------|----------------|--------|------|---------|
| TF-IDF + 전통 ML | 수 MB | 수백~수천 | 중간 | 매우 낮음 | 매우 빠름 |
| Word2Vec/FastText + ML | 수백 MB | 수천 | 중간~높음 | 낮음 | 빠름 |
| BERT fine-tuning | 110M~340M 파라미터 | 수천~수만 | 높음 | 중간 | 중간 |
| LLM 프롬프트 (Zero-shot) | 수십B 파라미터 | 0 | 중간~높음 | 높음 | 느림 |
| LLM fine-tuning | 수십B 파라미터 | 수백~수천 | 매우 높음 | 매우 높음 | 느림 |
| RAG | LLM + 검색 | 문서 DB | 높음 | 높음 | 느림 |

```
NLP 모델 선택 플로우:

학습 데이터 양은?
├── 없음 (Zero-shot)
│   ├── 비용 여유 → LLM 프롬프트 엔지니어링
│   └── 비용 제약 → 규칙 기반 / 키워드 매칭
├── 적음 (< 1,000)
│   ├── 비용 여유 → LLM few-shot 프롬프팅
│   └── 비용 제약 → TF-IDF + 로지스틱 회귀
├── 중간 (1,000 ~ 10,000)
│   ├── GPU 있음 → BERT/RoBERTa fine-tuning
│   └── GPU 없음 → TF-IDF + SVM
├── 많음 (> 10,000)
│   ├── 도메인 특화 필요 → BERT fine-tuning
│   └── 빠른 추론 필요 → DistilBERT / TF-IDF
└── 지식 기반 QA → RAG 파이프라인 (ms-16)
```

---

## 2. TF-IDF + 전통 ML: 여전히 강력한 베이스라인

### 언제 쓰는가
- 빠른 프로토타입이 필요할 때
- 컴퓨팅 자원이 제한적일 때
- 실시간 추론이 요구될 때 (< 1ms)
- 해석가능성이 필요할 때 (어떤 단어가 중요한지 확인)

### 언제 쓰지 않는가
- 문맥 이해가 중요한 과제 (감성의 뉘앙스, 아이러니 등)
- 긴 문서의 의미적 유사도 비교
- 다국어/제로샷 분류

> **핵심 직관**: TF-IDF + 로지스틱 회귀는 놀라울 정도로 강력합니다. 많은 실무 텍스트 분류 문제에서 BERT와 3~5% 차이 이내이며, 추론 속도는 100배 이상 빠릅니다. 항상 이 모델을 베이스라인으로 먼저 시도하십시오.

### 시나리오: 쇼핑몰 고객 리뷰 감성 분석

대형 이커머스 플랫폼에서 상품 리뷰의 긍정/부정을 자동 분류하려 합니다. 데이터는 50만 건 리뷰, 2개 클래스(긍정/부정), 평균 리뷰 길이 80자입니다.

TF-IDF + 로지스틱 회귀를 베이스라인으로 구축하면 F1 92%를 달성합니다. BERT fine-tuning으로 전환하면 F1 95%까지 올라가지만, GPU 서버 비용이 월 $800 추가되고 추론 속도가 100배 느려집니다. 3% 향상이 비즈니스에 미치는 영향을 계산해야 합니다. 리뷰 50만 건 중 3%는 1.5만 건의 분류 개선을 의미하며, 이로 인한 고객 경험 개선이 월 $800 GPU 비용을 정당화하는지 판단해야 합니다. 대부분의 경우 TF-IDF 베이스라인으로 시작하고, 비즈니스 임팩트가 확인된 후에만 BERT로 전환하는 것이 합리적입니다.

```python
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import cross_val_score

# 예시 데이터
texts = [
    "이 제품 정말 좋아요", "배송이 빨라서 만족합니다",
    "품질이 너무 나빠요", "환불 요청합니다",
    "가격 대비 훌륭합니다", "포장이 엉망이에요",
] * 100  # 실전에서는 더 많은 데이터
labels = [1, 1, 0, 0, 1, 0] * 100

pipeline = make_pipeline(
    TfidfVectorizer(max_features=5000, ngram_range=(1, 2)),
    LogisticRegression(max_iter=1000)
)

scores = cross_val_score(pipeline, texts, labels, cv=5, scoring='f1')
print(f"TF-IDF + LR F1: {scores.mean():.3f}")
```

---

## 3. BERT/RoBERTa Fine-tuning: 중간 규모

### 언제 쓰는가
- 문맥 이해가 중요한 과제 (NLI, 감성 뉘앙스)
- 1,000~10,000개의 레이블 데이터가 있을 때
- GPU 자원이 충분할 때
- 여러 NLP 태스크를 하나의 모델로 처리하고 싶을 때

### 언제 쓰지 않는가
- 추론 지연시간이 1ms 이하로 제한될 때
- GPU가 없고 CPU만 사용해야 할 때
- 단순 키워드 기반 분류로 충분할 때

| 모델 | 크기 | 한국어 지원 | 특징 |
|------|------|-----------|------|
| BERT-base | 110M | multilingual-BERT | 범용 |
| KoBERT | ~110M | 네이티브 | 한국어 최적화 |
| KoELECTRA | ~110M | 네이티브 | 효율적 사전학습 |
| RoBERTa | 125M | XLM-R (다국어) | BERT 개선 |
| DistilBERT | 66M | 지원 | 경량화 (6x 빠름) |

```python
# BERT fine-tuning (Hugging Face)
from transformers import (AutoTokenizer, AutoModelForSequenceClassification,
                           TrainingArguments, Trainer)

model_name = "klue/bert-base"  # 한국어 BERT
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(
    model_name, num_labels=2
)

# TrainingArguments 설정
training_args = TrainingArguments(
    output_dir="./results",
    num_train_epochs=3,
    per_device_train_batch_size=16,
    learning_rate=2e-5,          # BERT fine-tuning 표준
    weight_decay=0.01,
    evaluation_strategy="epoch",
)

# Trainer로 학습 (데이터셋 생략)
# trainer = Trainer(model=model, args=training_args, ...)
# trainer.train()
```

---

## 4. LLM 활용: Fine-tuning vs RAG vs 프롬프트

| 접근법 | 비용 (학습) | 비용 (추론) | 정확도 | 유연성 | 지식 최신성 |
|--------|-----------|-----------|--------|--------|-----------|
| 프롬프트 엔지니어링 | 없음 | API 비용 | 중간~높음 | 매우 높음 | 모델 학습 시점 |
| RAG | 인덱싱 비용 | API + 검색 | 높음 | 높음 | 실시간 업데이트 |
| LLM Fine-tuning | GPU 비용 높음 | API/자체 | 매우 높음 | 낮음 | 학습 시점 |

```
LLM 활용 전략 선택:

과제의 성격은?
├── 범용 (요약, 번역, QA)
│   └── 프롬프트 엔지니어링으로 충분
├── 도메인 지식 필요 (법률, 의료 QA)
│   └── RAG (ms-16 참조)
│       └── 정확도 부족? → RAG + fine-tuning
├── 특정 포맷/스타일 필요
│   └── LLM fine-tuning (LoRA/QLoRA)
└── 분류/추출 (구조화된 출력)
    ├── 레이블 데이터 있음 → BERT fine-tuning (더 효율적)
    └── 레이블 데이터 없음 → LLM zero/few-shot
```

> **핵심 직관**: 분류와 같은 구조화된 NLP 태스크에서는 BERT fine-tuning이 LLM보다 **비용 대비 효율이 훨씬 높습니다**. LLM은 "생성"이 필요한 과제(요약, QA, 대화)에서 진가를 발휘합니다.

### 시나리오: 사내 기술 문서 질의응답 시스템

IT 기업에서 기술 문서 1만 건(API 문서, 트러블슈팅 가이드, 아키텍처 설명서)을 기반으로 직원들의 자연어 질문에 답변하는 시스템을 구축합니다. 문서당 평균 2,000자, 총 2,000만 자 규모입니다.

RAG(검색 증강 생성) 방식은 문서를 임베딩하여 벡터 DB에 저장하고, 질문이 들어오면 관련 문서를 검색한 후 LLM이 답변을 생성합니다. 비용은 임베딩 인덱싱 1회 + API 호출당 약 $0.01이며, 새 문서 추가 시 해당 문서만 재인덱싱하면 됩니다. 반면 전체 문서로 LLM을 fine-tuning하면 학습에 GPU $500 이상 소요되고, 문서가 업데이트될 때마다 재학습이 필요합니다. 정확도는 fine-tuning이 5~10% 높을 수 있지만, 기술 문서는 주 단위로 갱신되므로 업데이트 용이성이 결정적입니다. 대부분의 사내 QA 시스템에서는 RAG가 비용, 정확도, 유지보수 측면에서 최적의 선택입니다.

---

## 5. 비용/정확도/지연시간 트레이드오프

| 모델 | 추론 비용 (1K문서) | 지연시간 (1문서) | F1 (감성분류 기준) |
|------|-------------------|----------------|-------------------|
| TF-IDF + LR | ~$0.001 | ~0.1ms | ~0.85 |
| DistilBERT | ~$0.10 | ~10ms | ~0.90 |
| BERT-base | ~$0.50 | ~30ms | ~0.92 |
| GPT-4 (API) | ~$5.00 | ~500ms | ~0.93 |

```
비용 vs 성능 의사결정:

성능 차이가 비즈니스에 중요한가?
├── F1 85% → 90% 차이가 크다
│   └── BERT fine-tuning 가치 있음
├── F1 90% → 93% 차이가 중요하다
│   └── LLM 비용 정당화 검토
└── F1 85%면 충분하다
    └── TF-IDF + LR 유지 (비용 최소화)
```

> **핵심 직관**: NLP에서 모델 선택은 결국 **비용 함수**입니다. "정확도 1% 향상에 추론 비용 10배를 쓸 가치가 있는가?"를 비즈니스 임팩트로 환산하여 판단하십시오.

---

## 핵심 정리

1. **TF-IDF + 로지스틱 회귀는 항상 첫 번째 베이스라인**: 구현이 빠르고, 추론이 즉각적이며, 많은 분류 문제에서 BERT와 큰 차이가 없습니다.
2. **BERT fine-tuning은 구조화된 NLP의 최적점**: 분류, NER, 감성 분석 등 레이블 데이터가 있는 과제에서는 LLM보다 비용 효율적입니다.
3. **LLM은 생성 과제에서 진가를 발휘**: 요약, QA, 대화, 코드 생성 등 구조가 고정되지 않은 과제에서 LLM이 본질적으로 유리합니다.
4. **RAG는 도메인 지식 + 최신성이 필요할 때**: 모델 학습 없이 외부 지식을 활용할 수 있으며, fine-tuning보다 유연하고 업데이트가 쉽습니다.
5. **비용/정확도/지연시간 트레이드오프를 정량적으로 비교**: "가장 정확한 모델"이 아니라 "ROI가 가장 높은 모델"을 선택하는 것이 실무의 핵심입니다.
