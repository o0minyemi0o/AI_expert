# 통계적 검정과 추론

## 왜 통계적 검정을 알아야 하는가

ML 엔지니어는 종종 "이 두 그룹의 차이가 통계적으로 유의한가?", "이 피처가 타겟과 관련이 있는가?"와 같은 질문에 답해야 합니다. 이런 질문에 ML 모델을 학습시키는 것은 과도한 접근이며, 통계적 검정만으로 충분합니다. 반대로, 통계적 검정의 한계를 모르면 ML이 필요한 문제에서 시간을 낭비합니다.

이 강의에서는 주요 통계 검정의 적용 조건과 선택 기준을 비교하고, "ML 대신 통계로 충분한 경우"를 판별하는 기준을 제시합니다.

---

## 1. 가설 검정의 기초

### 핵심 개념

- **귀무가설** $H_0$: 차이/효과가 없다 (기본 가정)
- **대립가설** $H_1$: 차이/효과가 있다
- **p-value**: $H_0$가 참일 때 관측된 결과 이상의 극단적 결과를 얻을 확률 (pt-06 참조)
- **유의수준** $\alpha$: 보통 0.05 (5%)

> **핵심 직관**: p-value는 "효과의 크기"가 아니라 "데이터가 $H_0$와 얼마나 모순되는가"를 나타냅니다. p < 0.05라도 실질적으로 무의미한 차이일 수 있으므로, 항상 **효과 크기(effect size)**와 함께 보고해야 합니다.

### 시나리오: 신약 임상시험

제약회사가 고혈압 신약의 효과를 검증하는 임상시험을 진행합니다. 치료군 200명과 대조군(위약) 200명을 무작위 배정한 뒤, 8주 후 수축기 혈압 감소량을 측정합니다. 치료군 평균 감소 12.3mmHg, 대조군 평균 감소 8.1mmHg입니다.

이 문제는 ML이 아닌 독립 표본 t-test로 충분히 해결됩니다. 두 그룹의 혈압 감소량이 통계적으로 유의하게 다른지 검정하고, Cohen's d로 효과 크기를 보고합니다. 규제 기관(FDA, 식약처)은 p-value와 신뢰구간을 요구하므로, ML 모델의 예측 성능이 아닌 통계적 유의성이 핵심입니다. 여기서 ML을 사용하면 오히려 과도한 접근이 됩니다.

### 시나리오: 웹사이트 UI 변경 효과 측정

이커머스 사이트가 결제 버튼 색상 변경(파란색→초록색)의 효과를 A/B 테스트로 확인합니다. 5만 유저를 무작위로 두 그룹에 배정하여 2주간 데이터를 수집한 결과, 대조군(파란색) 전환율 3.2%, 실험군(초록색) 전환율 3.5%입니다.

전환율은 이진 결과(구매/미구매)이므로, 카이제곱 검정 또는 비율 검정(z-test for proportions)이 적합합니다. 0.3%포인트 차이가 통계적으로 유의한지 확인하고, 유의하더라도 비즈니스적으로 의미 있는 차이인지(예: 연간 추가 매출 규모)를 함께 평가해야 합니다. 이 문제에 분류 모델을 학습시키는 것은 불필요하며, 단순한 통계 검정이 가장 효율적이고 해석 가능한 답을 제공합니다.

---

## 2. 모수 검정: t-test, ANOVA

### t-test (두 그룹 비교)

| 유형 | 상황 | 예시 |
|------|------|------|
| 독립 표본 | 두 독립 그룹 비교 | A/B 테스트 전환율 |
| 대응 표본 | 같은 대상 전후 비교 | 약물 투여 전후 혈압 |
| 단일 표본 | 모집단 평균과 비교 | 생산 품질 기준 충족 여부 |

### 언제 쓰는가
- 두 그룹의 평균 차이를 검정할 때
- 데이터가 대략 정규분포를 따를 때
- 연속형 결과 변수일 때

### ANOVA (세 그룹 이상 비교)

### 언제 쓰는가
- 세 개 이상 그룹의 평균을 동시에 비교할 때
- 예: 마케팅 캠페인 A, B, C의 효과 비교

```python
from scipy import stats
import numpy as np

# 독립 표본 t-test: A/B 테스트
np.random.seed(42)
group_a = np.random.normal(loc=10.0, scale=2.0, size=100)  # 대조군
group_b = np.random.normal(loc=10.5, scale=2.0, size=100)  # 실험군

t_stat, p_value = stats.ttest_ind(group_a, group_b)
print(f"t-statistic: {t_stat:.3f}")
print(f"p-value: {p_value:.4f}")

# 효과 크기 (Cohen's d)
cohens_d = (group_b.mean() - group_a.mean()) / np.sqrt(
    (group_a.std()**2 + group_b.std()**2) / 2)
print(f"Cohen's d: {cohens_d:.3f}")  # 0.2: 작음, 0.5: 중간, 0.8: 큼

# ANOVA: 세 그룹 비교
group_c = np.random.normal(loc=11.0, scale=2.0, size=100)
f_stat, p_anova = stats.f_oneway(group_a, group_b, group_c)
print(f"\nANOVA F-statistic: {f_stat:.3f}, p-value: {p_anova:.4f}")
```

---

## 3. 카이제곱 검정과 비율 검정

### 카이제곱 검정

### 언제 쓰는가
- 두 범주형 변수 간의 관계(독립성) 검정
- 관측 빈도와 기대 빈도의 차이 검정
- 예: 성별과 제품 선호도의 관련성

### 비율 검정

### 언제 쓰는가
- 두 그룹의 비율(전환율, 클릭률) 비교
- A/B 테스트에서 가장 흔히 사용

| 검정 | 데이터 유형 | 그룹 수 | 가정 | 대표 상황 |
|------|-----------|---------|------|----------|
| t-test | 연속형 | 2 | 정규성 | 평균 비교 |
| ANOVA | 연속형 | 3+ | 정규성, 등분산 | 다그룹 평균 비교 |
| 카이제곱 | 범주형 | 2+ | 기대빈도 ≥ 5 | 독립성 검정 |
| 비율 검정 | 이진 | 2 | 충분한 표본 | A/B 전환율 |

```python
from scipy.stats import chi2_contingency
import numpy as np

# 카이제곱 독립성 검정
# 예: 성별(남/여) × 제품선호(A/B/C)
observed = np.array([[50, 30, 20],   # 남성
                      [35, 40, 25]])  # 여성

chi2, p_val, dof, expected = chi2_contingency(observed)
print(f"카이제곱 통계량: {chi2:.3f}")
print(f"p-value: {p_val:.4f}")
print(f"자유도: {dof}")
```

---

## 4. 비모수 검정

정규성 가정을 만족하지 않거나, 순서형 데이터일 때 사용합니다.

| 모수 검정 | 비모수 대안 | 사용 조건 |
|----------|-----------|----------|
| 독립 t-test | Mann-Whitney U | 정규성 불만족, 순서형 |
| 대응 t-test | Wilcoxon 부호순위 | 정규성 불만족, 전후 비교 |
| ANOVA | Kruskal-Wallis | 정규성 불만족, 3+ 그룹 |

```
검정 방법 선택 플로우:

데이터가 정규분포를 따르는가?
├── Yes → 모수 검정
│   ├── 2그룹 → t-test
│   └── 3+그룹 → ANOVA
├── No → 비모수 검정
│   ├── 2그룹 → Mann-Whitney U
│   └── 3+그룹 → Kruskal-Wallis
└── 범주형 데이터 → 카이제곱 검정
```

> **핵심 직관**: 표본 크기가 30 이상이면 중심극한정리에 의해 t-test가 대체로 유효합니다. 하지만 분포가 극도로 비대칭이거나 이상치가 많으면 비모수 검정이 더 안전합니다.

```python
from scipy.stats import mannwhitneyu, kruskal
import numpy as np

np.random.seed(42)
# 비정규 분포 (지수분포)
group_a = np.random.exponential(scale=5.0, size=50)
group_b = np.random.exponential(scale=7.0, size=50)

# Mann-Whitney U 검정
u_stat, p_mw = mannwhitneyu(group_a, group_b, alternative='two-sided')
print(f"Mann-Whitney U: {u_stat:.1f}, p-value: {p_mw:.4f}")
```

---

## 5. 베이즈 추론 vs 빈도주의: 실전 선택

| 관점 | 빈도주의 | 베이즈 |
|------|---------|--------|
| 확률 해석 | 장기적 빈도 | 믿음의 정도 |
| 결과 | p-value, 신뢰구간 | 사후분포, 신용구간 |
| 사전 지식 | 사용 안 함 | 사전분포로 통합 |
| 소량 데이터 | 검정력 부족 | 사전분포로 보완 |
| 계산 비용 | 낮음 | 높음 (MCMC 등) |

### 언제 베이즈를 쓰는가
- 사전 지식을 반영해야 할 때 (도메인 전문가 의견)
- 소량 데이터에서 불확실성을 정량화할 때 (pt-04, pt-05 참조)
- 점 추정이 아닌 분포 전체가 필요할 때
- A/B 테스트에서 "B가 A보다 나을 확률"을 직접 계산하고 싶을 때

### 언제 빈도주의로 충분한가
- 표본이 크고 가정이 만족될 때
- 규제 기관에서 p-value를 요구할 때
- 빠른 검정이 필요할 때

> **핵심 직관**: 빈도주의는 "이 결과가 우연일 확률"을, 베이즈는 "B가 A보다 나을 확률"을 직접 답합니다. 비즈니스 의사결정에는 베이즈의 답이 더 직관적인 경우가 많습니다.

---

## 6. ML 대신 통계로 충분한 경우

```
ML vs 통계 판별 플로우:

목적이 "예측"인가, "추론/이해"인가?
├── 예측 → ML (새로운 데이터에 대한 예측이 목표)
└── 추론/이해 → 통계가 더 적합할 수 있음
                ├── "A와 B의 차이가 유의한가?" → 검정
                ├── "X가 Y에 미치는 영향은?" → 회귀 (계수 해석)
                ├── "효과의 불확실성은?" → 신뢰/신용구간
                └── "인과관계인가?" → 인과추론 (RCT, DoWhy)
```

| 상황 | 통계로 충분 | ML 필요 |
|------|-----------|---------|
| 두 그룹 평균 비교 | t-test | 불필요 |
| A/B 테스트 | 비율 검정 / 베이즈 | 불필요 |
| 피처 중요도 이해 | 회귀 계수 + p-value | 불필요 |
| 미래 매출 예측 | 부족 | 시계열 ML (ms-12) |
| 이미지 분류 | 불가 | CNN/ViT (ms-10) |
| 이상 패턴 탐지 | 제한적 (Z-score) | Isolation Forest 등 (ms-14) |

---

## 핵심 정리

1. **t-test는 두 그룹 평균, ANOVA는 세 그룹 이상**: 연속형 데이터에서 그룹 간 차이를 검정하는 가장 기본적인 도구이며, 정규성 가정이 필요합니다.
2. **정규성을 만족하지 않으면 비모수 검정**: Mann-Whitney, Kruskal-Wallis는 분포 가정 없이 사용 가능하며, 순서형 데이터에도 적합합니다.
3. **p-value만으로는 부족, 효과 크기를 함께 보고**: 표본이 크면 사소한 차이도 유의하게 나오므로, Cohen's d 등 효과 크기 지표를 반드시 확인합니다.
4. **베이즈는 소량 데이터와 의사결정에 강력**: "B가 A보다 나을 확률은 94%"와 같은 직관적 답을 제공하며, 사전 지식을 활용할 수 있습니다.
5. **"추론/이해"가 목적이면 통계, "예측"이 목적이면 ML**: 문제의 본질적 목적에 따라 도구를 선택하며, ML이 아닌 통계로 충분한 경우를 정확히 판별해야 합니다.
