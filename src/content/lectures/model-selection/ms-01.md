# 문제 정의와 접근법 선택

## 왜 문제 정의를 먼저 해야 하는가

많은 실무자가 "어떤 모델을 쓸까?"라는 질문부터 시작합니다. 하지만 올바른 첫 번째 질문은 **"이 문제에 ML이 정말 필요한가?"**입니다. 규칙 기반 시스템으로 충분한 문제에 딥러닝을 적용하면 개발 비용, 유지보수 부담, 해석 불가능성만 늘어납니다. 반대로, 복잡한 패턴이 존재하는 문제에 규칙을 수작업으로 짜면 성능 한계에 금방 부딪힙니다.

이 강의에서는 문제를 올바르게 정의하고, 가장 적합한 접근법을 체계적으로 선택하는 프레임워크를 배웁니다.

---

## 1. ML이 정말 필요한가?

### 규칙 기반 vs 통계 vs ML vs DL

| 접근법 | 장점 | 단점 | 적합한 상황 |
|--------|------|------|------------|
| 규칙 기반 | 해석 용이, 빠른 구현 | 복잡한 패턴 처리 불가 | 비즈니스 로직이 명확할 때 |
| 통계적 방법 | 이론적 보장, 불확실성 정량화 | 비선형 관계 포착 어려움 | 가설 검정, 인과 추론 |
| 전통 ML | 중간 복잡도, 해석 가능 | 피처 엔지니어링 필요 | 정형 데이터, 중간 규모 |
| 딥러닝 | 자동 피처 학습, 높은 성능 | 대량 데이터/GPU 필요 | 이미지, 텍스트, 음성 |

```
의사결정 플로우:

문제가 명확한 규칙으로 표현되는가?
├── Yes → 규칙 기반 시스템 (if-else, 전문가 시스템)
└── No → 데이터가 있는가?
          ├── No → 데이터 수집부터
          └── Yes → 데이터가 정형인가?
                    ├── Yes → 샘플 수 < 1,000?
                    │         ├── Yes → 통계적 방법 / 단순 ML
                    │         └── No → 전통 ML (트리, SVM 등)
                    └── No → 비정형 (이미지/텍스트/음성)?
                              ├── Yes → 딥러닝
                              └── No → 그래프/시계열 → 특화 모델
```

> **핵심 직관**: "ML이 필요한가?"를 먼저 묻는 것이 가장 중요합니다. 단순한 임계값 규칙이 90% 문제를 해결한다면, ML은 나머지 10%를 위한 것입니다.

### 시나리오: 은행 대출 심사 자동화

한 시중은행이 대출 심사 과정을 자동화하려 합니다. 데이터는 과거 대출 신청 기록 10만 건, 30개 피처(연소득, 신용점수, 부채비율, 근속연수, 주거 형태, 대출 목적 등)로 구성되며, 타겟은 승인/거절(이진 분류)입니다.

먼저 "이것이 ML 문제인가?"를 판단해야 합니다. 기존에 심사역이 사용하던 규칙(예: 신용점수 600점 미만이면 거절)이 있다면, 이 규칙 기반 시스템의 정확도를 베이스라인으로 측정합니다. 만약 규칙 기반으로 이미 정확도 85%를 달성하고 있다면, ML 모델은 이를 유의미하게 초과해야만 도입 가치가 있습니다. 또한 금융 규제상 설명가능성이 필수이므로, 블랙박스 모델보다는 로지스틱 회귀나 결정 트리처럼 해석 가능한 모델을 우선 검토해야 합니다.

### 시나리오: 커피 체인점 신규 매장 입지 선정

전국 500개 매장을 운영하는 커피 체인이 신규 매장 후보지를 평가하려 합니다. 데이터는 기존 매장 및 폐점 매장 포함 2,000건의 지역별 매출 데이터이며, 피처로 반경 500m 인구 수, 유동인구, 경쟁 점포 수, 평균 임대료, 대중교통 접근성 등 15개 변수를 포함합니다. 타겟은 월 평균 매출액(연속 값, 회귀 문제)입니다.

이 경우 "반경 500m 인구 5만 이상이고 경쟁 점포 2개 이하"와 같은 규칙 기반 접근도 가능합니다. 하지만 변수 간 상호작용(예: 유동인구는 많지만 임대료도 높은 지역)이 복잡하므로, ML 모델이 규칙 기반보다 나은 성능을 보일 가능성이 높습니다. 2,000건이라는 데이터 크기를 고려하면, Ridge 회귀나 Random Forest로 시작하는 것이 적절합니다.

---

## 2. 베이스라인의 중요성

어떤 복잡한 모델을 시도하기 전에, **항상 단순 베이스라인부터** 구축해야 합니다.

### 문제 유형별 베이스라인

| 문제 유형 | 가장 단순한 베이스라인 | 합리적 베이스라인 |
|-----------|----------------------|------------------|
| 이진 분류 | 다수 클래스 예측 | 로지스틱 회귀 |
| 다중 분류 | 다수 클래스 예측 | 로지스틱 회귀 + TF-IDF |
| 회귀 | 평균값 예측 | 선형 회귀, Ridge |
| 시계열 | 직전 값 반복 | 이동 평균, ARIMA |
| 추천 | 인기 순 추천 | 협업 필터링 |
| 텍스트 분류 | 키워드 규칙 | TF-IDF + 로지스틱 회귀 |

```python
# 베이스라인 구축 예시: 분류 문제
from sklearn.dummy import DummyClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score
from sklearn.datasets import make_classification

X, y = make_classification(n_samples=1000, n_features=20, random_state=42)

# 가장 단순한 베이스라인
dummy = DummyClassifier(strategy='most_frequent')
dummy_score = cross_val_score(dummy, X, y, cv=5, scoring='f1').mean()
print(f"다수 클래스 베이스라인 F1: {dummy_score:.3f}")

# 합리적 베이스라인
lr = LogisticRegression(max_iter=1000)
lr_score = cross_val_score(lr, X, y, cv=5, scoring='f1').mean()
print(f"로지스틱 회귀 베이스라인 F1: {lr_score:.3f}")

# 복잡한 모델은 이 점수를 유의미하게 이길 때만 채택
```

> **핵심 직관**: 베이스라인을 이기지 못하는 복잡한 모델은 가치가 없습니다. 항상 "이 모델이 베이스라인 대비 얼마나 개선되는가?"를 정량적으로 평가하십시오.

---

## 3. 문제 유형 분류

ML 문제를 올바르게 분류하는 것이 모델 선택의 출발점입니다.

### 지도 학습

- **분류**: 이산적 카테고리 예측 (스팸 여부, 질병 진단) → ms-03 참조
- **회귀**: 연속 값 예측 (가격, 온도) → ms-02 참조
- **랭킹**: 순서 예측 (검색 결과 정렬) → ms-16 참조

### 비지도 학습

- **클러스터링**: 유사한 데이터 그룹화 (고객 세분화) → ms-05 참조
- **차원 축소**: 고차원 데이터 압축/시각화 (la-06, la-07 참조) → ms-06 참조
- **이상 탐지**: 비정상 패턴 발견 (사기 감지) → ms-14 참조

### 기타

- **생성**: 새로운 데이터 생성 (이미지, 텍스트) → ms-17 참조
- **강화 학습**: 순차적 의사결정 (게임, 로봇)

```
문제 유형 판별 플로우:

정답 레이블이 있는가?
├── Yes (지도 학습)
│   ├── 예측 대상이 범주형인가?
│   │   ├── Yes → 분류 (ms-03)
│   │   └── No → 회귀 (ms-02)
│   └── 순서가 중요한가?
│       └── Yes → 랭킹 (ms-16)
├── No (비지도 학습)
│   ├── 그룹을 찾고 싶은가? → 클러스터링 (ms-05)
│   ├── 차원을 줄이고 싶은가? → 차원 축소 (ms-06)
│   └── 이상치를 찾고 싶은가? → 이상 탐지 (ms-14)
└── 보상 신호만 있는가?
    └── Yes → 강화 학습
```

---

## 4. 평가 지표 선택

문제를 정의했으면, **성공을 어떻게 측정할 것인지** 결정해야 합니다. 잘못된 지표를 최적화하면 비즈니스 가치가 없는 모델이 만들어집니다.

| 문제 유형 | 주요 지표 | 사용 조건 |
|-----------|----------|-----------|
| 이진 분류 (균형) | Accuracy, F1 | 클래스 비율이 비슷할 때 |
| 이진 분류 (불균형) | AUROC, AUPRC, F1 | 희소 클래스가 중요할 때 |
| 다중 분류 | Macro/Weighted F1 | 클래스 수가 많을 때 |
| 회귀 | RMSE, MAE, $R^2$ | 목적에 따라 선택 |
| 랭킹 | NDCG, MAP | 순서 품질이 중요할 때 |
| 클러스터링 | Silhouette, ARI | 외부 레이블 유무에 따라 |

> **핵심 직관**: 비즈니스 지표(매출, 이탈률)와 ML 지표(F1, AUROC)를 연결하는 것이 실무에서 가장 중요합니다. ML 지표가 0.01 올라도 비즈니스 임팩트가 없으면 의미가 없습니다.

```python
# 평가 지표 비교 예시
from sklearn.metrics import (accuracy_score, f1_score,
                              roc_auc_score, mean_squared_error)
import numpy as np

# 불균형 분류에서 accuracy의 함정
y_true = np.array([0]*950 + [1]*50)  # 95:5 불균형
y_pred_naive = np.zeros(1000)         # 모두 0으로 예측

print(f"Accuracy: {accuracy_score(y_true, y_pred_naive):.3f}")  # 0.950
print(f"F1 Score: {f1_score(y_true, y_pred_naive):.3f}")        # 0.000
# Accuracy는 높지만 F1은 0 — 쓸모없는 모델
```

---

## 5. 실전 체크리스트

프로젝트를 시작할 때 다음을 반드시 확인하십시오.

| 체크 항목 | 질문 | 결과 |
|-----------|------|------|
| 목표 정의 | 비즈니스 문제가 명확한가? | ML 문제로 변환 |
| 데이터 확인 | 충분한 양/질의 데이터가 있는가? | 수집 계획 수립 |
| 베이스라인 | 단순 모델의 성능은? | 개선 목표 설정 |
| 지표 선택 | 어떤 지표로 평가할 것인가? | 비즈니스 연결 |
| 제약 조건 | 지연시간, 비용, 해석가능성 요구는? | ms-19 참조 |

> **핵심 직관**: "좋은 모델"이란 가장 정확한 모델이 아니라, **제약 조건 안에서 비즈니스 문제를 가장 잘 해결하는 모델**입니다.

---

## 핵심 정리

1. **ML 필요성 판단이 최우선**: 규칙 기반으로 충분한 문제에 ML을 적용하는 것은 비용 낭비이며, 항상 "ML이 정말 필요한가?"를 먼저 질문해야 합니다.
2. **단순 베이스라인부터 시작**: 다수 클래스 예측, 평균값 예측 등 가장 단순한 모델의 성능을 먼저 확인하고, 복잡한 모델은 이를 유의미하게 이길 때만 채택합니다.
3. **문제 유형을 정확히 분류**: 분류/회귀/클러스터링/생성/랭킹 등 문제 유형에 따라 사용 가능한 모델과 평가 지표가 완전히 달라집니다.
4. **평가 지표는 비즈니스와 연결**: 불균형 데이터에서 accuracy만 보면 함정에 빠지며, 비즈니스 임팩트와 직결되는 지표를 선택해야 합니다.
5. **제약 조건을 미리 파악**: 지연시간, 비용, 해석가능성 등 실전 제약 조건이 모델 선택을 근본적으로 바꿀 수 있으므로, 프로젝트 초기에 확인해야 합니다.
