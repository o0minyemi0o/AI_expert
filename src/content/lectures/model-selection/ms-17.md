# 생성 모델 선택

## 왜 생성 모델 선택 전략이 필요한가

생성 AI는 이미지, 텍스트, 오디오, 비디오 등 다양한 모달리티에서 새로운 콘텐츠를 만들어냅니다. 하지만 "어떤 생성 모델을 써야 하는가?"는 생성 대상의 품질, 다양성, 제어 가능성, 비용에 따라 크게 달라집니다. 확산 모델, GAN, VAE, LLM 각각의 강점을 이해하고, 비용 대비 품질의 최적점을 찾는 것이 실무의 핵심입니다.

---

## 1. 이미지 생성: 확산 모델 vs GAN vs VAE

| 모델 | 생성 품질 | 다양성 | 학습 안정성 | 속도 | 제어 가능성 |
|------|----------|--------|-----------|------|-----------|
| GAN | 매우 높음 | 낮음 (모드 붕괴) | 불안정 | 빠름 | 중간 |
| VAE | 중간 | 높음 | 안정 | 빠름 | 높음 (잠재 공간) |
| 확산 모델 | 매우 높음 | 높음 | 안정 | 매우 느림 | 매우 높음 |

### GAN (Generative Adversarial Network)

### 언제 쓰는가
- 고해상도/고품질 단일 도메인 이미지 (얼굴, 풍경)
- 빠른 추론이 필요할 때 (단일 포워드 패스)
- 이미지 변환 (style transfer, super-resolution)

### 언제 쓰지 않는가
- 다양한 출력이 필요할 때 (모드 붕괴 위험)
- 학습 안정성이 중요할 때
- 텍스트 조건부 생성 (확산 모델이 우세)

### VAE (Variational AutoEncoder)

### 언제 쓰는가
- 의미 있는 잠재 공간이 필요할 때 (보간, 속성 편집)
- 생성과 추론을 동시에 (pt-07 참조)
- 이상 탐지의 생성 모델 구성요소로

### 확산 모델 (Diffusion)

### 언제 쓰는가
- 최고 품질 + 높은 다양성
- 텍스트-이미지 생성 (Stable Diffusion, DALL-E)
- 조건부 생성 (ControlNet 등)
- 이미지 편집 (inpainting, outpainting)

```
이미지 생성 모델 선택 플로우:

목적은?
├── 텍스트 → 이미지 생성
│   └── 확산 모델 (Stable Diffusion, DALL-E)
├── 단일 도메인 고품질 (얼굴 등)
│   └── GAN (StyleGAN)
├── 이미지 변환 (스타일, 해상도)
│   ├── 쌍 데이터 있음 → Pix2Pix (GAN)
│   └── 쌍 데이터 없음 → CycleGAN / 확산 모델
├── 잠재 공간 탐색 (보간, 편집)
│   └── VAE 또는 확산 모델 잠재 공간
└── 데이터 증강 목적
    └── 도메인에 따라: GAN / 확산 모델
```

> **핵심 직관**: 2023년 이후 확산 모델이 대부분의 이미지 생성 과제에서 GAN을 대체했습니다. 하지만 **추론 속도**가 중요하면 여전히 GAN이 유리하며, **잠재 공간 제어**가 중요하면 VAE가 적합합니다.

### 시나리오: 패션 이커머스 상품 이미지 생성

패션 이커머스에서 모델 착용 사진의 배경을 교체하고 다양한 포즈를 합성하려 합니다. 원본 이미지는 스튜디오 촬영 상품 사진 5만 장이며, 목표는 동일 상품을 카페, 거리, 사무실 등 10가지 배경에서 3가지 포즈로 생성하는 것입니다(5만 × 10 × 3 = 150만 장).

기존 이미지를 조건으로 사용하여 제어된 변형을 생성해야 하므로, 확산 모델(ControlNet + IP-Adapter)이 GAN보다 적합합니다. ControlNet은 원본 이미지의 포즈 골격을 조건으로 받아 다른 포즈를 생성하고, IP-Adapter는 상품의 시각적 특성(색상, 질감, 디자인)을 보존하면서 배경을 교체합니다. GAN(Pix2Pix 등)도 가능하지만, 배경과 포즈를 동시에 제어하는 것이 어렵고 모드 붕괴 위험이 있습니다. 확산 모델은 생성 1장당 약 3초(A100 GPU)로 GAN(0.1초)보다 느리지만, 150만 장은 배치 처리로 5일이면 완료됩니다. 품질과 제어 가능성이 속도보다 중요한 이 케이스에서는 확산 모델이 명확한 선택입니다.

---

## 2. 텍스트 생성: LLM 선택

### 모델 크기별 비교

| 모델 규모 | 파라미터 | 적합한 과제 | 비용 | 자체 호스팅 |
|----------|---------|------------|------|-----------|
| 소형 (1~3B) | 1~3B | 분류, 요약 (짧은) | 매우 낮음 | 쉬움 |
| 중형 (7~13B) | 7~13B | QA, 번역, 코드 | 낮음 | 가능 (단일 GPU) |
| 대형 (30~70B) | 30~70B | 복잡한 추론, 긴 생성 | 중간 | 다중 GPU |
| 초대형 (>100B) | 100B+ | 범용 AI, 멀티턴 | 높음 | 클러스터 |

### 오픈소스 vs 클로즈드 API

| 특성 | 오픈소스 (Llama, Mistral) | API (GPT-4, Claude) |
|------|-------------------------|---------------------|
| 비용 | 인프라 비용 (고정) | 토큰당 비용 (변동) |
| 커스터마이즈 | Fine-tuning 가능 | 제한적 |
| 데이터 프라이버시 | 완전 통제 | 제공자 의존 |
| 성능 | 크기에 비례 | 최고 수준 |
| 운영 부담 | 높음 | 없음 |

```
LLM 선택 플로우:

데이터 프라이버시가 중요한가?
├── Yes → 오픈소스 자체 호스팅
│   ├── 단일 GPU → Llama 7B / Mistral 7B
│   ├── 다중 GPU → Llama 70B
│   └── fine-tuning 필요 → LoRA/QLoRA 적용
└── No → 성능 vs 비용
          ├── 최고 성능 필요 → GPT-4 / Claude
          ├── 비용 효율 → GPT-4o-mini / Claude Haiku
          └── 대량 처리 → 배치 API (할인)
```

> **핵심 직관**: "가장 큰 모델 = 가장 좋은 선택"이 아닙니다. 7B 모델을 잘 fine-tuning하면 특정 과제에서 범용 100B+ 모델을 이길 수 있으며, 추론 비용은 1/10 이하입니다.

---

## 3. 오디오/음성 모델

| 과제 | 대표 모델 | 특징 | 적합한 상황 |
|------|----------|------|------------|
| 음성 인식 (STT) | Whisper | 다국어, 오픈소스 | 범용 STT |
| 음성 합성 (TTS) | VITS, Bark, XTTS | 자연스러운 음성 | 서비스 음성 |
| 음악 생성 | MusicGen, Udio | 텍스트→음악 | 배경 음악, 창작 |
| 오디오 분류 | Audio Spectrogram Transformer | 환경 소리 분류 | 모니터링 |

```
오디오 모델 선택:

과제는?
├── 음성 → 텍스트
│   ├── 다국어/범용 → Whisper
│   ├── 한국어 특화 → Whisper + fine-tuning
│   └── 실시간 → Whisper tiny/base
├── 텍스트 → 음성
│   ├── 다국어 → XTTS / Bark
│   └── 고품질 한국어 → 한국어 TTS 모델
├── 음악 생성
│   └── MusicGen (텍스트/멜로디 조건부)
└── 소리 분류/분석
    └── 스펙트로그램 + CNN 또는 AST
```

---

## 4. 비용 대비 품질 의사결정

| 고려 사항 | 질문 | 영향 |
|----------|------|------|
| 생성 품질 | 상용 수준이 필요한가? | 모델 크기/유형 |
| 생성 양 | 하루에 몇 건 생성하는가? | API vs 자체 호스팅 |
| 실시간 여부 | 사용자 응답이 즉시 필요한가? | 모델 크기, 최적화 |
| 제어 가능성 | 출력 스타일/내용 제어가 중요한가? | Fine-tuning 필요성 |
| 법적 이슈 | 저작권, 데이터 규정이 있는가? | 모델 라이선스 |

```
비용 최적화 전략:

생성 빈도는?
├── 저빈도 (일 수백 건)
│   └── API (GPT-4, DALL-E) — 인프라 불필요
├── 중빈도 (일 수천~수만 건)
│   ├── 비용 민감 → 오픈소스 자체 호스팅
│   └── 품질 우선 → API (배치 할인)
└── 고빈도 (일 수십만 건 이상)
    └── 자체 호스팅 + 모델 최적화
        ├── 양자화 (INT8/INT4)
        ├── vLLM / TensorRT-LLM
        └── 작은 fine-tuned 모델
```

> **핵심 직관**: 생성 모델의 실제 비용은 "모델 비용"만이 아닙니다. 인프라 운영, 모니터링, 품질 관리, 안전성 필터링 등 **숨겨진 비용**을 반드시 함께 고려하십시오.

### 시나리오: 고객 서비스 챗봇 구축

중견 이커머스 기업에서 고객 서비스 챗봇을 구축합니다. 도메인 FAQ 3,000건(반품/교환/배송/결제 관련), 월 10만 건 문의, 평균 대화 3턴입니다. 목표는 70%의 문의를 자동 해결하고, 나머지 30%는 상담원에게 전달하는 것입니다.

오픈소스 LLM(Llama 8B) fine-tuning 방식은 GPU 서버 월 $2,000(A100 1대), 초기 fine-tuning $500, 월간 재학습 $200이 소요됩니다. 응답 시간 500ms, 데이터 프라이버시 완전 통제가 장점입니다. 반면 Claude API + RAG 방식은 월 10만 건 × 3턴 × 평균 500토큰 기준 약 $500/월이며, 인프라 관리 불필요, RAG로 FAQ 업데이트가 즉시 반영됩니다. 손익분기점은 월 약 25만 건입니다. 현재 10만 건 규모에서는 API + RAG가 총비용 $500 vs $2,700으로 유리합니다. 다만 문의량이 25만 건을 넘거나 민감한 고객 데이터를 다루는 경우에는 자체 호스팅으로 전환하는 것이 합리적입니다.

---

## 5. 종합 비교

| 모달리티 | 베이스라인 | 고품질 | 최고 품질 |
|---------|----------|--------|----------|
| 이미지 | VAE | Stable Diffusion | DALL-E 3 / Midjourney |
| 텍스트 | GPT-4o-mini | Llama 70B fine-tuned | GPT-4 / Claude Opus |
| 음성 (STT) | Whisper small | Whisper large-v3 | 상용 STT API |
| 음성 (TTS) | gTTS | VITS | XTTS / 상용 TTS |
| 음악 | MusicGen small | MusicGen large | Udio / Suno |

> **핵심 직관**: 생성 모델은 빠르게 발전하므로, **특정 모델에 종속되지 않는 아키텍처**를 설계하는 것이 중요합니다. 모델은 교체 가능하도록 추상화하고, 파이프라인(전처리, 후처리, 안전 필터)은 안정적으로 유지하십시오.

---

## 핵심 정리

1. **확산 모델이 이미지 생성의 새로운 표준**: 품질, 다양성, 제어 가능성에서 GAN과 VAE를 능가하며, Stable Diffusion 등 오픈소스 생태계도 풍부합니다.
2. **LLM 선택은 과제 복잡도 + 비용으로 결정**: 단순 과제에 대형 모델을 쓰는 것은 낭비이며, 소형 모델의 fine-tuning이 더 비용 효율적일 수 있습니다.
3. **오픈소스 vs API는 빈도와 프라이버시로 결정**: 저빈도면 API, 고빈도면 자체 호스팅, 데이터 프라이버시가 중요하면 반드시 자체 호스팅을 선택합니다.
4. **Whisper는 음성 인식의 범용 표준**: 다국어 지원, 오픈소스, fine-tuning 가능으로 대부분의 STT 과제에서 첫 번째 선택입니다.
5. **모델 교체를 전제로 아키텍처를 설계**: 생성 AI 분야는 매우 빠르게 발전하므로, 특정 모델에 종속되지 않고 파이프라인을 모듈화하는 것이 장기적으로 유리합니다.
