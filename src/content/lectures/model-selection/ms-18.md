# 소량 데이터와 Few-shot 전략

## 왜 소량 데이터 전략이 필요한가

실무에서 "데이터가 부족하다"는 가장 흔한 제약 조건입니다. 학술 논문의 벤치마크는 수만~수백만 건의 데이터를 가정하지만, 현실에서는 수십~수백 건의 레이블 데이터로 모델을 만들어야 하는 경우가 대부분입니다. 이때 "데이터를 더 모아야 하는가, 모델을 바꿔야 하는가?"를 판단하는 것이 핵심입니다.

이 강의에서는 소량 데이터에서 최대 성능을 끌어내는 전략들을 비교하고, 각 상황에 맞는 최적 접근법을 제시합니다.

---

## 1. 소량 데이터 전략 스펙트럼

| 전략 | 데이터 요구 | 효과 | 복잡도 | 적합한 상황 |
|------|-----------|------|--------|------------|
| 단순 모델 + 정규화 | 매우 적음 | 중간 | 낮음 | 정형 데이터, 소량 |
| 데이터 증강 | 적음 | 중간~높음 | 중간 | 이미지, 텍스트 |
| 전이 학습 | 적음 | 높음 | 중간 | 비정형 데이터 |
| 능동 학습 | 비레이블 풍부 | 높음 | 중간 | 레이블링 비용 높음 |
| 메타 학습 | 다양한 태스크 | 높음 | 높음 | 여러 관련 태스크 |
| Few-shot 프롬프팅 | 없음~매우 적음 | 중간~높음 | 낮음 | LLM 활용 가능 |

```
소량 데이터 전략 선택 플로우:

데이터 양은?
├── 0 (레이블 없음)
│   ├── LLM 사용 가능 → Zero-shot 프롬프팅
│   └── LLM 불가 → 비지도 학습 / 규칙 기반
├── 1~50건
│   ├── LLM 사용 가능 → Few-shot 프롬프팅
│   └── 비정형 → 사전학습 모델 + 선형 분류기
├── 50~500건
│   ├── 정형 → 단순 모델 (로지스틱, RF 깊이 제한)
│   ├── 이미지 → 사전학습 + fine-tuning (ms-10)
│   └── 텍스트 → BERT + fine-tuning (ms-11)
├── 500~5,000건
│   ├── 데이터 증강 적용
│   ├── 전이 학습 + fine-tuning
│   └── 능동 학습으로 효율적 레이블링
└── 5,000건 이상 → 일반 ML 파이프라인 (ms-08, ms-09)
```

---

## 2. 전이 학습: 사전학습 모델 활용

### 핵심 아이디어

대규모 데이터로 학습된 모델의 지식을 소량 데이터의 타겟 과제에 전이합니다.

| 모달리티 | 사전학습 소스 | 전이 전략 | 참조 |
|---------|-------------|----------|------|
| 이미지 | ImageNet (1.4M장) | Feature extraction / Fine-tuning | ms-10 |
| 텍스트 | 대규모 코퍼스 | BERT fine-tuning / Prompt | ms-11 |
| 음성 | 대규모 오디오 | Whisper fine-tuning | ms-17 |
| 정형 | (제한적) | TabNet self-supervised | ms-08 |

### 도메인 간 전이 가능성

| 소스 → 타겟 | 전이 효과 | 전략 |
|------------|----------|------|
| ImageNet → 일반 사진 | 매우 높음 | Feature extraction만으로 충분 |
| ImageNet → 의료 영상 | 중간 | Fine-tuning 필요 |
| ImageNet → 위성 영상 | 낮음~중간 | 깊은 fine-tuning 또는 도메인 사전학습 |
| BERT → 일반 NLP | 높음 | 소량 fine-tuning |
| BERT → 법률/의료 텍스트 | 중간 | 도메인 사전학습 후 fine-tuning |

> **핵심 직관**: 전이 학습의 효과는 **소스와 타겟 도메인의 유사성**에 비례합니다. 도메인이 매우 다르면 전이 효과가 떨어지지만, 그래도 랜덤 초기화보다는 거의 항상 낫습니다.

### 시나리오: 희귀 질환 X선 진단

대학 병원에서 희귀 폐 질환의 X선 자동 진단 시스템을 개발합니다. 해당 질환 X선 영상은 200장뿐이지만, 정상 X선은 1만 장 확보되어 있습니다. 이미지 크기는 512×512 픽셀, 1채널(그레이스케일)입니다.

200장의 희귀 질환 데이터로 모델을 처음부터 학습하면 심각한 과적합이 발생합니다. 대신 ImageNet 사전학습 ResNet-50을 backbone으로 사용하고, 마지막 분류 레이어만 교체하여 fine-tuning합니다. 강한 데이터 증강(회전 ±15도, 수평 반전, 밝기/대비 변조, 랜덤 크롭)으로 학습 데이터를 실질적으로 5~10배 확장합니다. 1만:200의 극심한 불균형은 Focal Loss(gamma=2)로 대응하여 소수 클래스에 더 큰 가중치를 부여합니다. 이 조합으로 Sensitivity(재현율) 85%, Specificity 90%를 달성할 수 있으며, 이는 스크리닝 도구로서 전문의의 1차 판독을 보조하기에 충분한 수준입니다.

---

## 3. 데이터 증강

### 모달리티별 증강 기법

| 모달리티 | 기법 | 효과 | 주의점 |
|---------|------|------|--------|
| 이미지 | 회전, 뒤집기, CutMix | 높음 | 의미 보존 확인 (ms-10) |
| 텍스트 | 역번역, 동의어 대체, LLM 생성 | 중간~높음 | 라벨 보존 확인 |
| 정형 | SMOTE, 노이즈 추가 | 낮음~중간 | 과적합 위험 |
| 오디오 | 속도 변환, 피치 변환, 노이즈 | 높음 | 발화 내용 보존 |

```python
# 텍스트 데이터 증강 예시
import random

def text_augmentation(text, aug_type='synonym'):
    """간단한 텍스트 증강 (실전에서는 nlpaug 라이브러리 권장)"""
    words = text.split()

    if aug_type == 'deletion':
        # 랜덤 단어 삭제 (10%)
        n_delete = max(1, int(len(words) * 0.1))
        indices = random.sample(range(len(words)), n_delete)
        return ' '.join(w for i, w in enumerate(words) if i not in indices)

    elif aug_type == 'swap':
        # 인접 단어 교환
        if len(words) < 2:
            return text
        idx = random.randint(0, len(words) - 2)
        words[idx], words[idx+1] = words[idx+1], words[idx]
        return ' '.join(words)

    return text

original = "이 영화는 정말 재미있고 감동적이었습니다"
print(f"원본: {original}")
print(f"삭제: {text_augmentation(original, 'deletion')}")
print(f"교환: {text_augmentation(original, 'swap')}")

# LLM을 활용한 텍스트 증강 (의사코드)
# augmented = llm.generate(
#     f"다음 문장을 같은 의미로 다르게 표현해주세요: {original}"
# )
```

> **핵심 직관**: 데이터 증강은 "무료 데이터"가 아닙니다. 증강된 데이터가 원본 분포와 너무 다르면 오히려 성능이 떨어집니다. 특히 정형 데이터에서의 증강(SMOTE 등)은 효과가 제한적입니다.

---

## 4. 능동 학습 (Active Learning)

### 핵심 아이디어

모델이 **가장 불확실한 데이터**를 선별하여 전문가에게 레이블링을 요청합니다. 같은 수의 레이블로 더 높은 성능을 달성합니다.

| 전략 | 원리 | 장점 | 단점 |
|------|------|------|------|
| 불확실성 샘플링 | 예측 확률이 0.5에 가까운 것 | 단순, 효과적 | 로컬 최적 |
| 다양성 샘플링 | 다양한 영역의 데이터 선택 | 탐색적 | 불확실성 무시 |
| 혼합 (Hybrid) | 불확실 + 다양 결합 | 균형 | 복잡 |
| 배치 능동 학습 | 한 번에 여러 개 선택 | 효율적 | 중복 가능 |

```
능동 학습 적용 플로우:

비레이블 데이터가 풍부한가?
├── No → 데이터 수집부터
└── Yes → 레이블링 비용이 높은가?
          ├── No → 그냥 전부 레이블링
          └── Yes → 능동 학습 적용
                    ├── Step 1: 소량 초기 레이블로 모델 학습
                    ├── Step 2: 모델이 불확실한 샘플 선별
                    ├── Step 3: 전문가가 선별된 샘플 레이블링
                    ├── Step 4: 모델 재학습
                    └── Step 5: 목표 성능 도달까지 반복
```

```python
from sklearn.linear_model import LogisticRegression
from sklearn.datasets import make_classification
import numpy as np

np.random.seed(42)
X, y = make_classification(n_samples=1000, n_features=20, random_state=42)

# 능동 학습 시뮬레이션
labeled_idx = list(np.random.choice(1000, 20, replace=False))  # 초기 20개
unlabeled_idx = [i for i in range(1000) if i not in labeled_idx]

for iteration in range(5):
    model = LogisticRegression(max_iter=1000)
    model.fit(X[labeled_idx], y[labeled_idx])

    # 불확실성 기반 샘플 선택
    probs = model.predict_proba(X[unlabeled_idx])
    uncertainty = 1 - np.max(probs, axis=1)  # 가장 불확실한 것
    top_uncertain = np.argsort(uncertainty)[-10:]  # 상위 10개

    # 레이블링 (시뮬레이션에서는 이미 알고 있는 y 사용)
    new_labeled = [unlabeled_idx[i] for i in top_uncertain]
    labeled_idx.extend(new_labeled)
    unlabeled_idx = [i for i in unlabeled_idx if i not in new_labeled]

    acc = model.score(X, y)
    print(f"반복 {iteration+1}: 레이블 {len(labeled_idx)}개, 정확도 {acc:.3f}")
```

> **핵심 직관**: 능동 학습은 **레이블링 비용이 높을 때** 가장 가치 있습니다. 의료 영상 판독, 법률 문서 분류 등 전문가 레이블링이 필요한 도메인에서 랜덤 샘플링 대비 2~5배 효율적입니다.

### 시나리오: 신규 제조 공정 불량 예측

반도체 공장에서 새로운 제조 공정이 도입되어 양산 전 단계입니다. 현재까지 수집된 데이터는 50건뿐이며, 피처는 온도, 압력, 가스 유량, 공정 시간 등 센서 데이터 25개입니다. 불량률은 약 8%(50건 중 4건 불량)입니다.

50건으로는 어떤 복잡한 모델도 의미 있는 학습이 불가능합니다. 능동 학습을 적용하여 효율적으로 데이터를 축적합니다. 먼저 50건으로 간단한 로지스틱 회귀를 학습하고, 모델이 예측 확률 0.3~0.7 구간(가장 불확실한 영역)에 해당하는 웨이퍼를 우선적으로 검사원에게 전수 검사를 요청합니다. 랜덤 검사 대비 2~3배 빠르게 정보량이 높은 샘플이 축적됩니다. 100건에 도달하면 피처 25개에 적합한 Random Forest(max_depth=5, n_estimators=50)로 전환합니다. 트리 깊이를 제한하여 과적합을 방지하고, 피처 중요도 분석으로 불량에 가장 영향이 큰 공정 변수 5개를 식별하여 공정 엔지니어에게 피드백합니다.

---

## 5. 데이터를 더 모아야 하는가 vs 모델을 바꿔야 하는가

```
판단 플로우:

현재 성능이 부족한가?
├── 학습 데이터에서도 낮은 성능 (과소적합)
│   ├── 피처 부족? → 피처 엔지니어링 (ms-06)
│   ├── 모델 용량 부족? → 더 복잡한 모델 시도
│   └── 데이터 노이즈? → 데이터 품질 개선
├── 학습은 높고 검증은 낮음 (과적합)
│   ├── 정규화 강화 (L1/L2, 드롭아웃)
│   ├── 데이터 증강
│   └── 데이터를 더 모은다 (가장 효과적)
└── 양쪽 모두 적절하지만 비즈니스 요구 미달
    └── 데이터를 더 모으거나, 문제를 재정의
```

| 증상 | 원인 | 해결책 |
|------|------|--------|
| 학습/검증 모두 낮음 | 과소적합 | 더 복잡한 모델, 더 좋은 피처 |
| 학습 높고 검증 낮음 | 과적합 | 더 많은 데이터, 정규화 |
| 성능 정체 | 데이터 한계 | 데이터 수집, 문제 재정의 |
| 특정 클래스만 낮음 | 클래스 불균형 | 해당 클래스 데이터 추가 |

> **핵심 직관**: **학습 곡선(learning curve)**을 그려보면 답이 보입니다. 데이터가 늘어도 검증 성능이 정체되면 모델/피처를 바꿔야 하고, 아직 상승 중이면 데이터를 더 모아야 합니다.

```python
from sklearn.model_selection import learning_curve
from sklearn.ensemble import RandomForestClassifier
import numpy as np

# 학습 곡선으로 데이터 추가 효과 판단
# X, y = ... (데이터)
# train_sizes, train_scores, val_scores = learning_curve(
#     RandomForestClassifier(n_estimators=100),
#     X, y, cv=5,
#     train_sizes=np.linspace(0.1, 1.0, 10),
#     scoring='f1'
# )
# 그래프에서:
# - val_scores가 아직 상승 중 → 데이터 추가 효과 있음
# - val_scores가 정체 → 모델/피처 변경 필요
# - train과 val 간격이 큼 → 과적합, 정규화 또는 데이터 추가
```

---

## 핵심 정리

1. **전이 학습은 소량 데이터의 가장 강력한 무기**: 이미지(ImageNet), 텍스트(BERT/GPT)에서 사전학습 모델을 활용하면 수십~수백 건으로도 의미 있는 성능을 달성합니다.
2. **데이터 증강은 모달리티에 따라 효과가 다르다**: 이미지에서는 매우 효과적이지만, 정형 데이터에서는 제한적이며, 텍스트에서는 LLM 기반 증강이 최근 가장 효과적입니다.
3. **능동 학습은 레이블링 비용이 높을 때 필수**: 모델이 불확실한 데이터를 선별하여 전문가에게 질문함으로써, 같은 레이블 수로 2~5배 높은 효율을 달성합니다.
4. **학습 곡선으로 데이터 추가 vs 모델 변경 판단**: 검증 성능이 데이터 증가와 함께 상승 중이면 데이터 추가가 효과적이고, 정체되면 모델이나 피처를 바꿔야 합니다.
5. **Few-shot 프롬프팅은 레이블 데이터 없이 시작 가능**: LLM에 몇 개의 예시를 제공하는 것만으로 빠르게 프로토타입할 수 있으며, 이후 fine-tuning으로 전환하는 전략이 효율적입니다.
