# 그래프 데이터와 GNN

## 왜 그래프 데이터 접근법을 알아야 하는가

소셜 네트워크, 분자 구조, 지식 그래프, 공급망, 사기 탐지 네트워크 등 현실 세계의 많은 데이터는 본질적으로 그래프 구조를 가집니다. 노드 간의 관계가 핵심 정보이므로, 이를 무시하고 정형 데이터 모델을 적용하면 중요한 패턴을 놓칩니다. 하지만 GNN(Graph Neural Network)이 항상 필요한 것은 아닙니다. 전통적 그래프 특성 + ML이 더 효율적인 경우도 많습니다.

이 강의에서는 그래프 데이터의 접근법을 비교하고, GNN이 필수인 경우와 과도한 경우를 구분합니다.

---

## 1. 그래프 문제 유형

| 과제 | 설명 | 예시 |
|------|------|------|
| 노드 분류 | 노드의 카테고리 예측 | 사용자 유형 분류, 논문 주제 분류 |
| 링크 예측 | 노드 간 연결 존재 여부 예측 | 친구 추천, 약물-타겟 상호작용 |
| 그래프 분류 | 전체 그래프의 카테고리 예측 | 분자 독성 예측, 단백질 기능 |
| 커뮤니티 탐지 | 밀집 하위 그래프 발견 | 소셜 커뮤니티, 사기 집단 |
| 노드 임베딩 | 노드의 벡터 표현 학습 | 추천, 유사 노드 검색 |

---

## 2. 전통 그래프 특성 + ML

GNN을 사용하기 전에, 그래프 구조에서 피처를 추출하여 전통적 ML 모델에 입력하는 접근법입니다.

### 주요 그래프 특성

| 특성 | 설명 | 계산 복잡도 |
|------|------|-----------|
| Degree | 연결 수 | $O(n)$ |
| Clustering coefficient | 이웃 간 연결 밀도 | $O(n \cdot d^2)$ |
| Betweenness centrality | 최단 경로 매개 정도 | $O(n \cdot m)$ |
| PageRank | 재귀적 중요도 | $O(m \cdot k)$ (반복 $k$) |
| Community membership | 소속 커뮤니티 | 알고리즘 의존 |

### 언제 전통 특성 + ML로 충분한가
- 그래프 구조가 단순하고 노드 수가 적을 때
- 명확한 그래프 지표(degree, centrality)가 과제와 직접 관련될 때
- 해석가능성이 중요할 때

### 언제 부족한가
- 이웃의 피처 정보가 중요할 때
- 다중 홉(multi-hop) 정보가 필요할 때
- 그래프 구조가 동적으로 변할 때

```python
import networkx as nx
import numpy as np
from sklearn.ensemble import RandomForestClassifier

# 그래프 생성 및 피처 추출
G = nx.karate_club_graph()

# 노드 피처 추출
features = []
for node in G.nodes():
    features.append({
        'degree': G.degree(node),
        'clustering': nx.clustering(G, node),
        'betweenness': nx.betweenness_centrality(G)[node],
        'pagerank': nx.pagerank(G)[node],
        'closeness': nx.closeness_centrality(G)[node],
    })

import pandas as pd
df = pd.DataFrame(features)
labels = [G.nodes[n]['club'] == 'Mr. Hi' for n in G.nodes()]

# Random Forest로 노드 분류
rf = RandomForestClassifier(n_estimators=100, random_state=42)
# 소규모이므로 전체 학습 (실전에서는 train/test 분할)
rf.fit(df, labels)
print(f"Feature importances: {dict(zip(df.columns, rf.feature_importances_.round(3)))}")
```

> **핵심 직관**: 많은 그래프 문제에서 degree, PageRank 등 **수작업 그래프 피처 + XGBoost**가 GNN과 비슷하거나 더 나은 성능을 보입니다. GNN을 시도하기 전에 항상 이 베이스라인을 먼저 구축하십시오.

### 시나리오: SNS 친구 추천

대규모 SNS 플랫폼에서 친구 추천 기능을 구축합니다. 데이터는 1억 유저 노드, 50억 팔로우 엣지로 구성된 방향 그래프이며, 유저별 피처로 가입일, 활동 빈도, 관심사 태그 등 10개가 있습니다. 목표는 팔로우할 가능성이 높은 유저 상위 10명을 추천하는 것입니다.

1억 노드 그래프에서 GNN(GraphSAGE)을 실시간 추론에 사용하면 이웃 샘플링과 다중 홉 집약에 수백ms가 소요되어 서빙 지연이 큽니다. 대신 Node2Vec으로 유저 임베딩(128차원)을 사전 계산하고, 코사인 유사도 기반으로 추천하는 방식이 실용적입니다. Node2Vec은 랜덤 워크로 그래프 구조를 반영한 임베딩을 생성하며, 사전 계산된 임베딩은 FAISS로 밀리초 단위 검색이 가능합니다. GNN은 매일 배치로 임베딩을 업데이트하는 오프라인 파이프라인에서 활용하고, 실시간 서빙은 사전 계산 임베딩으로 처리하는 것이 최적의 아키텍처입니다.

---

## 3. GNN 모델 비교

### 주요 GNN 아키텍처

| 모델 | 메시지 전달 방식 | 특징 | 적합한 상황 |
|------|---------------|------|------------|
| GCN | 이웃 피처 평균 | 단순, 빠름 | 동질적 그래프 |
| GAT | 어텐션 가중 평균 | 이웃 중요도 학습 | 이질적 이웃 |
| GraphSAGE | 이웃 샘플링 + 집약 | 대규모 확장 가능 | 대규모 그래프 |
| GIN | 합(sum) 집약 | 이론적 표현력 최고 | 그래프 분류 |

```
GNN 모델 선택 플로우:

과제 유형은?
├── 노드 분류
│   ├── 그래프 크기 < 100K 노드 → GCN 또는 GAT
│   └── 그래프 크기 > 100K 노드 → GraphSAGE (미니배치)
├── 링크 예측
│   └── 노드 임베딩 학습 후 내적/MLP → GCN/GAT
├── 그래프 분류
│   └── GIN + 글로벌 풀링
└── 동적 그래프
    └── Temporal GNN (TGN, DyRep)
```

### GNN의 핵심: 메시지 전달

각 노드는 이웃의 피처를 **집약(aggregate)**하여 자신의 표현을 업데이트합니다:

$$\mathbf{h}_v^{(l+1)} = \text{UPDATE}\left(\mathbf{h}_v^{(l)}, \text{AGG}\left(\{\mathbf{h}_u^{(l)} : u \in \mathcal{N}(v)\}\right)\right)$$

여기서 $\mathcal{N}(v)$는 노드 $v$의 이웃, $l$은 레이어 번호입니다 (la-03, dl-08 참조).

> **핵심 직관**: GNN의 레이어 수는 "몇 홉의 이웃 정보를 사용하는가"를 결정합니다. 보통 2~3 레이어가 최적이며, 너무 깊으면 **과도한 평활화(over-smoothing)**로 모든 노드가 비슷해집니다.

---

## 4. 사례별 접근

### 소셜 네트워크

| 과제 | 추천 접근법 | 이유 |
|------|-----------|------|
| 영향력 분석 | PageRank + ML | 중심성 지표가 직접적 |
| 커뮤니티 탐지 | Louvain / Label Propagation | 전통 알고리즘 우수 |
| 사기 네트워크 | GNN + 행동 피처 | 이웃 패턴이 핵심 |
| 친구 추천 | GraphSAGE (링크 예측) | 대규모 확장 필요 |

### 분자 구조

| 과제 | 추천 접근법 | 이유 |
|------|-----------|------|
| 독성 예측 | GIN + 분자 피처 | 그래프 분류 |
| 약물 상호작용 | GAT (링크 예측) | 이질적 관계 |
| 분자 성질 | 분자 지문 + RF → GNN | 전통 방법 먼저 시도 |

### 지식 그래프

| 과제 | 추천 접근법 | 이유 |
|------|-----------|------|
| 엔티티 분류 | R-GCN | 관계 유형 고려 |
| 관계 예측 | TransE / RotatE | 임베딩 기반 |
| QA | RAG + 그래프 탐색 | ms-16 참조 |

---

## 5. GNN이 과도한 경우 vs 필수인 경우

```
GNN 필요성 판단 플로우:

그래프 구조가 과제에 중요한가?
├── No → 정형 ML로 충분 (노드 피처만 사용)
│         예: 사용자 속성으로 분류 (관계 무관)
└── Yes → 이웃 피처가 중요한가?
          ├── No → 그래프 통계 + ML
          │         예: degree, centrality로 충분
          └── Yes → GNN 필요
                    ├── 소규모 (<100K) → GCN, GAT
                    └── 대규모 (>100K) → GraphSAGE
                          └── 분산 처리 필요 → DGL, PyG 클러스터
```

| 상황 | GNN 필요 여부 | 대안 |
|------|-------------|------|
| 노드 피처만으로 분류 가능 | 불필요 | XGBoost + 노드 피처 |
| degree 등 통계로 충분 | 불필요 | 그래프 통계 + ML |
| 이웃의 피처 정보가 핵심 | 필요 | GCN / GAT |
| 다중 홉 패턴이 중요 | 필요 | 2-3 레이어 GNN |
| 매우 큰 그래프 | 필요 (확장형) | GraphSAGE + 미니배치 |
| 동적 그래프 | 필요 (특수) | Temporal GNN |

> **핵심 직관**: GNN의 진정한 가치는 **이웃의 피처 정보를 활용**하는 데 있습니다. 그래프 구조만 중요하다면 전통적 그래프 알고리즘이, 노드 피처만 중요하다면 정형 ML이 더 효율적입니다.

### 시나리오: 신약 후보 물질 독성 예측

제약사에서 신약 후보 물질의 간 독성을 사전 예측하려 합니다. 데이터는 10,000개 분자 구조이며, 각 분자는 그래프로 표현됩니다(원자=노드, 화학 결합=엣지). 분자당 평균 30개 노드(원자), 35개 엣지(결합)이며, 노드 피처는 원자 번호, 전하, 혼성 궤도 등 9개, 엣지 피처는 결합 유형, 결합 차수 등 3개입니다. 레이블은 독성(1)/비독성(0) 이진 분류입니다.

분자의 독성은 특정 원자가 아니라 원자들의 연결 구조(작용기, 고리 구조)에 의해 결정되므로, 구조 정보를 직접 활용하는 GNN이 필수적인 케이스입니다. GCN이나 GAT로 각 원자가 이웃 원자의 정보를 집약하고, 글로벌 풀링으로 분자 전체의 표현을 생성한 후 이진 분류합니다. 전통적인 분자 지문(molecular fingerprint) + Random Forest 대비 GNN(GIN)은 AUROC에서 5~8% 향상을 보이며, 특히 복잡한 구조의 분자에서 차이가 큽니다.

```python
# PyTorch Geometric 예시 (개념 코드)
# pip install torch-geometric
"""
import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv

class GCN(torch.nn.Module):
    def __init__(self, in_channels, hidden_channels, out_channels):
        super().__init__()
        self.conv1 = GCNConv(in_channels, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, out_channels)

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.conv2(x, edge_index)
        return F.log_softmax(x, dim=1)

# GCN 2레이어: 2홉 이웃 정보 활용
# over-smoothing 방지를 위해 2~3 레이어가 최적
"""
```

---

## 핵심 정리

1. **GNN 전에 그래프 피처 + ML 베이스라인 구축**: degree, centrality, PageRank 등 전통 그래프 지표를 피처로 사용하면 많은 과제에서 GNN과 비슷한 성능을 얻을 수 있습니다.
2. **GNN은 이웃의 피처 정보가 핵심일 때만 필요**: 그래프 구조만 중요하면 전통 알고리즘이, 노드 피처만 중요하면 정형 ML이 더 효율적입니다.
3. **GNN 레이어는 2~3개가 최적**: 레이어가 깊어지면 over-smoothing으로 노드 표현이 구분 불가능해지므로, 적은 레이어에서 시작해야 합니다.
4. **대규모 그래프에는 GraphSAGE**: 미니배치 학습이 가능하여 수백만 노드 그래프에도 적용할 수 있으며, 새로운 노드에 대한 인덕티브 학습이 가능합니다.
5. **도메인별 최적 접근이 다르다**: 소셜 네트워크에서는 커뮤니티 탐지 알고리즘이, 분자 구조에서는 GIN이, 지식 그래프에서는 TransE가 각각 강점을 가집니다.
