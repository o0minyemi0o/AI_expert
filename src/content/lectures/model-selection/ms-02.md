# 회귀 문제의 모델 선택

## 왜 회귀 모델 선택이 중요한가

회귀 문제는 연속 값을 예측하는 가장 기본적인 ML 과제입니다. 주택 가격, 매출 예측, 센서 값 추정 등 실무에서 가장 빈번하게 마주치는 문제 유형이지만, "어떤 회귀 모델을 써야 하는가?"에 대한 체계적 가이드는 부족합니다. 데이터의 크기, 비선형성, 해석가능성 요구에 따라 최적의 모델이 완전히 달라집니다.

이 강의에서는 선형 모델부터 신경망까지, 각 회귀 모델의 적합한 상황과 선택 기준을 비교합니다.

---

## 1. 선형 계열 회귀 모델

### 선형 회귀 (Ordinary Least Squares)

손실 함수: $\min_{\mathbf{w}} \| \mathbf{X}\mathbf{w} - \mathbf{y} \|_2^2$

### 언제 쓰는가
- 피처와 타겟의 관계가 선형에 가까울 때
- 해석가능성이 중요할 때 (계수의 의미 해석)
- 피처 수가 샘플 수보다 적을 때 ($p < n$)

### 언제 쓰지 않는가
- 비선형 관계가 강할 때
- 피처 간 다중공선성이 심할 때 (la-10 참조)
- 피처 수가 샘플 수보다 많을 때 ($p > n$)

### 정규화 회귀: Ridge, Lasso, ElasticNet

| 모델 | 정규화 | 수식 | 특징 | 적합한 상황 |
|------|--------|------|------|------------|
| Ridge | $L_2$ | $\|\mathbf{w}\|_2^2$ | 계수 축소, 변수 유지 | 다중공선성 존재 |
| Lasso | $L_1$ | $\|\mathbf{w}\|_1$ | 희소 해, 변수 선택 | 피처 선택이 필요할 때 |
| ElasticNet | $L_1 + L_2$ | $\alpha\|\mathbf{w}\|_1 + (1-\alpha)\|\mathbf{w}\|_2^2$ | 두 장점 결합 | 상관된 피처 그룹 |

> **핵심 직관**: 피처가 많고 어떤 것이 중요한지 모를 때는 Lasso로 시작하고, 피처 간 상관이 높으면 ElasticNet을 사용하십시오. Ridge는 "모든 피처가 조금씩 기여한다"고 믿을 때 적합합니다.

### 시나리오: 서울 아파트 실거래가 예측

부동산 스타트업이 서울 아파트 실거래가를 예측하는 서비스를 만들려 합니다. 데이터는 국토교통부 실거래가 공개 데이터 50만 건이며, 전용면적, 층수, 역세권 거리, 학군 점수, 건축년도, 동별 평균 소득, 공원 접근성 등 20개 피처를 포함합니다. 타겟은 실거래가(연속 값)입니다.

먼저 Ridge 회귀로 베이스라인을 구축합니다. 면적과 가격의 관계가 대체로 선형이므로 Ridge만으로도 $R^2$ 0.75 이상을 달성할 수 있습니다. 하지만 "오래된 건물인데 역세권"처럼 피처 간 상호작용이 가격에 큰 영향을 미치므로, XGBoost로 확장하면 $R^2$ 0.88 이상으로 개선됩니다. 최종적으로 Ridge(해석용) + XGBoost(예측용) 두 모델을 병행하는 것이 실무적 전략입니다.

### 시나리오: 반도체 공장 수율(yield) 예측

반도체 팹(fab)에서 웨이퍼 수율을 예측하려 합니다. 데이터는 공정 센서에서 수집한 300개 피처(온도, 압력, 가스 유량, 진동 등)와 5,000건의 웨이퍼 수율 기록입니다. 전형적인 고차원 + 소량 데이터($p \gg n$) 상황입니다.

이 경우 Lasso가 유리합니다. 300개 센서 중 실제로 수율에 영향을 미치는 것은 20~30개 정도이므로, Lasso의 $L_1$ 정규화가 불필요한 피처의 계수를 0으로 만들어 자동 변수 선택 효과를 제공합니다. OLS는 $p > n$일 때 풀 수조차 없고, Ridge는 모든 변수를 유지하므로 해석이 어렵습니다. 엔지니어가 "어떤 센서가 수율에 영향을 주는가?"를 알아야 하므로, Lasso의 희소 해가 비즈니스 가치까지 제공합니다.

```python
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.model_selection import cross_val_score
from sklearn.datasets import make_regression

X, y = make_regression(n_samples=500, n_features=50,
                        n_informative=10, noise=10, random_state=42)

models = {
    'LinearRegression': LinearRegression(),
    'Ridge(alpha=1)': Ridge(alpha=1.0),
    'Lasso(alpha=0.1)': Lasso(alpha=0.1),
    'ElasticNet(alpha=0.1)': ElasticNet(alpha=0.1, l1_ratio=0.5),
}

for name, model in models.items():
    scores = cross_val_score(model, X, y, cv=5, scoring='r2')
    print(f"{name:25s} R²: {scores.mean():.3f} ± {scores.std():.3f}")
```

---

## 2. 비선형 회귀 모델

### 다항 회귀

선형 모델에 다항 피처를 추가하여 비선형 관계를 포착합니다. 차수가 높아지면 과적합 위험이 급격히 증가합니다 (co-05, co-06 참조).

### 결정 트리 / Random Forest 회귀

| 모델 | 장점 | 단점 | 적합한 상황 |
|------|------|------|------------|
| 결정 트리 | 해석 용이, 비선형 포착 | 과적합, 불안정 | 해석이 필요한 비선형 문제 |
| Random Forest | 안정적, 과적합 감소 | 외삽 불가, 느림 | 중간 규모 정형 데이터 |
| Gradient Boosting | 높은 정확도 | 튜닝 필요 | 대회, 성능 극대화 |

```
비선형성 판별 플로우:

잔차 플롯에서 패턴이 보이는가?
├── No → 선형 모델로 충분
└── Yes → 비선형성의 형태는?
          ├── 단순 곡선 → 다항 회귀 (degree=2~3)
          ├── 복잡한 상호작용 → 트리 기반 모델
          └── 매우 복잡한 패턴 → 신경망 고려
```

> **핵심 직관**: 트리 기반 모델은 **외삽(extrapolation)이 불가능**합니다. 학습 데이터 범위 밖의 값을 예측해야 한다면 선형 모델이나 신경망을 고려하십시오.

---

## 3. 고급 회귀: 신경망

### 언제 신경망 회귀가 필요한가
- 피처 수가 수백 이상이고 복잡한 상호작용이 존재할 때
- 정형 + 비정형 데이터를 함께 사용할 때 (멀티모달)
- 데이터가 수만 건 이상으로 충분할 때

### 언제 쓰지 않는가
- 데이터가 수천 건 이하일 때 (트리 모델이 우세)
- 해석가능성이 필수인 규제 산업
- 빠른 프로토타이핑이 목적일 때

```python
import torch
import torch.nn as nn

# 간단한 회귀 신경망
class RegressionNet(nn.Module):
    def __init__(self, input_dim):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, 128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 1)
        )

    def forward(self, x):
        return self.net(x)

# 신경망은 데이터가 충분하고
# 복잡한 비선형 관계가 있을 때만 선형/트리 모델을 이깁니다
```

---

## 4. 종합 선택 가이드

```
회귀 모델 선택 플로우:

데이터 크기는?
├── < 1,000 샘플
│   ├── 선형 관계 → Ridge / Lasso
│   └── 비선형 관계 → Random Forest (깊이 제한)
├── 1,000 ~ 100,000 샘플
│   ├── 해석 필요 → Ridge/Lasso + 피처 중요도
│   ├── 성능 우선 → XGBoost / LightGBM
│   └── 외삽 필요 → 선형 모델 + 비선형 피처
└── > 100,000 샘플
    ├── 정형 데이터만 → XGBoost / LightGBM
    ├── 비정형 포함 → 신경망 (dl-01 참조)
    └── 실시간 필요 → 선형 모델 (ms-19 참조)
```

| 기준 | 선형 회귀 | Ridge/Lasso | Random Forest | XGBoost | 신경망 |
|------|----------|-------------|---------------|---------|--------|
| 해석가능성 | 매우 높음 | 높음 | 중간 | 낮음 | 매우 낮음 |
| 비선형 포착 | 불가 | 불가 | 우수 | 우수 | 매우 우수 |
| 학습 속도 | 매우 빠름 | 빠름 | 중간 | 중간 | 느림 |
| 소량 데이터 | 적합 | 적합 | 주의 필요 | 주의 필요 | 부적합 |
| 외삽 능력 | 우수 | 우수 | 불가 | 불가 | 제한적 |

> **핵심 직관**: 실무에서 회귀 문제의 80%는 Ridge/Lasso나 XGBoost로 해결됩니다. 신경망은 정형 데이터 단독 회귀에서는 거의 이점이 없습니다 (ms-08 참조).

---

## 5. 평가 지표 선택

| 지표 | 수식 | 특징 | 사용 상황 |
|------|------|------|----------|
| MSE | $\frac{1}{n}\sum(y_i - \hat{y}_i)^2$ | 큰 오차에 민감 | 큰 오차가 치명적일 때 |
| MAE | $\frac{1}{n}\sum\|y_i - \hat{y}_i\|$ | 이상치에 강건 | 이상치가 많을 때 |
| $R^2$ | $1 - \frac{SS_{res}}{SS_{tot}}$ | 설명력 비율 | 모델 비교 시 |
| MAPE | $\frac{1}{n}\sum\|\frac{y_i - \hat{y}_i}{y_i}\|$ | 비율 오차 | 스케일이 다른 비교 |

```python
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

y_true = np.array([3.0, 5.0, 2.5, 7.0, 4.5])
y_pred = np.array([2.8, 5.2, 2.0, 7.5, 4.0])

print(f"MSE:  {mean_squared_error(y_true, y_pred):.4f}")
print(f"RMSE: {np.sqrt(mean_squared_error(y_true, y_pred)):.4f}")
print(f"MAE:  {mean_absolute_error(y_true, y_pred):.4f}")
print(f"R²:   {r2_score(y_true, y_pred):.4f}")
```

> **핵심 직관**: 이상치가 많은 데이터에서는 MSE 대신 MAE를, 비율 오차가 중요한 비즈니스(매출 예측 등)에서는 MAPE를 사용하십시오.

---

## 핵심 정리

1. **선형 관계가 있고 해석이 필요하면 Ridge/Lasso부터 시작**: 정규화된 선형 모델은 빠르고, 해석 가능하며, 소량 데이터에서도 안정적입니다.
2. **비선형 관계가 있으면 트리 기반 모델**: Random Forest와 XGBoost는 피처 상호작용을 자동으로 포착하며, 정형 데이터에서 가장 강력합니다.
3. **트리 모델은 외삽이 불가능**: 학습 데이터 범위 밖의 예측이 필요하다면 선형 모델을 포함시켜야 합니다.
4. **신경망 회귀는 대부분 불필요**: 정형 데이터만 사용하는 회귀에서 신경망이 트리 모델을 이기는 경우는 드물며, 멀티모달이나 초대규모 데이터에서만 고려합니다.
5. **평가 지표를 비즈니스 맥락에 맞게 선택**: MSE, MAE, MAPE 각각의 특성을 이해하고, 비즈니스에서 어떤 종류의 오차가 더 치명적인지에 따라 지표를 결정합니다.
