# 정형 데이터 실전 파이프라인

## 왜 실전 파이프라인을 체계적으로 구축해야 하는가

모델 선택만큼 중요한 것이 **데이터 전처리 파이프라인**입니다. 실무에서 ML 프로젝트 시간의 70~80%는 데이터 정제, 결측치 처리, 피처 인코딩, 불균형 처리 등 전처리에 소비됩니다. 같은 모델이라도 전처리 전략에 따라 성능이 크게 달라지며, 잘못된 전처리는 데이터 누출(data leakage)로 이어져 실전에서 모델이 무용지물이 될 수 있습니다.

이 강의에서는 정형 데이터의 핵심 전처리 전략과 하이퍼파라미터 튜닝 방법을 비교합니다.

---

## 1. 결측치 처리 전략

| 전략 | 방법 | 장점 | 단점 | 적합한 상황 |
|------|------|------|------|------------|
| 삭제 | 행/열 제거 | 단순 | 정보 손실 | 결측 비율 < 5% |
| 대체 (평균/중앙값) | 통계량으로 채움 | 빠름 | 분포 왜곡 | MCAR 가정 시 |
| 대체 (최빈값) | 범주형 결측 | 빠름 | 빈도 편향 | 범주형 피처 |
| 모델 기반 | KNN, MICE | 관계 보존 | 느림, 복잡 | 결측 비율 높을 때 |
| 결측 표시 | 결측 여부 피처 추가 | 패턴 포착 | 차원 증가 | 결측 자체가 정보일 때 |

```
결측치 처리 플로우:

결측 비율은?
├── < 5% → 삭제 또는 단순 대체
├── 5~30% → 모델 기반 대체 (KNN/MICE)
│            └── 결측 표시 피처 추가 고려
└── > 30% → 해당 피처 제거 고려
              └── 결측 자체가 정보?
                  ├── Yes → 결측 표시 피처만 유지
                  └── No → 피처 제거
```

> **핵심 직관**: 결측치는 그 자체로 정보일 수 있습니다. 예를 들어, 소득을 입력하지 않은 고객은 특정 행동 패턴을 가질 수 있습니다. "결측 여부" 자체를 피처로 만드는 것을 항상 고려하십시오.

```python
from sklearn.impute import SimpleImputer, KNNImputer
from sklearn.pipeline import Pipeline
import numpy as np

# 전략별 결측치 처리
X_with_nan = np.array([[1, 2, np.nan],
                        [3, np.nan, 6],
                        [7, 8, 9],
                        [np.nan, 5, 3]])

# 1. 단순 대체 (중앙값)
simple = SimpleImputer(strategy='median')
print("중앙값 대체:\n", simple.fit_transform(X_with_nan))

# 2. KNN 기반 대체
knn_imp = KNNImputer(n_neighbors=2)
print("KNN 대체:\n", knn_imp.fit_transform(X_with_nan))
```

---

## 2. 불균형 데이터 처리

### 전략 비교

| 전략 | 방법 | 장점 | 단점 | 적합한 상황 |
|------|------|------|------|------------|
| 클래스 가중치 | `class_weight='balanced'` | 간단, 데이터 변경 없음 | 미세 조정 어려움 | 첫 번째 시도 |
| 오버샘플링 (SMOTE) | 소수 클래스 합성 | 정보 증가 | 노이즈 생성 위험 | 데이터 적을 때 |
| 언더샘플링 | 다수 클래스 축소 | 학습 빠름 | 정보 손실 | 데이터 매우 많을 때 |
| 임계값 조정 | 결정 임계값 변경 | 유연, 후처리 | 학습에 반영 안 됨 | 비용 비대칭 |
| 앙상블 + 샘플링 | BalancedRF 등 | 강건 | 복잡 | 종합 접근 |

```
불균형 처리 플로우:

불균형 비율은?
├── 약간 (70:30 ~ 80:20)
│   └── class_weight='balanced'로 충분
├── 중간 (90:10 ~ 95:5)
│   ├── 데이터 적음 → SMOTE + class_weight
│   └── 데이터 많음 → 언더샘플링 + 앙상블
└── 극심 (99:1 이상)
    ├── 이상 탐지로 재정의 (ms-14)
    └── 비용 민감 학습 + 임계값 조정
```

> **핵심 직관**: SMOTE를 교차 검증 **안에서** 적용해야 합니다. 전체 데이터에 SMOTE를 먼저 적용하면 검증 세트에 합성 데이터가 포함되어 성능이 과대 추정됩니다.

```python
from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline

# 불균형 데이터 생성
X, y = make_classification(n_samples=2000, n_features=20,
                            weights=[0.95, 0.05], random_state=42)
print(f"클래스 분포: {dict(zip(*np.unique(y, return_counts=True)))}")

# 방법 1: 클래스 가중치
lr_weighted = LogisticRegression(class_weight='balanced', max_iter=1000)
scores1 = cross_val_score(lr_weighted, X, y, cv=5, scoring='f1')

# 방법 2: SMOTE (파이프라인 내에서 적용!)
import numpy as np
smote_pipe = ImbPipeline([
    ('smote', SMOTE(random_state=42)),
    ('clf', LogisticRegression(max_iter=1000))
])
scores2 = cross_val_score(smote_pipe, X, y, cv=5, scoring='f1')

print(f"class_weight F1: {scores1.mean():.3f} ± {scores1.std():.3f}")
print(f"SMOTE        F1: {scores2.mean():.3f} ± {scores2.std():.3f}")
```

---

### 시나리오: 타이타닉 생존 예측 — 전처리 파이프라인 전체 과정

ML 입문의 대표 데이터셋인 타이타닉 생존 예측 문제를 살펴봅니다. 데이터는 891건이며, Age(20% 결측), Cabin(77% 결측), Fare, Pclass, Sex, Embarked(범주형) 등을 포함합니다. 타겟은 생존 여부(0/1)이며 생존률 38%로 약간의 불균형이 있습니다.

전처리 파이프라인은 다음과 같이 구성합니다. 첫째, Cabin은 결측이 77%이므로 피처 자체를 삭제하되 "Cabin 정보 유무"를 이진 피처로 생성합니다(1등실 승객일수록 Cabin 정보가 있으므로 생존과 상관). 둘째, Age는 20% 결측이므로 KNNImputer로 Pclass/Sex를 참조하여 대체합니다. 셋째, Sex와 Embarked는 원-핫 인코딩하고, Fare는 로그 변환으로 왜도를 줄입니다. 이 모든 단계를 `ColumnTransformer` + `Pipeline`으로 묶어 데이터 누출을 방지해야 합니다.

### 시나리오: 중고차 가격 예측 — 인코딩 전략 비교

중고차 거래 플랫폼이 차량 시세를 자동 추정하려 합니다. 데이터는 10만 건이며, 15% 결측치를 포함합니다. 피처 중 8개가 범주형(브랜드 40종, 모델명 300종, 연료 타입, 변속기, 색상, 지역 등)이고, 나머지는 수치형(연식, 주행거리, 배기량, 마력 등)입니다. 타겟은 판매 가격(회귀)입니다.

핵심 쟁점은 범주형 인코딩 전략입니다. 브랜드(40종)에 원-핫 인코딩을 적용하면 40개 열이 추가되어 관리 가능하지만, 모델명(300종)까지 원-핫으로 처리하면 차원이 폭발합니다. 타겟 인코딩은 모델명을 해당 모델의 평균 가격으로 대체하여 단일 열로 압축하므로 효율적입니다. 단, 반드시 CV fold 내에서 계산해야 과적합을 방지할 수 있습니다. LightGBM을 사용한다면 범주형 피처를 내장 기능으로 직접 처리할 수도 있습니다.

## 3. 범주형 인코딩

| 인코딩 | 원리 | 장점 | 단점 | 적합한 모델 |
|--------|------|------|------|------------|
| 원핫 | 이진 벡터 | 순서 가정 없음 | 고기수 시 차원 폭발 | 선형 모델, 신경망 |
| 라벨 | 정수 변환 | 차원 유지 | 순서 관계 강제 | 트리 모델 |
| 타겟 | 타겟 평균으로 대체 | 고기수 처리 가능 | 과적합 위험 | 모든 모델 |
| 임베딩 | 학습된 벡터 | 의미 포착 | 학습 필요 | 신경망 |

```
범주형 인코딩 선택 플로우:

범주 수(기수)는?
├── 적음 (< 10)
│   ├── 선형 모델/신경망 → 원핫 인코딩
│   └── 트리 모델 → 라벨 인코딩도 가능
├── 중간 (10 ~ 100)
│   ├── 트리 모델 → 라벨 인코딩
│   └── 선형/신경망 → 타겟 인코딩 (CV 내)
└── 많음 (> 100)
    ├── 트리 모델 → 타겟 인코딩 + CatBoost
    └── 신경망 → 엔티티 임베딩
```

> **핵심 직관**: 타겟 인코딩은 강력하지만, 반드시 **교차 검증 fold 내에서** 계산해야 합니다. 전체 데이터로 타겟 인코딩을 계산하면 심각한 데이터 누출이 발생합니다.

```python
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder
import numpy as np

categories = np.array(['서울', '부산', '대구', '인천', '광주']).reshape(-1, 1)

# 원핫 인코딩
ohe = OneHotEncoder(sparse_output=False)
print("원핫:\n", ohe.fit_transform(categories))

# 라벨(서수) 인코딩
oe = OrdinalEncoder()
print("라벨:", oe.fit_transform(categories).ravel())
```

---

## 4. 하이퍼파라미터 튜닝

| 방법 | 원리 | 장점 | 단점 | 적합한 상황 |
|------|------|------|------|------------|
| GridSearch | 격자 전체 탐색 | 완전 탐색 | 느림 | 파라미터 2~3개 |
| RandomSearch | 랜덤 조합 탐색 | 빠름, 효율적 | 최적 보장 없음 | 파라미터 많을 때 |
| Optuna | 베이즈 최적화 | 효율적, 조기 종료 | 설정 복잡 | 실전 추천 |

```python
import optuna
from sklearn.model_selection import cross_val_score
import lightgbm as lgb
from sklearn.datasets import make_classification

X, y = make_classification(n_samples=5000, n_features=20,
                            n_informative=10, random_state=42)

def objective(trial):
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 50, 500),
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
        'num_leaves': trial.suggest_int('num_leaves', 10, 100),
        'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),
        'subsample': trial.suggest_float('subsample', 0.6, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
        'random_state': 42,
        'verbose': -1,
    }
    model = lgb.LGBMClassifier(**params)
    scores = cross_val_score(model, X, y, cv=5, scoring='f1')
    return scores.mean()

study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=50, show_progress_bar=True)

print(f"최적 F1: {study.best_value:.4f}")
print(f"최적 파라미터: {study.best_params}")
```

---

## 5. 전체 파이프라인 구축

```
정형 데이터 전체 파이프라인:

원시 데이터
├── Step 1: EDA (분포, 결측, 이상치 확인)
├── Step 2: 결측치 처리 (전략 선택)
├── Step 3: 피처 인코딩 (범주형)
├── Step 4: 스케일링 (선형 모델용)
├── Step 5: 피처 엔지니어링 (ms-06)
├── Step 6: 불균형 처리 (필요 시)
├── Step 7: 모델 학습 + CV
├── Step 8: 하이퍼파라미터 튜닝
└── Step 9: 최종 평가 (홀드아웃)
```

```python
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
import lightgbm as lgb

# 실전 파이프라인 예시
numeric_features = ['age', 'income', 'tenure']
categorical_features = ['city', 'plan_type']

numeric_transformer = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler()),
])

categorical_transformer = Pipeline([
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OneHotEncoder(handle_unknown='ignore')),
])

preprocessor = ColumnTransformer([
    ('num', numeric_transformer, numeric_features),
    ('cat', categorical_transformer, categorical_features),
])

full_pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', lgb.LGBMClassifier(verbose=-1)),
])
# full_pipeline.fit(X_train, y_train)
```

> **핵심 직관**: `sklearn.pipeline.Pipeline`으로 전처리와 모델을 하나로 묶으면 **데이터 누출을 원천 방지**하고, 재현성과 배포가 쉬워집니다. 전처리를 파이프라인 밖에서 수행하는 것은 실무에서 가장 흔한 실수입니다.

---

## 핵심 정리

1. **결측치 전략은 비율과 패턴에 따라 선택**: 5% 미만은 단순 대체, 그 이상은 모델 기반 대체를 고려하며, 결측 자체가 정보인지 항상 확인합니다.
2. **불균형 처리에서 SMOTE는 CV 내에서만 적용**: 전체 데이터에 먼저 적용하면 데이터 누출이 발생하며, class_weight를 먼저 시도하는 것이 안전합니다.
3. **범주형 인코딩은 기수와 모델에 따라 결정**: 낮은 기수에는 원핫, 높은 기수에는 타겟 인코딩이나 임베딩을 사용하며, 트리 모델은 라벨 인코딩도 가능합니다.
4. **Optuna로 효율적 하이퍼파라미터 튜닝**: GridSearch보다 빠르고 효과적이며, 조기 종료와 파라미터 중요도 분석 기능이 실전에서 유용합니다.
5. **전처리와 모델을 Pipeline으로 통합**: 데이터 누출 방지, 재현성 확보, 배포 편의성을 위해 sklearn Pipeline 사용은 선택이 아니라 필수입니다.
