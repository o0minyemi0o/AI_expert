# 분류 문제의 모델 선택

## 왜 분류 모델 선택법을 알아야 하는가

분류는 ML에서 가장 빈번한 문제 유형입니다. 스팸 탐지, 질병 진단, 고객 이탈 예측, 감성 분석 등 대부분의 비즈니스 문제가 "어느 카테고리에 속하는가?"로 귀결됩니다. 하지만 동일한 분류 문제라도 데이터의 크기, 피처 특성, 클래스 수, 해석 요구에 따라 최적 모델이 완전히 달라집니다.

이 강의에서는 주요 분류 모델의 강점과 약점을 체계적으로 비교하고, 상황별 선택 가이드를 제시합니다.

---

## 1. 선형 분류 모델

### 로지스틱 회귀

결정 경계: $P(y=1|\mathbf{x}) = \sigma(\mathbf{w}^\top \mathbf{x} + b)$, 여기서 $\sigma$는 시그모이드 함수입니다 (dl-02 참조).

### 언제 쓰는가
- 피처와 결정 경계가 선형에 가까울 때
- 확률 추정이 필요할 때 (잘 캘리브레이션된 확률)
- 해석가능성이 요구될 때 (계수 해석 가능)
- 베이스라인으로 항상 유용

### 언제 쓰지 않는가
- 비선형 결정 경계가 필요할 때
- 피처 간 복잡한 상호작용이 존재할 때

### SVM (Support Vector Machine)

| 커널 | 결정 경계 | 적합한 상황 | 주의점 |
|------|----------|------------|--------|
| Linear | 선형 | 고차원, 텍스트 분류 | 로지스틱과 유사 성능 |
| RBF | 비선형 | 중간 규모, 복잡한 경계 | $C$, $\gamma$ 튜닝 필요 |
| Polynomial | 다항식 | 피처 상호작용 | 차수 선택이 중요 |

> **핵심 직관**: SVM은 고차원에서 강력하지만, 샘플이 10만 건을 넘으면 학습 시간이 급격히 증가합니다 ($O(n^2)$ ~ $O(n^3)$). 대규모 데이터에서는 로지스틱 회귀나 트리 모델이 더 실용적입니다.

### 시나리오: 전자상거래 고객 이탈 예측

대형 이커머스 플랫폼이 고객 이탈을 사전에 예측하려 합니다. 데이터는 50만 고객 기록이며, 가입일, 최근 구매일, 최근 30일 구매 횟수, 평균 결제 금액, 장바구니 이탈률, 고객 문의 횟수, 쿠폰 사용 비율 등 30개 피처를 포함합니다. 타겟은 이탈 여부(0/1)이며, 이탈 고객은 전체의 8%로 불균형합니다.

불균형 데이터이므로 Accuracy 대신 AUPRC나 F1을 지표로 선택해야 합니다. 로지스틱 회귀를 베이스라인으로 시작하되, `class_weight='balanced'`를 설정하여 소수 클래스에 더 높은 가중치를 부여합니다. 50만 건이라는 데이터 크기와 피처 간 비선형 상호작용(예: 구매 횟수는 많지만 금액이 감소하는 패턴)을 고려하면, XGBoost + SMOTE 조합이 최종 모델로 적합합니다.

### 시나리오: 이메일 스팸 필터링

사내 이메일 시스템의 스팸 필터를 구축합니다. 데이터는 10만 건의 이메일이며, TF-IDF로 벡터화하면 5,000차원의 희소 행렬이 됩니다. 타겟은 스팸/정상(이진 분류)입니다.

이 문제에서 나이브 베이즈(Multinomial NB)가 여전히 강력한 이유가 있습니다. 첫째, TF-IDF 피처는 단어 빈도이므로 피처 간 독립 가정이 크게 위배되지 않습니다. 둘째, 5,000차원의 고차원 데이터에서도 매우 빠르게 학습되며, 새 이메일 도착 시 실시간 예측이 가능합니다. 셋째, 학습 데이터가 적어도 잘 작동합니다. 실제로 나이브 베이즈는 F1 0.95 이상을 쉽게 달성하며, SVM(Linear)과 비슷한 성능을 1/10의 학습 시간으로 얻을 수 있습니다.

---

## 2. 확률 기반 / 거리 기반 모델

### 나이브 베이즈

베이즈 정리 기반: $P(y|\mathbf{x}) \propto P(y)\prod_{i} P(x_i|y)$ (pt-04 참조)

### 언제 쓰는가
- 텍스트 분류 (특히 TF-IDF와 조합)
- 피처 독립 가정이 대략 성립할 때
- 매우 빠른 학습/예측이 필요할 때
- 학습 데이터가 적을 때

### 언제 쓰지 않는가
- 피처 간 강한 상관이 있을 때
- 확률 추정의 정확성이 중요할 때 (캘리브레이션 나쁨)

### KNN (K-Nearest Neighbors)

### 언제 쓰는가
- 결정 경계가 매우 불규칙할 때
- 피처 수가 적고 해석이 필요할 때
- 새 클래스가 자주 추가될 때 (재학습 불필요)

### 언제 쓰지 않는가
- 고차원 데이터 (차원의 저주, la-07 참조)
- 대규모 데이터 (예측 시간 $O(n)$)
- 피처 스케일이 다를 때 (정규화 필수)

```python
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score
from sklearn.datasets import make_classification
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline

X, y = make_classification(n_samples=1000, n_features=20,
                            n_informative=10, random_state=42)

models = {
    'LogisticRegression': make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000)),
    'SVM (RBF)':          make_pipeline(StandardScaler(), SVC(kernel='rbf')),
    'Naive Bayes':        GaussianNB(),
    'KNN (k=5)':          make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=5)),
}

for name, model in models.items():
    scores = cross_val_score(model, X, y, cv=5, scoring='f1')
    print(f"{name:22s} F1: {scores.mean():.3f} ± {scores.std():.3f}")
```

---

## 3. 트리 기반 모델

### 결정 트리

### 언제 쓰는가
- 완전한 해석가능성이 필요할 때 (규칙 추출 가능)
- 비전문가에게 모델을 설명해야 할 때
- 피처 상호작용 탐색 용도

### 언제 쓰지 않는가
- 안정적 예측이 필요할 때 (데이터 변화에 민감)
- 높은 정확도가 필요할 때

### Random Forest

| 특성 | 결정 트리 | Random Forest |
|------|----------|---------------|
| 안정성 | 낮음 (높은 분산) | 높음 |
| 해석가능성 | 매우 높음 | 중간 (피처 중요도) |
| 과적합 위험 | 높음 | 낮음 |
| 학습 속도 | 빠름 | 중간 |
| 하이퍼파라미터 | 적음 | n_estimators, max_depth 등 |

```
결정 트리 vs Random Forest 선택:

해석가능성이 최우선인가?
├── Yes → 결정 트리 (max_depth 제한)
└── No → 성능이 더 중요한가?
          ├── Yes → Random Forest
          │         └── 더 높은 성능? → XGBoost/LightGBM (ms-04)
          └── No → 빠른 프로토타입? → 결정 트리
```

> **핵심 직관**: Random Forest는 "튜닝 없이도 잘 작동하는" 모델입니다. 하이퍼파라미터에 둔감하여 빠르게 합리적 성능을 얻고 싶을 때 가장 먼저 시도하십시오.

---

## 4. 모델 종합 비교

| 모델 | 학습 속도 | 예측 속도 | 비선형 | 확률 출력 | 해석성 | 대규모 데이터 |
|------|----------|----------|--------|----------|--------|-------------|
| 로지스틱 회귀 | 매우 빠름 | 매우 빠름 | 불가 | 우수 | 높음 | 적합 |
| SVM (RBF) | 느림 | 중간 | 우수 | 제한적 | 낮음 | 부적합 |
| 나이브 베이즈 | 매우 빠름 | 매우 빠름 | 제한적 | 나쁨 | 중간 | 적합 |
| KNN | 없음 | 매우 느림 | 우수 | 제한적 | 중간 | 부적합 |
| 결정 트리 | 빠름 | 매우 빠름 | 우수 | 나쁨 | 매우 높음 | 적합 |
| Random Forest | 중간 | 빠름 | 우수 | 중간 | 중간 | 적합 |

---

## 5. 데이터 특성별 선택 가이드

```
분류 모델 선택 플로우:

데이터가 정형인가?
├── No → 이미지 → CNN/ViT (ms-10)
│        텍스트 → BERT/LLM (ms-11)
└── Yes → 샘플 수는?
          ├── < 1,000
          │   ├── 피처 많음(>100) → 로지스틱 + L1 정규화
          │   ├── 피처 적음 → KNN 또는 SVM
          │   └── 텍스트 → 나이브 베이즈
          ├── 1,000 ~ 100,000
          │   ├── 해석 필요 → 로지스틱 / 결정 트리
          │   ├── 성능 우선 → Random Forest / XGBoost (ms-04)
          │   └── 확률 필요 → 로지스틱 회귀
          └── > 100,000
              ├── 선형 관계 → 로지스틱 회귀 (SGD)
              └── 비선형 → XGBoost / LightGBM (ms-04)
```

> **핵심 직관**: 실무에서 가장 흔한 실수는 "데이터를 보지 않고 모델을 선택하는 것"입니다. EDA로 피처 분포, 클래스 비율, 결측치를 확인한 뒤 모델을 선택하십시오.

```python
# 여러 모델 빠르게 비교하는 실전 코드
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.model_selection import cross_val_score
from sklearn.datasets import load_breast_cancer
import warnings
warnings.filterwarnings('ignore')

X, y = load_breast_cancer(return_X_y=True)

candidates = {
    'Logistic':       LogisticRegression(max_iter=5000),
    'LinearSVC':      LinearSVC(max_iter=5000),
    'RandomForest':   RandomForestClassifier(n_estimators=100, random_state=42),
    'GradientBoost':  GradientBoostingClassifier(n_estimators=100, random_state=42),
}

print(f"{'모델':18s} {'F1 (mean±std)':>15s}")
print("-" * 35)
for name, clf in candidates.items():
    scores = cross_val_score(clf, X, y, cv=5, scoring='f1')
    print(f"{name:18s} {scores.mean():.3f} ± {scores.std():.3f}")
```

> **핵심 직관**: 위 코드처럼 4~5개 후보 모델을 교차 검증으로 빠르게 비교한 뒤, 상위 1~2개 모델만 하이퍼파라미터 튜닝에 집중하는 것이 효율적입니다.

---

## 핵심 정리

1. **로지스틱 회귀는 만능 베이스라인**: 빠르고, 확률을 잘 추정하며, 해석이 가능합니다. 어떤 분류 문제든 로지스틱 회귀부터 시작하십시오.
2. **SVM은 중소 규모 + 고차원에서 강력**: 텍스트 분류 등 피처가 많은 중소 규모 데이터에서 탁월하지만, 대규모 데이터에서는 학습 시간이 문제입니다.
3. **나이브 베이즈는 텍스트와 소량 데이터의 친구**: 피처 독립 가정에도 불구하고 텍스트 분류에서 놀라울 정도로 잘 작동합니다.
4. **Random Forest는 튜닝 없는 강력한 선택지**: 하이퍼파라미터에 둔감하여 빠르게 합리적 성능을 얻을 수 있으며, 피처 중요도도 제공합니다.
5. **후보 모델을 빠르게 비교한 뒤 집중 튜닝**: 모든 모델을 깊이 튜닝하는 것은 비효율적이며, 교차 검증으로 상위 후보를 빠르게 선별하는 것이 실전 전략입니다.
