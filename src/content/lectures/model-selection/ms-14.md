# 이상 탐지 접근법

## 왜 이상 탐지 접근법 선택이 중요한가

이상 탐지(anomaly detection)는 사기 거래, 네트워크 침입, 장비 고장, 품질 결함 등 비즈니스에서 가장 직접적인 손실을 막는 ML 응용입니다. 하지만 이상 탐지의 근본적 어려움은 **이상치의 레이블이 거의 없다는 것**입니다. 정상 데이터는 풍부하지만 이상 데이터는 극히 드물며, 이상의 패턴도 계속 변합니다.

이 강의에서는 통계적 방법부터 딥러닝까지, 레이블 유무와 데이터 특성에 따른 이상 탐지 접근법 선택 전략을 비교합니다.

---

## 1. 이상 탐지의 세 가지 설정

| 설정 | 레이블 | 학습 데이터 | 적합한 접근법 |
|------|--------|-----------|-------------|
| 지도 학습 | 정상+이상 레이블 | 양쪽 모두 | 분류 모델 (ms-03) |
| 반지도 학습 | 정상만 레이블 | 정상 데이터만 | One-Class SVM, AutoEncoder |
| 비지도 학습 | 없음 | 혼합 데이터 | Isolation Forest, LOF |

```
이상 탐지 설정 선택 플로우:

이상 레이블이 있는가?
├── 충분함 (수백 개 이상)
│   └── 지도 학습 분류 (불균형 처리 필수, ms-09)
├── 적음 (수십 개)
│   └── 반지도 + 소량 이상 레이블로 임계값 조정
├── 없음, 정상만 알고 있음
│   └── 반지도 (One-Class SVM, AutoEncoder)
└── 없음, 정상도 불확실
    └── 비지도 (Isolation Forest, LOF)
```

> **핵심 직관**: 이상 레이블이 충분하면 이상 탐지가 아니라 **불균형 분류 문제**가 됩니다. 이 경우 ms-03과 ms-09에서 다룬 분류 + 불균형 처리 전략이 더 적합합니다.

---

## 2. 통계적 방법

### Z-Score

각 변수에서 평균으로부터 표준편차 몇 배 떨어져 있는지 계산합니다: $z = \frac{x - \mu}{\sigma}$

### IQR (사분위 범위)

$Q_1 - 1.5 \times \text{IQR}$ 미만이거나 $Q_3 + 1.5 \times \text{IQR}$ 초과인 값을 이상치로 판별합니다.

| 방법 | 가정 | 장점 | 단점 | 적합한 상황 |
|------|------|------|------|------------|
| Z-Score | 정규분포 | 단순, 빠름 | 비정규에서 부정확 | 단변량, 정규 분포 |
| IQR | 없음 | 분포 무관 | 다변량 부적합 | 단변량, 탐색적 분석 |
| Grubbs | 정규분포 | 통계적 검정 | 단일 이상치만 | 실험실 데이터 |
| Mahalanobis | 다변량 정규 | 상관 고려 | 정규 가정 필요 | 다변량, 정규 근사 |

```python
import numpy as np
from scipy import stats

np.random.seed(42)
data = np.concatenate([
    np.random.normal(0, 1, 1000),    # 정상
    np.random.normal(0, 1, 10) + 5   # 이상치
])

# Z-Score 기반 이상 탐지
z_scores = np.abs(stats.zscore(data))
outliers_z = np.sum(z_scores > 3)
print(f"Z-Score (|z|>3) 탐지: {outliers_z}개")

# IQR 기반 이상 탐지
q1, q3 = np.percentile(data, [25, 75])
iqr = q3 - q1
lower, upper = q1 - 1.5 * iqr, q3 + 1.5 * iqr
outliers_iqr = np.sum((data < lower) | (data > upper))
print(f"IQR 탐지: {outliers_iqr}개")
```

> **핵심 직관**: 통계적 방법은 **단변량 이상치**에는 효과적이지만, 개별 변수는 정상인데 변수 조합이 비정상인 **다변량 이상**을 탐지할 수 없습니다. 이 경우 ML 방법이 필요합니다.

### 시나리오: 신용카드 사기 탐지

카드사에서 실시간 결제 사기를 탐지합니다. 데이터는 일 100만 건 거래, 사기 비율 0.1%(약 1,000건/일)이며, 피처는 결제 금액, 가맹점 카테고리, 결제 시간, 위치, 직전 거래 간격 등 30개입니다. 사기 레이블은 존재하지만 극심한 불균형(1:999)입니다.

레이블이 있으므로 지도 학습이 가능하지만, 0.1% 불균형에서 단순 분류기는 "모두 정상"으로 예측해도 99.9% 정확도를 달성합니다. 효과적인 접근은 Isolation Forest로 전체 거래의 이상 스코어를 먼저 추출하고, 이 스코어를 추가 피처로 활용하여 XGBoost 이진 분류기를 학습하는 조합 전략입니다. Isolation Forest의 이상 스코어가 거래의 "비정상 정도"를 수치화해주므로, 분류기가 불균형 상황에서도 사기 패턴을 효과적으로 학습합니다. SMOTE 오버샘플링과 결합하면 Precision 80%, Recall 75% 수준을 달성할 수 있습니다.

---

## 3. ML 기반 방법

### Isolation Forest

핵심 아이디어: 이상치는 **적은 분할로도 고립**됩니다. 랜덤 트리에서 루트까지의 평균 경로 길이가 짧을수록 이상치일 가능성이 높습니다.

### LOF (Local Outlier Factor)

핵심 아이디어: 주변 이웃과 비교하여 **지역적 밀도가 낮은** 점을 이상치로 판별합니다.

### One-Class SVM

핵심 아이디어: 원점으로부터 데이터를 최대한 분리하는 초평면을 학습합니다 (정상 데이터만으로 학습).

| 모델 | 학습 데이터 | 대규모 데이터 | 고차원 | 해석성 | 주요 파라미터 |
|------|-----------|------------|--------|--------|-------------|
| Isolation Forest | 혼합 가능 | 우수 | 우수 | 중간 | n_estimators, contamination |
| LOF | 혼합 가능 | 부적합 | 약함 | 중간 | n_neighbors |
| One-Class SVM | 정상만 | 부적합 | 중간 | 낮음 | kernel, nu |

```python
from sklearn.ensemble import IsolationForest
from sklearn.neighbors import LocalOutlierFactor
from sklearn.svm import OneClassSVM
from sklearn.datasets import make_blobs
import numpy as np

# 정상 데이터 + 이상치 생성
X_normal, _ = make_blobs(n_samples=500, centers=1, random_state=42)
X_outliers = np.random.uniform(-8, 8, size=(20, 2))
X = np.vstack([X_normal, X_outliers])
y_true = np.array([1]*500 + [-1]*20)  # 1=정상, -1=이상

models = {
    'IsolationForest': IsolationForest(contamination=0.05, random_state=42),
    'LOF': LocalOutlierFactor(n_neighbors=20, contamination=0.05),
    'OneClassSVM': OneClassSVM(kernel='rbf', nu=0.05),
}

for name, model in models.items():
    if name == 'LOF':
        y_pred = model.fit_predict(X)
    else:
        y_pred = model.fit(X).predict(X)

    # 이상치를 올바르게 탐지한 비율
    detected = np.sum((y_pred == -1) & (y_true == -1))
    false_alarm = np.sum((y_pred == -1) & (y_true == 1))
    print(f"{name:18s}  탐지: {detected}/20,  오탐: {false_alarm}")
```

```
ML 이상 탐지 모델 선택:

데이터 크기와 차원은?
├── 대규모 + 고차원
│   └── Isolation Forest (확장성 최고)
├── 중소 규모 + 저차원
│   ├── 밀도 차이 중요 → LOF
│   └── 정상만 학습 → One-Class SVM
└── 정상 데이터만 사용 가능
    ├── 정형 데이터 → One-Class SVM / Isolation Forest
    └── 비정형 데이터 → AutoEncoder (아래 참조)
```

---

## 4. 딥러닝: AutoEncoder 기반 이상 탐지

### 핵심 아이디어

정상 데이터로 AutoEncoder를 학습시킨 후, **재구성 오차(reconstruction error)**가 큰 데이터를 이상치로 판별합니다 (ms-06 참조).

### 언제 쓰는가
- 고차원/비정형 데이터 (이미지, 시계열)
- 정상 데이터가 풍부할 때
- 복잡한 비선형 정상 패턴

### 언제 쓰지 않는가
- 데이터가 적을 때
- 정상 패턴이 단순할 때 (Isolation Forest로 충분)
- 해석가능성이 필요할 때

| 방법 | 데이터 유형 | 차원 | 학습 데이터 | 복잡도 |
|------|-----------|------|-----------|--------|
| Z-Score / IQR | 정형 | 단변량 | 불필요 | 매우 낮음 |
| Isolation Forest | 정형 | 다변량 | 혼합 가능 | 낮음 |
| LOF | 정형 | 저~중 | 혼합 가능 | 중간 |
| One-Class SVM | 정형 | 중 | 정상만 | 중간 |
| AutoEncoder | 정형/비정형 | 고차원 | 정상만 | 높음 |

```python
import torch
import torch.nn as nn
import numpy as np

class AnomalyAE(nn.Module):
    def __init__(self, input_dim):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, 32),
            nn.ReLU(),
            nn.Linear(32, 8),
        )
        self.decoder = nn.Sequential(
            nn.Linear(8, 32),
            nn.ReLU(),
            nn.Linear(32, input_dim),
        )

    def forward(self, x):
        z = self.encoder(x)
        return self.decoder(z)

# 학습: 정상 데이터만으로
# model = AnomalyAE(input_dim=20)
# 손실 = MSE(input, reconstruction)

# 추론: reconstruction error > threshold → 이상치
# threshold는 정상 데이터의 재구성 오차 분포에서 결정
# 예: 95 또는 99 백분위수
```

> **핵심 직관**: AutoEncoder 이상 탐지의 핵심은 **임계값(threshold) 설정**입니다. 너무 낮으면 오탐(false positive)이 많고, 너무 높으면 미탐(false negative)이 많습니다. 소량의 이상 레이블이 있으면 최적 임계값을 데이터 기반으로 결정할 수 있습니다.

### 시나리오: 클라우드 서버 장애 사전 탐지

클라우드 인프라팀에서 서버 장애를 사전에 감지하려 합니다. 데이터는 500대 서버에서 1분 간격으로 수집되는 CPU 사용률, 메모리 사용률, 네트워크 I/O, 디스크 I/O, 프로세스 수 등 50개 시계열 메트릭이며, 6개월 분량(약 1,300만 행)입니다. 장애 레이블은 존재하지 않습니다.

레이블이 없으므로 비지도 접근이 필요합니다. 50개 시계열 메트릭은 서로 복잡한 상관관계를 가지므로, LSTM AutoEncoder가 적합합니다. 정상 구간 데이터로 AutoEncoder를 학습시켜 50개 메트릭의 시간적 패턴을 압축(인코딩)하고 복원(디코딩)합니다. 추론 시 reconstruction error가 정상 분포의 99 백분위수를 초과하면 이상으로 판정합니다. 예를 들어 CPU는 정상인데 디스크 I/O와 네트워크가 동시에 비정상인 복합 패턴을 포착할 수 있습니다. 단일 메트릭 Z-Score로는 이러한 다변량 이상을 탐지할 수 없습니다. 임계값은 운영팀의 피드백으로 점진적으로 조정합니다.

---

## 5. 종합 선택 가이드

```
이상 탐지 종합 선택 플로우:

레이블 상태는?
├── 이상 레이블 충분 → 불균형 분류 (ms-03, ms-09)
├── 이상 레이블 소량 → 반지도 + 임계값 조정
└── 이상 레이블 없음
    ├── 데이터 유형은?
    │   ├── 단변량 정형 → Z-Score / IQR
    │   ├── 다변량 정형
    │   │   ├── 대규모 → Isolation Forest
    │   │   ├── 밀도 차이 → LOF
    │   │   └── 정상만 학습 → One-Class SVM
    │   ├── 이미지 → AutoEncoder / 사전학습 모델
    │   └── 시계열 → 예측 기반 (예측 오차 = 이상 점수)
    └── 실시간 요구?
        ├── Yes → Isolation Forest (빠른 추론)
        └── No → 앙상블 (여러 방법 결합)
```

---

## 핵심 정리

1. **이상 레이블이 충분하면 분류 문제로 풀기**: 이상 탐지 전용 알고리즘보다 XGBoost + 불균형 처리가 더 정확한 경우가 많습니다.
2. **Isolation Forest는 범용 이상 탐지의 첫 번째 선택**: 대규모 데이터, 고차원에서도 효율적이며, 하이퍼파라미터에 둔감하여 빠르게 적용 가능합니다.
3. **AutoEncoder는 고차원/비정형에서 강력**: 이미지나 시계열 등 복잡한 데이터의 정상 패턴을 학습하여 이상을 탐지하지만, 임계값 설정이 핵심 과제입니다.
4. **통계적 방법은 단변량 탐색에 여전히 유용**: Z-Score와 IQR은 EDA 단계에서 빠르게 이상치를 식별하는 데 효과적이며, 복잡한 모델의 전처리 단계로도 활용됩니다.
5. **여러 방법의 앙상블이 가장 강건**: 단일 방법으로는 모든 유형의 이상을 탐지할 수 없으므로, 통계 + ML + 규칙 기반을 결합하는 것이 실전 최선입니다.
