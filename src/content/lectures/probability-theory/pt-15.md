# ML에서의 확률과 정보 이론 응용

## 왜 종합적 응용을 배워야 하는가

지난 14개 강의에서 확률 공간부터 마팅게일까지, 확률론과 정보 이론의 기초를 쌓았습니다. 이번 마지막 강의에서는 이 모든 도구가 현대 ML의 핵심 모델들 — **VAE**, **GAN**, **확산 모델(Diffusion Model)** — 에서 어떻게 결합되는지 보여드립니다. 각 모델의 수학적 기초를 유도하면서, 이 과목 전체를 관통하는 통일적 관점을 제시합니다.

---

## 1. VAE의 ELBO 유도

### 1.1 생성 모델의 목표

관측 데이터 $\mathbf{x}$의 주변 우도를 최대화하고 싶습니다:

$$
\log p_\theta(\mathbf{x}) = \log \int p_\theta(\mathbf{x}|\mathbf{z})\,p(\mathbf{z})\,d\mathbf{z}
$$

그러나 이 적분은 일반적으로 다루기 어렵습니다 (pt-02의 주변화, pt-07의 증거 계산과 동일한 문제).

### 1.2 ELBO의 유도

근사 사후 분포 $q_\phi(\mathbf{z}|\mathbf{x})$를 도입합니다:

$$
\log p_\theta(\mathbf{x}) = \log \int p_\theta(\mathbf{x}|\mathbf{z})\,p(\mathbf{z})\frac{q_\phi(\mathbf{z}|\mathbf{x})}{q_\phi(\mathbf{z}|\mathbf{x})}\,d\mathbf{z}
$$

Jensen 부등식(co-03에서 다뤘던)과 $\log$의 오목성을 적용하면:

$$
\log p_\theta(\mathbf{x}) \geq \underbrace{\mathbb{E}_{q_\phi(\mathbf{z}|\mathbf{x})}\!\left[\log p_\theta(\mathbf{x}|\mathbf{z})\right]}_{\text{재구성 항}} - \underbrace{D_{\text{KL}}\!\left(q_\phi(\mathbf{z}|\mathbf{x}) \| p(\mathbf{z})\right)}_{\text{정규화 항}} = \text{ELBO}
$$

등호 조건: $q_\phi(\mathbf{z}|\mathbf{x}) = p_\theta(\mathbf{z}|\mathbf{x})$ (참 사후와 일치)

동치 표현:

$$
\log p_\theta(\mathbf{x}) = \text{ELBO} + D_{\text{KL}}\!\left(q_\phi(\mathbf{z}|\mathbf{x}) \| p_\theta(\mathbf{z}|\mathbf{x})\right)
$$

```
ELBO의 구조
──────────────────────────────────────────────────
log p(x) = ELBO  +  D_KL(q(z|x) ∥ p(z|x))
  (상수)    (최대화)     (≥ 0, 최소화)
             │
     ┌───────┴───────┐
     │               │
  재구성 항        -KL 항
 E_q[log p(x|z)]  -D_KL(q(z|x)∥p(z))
     │               │
  디코더 품질     사전분포에 가깝게
──────────────────────────────────────────────────
```

> **핵심 직관**: ELBO는 "데이터를 잘 복원하면서(재구성), 잠재 변수가 사전 분포에서 벗어나지 않도록(KL 정규화)" 하는 두 목표의 균형입니다. pt-11의 KL 발산과 pt-04의 가우시안이 직접 사용됩니다.

### 1.3 가우시안 VAE의 KL 항

$q_\phi(\mathbf{z}|\mathbf{x}) = \mathcal{N}(\boldsymbol{\mu}_\phi, \text{diag}(\boldsymbol{\sigma}_\phi^2))$, $p(\mathbf{z}) = \mathcal{N}(\mathbf{0}, \mathbf{I})$이면 (pt-11의 결과):

$$
D_{\text{KL}} = \frac{1}{2}\sum_{j=1}^{d}\left(\sigma_{\phi,j}^2 + \mu_{\phi,j}^2 - 1 - \log \sigma_{\phi,j}^2\right)
$$

---

## 2. GAN의 Divergence 관점

### 2.1 원조 GAN의 목적 함수

생성기 $G$와 판별기 $D$의 미니맥스 게임:

$$
\min_G \max_D \; \mathbb{E}_{\mathbf{x} \sim p_{\text{data}}}[\log D(\mathbf{x})] + \mathbb{E}_{\mathbf{z} \sim p(\mathbf{z})}[\log(1 - D(G(\mathbf{z})))]
$$

### 2.2 Jensen-Shannon Divergence와의 연결

최적 판별기 $D^*(\mathbf{x}) = \frac{p_{\text{data}}(\mathbf{x})}{p_{\text{data}}(\mathbf{x}) + p_g(\mathbf{x})}$를 대입하면:

$$
\max_D V(G, D^*) = 2\,\text{JSD}(p_{\text{data}} \| p_g) - \log 4
$$

따라서 생성기의 학습은 **JSD를 최소화**하는 것입니다 (pt-11의 f-divergence).

### 2.3 다양한 GAN 변형과 Divergence

| GAN 변형 | 최소화하는 Divergence | 참고 |
|----------|----------------------|------|
| 원조 GAN | Jensen-Shannon | pt-11 |
| f-GAN | 임의의 f-divergence | pt-11 |
| WGAN | Wasserstein-1 거리 | 최적 수송 |
| MMD-GAN | Maximum Mean Discrepancy | 커널 방법 |

> **핵심 직관**: GAN의 변형들은 "두 분포의 차이를 어떤 척도로 측정하는가"의 선택에 의해 결정됩니다. WGAN이 학습 안정성이 높은 이유는 Wasserstein 거리가 KL/JSD보다 "부드러운" 거리 함수이기 때문입니다.

---

## 3. 확산 모델의 Score Function

### 3.1 점수 함수의 정의

분포 $p(\mathbf{x})$의 **점수 함수(score function)**:

$$
\mathbf{s}(\mathbf{x}) = \nabla_{\mathbf{x}} \log p(\mathbf{x})
$$

la-05에서 배운 그래디언트가 여기서 확률 밀도의 로그에 적용됩니다.

### 3.2 확산 과정

**Forward process** (데이터 → 노이즈):

$$
q(\mathbf{x}_t | \mathbf{x}_{t-1}) = \mathcal{N}(\mathbf{x}_t; \sqrt{1-\beta_t}\,\mathbf{x}_{t-1}, \beta_t \mathbf{I})
$$

$$
q(\mathbf{x}_t | \mathbf{x}_0) = \mathcal{N}(\mathbf{x}_t; \sqrt{\bar{\alpha}_t}\,\mathbf{x}_0, (1-\bar{\alpha}_t)\mathbf{I})
$$

여기서 $\alpha_t = 1 - \beta_t$, $\bar{\alpha}_t = \prod_{s=1}^{t} \alpha_s$.

**Reverse process** (노이즈 → 데이터):

$$
p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t) = \mathcal{N}(\mathbf{x}_{t-1}; \boldsymbol{\mu}_\theta(\mathbf{x}_t, t), \sigma_t^2 \mathbf{I})
$$

### 3.3 학습 목적 함수

ELBO를 유도하면 (VAE와 동일한 원리):

$$
L = \mathbb{E}\!\left[\sum_{t=1}^{T} D_{\text{KL}}\!\left(q(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0) \| p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)\right)\right]
$$

이것은 단순화되어 **노이즈 예측 손실**이 됩니다:

$$
L_{\text{simple}} = \mathbb{E}_{t, \mathbf{x}_0, \boldsymbol{\epsilon}}\!\left[\|\boldsymbol{\epsilon} - \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)\|^2\right]
$$

여기서 $\boldsymbol{\epsilon}_\theta$는 $\mathbf{x}_t$에 추가된 노이즈를 예측하는 신경망입니다.

> **핵심 직관**: 확산 모델은 "노이즈 제거의 반복"으로 데이터를 생성합니다. pt-04의 가우시안, pt-11의 KL 발산, pt-14의 마르코프 체인이 모두 결합된 프레임워크입니다. 노이즈 예측 $\boldsymbol{\epsilon}_\theta$는 점수 함수 $\nabla_\mathbf{x} \log p_t(\mathbf{x})$의 재파라미터화입니다.

---

## 4. 세 모델의 비교

| | VAE | GAN | 확산 모델 |
|---|-----|-----|----------|
| 핵심 원리 | ELBO 최대화 | Divergence 최소화 | Score 매칭 |
| 손실 함수 | 재구성 + KL | 적대적 손실 | 노이즈 예측 MSE |
| 사용된 확률론 | 베이즈 추론 (pt-07) | f-divergence (pt-11) | 마르코프 체인 (pt-14) |
| 정보 이론 | KL 발산 (pt-11) | JSD (pt-11) | KL 발산 (pt-11) |
| 분포 가정 | 가우시안 (pt-04) | 암시적 | 가우시안 (pt-04) |
| 잠재 공간 | 명시적 | 암시적 | 없음 (시간축) |
| 밀도 추정 | 가능 (하한) | 불가 | 가능 |
| 생성 품질 | 중간 | 높음 | 매우 높음 |

---

## 5. 전체 과목 종합: ML과의 연결 지도

```
확률 & 정보 이론 → ML 연결 지도
═══════════════════════════════════════════════════════
확률 공간 (pt-01) ─────────────→ 데이터 생성 과정
결합/조건부 (pt-02) ──────────→ 베이즈 네트워크, 그래프 모델
기댓값/분산 (pt-03) ──────────→ 편향-분산 분해, PCA
확률 분포 (pt-04) ────────────→ 모델 설계 (출력 분포 선택)
LLN/CLT (pt-05) ──────────────→ ERM, SGD, 부트스트랩
집중 부등식 (pt-06) ──────────→ PAC 학습, 일반화 bound
베이즈 추론 (pt-07) ──────────→ MAP, 정규화, 불확실성 정량화
켤레 사전/지수족 (pt-08) ────→ GLM, 로지스틱 회귀
충분 통계량 (pt-09) ──────────→ 피처 추출, 온라인 학습
엔트로피 (pt-10) ─────────────→ 교차 엔트로피 손실, 결정 트리
KL/MI (pt-11) ────────────────→ VAE, GAN, 특성 선택
최대 엔트로피/Fisher (pt-12) ─→ 자연 경사법, 정보 기하
측도론 (pt-13) ───────────────→ 정규화 흐름, 밀도 추정
마팅게일 (pt-14) ─────────────→ SGD 수렴, 강화 학습
═══════════════════════════════════════════════════════
```

---

## 6. Python으로 확인하기

```python
import numpy as np

np.random.seed(42)

# --- VAE의 ELBO 구성 요소 ---
d_latent = 2

# 인코더 출력 (간단한 예시)
mu = np.array([1.0, -0.5])
log_var = np.array([-1.0, 0.5])
sigma_sq = np.exp(log_var)

# KL 항: D_KL(q(z|x) || p(z))
kl_term = 0.5 * np.sum(sigma_sq + mu**2 - 1 - log_var)
print(f"VAE KL 항: {kl_term:.4f}")

# 재파라미터화 트릭: z = μ + σ * ε, ε ~ N(0, I)
epsilon = np.random.randn(1000, d_latent)
z_samples = mu + np.sqrt(sigma_sq) * epsilon
print(f"잠재 변수 z 평균: {z_samples.mean(axis=0).round(3)}")
print(f"잠재 변수 z 분산: {z_samples.var(axis=0).round(3)}")

# --- GAN: JSD 계산 ---
# 이산 분포 예시
p = np.array([0.1, 0.2, 0.3, 0.4])  # 데이터 분포
q = np.array([0.25, 0.25, 0.25, 0.25])  # 생성 분포

m = 0.5 * (p + q)
jsd = 0.5 * np.sum(p * np.log(p / m)) + 0.5 * np.sum(q * np.log(q / m))
print(f"\nJSD(p || q) = {jsd:.4f}")
print(f"JSD 상한 (log 2) = {np.log(2):.4f}")

# --- 확산 모델: Forward process 확인 ---
T = 100
betas = np.linspace(0.0001, 0.02, T)
alphas = 1 - betas
alpha_bar = np.cumprod(alphas)

# x_0에서 x_t로의 직접 샘플링
x_0 = 3.0
noise_levels = []
for t in [0, 10, 25, 50, 75, 99]:
    x_t_samples = np.sqrt(alpha_bar[t]) * x_0 + np.sqrt(1 - alpha_bar[t]) * np.random.randn(10000)
    noise_levels.append((t, x_t_samples.mean(), x_t_samples.std()))
    print(f"t={t:3d}: E[x_t]={x_t_samples.mean():.3f} "
          f"(이론: {np.sqrt(alpha_bar[t])*x_0:.3f}), "
          f"Std[x_t]={x_t_samples.std():.3f} "
          f"(이론: {np.sqrt(1-alpha_bar[t]):.3f})")

# --- Score function 확인 ---
# p(x) = N(μ, σ²) → ∇_x log p(x) = -(x-μ)/σ²
mu_true, sigma_true = 2.0, 1.5
x_test = np.array([0.0, 1.0, 2.0, 3.0, 4.0])
score_analytic = -(x_test - mu_true) / sigma_true**2
print(f"\nScore function at x={x_test}:")
print(f"  ∇log p(x) = {score_analytic.round(4)}")
print(f"  (μ 방향으로의 '힘'이 작용)")
```

---

## 핵심 정리

1. **VAE의 ELBO** = 재구성 항 $-$ KL 정규화 항이며, Jensen 부등식과 KL 발산(pt-11)으로 유도된다.
2. **GAN**은 생성 분포와 데이터 분포 사이의 **f-divergence(pt-11)**를 최소화하며, 원조 GAN은 JSD를 최소화한다.
3. **확산 모델**은 가우시안 노이즈의 순차적 추가/제거를 통해 데이터를 생성하며, 점수 함수 $\nabla \log p(\mathbf{x})$의 추정이 핵심이다.
4. 세 모델 모두 **확률 분포(pt-04)**, **KL 발산(pt-11)**, **베이즈 추론(pt-07)**을 공통 기반으로 하며, 각각 다른 관점에서 생성 문제를 풉니다.
5. 확률과 정보 이론은 ML의 **설계 원리**를 제공합니다 — 손실 함수 선택(엔트로피), 정규화(베이즈), 수렴 보장(LLN/마팅게일), 효율적 학습(Fisher 정보)이 모두 이 과목에서 다뤘던 내용입니다.
