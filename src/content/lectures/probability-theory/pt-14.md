# 마팅게일과 수렴 이론

## 왜 마팅게일을 배워야 하는가

**마팅게일(martingale)**은 "공정한 게임"의 수학적 모델입니다. 현재까지의 정보를 주어졌을 때, 미래의 기댓값이 현재 값과 같은 확률 과정을 말합니다. 강화 학습의 가치 함수, 확률적 경사하강법의 수렴 분석, 금융 수학의 자산 가격 모델, 그리고 pt-05에서 다뤘던 대수의 법칙의 세련된 증명 모두 마팅게일 이론에 기반합니다.

이번 강의에서는 마팅게일의 정의와 예시, 선택적 중단 정리, 그리고 다양한 수렴 모드들의 관계를 다룹니다.

---

## 1. 마팅게일의 정의

확률 과정 $\{M_n\}_{n \geq 0}$이 **필트레이션(filtration)** $\{\mathcal{F}_n\}$에 대해 **마팅게일**이란:

1. $M_n$은 $\mathcal{F}_n$-가측 (현재 정보로 결정)
2. $\mathbb{E}[|M_n|] < \infty$ (유한 기댓값)
3. **마팅게일 성질**: $\mathbb{E}[M_{n+1} | \mathcal{F}_n] = M_n$ (미래 기댓값 = 현재 값)

유사하게:
- **서브마팅게일**: $\mathbb{E}[M_{n+1}|\mathcal{F}_n] \geq M_n$ (평균적으로 증가)
- **슈퍼마팅게일**: $\mathbb{E}[M_{n+1}|\mathcal{F}_n] \leq M_n$ (평균적으로 감소)

> **핵심 직관**: 마팅게일은 "공정한 게임의 누적 수익"입니다. 서브마팅게일은 유리한 게임, 슈퍼마팅게일은 불리한 게임에 대응합니다. 필트레이션 $\mathcal{F}_n$은 "시점 $n$까지 알 수 있는 정보"입니다.

---

## 2. 마팅게일의 예시

### 2.1 랜덤 워크

$X_i$가 i.i.d.이고 $\mathbb{E}[X_i] = 0$이면:

$$
M_n = \sum_{i=1}^{n} X_i
$$

$\mathbb{E}[M_{n+1}|\mathcal{F}_n] = M_n + \mathbb{E}[X_{n+1}] = M_n$

### 2.2 곱 마팅게일

$X_i > 0$이 i.i.d.이고 $\mathbb{E}[X_i] = 1$이면:

$$
M_n = \prod_{i=1}^{n} X_i
$$

### 2.3 조건부 기댓값 마팅게일

임의의 적분 가능한 확률 변수 $Y$에 대해:

$$
M_n = \mathbb{E}[Y | \mathcal{F}_n]
$$

이것은 $Y$에 대한 "정보가 축적되면서 점점 정밀해지는 추정"입니다.

### 2.4 베이즈 업데이트와 마팅게일

사후 확률 $p(\theta | x_1, \ldots, x_n)$에 대해:

$$
\mathbb{E}[p(\theta | x_1, \ldots, x_{n+1}) | x_1, \ldots, x_n] = p(\theta | x_1, \ldots, x_n)
$$

pt-07의 베이즈 추론에서 사후 확률은 마팅게일입니다.

> **핵심 직관**: 조건부 기댓값 마팅게일 $M_n = \mathbb{E}[Y|\mathcal{F}_n]$은 "점점 더 많은 정보를 얻으면서 $Y$를 추정하는 과정"입니다. 이것은 ML에서 학습 과정의 수학적 모델이기도 합니다.

---

## 3. 마팅게일 수렴 정리

### Doob의 마팅게일 수렴 정리

$\{M_n\}$이 서브마팅게일이고 $\sup_n \mathbb{E}[M_n^+] < \infty$이면:

$$
M_n \xrightarrow{\text{a.s.}} M_\infty \quad \text{(거의 확실한 수렴)}
$$

여기서 $\mathbb{E}[|M_\infty|] < \infty$입니다.

### $L^2$ 마팅게일 수렴

$\{M_n\}$이 마팅게일이고 $\sup_n \mathbb{E}[M_n^2] < \infty$이면:

$$
M_n \xrightarrow{L^2} M_\infty
$$

```
마팅게일 수렴의 직관
──────────────────────────────────────────
M_n 값
 ▲
 │    ╱╲
 │   ╱  ╲  ╱╲╱╲
 │  ╱    ╲╱    ╲    ╱╲
 │ ╱              ╲╱  ╲╱╲──────── M_∞
 │╱
 └─────────────────────────────────► n
   (초기 변동이 크다가 수렴)
──────────────────────────────────────────
```

---

## 4. 선택적 중단 정리 (Optional Stopping Theorem)

**중단 시점(stopping time)** $\tau$: $\{\tau = n\} \in \mathcal{F}_n$ (현재 정보만으로 멈출지 결정)

**Doob의 선택적 중단 정리**: $\{M_n\}$이 마팅게일이고, 다음 중 하나를 만족하면:

1. $\tau$가 거의 확실하게 유계: $P(\tau \leq N) = 1$
2. $\mathbb{E}[\tau] < \infty$이고 $|M_{n+1} - M_n| \leq C$

이 때:

$$
\mathbb{E}[M_\tau] = \mathbb{E}[M_0]
$$

> **핵심 직관**: "공정한 게임에서 어떤 전략으로 멈추더라도, 기대 수익은 0이다." 이것은 "시장을 이길 수 없다"는 효율적 시장 가설의 수학적 표현이기도 합니다. 단, 중단 시점이 유한하다는 조건이 필수적입니다.

**반례**: 무한 자금의 도박사가 "이길 때까지" 배팅을 두 배로 늘리는 전략 (마팅게일 배팅) — 이론적으로는 반드시 이기지만, 중단 시점의 기댓값이 무한이므로 정리가 적용되지 않습니다.

---

## 5. Azuma-Hoeffding 부등식

마팅게일에 대한 집중 부등식으로, pt-06의 Hoeffding 부등식의 일반화입니다.

$\{M_n\}$이 마팅게일이고 $|M_k - M_{k-1}| \leq c_k$이면:

$$
P(|M_n - M_0| \geq t) \leq 2\exp\!\left(-\frac{t^2}{2\sum_{k=1}^{n} c_k^2}\right)
$$

ML에서 이 부등식은:
- SGD의 수렴 분석
- 적응적 데이터 분석의 일반화 bound
- 온라인 학습의 후회(regret) 분석

에 사용됩니다.

---

## 6. 수렴 모드들의 관계 (종합)

pt-05에서 소개한 수렴 모드들의 전체 관계도를 정리합니다:

```
수렴 모드들의 완전한 관계
──────────────────────────────────────────────────
            L^p 수렴 (p ≥ 1)
              │
              ▼
 a.s. 수렴 ──→ 확률 수렴 ──→ 분포 수렴
   ↑              ↑
   │              │
   └── (DCT) ─────┘

추가 관계:
- 분포 수렴 → 상수로의 확률 수렴 (상수 극한일 때만)
- 확률 수렴 → a.s. 수렴하는 부분열 존재
- L^p 수렴 + a.s. 수렴은 서로 함의하지 않음 (일반적)
- 마팅게일 수렴: 유계 조건 하에서 a.s. + L^1 수렴
──────────────────────────────────────────────────
```

| 수렴 | 사용되는 곳 |
|------|------------|
| 거의 확실한 수렴 | SLLN, 마팅게일 수렴 |
| 확률 수렴 | WLLN, 일치 추정량 |
| 분포 수렴 | CLT, MLE의 점근적 정규성 |
| $L^2$ 수렴 | MSE 일치성, 베이즈 추정 |

---

## 7. Python으로 확인하기

```python
import numpy as np

np.random.seed(42)

# --- 랜덤 워크 마팅게일 ---
n_steps = 1000
n_paths = 5

for path in range(n_paths):
    increments = np.random.choice([-1, 1], size=n_steps)
    M = np.cumsum(increments)
    print(f"경로 {path+1}: E[M_0]={0}, M_n={M[-1]}, "
          f"표본 평균(M_n)={M.mean():.2f}")

# --- 선택적 중단 정리 검증 ---
# 공정한 동전: +1/-1, 중단 조건: |M_n| >= K 또는 n >= N
K, N_max = 10, 10000
n_trials = 50000
stopped_values = []

for _ in range(n_trials):
    M = 0
    for n in range(N_max):
        M += np.random.choice([-1, 1])
        if abs(M) >= K:
            break
    stopped_values.append(M)

print(f"\n선택적 중단 정리:")
print(f"E[M_0] = 0")
print(f"E[M_τ] = {np.mean(stopped_values):.4f} (≈ 0)")

# --- 조건부 기댓값 마팅게일 ---
# Y ~ N(5, 1), 관측 X_i = Y + ε_i, ε_i ~ N(0, σ²)
Y_true = 5.0
sigma_noise = 2.0
n_obs = 50

estimates = []
Y_samples = np.random.normal(Y_true, 1.0, size=10000)

for trial in range(10000):
    Y = Y_samples[trial]
    observations = Y + np.random.normal(0, sigma_noise, size=n_obs)
    # 순차적 베이즈 업데이트 (가우시안 켤레)
    mu_prior, sigma_prior_sq = 0.0, 100.0
    path = []
    for i in range(n_obs):
        sigma_post_sq = 1 / (1/sigma_prior_sq + 1/sigma_noise**2)
        mu_post = sigma_post_sq * (mu_prior/sigma_prior_sq + observations[i]/sigma_noise**2)
        path.append(mu_post)
        mu_prior, sigma_prior_sq = mu_post, sigma_post_sq
    estimates.append(path)

estimates = np.array(estimates)
print(f"\n조건부 기댓값 마팅게일:")
print(f"E[M_1] = {estimates[:, 0].mean():.4f}")
print(f"E[M_10] = {estimates[:, 9].mean():.4f}")
print(f"E[M_50] = {estimates[:, 49].mean():.4f}")
print(f"E[Y] = {Y_samples.mean():.4f}")
# 모두 E[Y]에 가까워야 함 (마팅게일 성질)

# --- Azuma-Hoeffding 검증 ---
n_steps = 500
c = 1  # |M_k - M_{k-1}| ≤ 1
t_values = [5, 10, 15, 20]

for t in t_values:
    count = 0
    for _ in range(50000):
        M_n = np.sum(np.random.choice([-1, 1], size=n_steps))
        if abs(M_n) >= t:
            count += 1
    empirical = count / 50000
    azuma = 2 * np.exp(-t**2 / (2 * n_steps * c**2))
    print(f"t={t:2d}: P(|M_n|≥t)={empirical:.5f}, Azuma bound={azuma:.5f}")
```

---

## 핵심 정리

1. **마팅게일**은 $\mathbb{E}[M_{n+1}|\mathcal{F}_n] = M_n$을 만족하는 "공정한 게임" 모델이며, 베이즈 업데이트와 SGD의 수학적 기초이다.
2. **Doob의 수렴 정리**: 유계 서브마팅게일은 거의 확실하게 수렴하며, 이는 SLLN과 베이즈 일치성의 증명에 핵심적이다.
3. **선택적 중단 정리**: 적절한 조건 하에서 $\mathbb{E}[M_\tau] = \mathbb{E}[M_0]$이며, "공정한 게임에서 전략으로 이길 수 없음"을 수학화한다.
4. **Azuma-Hoeffding 부등식**은 마팅게일의 집중 부등식으로, SGD 수렴 분석과 온라인 학습의 후회 bound에 사용된다.
5. 수렴 모드들의 관계: a.s. $\Rightarrow$ 확률 $\Rightarrow$ 분포이며, 각각 SLLN·WLLN·CLT에 대응하고, 마팅게일은 유계 조건 하에서 a.s. 수렴을 보장한다.
