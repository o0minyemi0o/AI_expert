# 인과 추론의 실전 응용

## 왜 인과 추론을 실무에 적용해야 하는가

ci-01~ci-11에서 인과 추론의 이론과 방법론을 체계적으로 학습했습니다. 이 마지막 강의에서는 이 모든 도구를 실제 비즈니스와 과학 문제에 적용하는 방법을 다룹니다. 예측 모델만으로는 "어떤 행동을 취해야 하는가"에 답할 수 없으며, 인과 추론은 이 간극을 메우는 핵심 기술입니다.

---

## 1. 업리프트 모델링 (Uplift Modeling)

업리프트 모델링은 ci-10의 CATE 추정을 마케팅 의사결정에 직접 적용한 것입니다. "누구에게 쿠폰을 보내야 구매 증가가 최대인가"라는 질문에 답합니다.

$$
\text{Uplift}(x) = P(Y=1 \mid T=1, X=x) - P(Y=1 \mid T=0, X=x) = \tau(x)
$$

| 고객 유형 | $Y(0)$ | $Y(1)$ | Uplift | 최적 행동 |
|----------|--------|--------|--------|----------|
| 확실한 구매자 (Sure Things) | 1 | 1 | 0 | 쿠폰 불필요 |
| 이탈 고객 (Lost Causes) | 0 | 0 | 0 | 쿠폰 무효 |
| 설득 가능 (Persuadables) | 0 | 1 | +1 | **쿠폰 발송** |
| 반항적 (Do Not Disturbs) | 1 | 0 | -1 | 쿠폰 역효과 |

> **핵심 직관**: 전체 구매율을 높이는 예측 모델과 달리, 업리프트 모델은 "쿠폰 때문에 구매한" 사람을 식별합니다. 확실한 구매자에게 쿠폰을 보내면 비용만 낭비합니다.

```python
import numpy as np
from sklearn.ensemble import GradientBoostingClassifier

# 업리프트 모델링 시뮬레이션
np.random.seed(42)
n = 10000

X = np.random.normal(0, 1, (n, 5))
T = np.random.binomial(1, 0.5, n)  # 무작위 쿠폰 발송

# 고객 유형에 따른 이질적 효과
uplift_true = 0.1 + 0.15 * X[:, 0] - 0.1 * X[:, 1]  # CATE
base_prob = 1 / (1 + np.exp(-(X @ [0.5, 0.3, -0.2, 0.1, 0])))
Y = np.random.binomial(1, np.clip(base_prob + uplift_true * T, 0, 1), n)

# T-Learner로 업리프트 추정
m1 = GradientBoostingClassifier(n_estimators=100, max_depth=3)
m0 = GradientBoostingClassifier(n_estimators=100, max_depth=3)
m1.fit(X[T==1], Y[T==1])
m0.fit(X[T==0], Y[T==0])

uplift_hat = m1.predict_proba(X)[:, 1] - m0.predict_proba(X)[:, 1]

# 상위 20%에게만 쿠폰 발송 시 효율
threshold = np.percentile(uplift_hat, 80)
targeted = uplift_hat >= threshold
print(f"전체 대상 쿠폰 ATE: {uplift_true.mean():.4f}")
print(f"타겟팅 대상 CATE: {uplift_true[targeted].mean():.4f}")
print(f"효율 향상: {uplift_true[targeted].mean() / uplift_true.mean():.1f}배")
```

---

## 2. 인과적 추천 시스템

전통적 추천 시스템은 "사용자가 좋아할 아이템"을 예측하지만, 인과적 추천은 "추천 *때문에* 소비가 증가하는 아이템"을 식별합니다.

$$
\text{예측적}: \quad \hat{r}(u, i) = P(\text{구매} \mid \text{사용자}=u, \text{아이템}=i)
$$
$$
\text{인과적}: \quad \hat{\tau}(u, i) = P(\text{구매} \mid do(\text{추천}=i), \text{사용자}=u) - P(\text{구매} \mid \text{사용자}=u)
$$

| 비교 | 예측적 추천 | 인과적 추천 |
|------|-----------|-----------|
| 목표 | 선호도 예측 | 추천의 인과 효과 |
| 편향 | 인기 편향, 노출 편향 | 편향 보정 |
| 방법 | 협업 필터링, MF | IPS 보정, 인과 임베딩 |
| 평가 | 정확도 (RMSE, AUC) | 인과 효과 (업리프트) |

> **핵심 직관**: 인기 영화는 추천하지 않아도 시청하므로 추천의 인과 효과가 낮습니다. 인과적 추천은 "추천이 없었다면 발견하지 못했을 콘텐츠"를 제안합니다. ci-06의 IPW를 추천 로그에 적용하여 노출 편향을 보정합니다.

```python
import numpy as np

# 추천 시스템의 노출 편향 보정 (IPS)
np.random.seed(42)
n_users, n_items = 1000, 50

# 실제 선호도 행렬 (관측 불가)
true_preference = np.random.normal(0, 1, (n_users, n_items))

# 노출 확률: 인기 아이템일수록 더 많이 노출
item_popularity = np.random.uniform(0.1, 0.9, n_items)
exposure_prob = np.outer(np.ones(n_users), item_popularity)

# 관측: 노출된 것만 관측 (MNAR)
exposed = np.random.binomial(1, exposure_prob)
clicks = (true_preference > 0).astype(float) * exposed

# Naive 인기도 (편향됨)
naive_score = clicks.sum(axis=0) / exposed.sum(axis=0)

# IPS 보정된 점수
ips_score = (clicks / exposure_prob).sum(axis=0) / n_users

# 비교
true_score = (true_preference > 0).mean(axis=0)
corr_naive = np.corrcoef(naive_score, true_score)[0, 1]
corr_ips = np.corrcoef(ips_score, true_score)[0, 1]
print(f"Naive vs 실제 상관: {corr_naive:.3f}")
print(f"IPS vs 실제 상관: {corr_ips:.3f}")
```

---

## 3. A/B 테스트를 넘어서

A/B 테스트(ed-02에서 다룰 무작위 통제 실험)는 인과 추론의 gold standard이지만, 실무에서는 여러 한계가 있습니다. 인과 추론 방법론은 이러한 한계를 극복합니다.

| A/B 테스트의 한계 | 인과 추론 해결책 | 관련 강의 |
|----------------|---------------|----------|
| 윤리적/법적 제약 | 관측 데이터 인과 추론 | ci-06, ci-07, ci-08 |
| 긴 실험 기간 | 서로게이트 결과변수 | 단기 지표의 인과적 활용 |
| 간섭 효과 (SUTVA 위반) | 클러스터 RCT, 네트워크 효과 모델 | ci-05 |
| 이질적 효과 미탐지 | CATE 추정, 인과 포레스트 | ci-10 |
| 다중 비교 문제 | 적응적 실험 설계 | si-05, ed-02 |
| 장기 효과 추정 | DID, 합성 대조군 | ci-08 |

> **핵심 직관**: A/B 테스트가 불가능하거나 비용이 클 때, 관측 데이터에서의 인과 추론이 유일한 대안입니다. 역으로, A/B 테스트 데이터도 CATE 분석으로 더 많은 정보를 추출할 수 있습니다.

```python
import numpy as np

# A/B 테스트 + CATE 분석: 이질적 효과 발견
np.random.seed(42)
n = 5000

# A/B 테스트 데이터
X_age = np.random.normal(35, 10, n)
X_freq = np.random.poisson(5, n)
T = np.random.binomial(1, 0.5, n)  # 무작위 배정

# 이질적 효과: 젊은 고빈도 사용자에게만 효과적
tau = np.maximum(0, 5 - 0.1 * X_age + 0.3 * X_freq)
Y = 10 + 0.5 * X_age + 2 * X_freq + tau * T + np.random.normal(0, 3, n)

# 전체 ATE
ate = Y[T==1].mean() - Y[T==0].mean()
print(f"전체 ATE: {ate:.3f}")

# 하위 그룹 분석
young_freq = (X_age < 30) & (X_freq > 5)
old_infreq = (X_age > 40) & (X_freq < 3)
print(f"젊은 고빈도: ATE = {Y[T==1][young_freq[T==1]].mean() - Y[T==0][young_freq[T==0]].mean():.3f}")
print(f"나이 많은 저빈도: ATE = {Y[T==1][old_infreq[T==1]].mean() - Y[T==0][old_infreq[T==0]].mean():.3f}")
print("→ ci-10의 인과 포레스트로 자동화 가능")
```

---

## 4. 합성 대조군 방법 (Synthetic Control)

합성 대조군은 ci-08의 DID를 일반화한 방법으로, 단일 처치 단위에 대해 여러 비처치 단위의 가중 평균으로 반사실을 구성합니다.

$$
\hat{Y}_{1t}^{(0)} = \sum_{j=2}^{J+1} w_j Y_{jt}, \quad \sum_j w_j = 1, \quad w_j \geq 0
$$

$$
\hat{\tau}_t = Y_{1t} - \hat{Y}_{1t}^{(0)} \quad \text{(처치 후 기간)}
$$

| 비교 | DID | 합성 대조군 |
|------|-----|-----------|
| 대조군 | 실제 대조군 | 가중 평균으로 합성 |
| 가정 | 평행 추세 | 잠재 요인 모델 |
| 처치 단위 | 다수 가능 | 소수 (1~몇 개) |
| 가중치 | 동일 가중 | 데이터 기반 최적화 |

> **핵심 직관**: 캘리포니아의 담배 규제 효과를 평가할 때, 다른 주들의 가중 조합으로 "규제가 없었던 가상의 캘리포니아"를 합성합니다. 이 합성 대조군과 실제 캘리포니아의 차이가 인과 효과입니다.

```python
import numpy as np

# 합성 대조군 시뮬레이션
np.random.seed(42)
T_periods = 20
treat_period = 10
n_control = 10

# 잠재 요인 모델
factor = np.random.normal(0, 1, T_periods)
loadings_treat = np.array([0.3, 0.7])
loadings_control = np.random.dirichlet([2, 2], n_control)

# 처치 단위와 대조군 단위 시계열
factor2 = np.random.normal(0, 0.5, T_periods)
factors = np.column_stack([factor, factor2])
Y_treat = factors @ loadings_treat + np.random.normal(0, 0.3, T_periods)
Y_control = factors @ loadings_control.T + np.random.normal(0, 0.3, (T_periods, n_control))

# 처치 효과 추가 (처치 후)
effect = 3.0
Y_treat[treat_period:] += effect

# 합성 대조군: 처치 전 기간에서 최적 가중치 학습
from scipy.optimize import minimize

def sc_loss(w, Y_treat_pre, Y_control_pre):
    synthetic = Y_control_pre @ w
    return np.sum((Y_treat_pre - synthetic) ** 2)

Y_treat_pre = Y_treat[:treat_period]
Y_control_pre = Y_control[:treat_period]

res = minimize(sc_loss, x0=np.ones(n_control) / n_control,
               args=(Y_treat_pre, Y_control_pre),
               constraints={'type': 'eq', 'fun': lambda w: w.sum() - 1},
               bounds=[(0, 1)] * n_control)
w_star = res.x

# 추정된 인과 효과
synthetic_post = Y_control[treat_period:] @ w_star
estimated_effect = (Y_treat[treat_period:] - synthetic_post).mean()
print(f"추정된 인과 효과: {estimated_effect:.3f}")
print(f"진정한 인과 효과: {effect:.3f}")
```

---

## 5. 인과 추론 실무 워크플로우

실무에서 인과 추론을 적용할 때의 체계적 워크플로우입니다.

| 단계 | 작업 | 도구/강의 |
|------|------|----------|
| 1. 질문 정의 | 인과적 질문 명확화 | ci-01 인과 사다리 |
| 2. DAG 구성 | 도메인 지식 + 데이터 탐색 | ci-02, ci-09 |
| 3. 식별 전략 | 백도어/프론트도어/IV 선택 | ci-03, ci-04 |
| 4. 추정 방법 | PSM, IPW, DR, DML 선택 | ci-06, ci-11 |
| 5. 추정 실행 | 경향 점수, 뉘앙스 모델 학습 | ci-06, ci-10 |
| 6. 진단 | 밸런스 검증, 민감도 분석 | ci-06 |
| 7. 반박 | 위약 검정, 반박 테스트 | ci-08 |
| 8. 보고 | 가정 명시, 한계 논의 | 전체 |

> **핵심 직관**: 인과 추론에서 가장 중요한 단계는 2번(DAG 구성)과 3번(식별 전략)입니다. 통계적 추정(4~5단계)은 올바른 식별 전략 위에서만 의미가 있습니다.

```python
# DoWhy를 활용한 실무 워크플로우 (개념적)
# pip install dowhy

# import dowhy
# from dowhy import CausalModel

# Step 1-2: 인과 모델 정의
# model = CausalModel(
#     data=df,
#     treatment='coupon',
#     outcome='purchase',
#     graph='digraph{loyalty->coupon; loyalty->purchase; coupon->purchase}'
# )

# Step 3: 식별
# identified = model.identify_effect()
# print(identified)

# Step 4-5: 추정
# estimate = model.estimate_effect(
#     identified,
#     method_name="backdoor.propensity_score_matching"
# )

# Step 7: 반박
# refute = model.refute_estimate(
#     identified, estimate,
#     method_name="random_common_cause"
# )

print("DoWhy 워크플로우:")
print("1. CausalModel(data, treatment, outcome, graph)")
print("2. model.identify_effect() → 식별 전략")
print("3. model.estimate_effect() → 인과 효과 추정")
print("4. model.refute_estimate() → 견고성 검증")
```

---

## 6. 인과 추론의 미래 방향

인과 추론은 빠르게 발전하는 분야로, 여러 유망한 연구 방향이 있습니다.

| 연구 방향 | 핵심 과제 | 현재 진행 상황 |
|----------|---------|-------------|
| 대규모 언어 모델 + 인과 | LLM의 인과 추론 능력 | 초기 탐색 단계 |
| 인과 강화 학습 | 인과 구조를 활용한 RL | 오프라인 정책 평가 |
| 연속적 처치 효과 | 용량-반응 함수 추정 | 일반화된 경향 점수 |
| 시계열 인과 추론 | 시간적 인과 관계 | ts-01에서 다룰 그랜저 인과 |
| 분산 강건 추정 | 분포 변화에 강건한 인과 효과 | DRO + 인과 추론 |
| 인과 발견의 확장 | 대규모 변수, 시계열 | ci-09의 확장 |

> **핵심 직관**: 인과 추론의 궁극적 목표는 "데이터와 도메인 지식을 결합하여 최적의 의사결정을 내리는 것"입니다. 예측을 넘어 행동(action)으로 이어지는 인과적 사고가 데이터 과학의 핵심 역량입니다.

---

## 7. 과정 총정리

이 과정에서 다룬 핵심 개념과 방법론의 관계를 정리합니다.

| 강의 | 핵심 주제 | 해결하는 문제 |
|------|----------|-------------|
| ci-01 | 상관 vs 인과 | 인과적 사고의 필요성 |
| ci-02~04 | SCM, DAG, d-분리 | 인과 구조의 표현과 분석 |
| ci-03 | do-연산 | 개입 효과의 식별 |
| ci-05 | 잠재 결과 | 반사실과 인과 효과 정의 |
| ci-06 | 경향 점수, IPW, DR | 관측 데이터에서 교란 통제 |
| ci-07~08 | IV, RDD, DID | 관측되지 않은 교란 대응 |
| ci-09 | 인과 발견 | 데이터에서 DAG 학습 |
| ci-10 | CATE, 인과 포레스트 | 이질적 효과 추정 |
| ci-11 | DML, 인과 표현 학습 | ML과의 결합 |
| ci-12 | 업리프트, 실전 응용 | 비즈니스 적용 |

> **핵심 직관**: 인과 추론은 단일 기법이 아니라 사고 방식(framework)입니다. "이 상관관계가 인과관계인가?", "어떤 가정이 필요한가?", "그 가정은 현실적인가?"를 항상 물어보는 습관이 가장 중요합니다.

---

## 핵심 정리

- **업리프트 모델링은 CATE 추정을 마케팅에 적용하여 "처치 때문에 행동이 변하는" 고객을 식별합니다**: 확실한 구매자가 아닌 설득 가능한 고객에게 자원을 집중합니다
- **인과적 추천 시스템은 노출 편향을 IPS로 보정하여 "추천 때문에 소비가 증가하는" 콘텐츠를 제안합니다**
- **합성 대조군 방법은 여러 비처치 단위의 가중 평균으로 반사실을 구성하여, 소수의 처치 단위에 대한 인과 효과를 추정합니다**
- **실무 워크플로우에서 가장 중요한 단계는 DAG 구성과 식별 전략 도출이며, 이는 도메인 지식에 의존합니다**
- **인과 추론은 예측을 넘어 "어떤 행동을 취해야 하는가"에 답하는 의사결정의 핵심 도구입니다**: 데이터 과학자의 필수 역량으로 자리잡고 있습니다
