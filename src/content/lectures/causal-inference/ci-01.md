# 인과 추론의 필요성: 상관 vs 인과

## 왜 상관관계만으로는 부족한가

데이터 분석에서 두 변수 사이의 상관관계를 발견하는 것은 쉽습니다. 그러나 "X가 Y를 *일으키는가*"라는 질문에 답하려면 상관관계 이상의 프레임워크가 필요합니다. 인과 추론은 관측 데이터에서 인과적 결론을 이끌어내기 위한 체계적 방법론을 제공합니다.

---

## 1. 상관관계와 인과관계의 구분

상관관계(correlation)는 두 변수가 함께 변하는 통계적 경향을 의미합니다. 인과관계(causation)는 한 변수의 변화가 다른 변수의 변화를 **직접적으로 유발**하는 관계입니다.

$$
\text{Corr}(X, Y) = \frac{\text{Cov}(X, Y)}{\sigma_X \sigma_Y}
$$

| 구분 | 상관관계 | 인과관계 |
|------|----------|----------|
| 정의 | 두 변수의 공변 패턴 | 원인 → 결과의 방향성 |
| 방향성 | 대칭적 ($\text{Corr}(X,Y) = \text{Corr}(Y,X)$) | 비대칭적 ($X \to Y \neq Y \to X$) |
| 개입 | 개입 없이 관측만으로 측정 | 개입(intervention)을 통해 확인 |
| 교란 | 교란 변수에 의해 발생 가능 | 교란 변수를 통제해야 식별 |

> **핵심 직관**: 아이스크림 판매량과 익사 사고는 강한 양의 상관관계를 보이지만, 아이스크림이 익사를 유발하는 것이 아니라 '기온'이라는 공통 원인이 존재합니다.

```python
import numpy as np

# 교란 변수(기온)가 만들어내는 거짓 상관관계 시뮬레이션
np.random.seed(42)
temperature = np.random.normal(25, 5, 1000)       # 기온 (공통 원인)
ice_cream = 0.8 * temperature + np.random.normal(0, 2, 1000)  # 아이스크림 판매
drowning = 0.3 * temperature + np.random.normal(0, 3, 1000)   # 익사 사고

spurious_corr = np.corrcoef(ice_cream, drowning)[0, 1]
print(f"거짓 상관계수: {spurious_corr:.3f}")  # 약 0.5 이상
```

---

## 2. Simpson's Paradox

Simpson's paradox는 전체 데이터에서 관찰되는 경향이 하위 그룹별로 분석하면 **역전**되는 현상입니다. 이는 인과 추론 없이 단순 통계만으로는 올바른 결론을 내릴 수 없음을 극적으로 보여줍니다.

$$
P(Y \mid X) \neq \sum_z P(Y \mid X, Z=z) \cdot P(Z=z) \quad \text{(방향이 역전될 수 있음)}
$$

| 전체 | 치료군 회복률 | 대조군 회복률 | 결론 |
|------|-------------|-------------|------|
| 전체 집단 | 50% | 60% | 치료 무효? |
| 경증 환자 | 80% | 70% | 치료 유효 |
| 중증 환자 | 30% | 20% | 치료 유효 |

> **핵심 직관**: 중증 환자가 치료군에 더 많이 배정되면서 전체 통계가 역전됩니다. 올바른 인과적 결론을 내리려면 ci-04에서 다룰 d-분리와 ci-03의 do-연산이 필요합니다.

```python
import numpy as np

# Simpson's Paradox 시뮬레이션
# 중증 환자가 치료군에 더 많이 배정되는 상황
severity = np.random.binomial(1, 0.5, 2000)  # 0: 경증, 1: 중증
treatment = np.random.binomial(1, 0.3 + 0.4 * severity, 2000)  # 중증일수록 치료 확률 높음
recovery = np.random.binomial(1, 0.8 - 0.5 * severity + 0.1 * treatment, 2000)

# 전체: 치료군 회복률 vs 대조군 회복률 (역전 가능)
print(f"전체 치료군 회복률: {recovery[treatment==1].mean():.3f}")
print(f"전체 대조군 회복률: {recovery[treatment==0].mean():.3f}")
```

---

## 3. 관측 데이터의 한계와 교란 변수

관측(observational) 데이터에서 인과 효과를 추정할 때 가장 큰 장애물은 **교란 변수(confounder)** 입니다. 교란 변수는 처치(treatment)와 결과(outcome) 모두에 영향을 미치는 변수로, 이를 통제하지 않으면 편향된 추정치를 얻게 됩니다.

$$
\text{편향} = E[Y \mid X=1] - E[Y \mid X=0] - \underbrace{(E[Y^1] - E[Y^0])}_{\text{진정한 인과 효과}}
$$

| 데이터 유형 | 교란 통제 | 인과 식별 | 예시 |
|------------|----------|----------|------|
| 실험 데이터 (RCT) | 무작위 배정으로 자동 통제 | 가능 | ed-02에서 배울 A/B 테스트 |
| 관측 데이터 | 분석 기법으로 사후 통제 | 조건부 가능 | 의료 기록, 행정 데이터 |
| 준실험 데이터 | 자연실험 활용 | 조건부 가능 | ci-08의 RDD, DID |

> **핵심 직관**: 흡연→폐암에서 '나이'라는 교란 변수를 통제하지 않으면 흡연의 진정한 인과 효과를 과대 또는 과소추정하게 됩니다.

```python
import numpy as np

# 교란 변수가 있을 때 naive 추정 vs 올바른 추정
np.random.seed(42)
n = 5000
confounder = np.random.normal(0, 1, n)                 # 교란 변수
treatment = (confounder + np.random.normal(0, 1, n) > 0).astype(int)
outcome = 2.0 * treatment + 3.0 * confounder + np.random.normal(0, 1, n)

# Naive 추정 (교란 무시): 편향됨
naive_ate = outcome[treatment==1].mean() - outcome[treatment==0].mean()
print(f"Naive ATE (편향): {naive_ate:.3f}")  # 진정한 효과 2.0보다 큼
```

---

## 4. 인과 추론의 세 가지 주요 프레임워크

현대 인과 추론은 크게 세 가지 접근법으로 나뉩니다. 각각의 프레임워크는 고유한 강점을 가지며, 실제 분석에서는 상호 보완적으로 사용됩니다.

| 프레임워크 | 핵심 개념 | 대표 학자 | 관련 강의 |
|-----------|----------|----------|----------|
| 구조적 인과 모델 (SCM) | DAG, do-연산 | Judea Pearl | ci-02, ci-03, ci-04 |
| 잠재 결과 (Potential Outcomes) | 반사실, SUTVA | Donald Rubin | ci-05, ci-06 |
| 그랜저 인과 / 시계열 | 시간적 선행성 | Clive Granger | 제한적 사용 |

> **핵심 직관**: Pearl의 SCM은 "왜"를 구조로 표현하고, Rubin의 잠재 결과는 "만약 ~했다면"이라는 반사실을 정량화합니다. 두 프레임워크는 수학적으로 동치임이 증명되어 있습니다.

---

## 5. 인과적 질문의 계층: Pearl의 인과 사다리

Pearl은 인과적 사고를 세 단계의 계층(ladder of causation)으로 분류합니다. 각 단계는 이전 단계의 정보만으로는 답할 수 없는 고유한 질문 유형을 포함합니다.

| 단계 | 이름 | 질문 유형 | 수학적 표현 | 예시 |
|------|------|----------|------------|------|
| 1 | 관측 (Association) | "X를 관측하면 Y는?" | $P(Y \mid X)$ | 흡연자의 폐암 비율은? |
| 2 | 개입 (Intervention) | "X를 *바꾸면* Y는?" | $P(Y \mid do(X))$ | 흡연을 금지하면 폐암이 줄까? |
| 3 | 반사실 (Counterfactual) | "X를 *안 했더라면* Y는?" | $P(Y_x \mid X', Y')$ | 이 환자가 치료받았더라면 살았을까? |

> **핵심 직관**: 머신러닝은 대부분 1단계(관측)에 머물러 있습니다. ci-03에서 다룰 do-연산은 2단계, ci-05의 잠재 결과 프레임워크는 3단계 질문에 답하기 위한 도구입니다.

---

## 6. 실무에서 인과 추론이 필요한 이유

인과 추론은 학문적 관심을 넘어 실질적인 의사결정에 핵심적인 역할을 합니다. 예측 모델만으로는 "어떤 행동을 취해야 하는가"라는 질문에 답할 수 없기 때문입니다.

| 분야 | 예측 모델의 한계 | 인과 추론의 역할 |
|------|----------------|----------------|
| 마케팅 | 쿠폰 수신자가 구매율 높음 → 쿠폰 효과? | 업리프트 모델링 (ci-12) |
| 의학 | 관측적 치료 효과 추정의 편향 | RCT 설계, 경향 점수 (ci-06) |
| 정책 | 정책 시행 전후 비교의 교란 | DID, RDD (ci-08) |
| ML | 모델 공정성, 설명 가능성 | 인과적 공정성 (ci-11) |

> **핵심 직관**: "상관관계는 인과관계가 아니다"라는 경고를 넘어, 인과 추론은 관측 데이터에서도 인과적 결론을 이끌어낼 수 있는 **구체적 방법론**을 제공합니다.

```python
# 예측 모델 vs 인과 모델의 차이: 쿠폰 효과
# 예측: P(구매 | 쿠폰 수신) — 선택 편향 포함
# 인과: P(구매 | do(쿠폰)) — 쿠폰의 순수 효과
import numpy as np

np.random.seed(42)
n = 10000
loyalty = np.random.normal(0, 1, n)  # 충성도 (교란 변수)
coupon = (loyalty + np.random.normal(0, 1, n) > 0).astype(int)  # 충성 고객에게 쿠폰 발송
purchase = (0.5 * loyalty + 0.2 * coupon + np.random.normal(0, 0.5, n) > 0).astype(int)

naive_effect = purchase[coupon==1].mean() - purchase[coupon==0].mean()
print(f"Naive 쿠폰 효과 (편향): {naive_effect:.3f}")
print(f"진정한 인과 효과는 0.2에 가까워야 합니다")
```

---

## 핵심 정리

- **상관관계는 인과관계가 아닙니다**: 교란 변수, 역인과, 선택 편향 등이 거짓 상관을 만들어냅니다
- **Simpson's paradox는 단순 집계의 위험성을 보여줍니다**: 하위 그룹 분석과 인과 구조 파악이 필수적입니다
- **관측 데이터에서 인과 추론은 가능하지만 추가 가정이 필요합니다**: 무교란성, 양성성, 일관성 등의 식별 조건을 만족해야 합니다
- **Pearl의 인과 사다리는 관측-개입-반사실의 세 단계로 구성됩니다**: 각 단계는 이전 단계로 환원 불가능합니다
- **인과 추론은 의사결정을 위한 필수 도구입니다**: 예측을 넘어 "무엇을 해야 하는가"에 답하려면 인과적 사고가 반드시 필요합니다
