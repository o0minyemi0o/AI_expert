# 회귀 불연속과 이중차분

## 왜 준실험적 방법이 필요한가

ci-06의 경향 점수는 관측된 교란만 통제하고, ci-07의 도구 변수는 적절한 IV를 찾기 어렵습니다. 회귀 불연속 설계(RDD)와 이중차분법(DID)은 제도적 특성이나 시간적 변화를 활용하여 관측되지 않은 교란까지 통제할 수 있는 준실험적(quasi-experimental) 방법입니다. 자연실험(natural experiment)의 논리를 형식화한 것입니다.

---

## 1. 회귀 불연속 설계 (RDD)의 기본 개념

RDD는 연속적인 배정 변수(running variable)의 특정 **절단점(cutoff)**을 기준으로 치료가 결정되는 상황을 활용합니다.

$$
T_i = \mathbb{1}(X_i \geq c)
$$

$$
\tau_{\text{RDD}} = \lim_{x \downarrow c} E[Y \mid X=x] - \lim_{x \uparrow c} E[Y \mid X=x]
$$

| 요소 | 설명 | 예시 |
|------|------|------|
| 배정 변수 ($X$) | 치료 배정을 결정하는 연속 변수 | 시험 점수, 나이, 소득 |
| 절단점 ($c$) | 치료 배정의 경계 | 합격선 60점, 법적 음주 연령 21세 |
| 인과 효과 ($\tau$) | 절단점에서의 국소 효과 | 장학금 수혜의 학업 효과 |

> **핵심 직관**: 시험 점수 59점인 학생과 60점인 학생은 거의 동일한 특성을 가지지만, 60점 학생만 장학금을 받습니다. 이 "우연한" 차이가 자연실험을 만들어냅니다.

```python
import numpy as np
import statsmodels.api as sm

# Sharp RDD 시뮬레이션
np.random.seed(42)
n = 2000
X = np.random.uniform(40, 80, n)  # 배정 변수 (시험 점수)
c = 60  # 절단점

T = (X >= c).astype(int)  # 장학금 수혜
Y = 0.5 * X + 3.0 * T + np.random.normal(0, 3, n)  # 결과 (학업 성취)

# 절단점 근처에서 추정 (bandwidth = 10)
bw = 10
near = np.abs(X - c) <= bw
X_near = X[near] - c  # 중심화
T_near = T[near]
Y_near = Y[near]

# 국소 선형 회귀
design = np.column_stack([np.ones(near.sum()), X_near, T_near, X_near * T_near])
model = sm.OLS(Y_near, design).fit()
print(f"RDD 인과 효과 추정: {model.params[2]:.3f}")  # ≈ 3.0
```

---

## 2. Sharp RDD vs Fuzzy RDD

실제 상황에서는 절단점이 치료를 완벽하게 결정하지 않는 경우가 많습니다.

$$
\text{Sharp}: \quad P(T=1 \mid X=x) = \begin{cases} 1 & x \geq c \\ 0 & x < c \end{cases}
$$

$$
\text{Fuzzy}: \quad P(T=1 \mid X=x) \text{가 } x=c \text{에서 불연속적 점프}
$$

$$
\tau_{\text{Fuzzy}} = \frac{\lim_{x \downarrow c} E[Y \mid X=x] - \lim_{x \uparrow c} E[Y \mid X=x]}{\lim_{x \downarrow c} E[T \mid X=x] - \lim_{x \uparrow c} E[T \mid X=x]}
$$

| 유형 | 치료 배정 | 추정 방법 | 식별 대상 |
|------|---------|----------|----------|
| Sharp | 절단점에서 0→1 완전 전환 | 결과의 불연속 크기 | ATE at cutoff |
| Fuzzy | 절단점에서 확률적 점프 | Wald 비율 (= IV) | LATE at cutoff |

> **핵심 직관**: Fuzzy RDD는 ci-07의 도구 변수와 동일한 논리입니다. 배정 변수가 절단점을 넘는지 여부($\mathbb{1}(X \geq c)$)를 도구 변수로 사용하고, 2SLS로 추정합니다.

```python
import numpy as np
import statsmodels.api as sm

# Fuzzy RDD 시뮬레이션
np.random.seed(42)
n = 3000
X = np.random.uniform(40, 80, n)
c = 60

# Fuzzy: 절단점에서 치료 확률이 점프하지만 100%는 아님
prob_treat = 0.2 + 0.5 * (X >= c)  # 20% → 70%
T = np.random.binomial(1, prob_treat, n)
Y = 0.5 * X + 4.0 * T + np.random.normal(0, 3, n)

# Fuzzy RDD (= IV with Z = 1(X >= c))
bw = 10
near = np.abs(X - c) <= bw
Z_near = (X[near] >= c).astype(float)
T_near = T[near].astype(float)
Y_near = Y[near]

# Wald 추정
wald = (Y_near[Z_near==1].mean() - Y_near[Z_near==0].mean()) / \
       (T_near[Z_near==1].mean() - T_near[Z_near==0].mean())
print(f"Fuzzy RDD (Wald) 추정: {wald:.3f}")  # ≈ 4.0
```

---

## 3. RDD의 핵심 가정과 검증

RDD의 타당성은 배정 변수가 절단점 근처에서 **조작 불가능(non-manipulation)**하다는 가정에 핵심적으로 의존합니다.

| 가정 | 내용 | 검증 방법 |
|------|------|----------|
| 연속성 | $E[Y(0) \mid X=x]$, $E[Y(1) \mid X=x]$가 $c$에서 연속 | 본질적으로 검증 불가 |
| 비조작 | 개체가 $X$를 절단점 근처에서 조작 불가 | McCrary 밀도 검정 |
| 국소 무작위화 | $c$ 근처에서 치료 배정이 사실상 무작위 | 공변량 밸런스 검정 |

> **핵심 직관**: 시험 점수를 학생이 조작할 수 있다면 (예: 채점 기준 조정 요청), 절단점 근처의 학생들은 더 이상 동질적이지 않으므로 RDD가 무효화됩니다.

```python
import numpy as np

# McCrary 밀도 검정 (조작 탐지)
np.random.seed(42)
n = 5000
c = 60

# 조작 없는 경우
X_clean = np.random.uniform(40, 80, n)
below = (X_clean < c).sum()
above = (X_clean >= c).sum()
print(f"조작 없음: 절단점 이하 {below}, 이상 {above}")

# 조작 있는 경우 (일부가 점수를 올림)
X_manip = X_clean.copy()
bump = (X_manip > 57) & (X_manip < 60)
X_manip[bump] = X_manip[bump] + 3  # 조작
below_m = (X_manip < c).sum()
above_m = (X_manip >= c).sum()
print(f"조작 있음: 절단점 이하 {below_m}, 이상 {above_m} (불균형!)")
```

---

## 4. 이중차분법 (Difference-in-Differences, DID)

DID는 처치 전후의 변화를 치료군과 대조군 사이에서 비교하여, 시간에 따른 공통 추세를 제거합니다.

$$
\hat{\tau}_{\text{DID}} = (E[Y_{1,\text{post}} - Y_{1,\text{pre}}]) - (E[Y_{0,\text{post}} - Y_{0,\text{pre}}])
$$

$$
= (\bar{Y}_{1,\text{post}} - \bar{Y}_{1,\text{pre}}) - (\bar{Y}_{0,\text{post}} - \bar{Y}_{0,\text{pre}})
$$

| 기간 | 치료군 ($T=1$) | 대조군 ($T=0$) | 차이 |
|------|-------------|-------------|------|
| 사전 (pre) | $\bar{Y}_{1,\text{pre}}$ | $\bar{Y}_{0,\text{pre}}$ | $\Delta_\text{pre}$ |
| 사후 (post) | $\bar{Y}_{1,\text{post}}$ | $\bar{Y}_{0,\text{post}}$ | $\Delta_\text{post}$ |
| 시간 차이 | $\Delta_{1}$ | $\Delta_{0}$ | $\tau_{\text{DID}}$ |

> **핵심 직관**: 최저임금이 인상된 주(치료군)와 인상되지 않은 주(대조군)의 고용 변화를 비교합니다. 양쪽 모두 경기 변동의 영향을 받지만, DID는 이 공통 추세를 차감합니다.

```python
import numpy as np
import statsmodels.api as sm

# DID 시뮬레이션: 최저임금 인상 효과
np.random.seed(42)
n = 2000  # 각 그룹 n/2

# 치료군/대조군
treat = np.repeat([1, 0], n // 2)
# 사전/사후
post = np.tile(np.repeat([0, 1], n // 4), 2)

# 공통 추세 + 치료 효과
common_trend = 2.0 * post
group_effect = 1.5 * treat  # 그룹 간 기본 차이
treatment_effect = 3.0 * treat * post  # DID 인과 효과
noise = np.random.normal(0, 1, n)
Y = 10 + group_effect + common_trend + treatment_effect + noise

# DID 회귀
X_did = np.column_stack([treat, post, treat * post, np.ones(n)])
model = sm.OLS(Y, X_did).fit()
print(f"DID 인과 효과: {model.params[2]:.3f}")  # ≈ 3.0
print(f"그룹 효과: {model.params[0]:.3f}")
print(f"시간 효과: {model.params[1]:.3f}")
```

---

## 5. 평행 추세 가정

DID의 핵심 가정은 **평행 추세(parallel trends)** 가정입니다. 치료가 없었더라면 두 그룹의 추세가 동일했을 것이라는 가정입니다.

$$
E[Y_0^{\text{post}} - Y_0^{\text{pre}} \mid T=1] = E[Y_0^{\text{post}} - Y_0^{\text{pre}} \mid T=0]
$$

| 검증 방법 | 설명 | 한계 |
|----------|------|------|
| 사전 추세 검정 | 치료 전 기간에 두 그룹 추세 비교 | 필요 조건이지 충분 조건 아님 |
| 위약 검정 | 치료 전 시점에 가짜 치료 적용 | 사전 데이터 충분해야 함 |
| 이벤트 연구 | 시차별 효과를 시각적으로 확인 | 동적 효과 구분 어려움 |

> **핵심 직관**: 평행 추세 가정은 "치료가 없었더라면"이라는 반사실에 대한 가정이므로 직접 검증할 수 없습니다. 치료 전 기간의 추세가 평행한 것은 필요 조건이지 충분 조건이 아닙니다.

```python
import numpy as np
import statsmodels.api as sm

# 이벤트 연구 (Event Study) 시뮬레이션
np.random.seed(42)
n_units = 200
n_periods = 10
treat_period = 5

# 패널 데이터 생성
unit = np.repeat(np.arange(n_units), n_periods)
time = np.tile(np.arange(n_periods), n_units)
treated = (unit < n_units // 2).astype(int)  # 절반이 치료군

# 평행 추세 + 치료 후 효과
Y = (2.0 * treated + 0.5 * time +
     3.0 * treated * (time >= treat_period) +
     np.random.normal(0, 1, n_units * n_periods))

# 이벤트 연구: 각 시점별 치료군-대조군 차이
for t in range(n_periods):
    mask = time == t
    diff = Y[mask & (treated == 1)].mean() - Y[mask & (treated == 0)].mean()
    marker = " ← 치료 시작" if t == treat_period else ""
    print(f"t={t}: 차이 = {diff:.2f}{marker}")
```

---

## 6. RDD와 DID의 비교 및 확장

두 방법은 서로 다른 상황에서 적용되지만, 공통적으로 "자연실험"의 논리를 활용합니다.

| 비교 항목 | RDD | DID |
|----------|-----|-----|
| 핵심 변동 | 절단점 근처의 불연속 | 시간에 따른 처치 변화 |
| 핵심 가정 | 비조작 + 연속성 | 평행 추세 |
| 식별 대상 | 절단점에서의 국소 효과 | 처치군의 평균 효과 |
| 외적 타당성 | 절단점 근처에 한정 | 더 넓은 대상 가능 |
| 데이터 구조 | 횡단면 | 패널 (반복 측정) |
| 확장 | 다중 절단점, Kink RDD | Staggered DID, TWFE |

> **핵심 직관**: 최근 연구에서 기존의 이원 고정 효과(TWFE) DID 추정이 이질적 처치 효과가 있을 때 편향될 수 있음이 밝혀졌습니다. ci-10의 이질적 처치 효과와 연결되는 중요한 발전입니다.

```python
# 최신 DID: 시차적 처치 (Staggered DID) 문제
# 기존 TWFE의 한계와 새로운 추정량 (개념적)

print("=== Staggered DID의 문제 ===")
print("처치 시점이 그룹마다 다르면 (staggered adoption)")
print("기존 TWFE 추정은 '이미 처치받은 그룹'을 대조군으로 사용할 수 있습니다")
print("")
print("해결 방법:")
print("  - Callaway & Sant'Anna (2021): 그룹-시점별 ATT")
print("  - Sun & Abraham (2021): Interaction-weighted estimator")
print("  - de Chaisemartin & D'Haultfeuille: DID_M estimator")
print("")
print("이질적 처치 효과가 의심되면 ci-10의 CATE 추정과 결합합니다")
```

---

## 핵심 정리

- **RDD는 배정 변수의 절단점에서 발생하는 불연속을 활용하여, 절단점 근처에서 사실상 무작위 배정과 동일한 효과를 얻습니다**
- **Sharp RDD는 절단점에서 치료가 완전히 결정되고, Fuzzy RDD는 확률적으로 결정되어 ci-07의 IV/2SLS로 추정합니다**
- **DID는 치료군과 대조군의 시간에 따른 변화 차이를 비교하여, 시간 불변 교란과 공통 시간 추세를 동시에 제거합니다**
- **평행 추세 가정은 DID의 핵심 가정으로, 사전 추세 검정과 이벤트 연구로 간접적으로 검증합니다**
- **Staggered DID에서 기존 TWFE 추정의 편향 문제가 최근 활발히 연구되고 있으며, 이질적 효과에 강건한 새로운 추정량들이 제안되었습니다**
