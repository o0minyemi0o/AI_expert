# 이질적 처치 효과

## 왜 평균 효과를 넘어서야 하는가

ci-05에서 정의한 ATE는 모집단 전체의 평균 인과 효과입니다. 그러나 현실에서 처치 효과는 개인의 특성에 따라 크게 다를 수 있습니다. 약이 남성에게는 효과적이지만 여성에게는 부작용이 있을 수 있고, 쿠폰이 신규 고객에게는 효과적이지만 기존 고객에게는 무의미할 수 있습니다. 이질적 처치 효과(Heterogeneous Treatment Effects, HTE)를 추정하면 **누구에게** 처치가 효과적인지를 파악할 수 있습니다.

---

## 1. CATE의 정의와 목표

조건부 평균 처치 효과(Conditional Average Treatment Effect, CATE)는 특성 $X$에 따라 달라지는 인과 효과입니다.

$$
\tau(x) = E[Y(1) - Y(0) \mid X = x]
$$

$$
\text{ATE} = E[\tau(X)] = E_X[\tau(x)]
$$

| 개념 | 정의 | 활용 |
|------|------|------|
| ATE | $E[Y(1) - Y(0)]$ | 정책의 전반적 효과 평가 |
| CATE | $E[Y(1) - Y(0) \mid X=x]$ | 개인화된 처치 결정 |
| ITE | $Y_i(1) - Y_i(0)$ | 개인 수준 (관측 불가) |
| 최적 처치 규칙 | $d^*(x) = \mathbb{1}(\tau(x) > 0)$ | ci-12의 업리프트 모델링 |

> **핵심 직관**: ATE = 2.0이라도, 절반의 사람에게 $\tau = 5$이고 나머지 절반에게 $\tau = -1$이면 치료 정책은 매우 달라져야 합니다. CATE 추정은 "누구에게 치료해야 하는가"에 답합니다.

```python
import numpy as np

# 이질적 처치 효과 시뮬레이션
np.random.seed(42)
n = 5000

X1 = np.random.normal(0, 1, n)  # 나이 (표준화)
X2 = np.random.binomial(1, 0.5, n)  # 성별

# CATE: 나이가 적고 남성일수록 효과가 큼
tau = 3.0 - 1.5 * X1 + 2.0 * X2  # 이질적 효과
Y0 = 1 + 0.5 * X1 + np.random.normal(0, 1, n)
Y1 = Y0 + tau
T = np.random.binomial(1, 0.5, n)  # RCT
Y = T * Y1 + (1 - T) * Y0

print(f"ATE: {tau.mean():.3f}")
print(f"CATE (젊은 남성, X1<0, X2=1): {tau[(X1<0) & (X2==1)].mean():.3f}")
print(f"CATE (나이 많은 여성, X1>0, X2=0): {tau[(X1>0) & (X2==0)].mean():.3f}")
```

---

## 2. 메타러너: S-Learner, T-Learner, X-Learner

메타러너(Meta-Learner)는 기존의 지도 학습 알고리즘을 활용하여 CATE를 추정하는 프레임워크입니다.

### S-Learner (Single model)

$$
\hat{\mu}(x, t) = \hat{E}[Y \mid X=x, T=t]
$$
$$
\hat{\tau}_S(x) = \hat{\mu}(x, 1) - \hat{\mu}(x, 0)
$$

### T-Learner (Two models)

$$
\hat{\mu}_1(x) = \hat{E}[Y \mid X=x, T=1], \quad \hat{\mu}_0(x) = \hat{E}[Y \mid X=x, T=0]
$$
$$
\hat{\tau}_T(x) = \hat{\mu}_1(x) - \hat{\mu}_0(x)
$$

### X-Learner (Cross-fitting)

$$
\tilde{D}_i^1 = Y_i^1 - \hat{\mu}_0(X_i^1), \quad \tilde{D}_i^0 = \hat{\mu}_1(X_i^0) - Y_i^0
$$
$$
\hat{\tau}_X(x) = g(x) \hat{\tau}_1(x) + (1 - g(x)) \hat{\tau}_0(x)
$$

| 메타러너 | 모델 수 | 장점 | 단점 |
|---------|--------|------|------|
| S-Learner | 1개 | 단순, 정규화 내재 | $T$ 효과 축소 위험 |
| T-Learner | 2개 | 유연, 직관적 | 각 그룹 표본 수 감소 |
| X-Learner | 2+2개 | 불균형 표본에 강함 | 복잡, 가중치 선택 |

> **핵심 직관**: S-Learner는 치료 변수를 공변량처럼 취급하므로 정규화가 효과를 0으로 축소할 수 있습니다. T-Learner는 각 그룹을 독립적으로 모델링하므로 공통 패턴을 공유하지 못합니다.

```python
import numpy as np
from sklearn.ensemble import GradientBoostingRegressor

# S-Learner vs T-Learner
np.random.seed(42)
n = 3000
X = np.random.normal(0, 1, (n, 5))
tau = 2.0 + 1.5 * X[:, 0] - 1.0 * X[:, 1]
Y0 = X @ [1, 0.5, -0.3, 0.2, 0] + np.random.normal(0, 1, n)
Y1 = Y0 + tau
T = np.random.binomial(1, 0.5, n)
Y = T * Y1 + (1 - T) * Y0

# S-Learner
X_with_T = np.column_stack([X, T])
s_model = GradientBoostingRegressor(n_estimators=100, max_depth=3)
s_model.fit(X_with_T, Y)
cate_s = (s_model.predict(np.column_stack([X, np.ones(n)])) -
          s_model.predict(np.column_stack([X, np.zeros(n)])))

# T-Learner
t1_model = GradientBoostingRegressor(n_estimators=100, max_depth=3)
t0_model = GradientBoostingRegressor(n_estimators=100, max_depth=3)
t1_model.fit(X[T==1], Y[T==1])
t0_model.fit(X[T==0], Y[T==0])
cate_t = t1_model.predict(X) - t0_model.predict(X)

print(f"진정한 ATE: {tau.mean():.3f}")
print(f"S-Learner ATE: {cate_s.mean():.3f}")
print(f"T-Learner ATE: {cate_t.mean():.3f}")
```

---

## 3. 인과 포레스트 (Causal Forest)

Athey & Imbens(2018)의 인과 포레스트는 랜덤 포레스트를 인과 추론에 특화시킨 방법으로, CATE의 점 추정과 신뢰 구간을 동시에 제공합니다.

$$
\hat{\tau}(x) = \frac{\sum_{i \in \text{leaf}(x)} w_i(x) \cdot (2T_i - 1) \cdot Y_i}{\sum_{i \in \text{leaf}(x)} w_i(x)}
$$

핵심 특징:

$$
\text{Honest splitting}: \quad \text{분할용 데이터} \neq \text{추정용 데이터}
$$

| 특징 | 인과 포레스트 | 일반 랜덤 포레스트 |
|------|------------|-----------------|
| 분할 기준 | CATE 이질성 극대화 | MSE 최소화 |
| 정직한 추정 | Honest splitting | 해당 없음 |
| 점근적 정규성 | 보장 (신뢰 구간 가능) | 보장 안 됨 |
| 목표 | $\hat{\tau}(x)$ 추정 | $\hat{y}(x)$ 예측 |

> **핵심 직관**: 인과 포레스트는 트리를 만들 때 "어디서 처치 효과가 가장 다른가"를 기준으로 분할합니다. 결과 예측이 아닌 효과 이질성 탐지가 목적입니다.

```python
import numpy as np

# 인과 포레스트의 핵심 아이디어: 효과 이질성 기반 분할
np.random.seed(42)
n = 2000
X = np.random.normal(0, 1, (n, 3))
tau = 3.0 * (X[:, 0] > 0) + 1.0 * (X[:, 0] <= 0)  # X0 기준 이질적
Y0 = X @ [1, 0.5, -0.3] + np.random.normal(0, 1, n)
Y1 = Y0 + tau
T = np.random.binomial(1, 0.5, n)
Y = T * Y1 + (1 - T) * Y0

# 하위 그룹별 효과 확인
for label, mask in [("X0>0", X[:, 0] > 0), ("X0<=0", X[:, 0] <= 0)]:
    ate_sub = Y[(T==1) & mask].mean() - Y[(T==0) & mask].mean()
    true_tau = tau[mask].mean()
    print(f"{label}: 추정 ATE={ate_sub:.3f}, 진정한 CATE={true_tau:.3f}")

# 실무에서는 econml 라이브러리 사용
# from econml.dml import CausalForestDML
# cf = CausalForestDML(model_y=..., model_t=...)
# cf.fit(Y, T, X=X)
# cate = cf.effect(X)
print("\n실무: econml.dml.CausalForestDML 사용")
```

---

## 4. R-Learner와 직교화

R-Learner(Robinson, 1988 기반)는 처치 변수와 결과 변수 모두에서 공변량의 효과를 "직교화(orthogonalize)"한 후 CATE를 추정합니다.

$$
Y_i - \hat{m}(X_i) = \tau(X_i) \cdot (T_i - \hat{e}(X_i)) + \epsilon_i
$$

$$
\hat{\tau} = \arg\min_{\tau} \sum_{i=1}^n \left[ (Y_i - \hat{m}(X_i)) - \tau(X_i)(T_i - \hat{e}(X_i)) \right]^2
$$

| 구성 요소 | 추정 대상 | 역할 |
|----------|----------|------|
| $\hat{m}(X)$ | $E[Y \mid X]$ | 결과의 뉘앙스 모델 |
| $\hat{e}(X)$ | $P(T=1 \mid X)$ | 경향 점수 (ci-06) |
| $\hat{\tau}(X)$ | CATE | 최종 관심 대상 |

> **핵심 직관**: R-Learner는 ci-11에서 다룰 이중 머신러닝(DML)의 아이디어를 CATE 추정에 적용한 것입니다. 뉘앙스 파라미터($m, e$)의 추정 오차가 CATE 추정에 미치는 영향을 최소화합니다.

```python
import numpy as np
from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier

# R-Learner 구현
np.random.seed(42)
n = 3000
X = np.random.normal(0, 1, (n, 4))
e_true = 1 / (1 + np.exp(-(X @ [0.3, -0.2, 0.1, 0])))
T = np.random.binomial(1, e_true, n)
tau = 2.0 + 1.5 * X[:, 0]
Y = X @ [1, 0.5, -0.3, 0.2] + tau * T + np.random.normal(0, 1, n)

# Step 1: 뉘앙스 모델 추정
m_model = GradientBoostingRegressor(n_estimators=100).fit(X, Y)
e_model = GradientBoostingClassifier(n_estimators=100).fit(X, T)
m_hat = m_model.predict(X)
e_hat = e_model.predict_proba(X)[:, 1]
e_hat = np.clip(e_hat, 0.05, 0.95)

# Step 2: 잔차 계산
Y_resid = Y - m_hat
T_resid = T - e_hat

# Step 3: CATE 추정 (가중 회귀)
# tau(X) 추정을 위한 가중 최소제곱
weights = T_resid ** 2
pseudo_outcome = Y_resid / T_resid
tau_model = GradientBoostingRegressor(n_estimators=100).fit(
    X, pseudo_outcome, sample_weight=weights
)
cate_r = tau_model.predict(X)
print(f"R-Learner ATE: {cate_r.mean():.3f}")
print(f"진정한 ATE: {tau.mean():.3f}")
```

---

## 5. CATE 추정의 평가

CATE 추정의 평가는 개인 수준의 진정한 효과를 관측할 수 없기 때문에 일반적인 예측 문제보다 어렵습니다.

$$
\text{PEHE} = E[(\hat{\tau}(X) - \tau(X))^2] \quad \text{(관측 불가)}
$$

| 평가 방법 | 적용 조건 | 설명 |
|----------|----------|------|
| 시뮬레이션 | 합성 데이터 | $\tau(x)$ 알려짐, PEHE 직접 계산 |
| IHDP/ACIC 벤치마크 | 반합성 데이터 | 표준 비교 데이터셋 |
| 처치군 내 검증 | RCT 데이터 | $\hat{\tau}$ 기준 그룹 분할 후 효과 비교 |
| RATE (Ranked ATE) | 관측 데이터 | 추정 CATE 순위별 ATE 비교 |

> **핵심 직관**: CATE 추정의 정확도를 직접 검증하는 것은 근본적으로 어렵습니다. 실무에서는 추정된 CATE로 그룹을 나눈 후, 그룹별 ATE가 단조적으로 변하는지를 간접적으로 검증합니다.

```python
import numpy as np

# CATE 평가: 시뮬레이션에서 PEHE 계산
np.random.seed(42)
n = 2000
X = np.random.normal(0, 1, (n, 3))
tau_true = 2.0 + 1.0 * X[:, 0] - 0.5 * X[:, 1]

# 가상의 추정 CATE
tau_hat = 2.1 + 0.9 * X[:, 0] - 0.4 * X[:, 1] + np.random.normal(0, 0.3, n)

pehe = np.sqrt(np.mean((tau_hat - tau_true) ** 2))
print(f"PEHE (Root): {pehe:.3f}")

# 순위 기반 평가: CATE 상위 vs 하위 그룹의 실제 ATE 비교
q25, q75 = np.percentile(tau_hat, [25, 75])
print(f"\nCATE 상위 25% (진정한 CATE): {tau_true[tau_hat > q75].mean():.3f}")
print(f"CATE 하위 25% (진정한 CATE): {tau_true[tau_hat < q25].mean():.3f}")
print("→ 상위 그룹의 진정한 효과가 더 크면 추정이 양호")
```

---

## 6. 이질적 효과의 실무 활용

CATE 추정은 다양한 실무 영역에서 의사결정을 개선합니다.

| 분야 | 활용 | 구체적 적용 |
|------|------|-----------|
| 의학 | 개인화 치료 | 환자 특성별 약물 선택 |
| 마케팅 | 타겟팅 최적화 | ci-12의 업리프트 모델링 |
| 교육 | 맞춤형 교육 | 학습 방법의 차별적 효과 |
| 정책 | 보조금 배분 | 한계 효과가 큰 대상 선정 |

> **핵심 직관**: CATE를 활용한 최적 처치 규칙 $d^*(x) = \mathbb{1}(\hat{\tau}(x) > c)$은 제한된 자원을 효과가 가장 큰 대상에게 집중할 수 있게 합니다. ci-12에서 이를 실전에 적용하는 방법을 다룹니다.

---

## 핵심 정리

- **CATE $\tau(x) = E[Y(1) - Y(0) \mid X=x]$는 개인 특성에 따라 달라지는 인과 효과입니다**: ATE만으로는 "누구에게" 처치해야 하는지 알 수 없습니다
- **S/T/X-Learner는 기존 ML 알고리즘을 활용한 CATE 추정 메타러너입니다**: 각각 단일 모델, 이중 모델, 교차 학습 전략을 사용합니다
- **인과 포레스트는 효과 이질성을 기준으로 분할하며, 정직한 추정으로 유효한 신뢰 구간을 제공합니다**
- **R-Learner는 직교화를 통해 뉘앙스 파라미터의 추정 오차에 강건한 CATE 추정을 제공합니다**: ci-11의 이중 머신러닝과 밀접하게 연결됩니다
- **CATE 추정의 평가는 개인 수준 진정한 효과를 관측할 수 없어 근본적으로 어렵지만, 순위 기반 검증으로 간접적으로 평가할 수 있습니다**
