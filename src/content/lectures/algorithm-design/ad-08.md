# 랜덤화 알고리즘

## 왜 랜덤화가 중요한가

"무작위성이 알고리즘을 더 빠르고 단순하게 만든다"—직관에 반하지만 사실입니다. Randomized QuickSort는 최악 피벗을 피하고, Karger의 Min-Cut은 놀랍도록 간단하게 최소 컷을 찾으며, ads-07의 해싱은 랜덤화의 가장 흔한 응용입니다. 랜덤화는 적대적 입력(adversarial input)에 대한 강력한 방어이며, 분산 시스템과 암호학의 기반입니다.

> **핵심 직관**: 랜덤화 알고리즘의 두 가지 유형을 구분해야 합니다. **Las Vegas**는 "항상 정확, 시간이 랜덤"이고, **Monte Carlo**는 "항상 빠름, 정확도가 랜덤"입니다. 대부분의 실무 랜덤화는 Las Vegas(QuickSort, 해싱)입니다.

## 1. Las Vegas vs Monte Carlo

```
Las Vegas 알고리즘:
  항상 올바른 결과, 실행 시간이 확률적
  기대 시간은 좋지만 최악은 나쁠 수 있음

  예: Randomized QuickSort
  항상 정렬된 배열 반환
  기대 O(N log N), 최악 O(N²) (극히 낮은 확률)

Monte Carlo 알고리즘:
  항상 빠르게 종료, 결과가 확률적으로 정확
  오류 확률을 반복으로 줄일 수 있음

  예: Karger Min-Cut
  높은 확률로 최소 컷 반환 (아닐 수도 있음)
  한 번 실행: 성공 확률 ≥ 2/n²
  O(n²) 반복: 성공 확률 → 1 - 1/e

  오류 유형:
  ├─ 단측 오류: "YES"면 항상 정확, "NO"는 틀릴 수 있음
  │   (RP, co-RP)
  └─ 양측 오류: 둘 다 틀릴 수 있지만 확률 < 1/3
      (BPP)
```

## 2. Randomized QuickSort

```python
import random

def randomized_quicksort(arr):
    if len(arr) <= 1:
        return arr
    pivot = random.choice(arr)  # 랜덤 피벗!
    left = [x for x in arr if x < pivot]
    middle = [x for x in arr if x == pivot]
    right = [x for x in arr if x > pivot]
    return randomized_quicksort(left) + middle + randomized_quicksort(right)
```

```
왜 랜덤 피벗이 중요한가?

  결정적 QuickSort (첫 원소 피벗):
  정렬된 배열 → 매번 1:N-1 분할 → O(N²)
  적대적 입력이 존재!

  랜덤 피벗:
  어떤 입력에도 기대 O(N log N)
  "나쁜 피벗"이 연속될 확률이 기하급수적으로 감소

  분석:
  "좋은 피벗" = 25%~75% 사이로 분할
  → 원소의 50%가 좋은 피벗
  → 2번 중 1번은 좋은 피벗
  → O(log N)번의 좋은 분할이면 충분
  → 기대 O(2 log N) = O(log N) 레벨
  → 기대 O(N log N)

  높은 확률 보장:
  P[시간 > cN log N] ≤ 1/N^c
  → "사실상 항상" O(N log N)
```

> **핵심 직관**: Randomized QuickSort가 결정적 버전보다 우월한 이유는 **"적대적 입력이 불가능"**하기 때문입니다. 결정적 알고리즘은 최악 입력을 만들 수 있지만, 랜덤 알고리즘은 입력에 무관하게 좋은 성능을 보입니다.

## 3. Karger의 최소 컷

```
Karger's Min-Cut: 간선 수축(Contraction) 기반

  알고리즘:
  1. 랜덤 간선 (u, v) 선택
  2. u와 v를 하나의 노드로 합침 (수축)
  3. 자기 루프 제거, 다중 간선 유지
  4. 노드가 2개 남을 때까지 반복
  5. 남은 간선 수 = 컷 크기

  def karger_min_cut(graph):
      while len(graph.nodes) > 2:
          u, v = random.choice(graph.edges)
          contract(graph, u, v)
      return count_edges(graph)

  성공 확률: ≥ 2 / (n(n-1)) ≈ 2/n²

  증명:
  최소 컷 크기 = k, 최소 컷 간선 = C
  각 단계에서 C의 간선을 뽑지 않을 확률:
  1 - k/(총 간선 수) ≥ 1 - k/(nk/2) = 1 - 2/n
  n-2번 반복:
  Π(1 - 2/i) for i=n to 3 = 2/(n(n-1))
```

```
Karger-Stein 개선:

  관찰: 초기에는 컷 간선을 뽑을 확률이 낮음
        후반에 갈수록 위험
  → 초반은 수축, 후반에 분기(재귀)

  Karger-Stein:
  1. N/√2개 노드까지 수축 (빠름)
  2. 두 번 독립 반복 (분기)
  3. 재귀적으로 반복

  성공 확률: O(1/log n)
  반복 횟수: O(log n)이면 높은 확률
  총 시간: O(N² log³ N)

  ga-04의 결정적 Max-Flow와 비교:
  Dinic: O(V²E) — 항상 정확
  Karger-Stein: O(N² log³ N) — 높은 확률로 정확
  희소 그래프에서 Karger가 더 빠를 수 있음
```

## 4. 랜덤화 해싱

```
Universal Hashing (ads-07 복습):

  해시 충돌을 확률적으로 보장
  해시 함수 패밀리 H에서 랜덤 선택:
  P[h(x) = h(y)] ≤ 1/m (x ≠ y일 때)

  응용:
  ├─ 해시 테이블: 기대 O(1) 연산
  ├─ Bloom Filter (ads-04): 거짓 양성 확률 제어
  └─ Count-Min Sketch (ads-04): 빈도 추정

Reservoir Sampling:
  스트림에서 K개 원소를 균등 확률로 샘플링
  각 원소를 정확히 K/i 확률로 선택

  def reservoir_sample(stream, k):
      reservoir = []
      for i, item in enumerate(stream):
          if i < k:
              reservoir.append(item)
          else:
              j = random.randint(0, i)
              if j < k:
                  reservoir[j] = item
      return reservoir

  증명: 각 원소가 최종 결과에 있을 확률 = k/n (균등)
```

> **핵심 직관**: Universal Hashing의 핵심은 **"해시 함수를 랜덤으로 선택"**하는 것입니다. 특정 해시 함수에 대한 최악 입력이 있어도, 랜덤 선택이면 적대적 입력을 만들 수 없습니다. Randomized QuickSort의 "랜덤 피벗"과 같은 원리입니다.

## 5. 확률적 분석 기법

```
기대값의 선형성 (Linearity of Expectation):

  E[X₁ + X₂ + ... + Xₙ] = E[X₁] + ... + E[Xₙ]
  독립이 아니어도 성립!

  응용: QuickSort 비교 횟수
  Xᵢⱼ = 원소 i와 j가 비교되면 1, 아니면 0
  E[비교 횟수] = Σᵢ<ⱼ E[Xᵢⱼ] = Σᵢ<ⱼ 2/(j-i+1)
  = O(N log N)

Markov 부등식:
  P[X ≥ a] ≤ E[X] / a (X ≥ 0)

Chebyshev 부등식:
  P[|X - E[X]| ≥ a] ≤ Var[X] / a²

Chernoff Bound:
  X = Σ Xᵢ (독립 베르누이)
  P[X ≥ (1+δ)μ] ≤ exp(-δ²μ/3)
  → "기대값에서 크게 벗어날 확률이 지수적으로 작음"
  → 랜덤 알고리즘의 "높은 확률" 보장의 핵심 도구
```

## 6. 실전 응용

```
응용 1: 소수 판별 (Miller-Rabin)
  입력: n이 소수인가?
  Monte Carlo: O(k log²n) — k번 반복으로 오류 4^{-k}
  → 암호학에서 표준 (충분히 큰 k면 "사실상" 정확)

응용 2: 랜덤 워크와 MCMC
  그래프 위 랜덤 워크 → 정상 분포 수렴
  → PageRank (ga-11), 베이지안 추론 (pt-14)

응용 3: Skip List (ads-05)
  삽입/삭제/검색 기대 O(log N)
  랜덤 레벨 할당으로 균형 유지

응용 4: 랜덤화 환원
  MAX-SAT: 각 변수를 랜덤 True/False → 3/4-근사 (ad-07)
  MAX-CUT: 각 노드를 랜덤 분할 → 1/2-근사
  → 놀랍도록 간단한 랜덤 배정이 좋은 근사비!

알고리즘 선택:
  적대적 입력 우려 → 랜덤화 (QuickSort, 해싱)
  NP-hard 근사 → 랜덤 반올림 (MAX-SAT)
  대규모 데이터 → 확률적 자료구조 (ads-04)
  스트리밍 → Reservoir Sampling, 스케치
```

랜덤화는 ads-04의 확률적 자료구조, ads-05의 스킵 리스트, ads-07의 해싱에서 기반 원리이며, pt-09의 확률 부등식이 분석 도구를 제공합니다.

## 핵심 정리

- **Las Vegas**는 "항상 정확, 시간이 랜덤"(QuickSort), **Monte Carlo**는 "항상 빠름, 정확도가 랜덤"(Karger, Miller-Rabin)입니다
- **Randomized QuickSort**는 랜덤 피벗으로 적대적 입력을 방지하며, 기대 $O(N \log N)$을 모든 입력에 보장합니다
- **Karger Min-Cut**은 랜덤 간선 수축으로 성공 확률 $\geq 2/n^2$이며, $O(n^2)$번 반복으로 높은 확률의 정확성을 달성합니다
- **기대값의 선형성**과 **Chernoff Bound**가 랜덤 알고리즘 분석의 핵심 도구입니다
- 랜덤화의 핵심 가치는 **적대적 입력 방어**이며, "랜덤 선택이면 최악 입력을 만들 수 없다"는 원리가 해싱/정렬/탐색에 공통적으로 적용됩니다
