# 병렬 알고리즘

## 왜 병렬 알고리즘이 중요한가

무어의 법칙이 단일 코어 성능에서 멀티코어로 전환된 지 오래입니다. CPU는 수십 코어, GPU는 수천 코어를 가지며, 분산 시스템은 수만 노드를 동원합니다. **병렬 알고리즘(Parallel Algorithm)**은 이 자원을 효과적으로 활용하는 방법을 다룹니다. ad-01의 분할 정복은 자연스러운 병렬화 대상이며, ga-11의 분산 그래프 처리도 병렬 알고리즘의 응용입니다.

> **핵심 직관**: 병렬 알고리즘의 핵심 제약은 **"순차적 병목(Sequential Bottleneck)"**입니다. 아무리 프로세서가 많아도, 순차적으로만 처리 가능한 부분이 전체 속도를 제한합니다. **Work-Span 모델**에서 span(가장 긴 순차 경로)이 병렬 시간의 하한입니다.

## 1. PRAM 모델

```
PRAM (Parallel Random Access Machine):

  p개 프로세서가 공유 메모리에 동시 접근
  각 단계: 모든 프로세서가 하나의 연산 수행

  메모리 접근 충돌 해결:
  ├─ EREW (Exclusive Read, Exclusive Write):
  │   동시 읽기/쓰기 불가 → 가장 제한적
  ├─ CREW (Concurrent Read, Exclusive Write):
  │   동시 읽기 가능, 동시 쓰기 불가 → 가장 일반적
  └─ CRCW (Concurrent Read, Concurrent Write):
      동시 쓰기도 가능 (충돌 규칙 필요)
      → 가장 강력하지만 비현실적

  CRCW 충돌 규칙:
  ├─ Common: 같은 값만 동시 쓰기
  ├─ Arbitrary: 하나가 랜덤으로 성공
  └─ Priority: 번호 낮은 프로세서 우선

  PRAM은 이론적 모델!
  실제: 메모리 지연, 동기화 비용, 통신 오버헤드
  하지만 병렬 가능성의 상한을 분석하는 데 유용
```

## 2. Work-Span 모델

```
Work-Span (Work-Depth) 모델:

  Work (W): 모든 연산의 총 수 = 순차 시간
  Span (S): 가장 긴 의존성 경로 = 무한 프로세서 시 시간

  병렬 시간 (p 프로세서):
  T_p = W/p + S (Brent's Theorem)

  병렬도 (Parallelism):
  W/S = 유용하게 쓸 수 있는 최대 프로세서 수

  예: 병합 정렬
  W = O(N log N)  (총 연산 수)
  S = O(log² N)   (가장 긴 경로: 분할 log N + 합치기 log N)
  병렬도 = N log N / log² N = N / log N
  → 100만 원소: ~50,000 프로세서까지 유효

  예: 배열 합산
  W = O(N)
  S = O(log N)
  병렬도 = N / log N
  → 자연스러운 트리 형태의 축소

  | 알고리즘 | Work | Span | 병렬도 |
  |---------|------|------|--------|
  | 배열 합 | O(N) | O(log N) | N/log N |
  | 병합 정렬 | O(N log N) | O(log²N) | N/log N |
  | 행렬 곱 | O(N³) | O(log N) | N³/log N |
  | BFS | O(V+E) | O(D log V) | (V+E)/(D log V) |
```

> **핵심 직관**: **Work-Optimal**이란 "병렬 알고리즘의 총 연산 수가 최선의 순차 알고리즘과 같다"는 의미입니다. Work가 같으면 프로세서를 추가해도 총 일은 늘지 않으므로, 순수하게 속도만 개선됩니다. Work-optimal + 짧은 Span이 이상적입니다.

## 3. Parallel Prefix (Prefix Sum)

```
Prefix Sum (Scan): 병렬 알고리즘의 기본 빌딩 블록

  입력: [a₁, a₂, a₃, a₄, a₅, a₆, a₇, a₈]
  출력: [a₁, a₁+a₂, a₁+a₂+a₃, ..., a₁+...+a₈]

  순차: O(N)
  병렬: Work O(N), Span O(log N)

  Up-Sweep (Reduce):
  Level 0: [1, 2, 3, 4, 5, 6, 7, 8]
  Level 1: [-, 3, -, 7, -, 11, -, 15]
  Level 2: [-, -, -, 10, -, -, -, 26]
  Level 3: [-, -, -, -, -, -, -, 36]

  Down-Sweep (Distribute):
  Level 3: [-, -, -, -, -, -, -, 0]
  Level 2: [-, -, -, 0, -, -, -, 10]
  Level 1: [-, 0, -, 3, -, 10, -, 15]
  Level 0: [0, 1, 3, 6, 10, 15, 21, 28]
  → exclusive prefix sum

  총: 2 × O(N) work, 2 × O(log N) span
  → Work-optimal!
```

```python
# 개념적 병렬 Prefix Sum
def parallel_prefix_sum(arr):
    n = len(arr)
    # Up-sweep
    temp = arr[:]
    stride = 1
    while stride < n:
        # 병렬: 모든 i에서 temp[i] += temp[i - stride]
        for i in range(stride * 2 - 1, n, stride * 2):
            temp[i] += temp[i - stride]
        stride *= 2

    # Down-sweep
    temp[n - 1] = 0
    stride = n // 2
    while stride >= 1:
        for i in range(stride * 2 - 1, n, stride * 2):
            left = temp[i - stride]
            temp[i - stride] = temp[i]
            temp[i] += left
        stride //= 2
    return temp
```

```
Prefix Sum의 응용:

  Prefix Sum은 "순차적 의존성이 있는 계산을 병렬화"하는
  핵심 도구이며, 수많은 병렬 알고리즘의 빌딩 블록입니다.

  ├─ Parallel Filter: 조건 만족 원소만 추출
  │   flags = [1 if cond(x) else 0 for x in arr]
  │   indices = prefix_sum(flags) → 각 원소의 출력 위치
  ├─ Parallel Sort (Radix Sort): 비트별 prefix sum
  ├─ 다항식 평가: Horner's + parallel prefix
  ├─ 구간 쿼리: prefix sum → O(1) 구간 합
  └─ GPU 프로그래밍: CUDA의 scan 프리미티브
```

## 4. 병렬 알고리즘 패턴

```
패턴 1: Divide and Conquer (ad-01)
  자연스러운 병렬화 — 부분 문제가 독립
  병합 정렬: 분할 후 두 반을 병렬 재귀
  최근접 점 쌍: 좌/우 반을 병렬 처리

패턴 2: Map-Reduce
  Map: 각 원소에 독립적 함수 적용 (완전 병렬)
  Reduce: 결과를 트리 구조로 합산 (O(log N) span)

  word_count:
    Map: 각 문서에서 (단어, 1) 쌍 생성
    Reduce: 같은 단어의 카운트 합산

  dp-02의 Apache Spark: 이 패턴의 분산 구현

패턴 3: Parallel Graph Algorithms
  BFS: 레벨별 병렬 처리 (ga-01)
  → 같은 레벨의 노드를 동시 탐색
  → Span = O(D × log V), D = 그래프 직경

  PageRank: 각 노드 독립 갱신 (ga-11 Pregel)
  → 수렴까지 O(log N) 반복 × O(V+E)/p per 반복

패턴 4: 행렬 연산
  행렬 곱: 각 원소 독립 계산 → W=O(N³), S=O(log N)
  → GPU에서 매우 효율적 (dl-01 역전파)
```

## 5. Amdahl의 법칙과 한계

```
Amdahl의 법칙:

  프로그램의 순차 부분 비율 = s
  병렬 가능 부분 = 1 - s

  p 프로세서로의 최대 속도 향상:
  Speedup ≤ 1 / (s + (1-s)/p)

  p → ∞이면:
  Speedup ≤ 1/s

  예: s = 5% (순차 부분 5%)
  최대 속도 향상 = 1/0.05 = 20배
  100 코어: 1/(0.05 + 0.95/100) ≈ 17배
  1000 코어: 1/(0.05 + 0.95/1000) ≈ 19.6배
  → 100코어 이후 개선 미미!

  Gustafson의 법칙 (반론):
  문제 크기를 키우면 병렬 부분이 증가
  "더 큰 문제를 같은 시간에 풀 수 있다"
  → Amdahl보다 낙관적인 관점

  실무 한계:
  ├─ 동기화 오버헤드: 락, 배리어
  ├─ 통신 비용: 프로세서 간 데이터 교환
  ├─ 로드 밸런싱: 작업 불균형
  └─ 메모리 경합: 캐시 일관성 프로토콜
```

> **핵심 직관**: Amdahl의 법칙의 교훈은 **"순차 병목이 1%라도 있으면 100배 이상 속도 향상은 불가"**하다는 것입니다. 병렬 알고리즘 설계에서 순차 부분(span)을 줄이는 것이 프로세서를 늘리는 것보다 중요합니다.

## 6. 실전 병렬 프레임워크

```
프레임워크별 특성:

  멀티스레드 (공유 메모리):
  ├─ OpenMP: #pragma 기반, 간단
  ├─ Java Streams: .parallel() 추가
  ├─ Python multiprocessing: GIL 회피
  └─ 적합: 단일 머신, 코어 수 수십 개

  GPU (SIMD):
  ├─ CUDA: NVIDIA GPU 직접 프로그래밍
  ├─ PyTorch/TensorFlow: 텐서 연산 자동 병렬
  └─ 적합: 행렬 연산, 딥러닝 (dl-01)

  분산 (메시지 패싱):
  ├─ MPI: 프로세스 간 메시지 교환
  ├─ Spark: RDD/DataFrame 기반 분산
  ├─ Pregel/GraphX: 그래프 병렬 (ga-11)
  └─ 적합: 대규모 데이터, 수백~수천 노드

  선택 기준:
  데이터 < 1GB: 멀티스레드 충분
  행렬/텐서: GPU (PyTorch)
  데이터 > 100GB: Spark
  그래프: GraphX / Pregel
```

병렬 알고리즘은 ad-01의 분할 정복(자연스러운 병렬화), ga-11의 분산 그래프 처리, dp-02의 Spark/MapReduce와 직접 연결됩니다.

## 핵심 정리

- **Work-Span 모델**에서 Work는 총 연산 수, Span은 가장 긴 순차 경로이며, 병렬 시간은 $T_p \leq W/p + S$입니다
- **Parallel Prefix Sum**은 $O(N)$ work, $O(\log N)$ span으로 병렬 알고리즘의 핵심 빌딩 블록이며, 필터/정렬/쿼리에 활용됩니다
- **Amdahl의 법칙**에 의해 순차 부분 비율 $s$가 속도 향상의 상한 $1/s$를 결정하며, span 최소화가 프로세서 추가보다 중요합니다
- **Work-optimal**은 병렬 총 연산이 순차 최선과 같다는 의미이며, Work-optimal + 짧은 Span이 이상적인 병렬 알고리즘입니다
- 실무에서는 멀티스레드(OpenMP), GPU(CUDA/PyTorch), 분산(Spark/MPI)을 데이터 크기와 연산 유형에 따라 선택합니다
