# 추론 능력과 에이전트

## 왜 추론과 에이전트가 중요한가

LLM이 "다음 토큰 예측"에서 시작했지만, 이제 **복잡한 추론, 도구 사용, 자율적 행동**을 수행합니다. CoT가 수학 추론을 가능하게 했다면, Tool Use는 계산기와 검색 엔진을 쓸 수 있게 했고, 에이전트 아키텍처는 여러 단계의 계획과 실행을 자율적으로 수행합니다. 이 강의에서는 LLM의 추론 능력과 에이전트의 현재와 미래를 다룹니다.

> **핵심 직관**: LLM 에이전트의 핵심 질문은 **"LLM이 단순한 텍스트 생성기에서 자율적 문제 해결자로 진화할 수 있는가?"**입니다. 현재 에이전트는 "도구를 쓸 수 있는 LLM"이지만, 궁극적으로는 "계획하고, 실행하고, 반성하고, 적응하는 시스템"을 지향합니다.

## 1. LLM의 추론 능력

```
추론 능력의 계층:

  Level 1: 패턴 매칭
  "파리는 ___의 수도" → "프랑스"
  학습 데이터의 패턴 재현, 진정한 추론 아님

  Level 2: 단일 단계 추론
  "모든 고양이는 동물. 톰은 고양이. 톰은 ___?" → "동물"
  삼단논법, 단순한 논리적 추론

  Level 3: 다단계 추론
  "5+3=8, 8×2=16, 16-4=?" → "12"
  연쇄적 계산, CoT로 개선 (nlp-09)

  Level 4: 계획과 탐색
  "이 코드의 버그를 찾아 수정하라"
  가설 생성 → 검증 → 수정의 반복

  Level 5: 메타인지
  "이 문제를 풀 수 있는지 판단하라"
  자기 능력의 한계 인식 — 현재 매우 약함

추론의 한계:

  1. 산술 추론:
     단순: "25 × 4 = ?" → 100 (대부분 정확)
     복잡: "17 × 38 = ?" → 환각 가능
     → 토크나이제이션 문제 (nlp-05)
     → 해결: Calculator 도구 사용

  2. 논리 추론:
     모순 탐지 가능하지만 불완전
     긴 논증에서 일관성 유지 어려움

  3. 공간 추론:
     "왼쪽에서 3번째와 오른쪽에서 2번째가 같은 자리?"
     → 시각적/공간적 추론에 약함

  4. 반사실적 추론:
     "만약 중력이 없다면?" → 패턴에 없는 상황
     → ci-01의 인과 추론과 연결
```

## 2. Tool Use (도구 사용)

```
Tool Use의 필요성:

  LLM의 약점을 외부 도구로 보완:
  ├─ 계산: Calculator, Python 실행
  ├─ 검색: 웹 검색, 데이터베이스 쿼리
  ├─ 코드: 코드 실행, 테스트 실행
  ├─ API: 날씨, 주식, 일정 관리
  └─ 파일: 읽기, 쓰기, 분석

Function Calling 메커니즘:

  1. 도구 정의:
     tools = [
       {"name": "search",
        "description": "Search the web",
        "parameters": {"query": "string"}},
       {"name": "calculator",
        "description": "Evaluate math expression",
        "parameters": {"expression": "string"}}
     ]

  2. LLM이 도구 호출 결정:
     사용자: "2024년 한국 GDP의 제곱근은?"
     LLM: → search("2024년 한국 GDP")
     결과: "약 1.7조 달러"
     LLM: → calculator("sqrt(1700000000000)")
     결과: "1303840"
     LLM: "약 1,303,840입니다."

  3. 병렬 도구 호출:
     여러 도구를 동시에 호출
     → 지연시간 감소

도구 선택의 학습:
  ├─ 파인튜닝: (질문, 도구 호출, 결과, 답변) 데이터로
  ├─ 프롬프트: 도구 설명을 시스템 프롬프트에
  └─ Few-shot: 도구 사용 예시 제공
```

## 3. 에이전트 아키텍처

```
기본 에이전트 루프:

  while not done:
    1. 관찰 (Observe): 현재 상태 파악
    2. 생각 (Think): 다음 행동 계획
    3. 행동 (Act): 도구 사용 또는 응답
    4. 평가 (Evaluate): 결과 확인
    → 목표 달성 시 종료

  ReAct 패턴 (nlp-09):
  Thought → Action → Observation → Thought → ...

주요 에이전트 프레임워크:

  1. Single Agent:
     하나의 LLM이 모든 것을 처리
     간단하지만 복잡한 태스크에 한계
     → 작은 태스크에 적합

  2. Multi-Agent:
     여러 전문 에이전트가 협력
     ├─ Planner: 태스크 분해
     ├─ Coder: 코드 작성
     ├─ Reviewer: 코드 검토
     └─ Tester: 테스트 실행

     예: ChatDev, MetaGPT — "가상 소프트웨어 회사"
     각 에이전트가 PM, 개발자, 테스터 역할

  3. Hierarchical Agent:
     상위 에이전트가 하위 에이전트에게 위임
     CEO → Manager → Worker 구조

  | 구조 | 복잡도 | 적합한 태스크 |
  |------|--------|-------------|
  | Single | 낮음 | 단순 Q&A, 검색 |
  | Multi | 중간 | 소프트웨어 개발, 연구 |
  | Hierarchical | 높음 | 복잡한 프로젝트 |
```

> **핵심 직관**: 에이전트의 핵심 도전은 **"계획의 정확성"**입니다. LLM은 한 단계의 추론은 잘하지만, 10단계 계획에서 각 단계가 90% 정확하면 전체 성공률은 $0.9^{10} \approx 35\%$입니다. 이 "복합 오류"가 에이전트의 신뢰성을 제한하는 근본 원인입니다.

## 4. Planning과 메모리

```
Planning (계획):

  1. 태스크 분해 (Task Decomposition):
     복잡한 태스크를 하위 태스크로 분해
     "웹사이트 만들기" → [요구사항 분석, UI 설계,
      프론트엔드 구현, 백엔드 구현, 테스트, 배포]

  2. 계획 생성:
     LLM이 단계별 계획 생성
     → 계획의 질이 최종 결과를 좌우

  3. 적응적 재계획:
     실행 중 오류 → 계획 수정
     → 반성(Reflection) + 재계획

  Reflexion (Shinn et al., 2023):
  실패 후 "왜 실패했는가?" 반성
  → 반성 결과를 다음 시도에 반영
  → 인간의 학습 과정과 유사

메모리 시스템:

  1. 작업 메모리 (Working Memory):
     현재 문맥 창의 내용
     → 대화 이력, 검색 결과, 중간 결과
     → 문맥 창 제한이 병목

  2. 단기 메모리 (Short-term Memory):
     현재 세션의 대화 이력
     → 대화 요약으로 압축

  3. 장기 메모리 (Long-term Memory):
     세션 간 지속되는 정보
     ├─ 벡터 DB에 경험/지식 저장
     ├─ 구조화된 지식 그래프
     └─ 사용자 프로필/선호도

  4. 절차적 메모리 (Procedural Memory):
     성공한 전략/패턴의 저장
     "이런 유형의 문제는 이렇게 풀었다"
     → 미래 태스크에 재활용
```

## 5. 에이전트의 실전 응용

```
코딩 에이전트:
  ├─ SWE-Agent: GitHub 이슈를 자동으로 해결
  │   파일 탐색 → 버그 이해 → 수정 → 테스트
  │   SWE-bench에서 12%+ 해결률 (GPT-4)
  ├─ Devin: 자율 소프트웨어 엔지니어
  │   코드 편집기, 브라우저, 터미널 사용
  └─ Claude Code, Cursor: 대화형 코딩 에이전트

연구 에이전트:
  ├─ 논문 검색, 요약, 분석 자동화
  ├─ 실험 설계와 코드 작성
  └─ 문헌 리뷰 보조

데이터 분석 에이전트:
  ├─ 데이터 로드 → 탐색 → 분석 → 시각화
  ├─ Python/SQL 코드 자동 생성 및 실행
  └─ 인사이트 도출과 보고서 작성

웹 브라우징 에이전트:
  ├─ 웹 페이지 탐색, 폼 작성, 클릭
  ├─ 정보 수집과 비교
  └─ 온라인 작업 자동화

  현재 에이전트의 성능:
  ├─ 단순 태스크 (검색+답변): 높은 성공률 (80%+)
  ├─ 중간 태스크 (코드 수정): 중간 (30-50%)
  ├─ 복잡 태스크 (프로젝트 구현): 낮음 (<20%)
  └─ 인간 감독 필요: 현재 모든 수준에서 권장
```

## 6. LLM의 한계와 미래 방향

```
현재 한계:

  1. 추론 깊이:
     복잡한 수학 증명, 장기 계획에서 한계
     → Test-time compute로 부분 해결 (더 오래 생각)

  2. 세계 모델:
     물리적 세계에 대한 이해 부족
     "컵을 뒤집으면 물이 어떻게 되는가?" → 종종 실패
     → 멀티모달 학습(mm-01~12)으로 보완

  3. 일관성:
     긴 대화에서 자기 모순
     → 메모리 시스템으로 완화

  4. 신뢰성:
     에이전트의 행동을 100% 신뢰할 수 없음
     → Human-in-the-loop 필수

미래 방향:

  1. o1/o3 스타일 추론:
     추론 시간에 더 많은 계산을 투자
     "빠르게 대충" → "느리지만 정확하게"
     → 수학, 코딩에서 큰 성능 향상

  2. 자기 개선 (Self-Improvement):
     에이전트가 자체 경험에서 학습
     → 실패 → 반성 → 개선 → 재시도

  3. 전문화:
     범용 에이전트보다 도메인 전문 에이전트
     의료, 법률, 금융 등 특화 에이전트

  4. 협업:
     인간-AI 협업 최적화
     AI가 80%를 처리하고 인간이 20%를 검증
     → 생산성 극대화

  5. 안전성:
     에이전트의 행동 범위 제한
     되돌릴 수 없는 행동에 대한 확인
     → responsible-ai에서 다루는 거버넌스

  NLP/LLM 분야의 전체 요약:
  nlp-01 텍스트 표현 → nlp-03 Transformer → nlp-06 스케일링
  → nlp-08 정렬 → nlp-10 RAG → nlp-14 에이전트

  "텍스트 분류 도구"에서 "자율적 문제 해결자"로의 진화
  이 진화의 방향과 한계를 이해하는 것이
  AI 엔지니어의 핵심 역량입니다.
```

> **핵심 직관**: LLM 에이전트의 미래는 **"독립적 실행"이 아니라 "인간과의 효과적 협업"**에 있습니다. 현재 LLM은 모든 것을 자율적으로 하기에는 불완전하지만, 인간의 생산성을 몇 배로 높이기에는 충분합니다. "AI가 인간을 대체"가 아니라 "AI가 인간을 증강"하는 방향이 현실적이고 가치 있습니다.

## 핵심 정리

- LLM의 추론 능력은 패턴 매칭부터 다단계 추론까지 계층적이며, **산술, 공간, 반사실 추론**에서 여전히 한계가 있습니다
- **Tool Use**는 LLM의 약점(계산, 검색, 코드 실행)을 외부 도구로 보완하며, Function Calling이 표준 인터페이스입니다
- 에이전트 아키텍처는 **관찰→생각→행동→평가** 루프로, 단일/다중/계층적 구조가 태스크 복잡도에 따라 선택됩니다
- **Planning과 메모리**가 에이전트의 핵심 모듈이며, 복합 오류($0.9^{10} \approx 35\%$)가 신뢰성의 근본 제약입니다
- LLM의 미래는 **test-time compute 확대, 자기 개선, 도메인 전문화, 인간-AI 협업**의 방향이며, 안전한 에이전트 설계가 핵심 과제입니다
