# 직교성과 투영

## 왜 직교성과 투영을 배워야 하는가

최소제곱법(least squares)의 기하학적 본질은 **투영(projection)**입니다. 데이터 $\mathbf{y}$를 열 공간에 투영하면 최적의 예측 $\hat{\mathbf{y}}$를 얻고, 투영 오차 $\mathbf{y} - \hat{\mathbf{y}}$가 최소가 됩니다. QR 분해는 수치적으로 안정한 최소제곱 풀이의 핵심이며, Gram-Schmidt 과정은 직교 기저를 만드는 기본 알고리즘입니다.

---

## 1. 직교와 정규직교

### 직교 (Orthogonal)

두 벡터 $\mathbf{u}, \mathbf{v}$가 **직교**한다 함은,

$$
\mathbf{u}^T\mathbf{v} = 0 \quad (\mathbf{u} \perp \mathbf{v})
$$

### 정규직교 (Orthonormal)

직교이면서 각 벡터의 노름이 1인 경우입니다.

$$
\mathbf{u}_i^T\mathbf{u}_j = \delta_{ij} = \begin{cases} 1 & i = j \\ 0 & i \neq j \end{cases}
$$

### 직교 행렬 (Orthogonal Matrix)

열 벡터가 정규직교인 정방행렬 $Q$입니다.

$$
Q^TQ = QQ^T = I \implies Q^{-1} = Q^T
$$

> **핵심 직관**: 직교 행렬은 **회전과 반사**만 수행합니다. 벡터의 길이와 각도를 보존하므로, 수치적으로 매우 안정적입니다. $Q^{-1} = Q^T$라서 역행렬 계산이 공짜입니다.

---

## 2. Gram-Schmidt 과정

임의의 선형 독립 벡터 $\{\mathbf{a}_1, \ldots, \mathbf{a}_k\}$를 정규직교 벡터 $\{\mathbf{q}_1, \ldots, \mathbf{q}_k\}$로 변환하는 알고리즘입니다.

### 알고리즘

**Step 1**: $\mathbf{q}_1 = \mathbf{a}_1 / \|\mathbf{a}_1\|$

**Step 2**: $\mathbf{a}_2$에서 $\mathbf{q}_1$ 성분을 빼고 정규화

$$
\tilde{\mathbf{q}}_2 = \mathbf{a}_2 - (\mathbf{q}_1^T\mathbf{a}_2)\mathbf{q}_1, \quad \mathbf{q}_2 = \tilde{\mathbf{q}}_2 / \|\tilde{\mathbf{q}}_2\|
$$

**Step k**: 이전 모든 $\mathbf{q}$의 성분을 빼고 정규화

$$
\tilde{\mathbf{q}}_k = \mathbf{a}_k - \sum_{j=1}^{k-1}(\mathbf{q}_j^T\mathbf{a}_k)\mathbf{q}_j, \quad \mathbf{q}_k = \tilde{\mathbf{q}}_k / \|\tilde{\mathbf{q}}_k\|
$$

### 예시

$\mathbf{a}_1 = (1, 1, 0)^T$, $\mathbf{a}_2 = (1, 0, 1)^T$

$$
\mathbf{q}_1 = \frac{1}{\sqrt{2}}(1, 1, 0)^T
$$

$$
\tilde{\mathbf{q}}_2 = (1, 0, 1)^T - \frac{1}{\sqrt{2}} \cdot \frac{1}{\sqrt{2}}(1, 1, 0)^T = (1, 0, 1)^T - \frac{1}{2}(1, 1, 0)^T = \frac{1}{2}(1, -1, 2)^T
$$

$$
\mathbf{q}_2 = \frac{1}{\sqrt{6}}(1, -1, 2)^T
$$

검증: $\mathbf{q}_1^T\mathbf{q}_2 = \frac{1}{\sqrt{12}}(1 \cdot 1 + 1 \cdot (-1) + 0 \cdot 2) = 0$ ✓

---

## 3. QR 분해

행렬 $A$의 열에 Gram-Schmidt를 적용하면, **QR 분해**를 얻습니다.

$$
A = QR
$$

- $Q \in \mathbb{R}^{m \times n}$: 정규직교 열을 가진 행렬
- $R \in \mathbb{R}^{n \times n}$: 상삼각 행렬 (양의 대각 원소)

### QR로 최소제곱 풀기

$A\mathbf{x} = \mathbf{b}$의 최소제곱해를 구할 때,

$$
A^TA\mathbf{x} = A^T\mathbf{b} \quad \text{(정규방정식)}
$$

직접 풀면 $A^TA$의 조건수가 $\kappa(A)^2$으로 악화됩니다. QR 분해를 사용하면,

$$
QR\mathbf{x} = \mathbf{b} \implies R\mathbf{x} = Q^T\mathbf{b}
$$

$R$은 상삼각이므로 후진 대입(back substitution)으로 쉽게 풀 수 있고, 조건수가 $\kappa(A)$로 유지됩니다.

| 방법 | 조건수 | 안정성 |
|------|--------|--------|
| 정규방정식 $A^TA$ | $\kappa(A)^2$ | 불안정할 수 있음 |
| QR 분해 | $\kappa(A)$ | 안정적 |
| SVD | $\kappa(A)$ | 가장 안정적, 가장 느림 |

---

## 4. 직교 투영

### 1차원 투영

벡터 $\mathbf{b}$를 벡터 $\mathbf{a}$ 위에 투영하면,

$$
\text{proj}_\mathbf{a}(\mathbf{b}) = \frac{\mathbf{a}^T\mathbf{b}}{\mathbf{a}^T\mathbf{a}}\mathbf{a}
$$

### 부분 공간 투영

열 공간 $\mathcal{C}(A)$ 위로의 투영은,

$$
\hat{\mathbf{b}} = A(A^TA)^{-1}A^T\mathbf{b}
$$

**투영 행렬(projection matrix)**은,

$$
P = A(A^TA)^{-1}A^T
$$

### 투영 행렬의 성질

| 성질 | 수식 | 의미 |
|------|------|------|
| 대칭 | $P^T = P$ | 투영은 자기수반 |
| 멱등 | $P^2 = P$ | 이미 투영된 벡터를 다시 투영해도 변하지 않음 |
| 고유값 | 0 또는 1만 | 투영은 "유지하거나 버리거나" |

$A$의 열이 정규직교이면($A = Q$), 투영이 더 간단해집니다.

$$
P = QQ^T
$$

> **핵심 직관**: 투영 $\hat{\mathbf{b}} = P\mathbf{b}$는 부분 공간에서 $\mathbf{b}$에 가장 가까운 점입니다. 오차 $\mathbf{b} - \hat{\mathbf{b}}$는 부분 공간에 **수직**입니다.

---

## 5. 최소제곱법의 투영 해석

$A\mathbf{x} = \mathbf{b}$에 정확한 해가 없을 때(과결정 시스템), 잔차 $\|\mathbf{b} - A\mathbf{x}\|$를 최소화하는 $\hat{\mathbf{x}}$를 찾습니다.

기하학적으로, $A\hat{\mathbf{x}}$는 $\mathbf{b}$를 열 공간 $\mathcal{C}(A)$에 투영한 것입니다.

$$
A\hat{\mathbf{x}} = P\mathbf{b} = A(A^TA)^{-1}A^T\mathbf{b}
$$

양변에 왼쪽에서 $A^T$를 곱하면 정규방정식을 얻습니다.

$$
A^TA\hat{\mathbf{x}} = A^T\mathbf{b}
$$

잔차 벡터 $\mathbf{e} = \mathbf{b} - A\hat{\mathbf{x}}$는 열 공간에 직교합니다.

$$
A^T\mathbf{e} = A^T(\mathbf{b} - A\hat{\mathbf{x}}) = \mathbf{0}
$$

이것이 **최소제곱의 핵심**: 잔차가 열 공간에 수직일 때 오차가 최소입니다.

---

## 6. NumPy로 확인하기

```python
import numpy as np

# Gram-Schmidt
def gram_schmidt(A):
    m, n = A.shape
    Q = np.zeros_like(A, dtype=float)
    R = np.zeros((n, n))
    for j in range(n):
        v = A[:, j].astype(float)
        for i in range(j):
            R[i, j] = Q[:, i] @ A[:, j]
            v -= R[i, j] * Q[:, i]
        R[j, j] = np.linalg.norm(v)
        Q[:, j] = v / R[j, j]
    return Q, R

A = np.array([[1, 1], [1, 0], [0, 1]], dtype=float)
Q, R = gram_schmidt(A)
print(f"Q (정규직교):\n{Q.round(4)}")
print(f"Q^T Q:\n{(Q.T @ Q).round(10)}")  # 단위행렬
print(f"A - QR:\n{(A - Q @ R).round(10)}")  # 0

# NumPy QR 분해
Q_np, R_np = np.linalg.qr(A)
print(f"\nNumPy QR - Q:\n{Q_np.round(4)}")

# 투영 행렬
P = A @ np.linalg.inv(A.T @ A) @ A.T
print(f"\n투영 행렬 P:\n{P.round(4)}")
print(f"P^2 = P? {np.allclose(P @ P, P)}")  # True
print(f"P^T = P? {np.allclose(P.T, P)}")    # True

# 최소제곱
b = np.array([1, 2, 3], dtype=float)
x_hat = np.linalg.lstsq(A, b, rcond=None)[0]
b_hat = A @ x_hat
residual = b - b_hat
print(f"\n최소제곱해: {x_hat.round(4)}")
print(f"잔차 ⊥ 열공간? {np.allclose(A.T @ residual, 0)}")  # True
```

---

## 7. ML에서의 의미

### 직교 초기화

신경망의 가중치를 직교 행렬로 초기화하면, 신호가 층을 통과할 때 크기가 보존됩니다. 기울기 소실/폭발 문제를 완화하는 효과적인 방법입니다.

### 정규직교 임베딩

단어 임베딩에 직교 제약을 부과하면 각 차원이 독립적인 의미를 담도록 유도할 수 있습니다. Gram-Schmidt 과정을 학습 중에 적용하는 기법도 있습니다.

### Least Squares와 선형 회귀

선형 회귀의 정규방정식은 투영의 직접적 결과입니다. 이 관점을 이해하면 릿지 회귀($A^TA + \lambda I$)가 왜 수치적으로 안정한지도 자연스럽게 이해됩니다.

---

## 핵심 정리

1. **직교 행렬** $Q^TQ = I$는 회전/반사만 수행하며, 역행렬이 전치와 같아 계산이 효율적이다.
2. **Gram-Schmidt** 과정은 임의의 선형 독립 벡터를 정규직교 벡터로 변환하며, QR 분해의 기초이다.
3. **QR 분해** $A = QR$은 정규방정식보다 수치적으로 안정한 최소제곱 풀이를 제공한다.
4. **투영 행렬** $P = A(A^TA)^{-1}A^T$는 대칭이고 멱등($P^2 = P$)이며, 부분 공간에서 가장 가까운 점을 찾는다.
5. **최소제곱법의 본질**: 잔차가 열 공간에 수직일 때 오차가 최소이며, 이것이 정규방정식의 기하학적 의미이다.
