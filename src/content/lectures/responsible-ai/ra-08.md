# 모델 거버넌스

## 왜 모델 거버넌스가 중요한가

ra-01에서 책임있는 AI의 프레임워크를, ra-02~ra-07에서 공정성, 설명 가능성, 프라이버시, 강건성의 기술적 기법을 학습했습니다. 그러나 이러한 기법을 일관되게 적용하고 추적하려면 체계적인 거버넌스가 필요합니다. 모델 거버넌스는 모델의 전체 생명주기에 걸쳐 문서화, 감사, 리스크 관리, 규제 준수를 보장하는 조직적 프로세스입니다. MLOps(mo-01)가 기술적 운영을 다룬다면, 모델 거버넌스는 그 위에 놓이는 정책과 책임의 층위입니다.

> **핵심 직관**: 좋은 모델 거버넌스는 "관료주의적 부담"이 아니라 "신뢰를 가능하게 하는 인프라"입니다. 문서화와 감사 체계가 없으면, 문제 발생 시 원인 추적과 신속한 대응이 불가능합니다.

## 1. 모델 문서화 (Model Card)

### 1.1 Model Card의 구조

Mitchell et al.(2019)이 제안한 Model Card는 모델의 목적, 성능, 한계를 표준화된 형식으로 기록합니다.

| 섹션 | 내용 | 관련 강의 |
|------|------|-----------|
| 모델 개요 | 아키텍처, 버전, 개발 일자 | dl-01, ms-03 |
| 의도된 용도 | 적합/부적합한 사용 시나리오 | ra-01 |
| 학습 데이터 | 데이터셋 정보, 전처리 방법 | ra-03, mo-04 |
| 성능 지표 | 전체 및 하위 집단별 성능 | ms-02, ra-02 |
| 공정성 분석 | 보호 속성별 공정성 지표 | ra-02, ra-03 |
| 설명 가능성 | 사용된 설명 기법, 주요 피처 | ra-04, ra-05 |
| 강건성 | 적대적 공격 평가 결과 | ra-07 |
| 한계 및 주의사항 | 알려진 제약, 부적합 시나리오 | - |
| 윤리적 고려사항 | 잠재적 위험, 완화 조치 | ra-01 |

### 1.2 Model Card 자동 생성

```python
from dataclasses import dataclass, field
from typing import Dict, List, Optional
from datetime import datetime
import json

@dataclass
class ModelCard:
    # 기본 정보
    model_name: str
    version: str
    date: str = field(default_factory=lambda: datetime.now().isoformat())
    description: str = ""
    architecture: str = ""

    # 의도된 용도
    intended_use: str = ""
    out_of_scope_use: str = ""

    # 성능 지표
    overall_metrics: Dict[str, float] = field(default_factory=dict)
    subgroup_metrics: Dict[str, Dict[str, float]] = field(default_factory=dict)

    # 공정성
    fairness_metrics: Dict[str, float] = field(default_factory=dict)
    protected_attributes: List[str] = field(default_factory=list)

    # 강건성
    robustness_metrics: Dict[str, float] = field(default_factory=dict)

    # 한계
    known_limitations: List[str] = field(default_factory=list)
    ethical_considerations: List[str] = field(default_factory=list)

    def to_markdown(self) -> str:
        md = f"# Model Card: {self.model_name} v{self.version}\n\n"
        md += f"**Date**: {self.date}\n\n"
        md += f"## Overview\n{self.description}\n\n"
        md += f"## Intended Use\n{self.intended_use}\n\n"
        md += f"## Out of Scope\n{self.out_of_scope_use}\n\n"

        md += "## Performance\n"
        for metric, value in self.overall_metrics.items():
            md += f"- {metric}: {value:.4f}\n"

        md += "\n## Fairness Analysis\n"
        for metric, value in self.fairness_metrics.items():
            md += f"- {metric}: {value:.4f}\n"

        md += "\n## Limitations\n"
        for lim in self.known_limitations:
            md += f"- {lim}\n"
        return md

# 사용 예시
card = ModelCard(
    model_name="LoanApprovalModel",
    version="2.1",
    description="XGBoost 기반 대출 승인 모델",
    intended_use="개인 신용대출 심사 보조 (최종 결정은 인간 심사관)",
    out_of_scope_use="기업 대출, 자동 승인 (인간 감독 없이)",
    overall_metrics={"AUC": 0.891, "Accuracy": 0.847},
    fairness_metrics={"SPD_gender": -0.03, "EOD_gender": -0.02, "DIR_race": 0.85},
    known_limitations=["25세 미만 데이터 부족", "자영업자 성능 검증 불충분"]
)
```

## 2. 모델 감사 (Model Audit)

### 2.1 감사 프로세스

```
┌──────────────────────────────────────────────────────────┐
│                모델 감사 프로세스                          │
├──────────────────────────────────────────────────────────┤
│                                                          │
│  [1단계: 범위 설정]                                       │
│     감사 목적, 대상 모델, 규제 요건 확인                   │
│     ↓                                                    │
│  [2단계: 문서 검토]                                       │
│     Model Card, 학습 데이터 문서, 코드 리뷰               │
│     ↓                                                    │
│  [3단계: 기술 평가]                                       │
│     ├── 성능 검증: 하위 집단별 성능 분석 (ra-02)          │
│     ├── 공정성 테스트: 편향 탐지 및 측정 (ra-03)          │
│     ├── 설명 가능성: 설명 품질 평가 (ra-04, ra-05)        │
│     ├── 프라이버시: 멤버십 추론 공격 테스트 (ra-06)        │
│     └── 강건성: 적대적 공격 평가 (ra-07)                  │
│     ↓                                                    │
│  [4단계: 결과 보고]                                       │
│     발견 사항, 위험 등급, 개선 권고 문서화                 │
│     ↓                                                    │
│  [5단계: 후속 조치]                                       │
│     개선 이행, 재감사 일정, 모니터링 계획 (mo-07)          │
│                                                          │
└──────────────────────────────────────────────────────────┘
```

### 2.2 자동화된 감사 파이프라인

```python
class ModelAuditor:
    def __init__(self, model, X_test, y_test, sensitive_features):
        self.model = model
        self.X_test = X_test
        self.y_test = y_test
        self.sensitive = sensitive_features
        self.results = {}

    def audit_performance(self):
        """하위 집단별 성능 감사"""
        from fairlearn.metrics import MetricFrame
        from sklearn.metrics import accuracy_score, roc_auc_score

        y_pred = self.model.predict(self.X_test)
        mf = MetricFrame(
            metrics={"accuracy": accuracy_score},
            y_true=self.y_test,
            y_pred=y_pred,
            sensitive_features=self.sensitive
        )
        self.results["performance"] = {
            "overall": mf.overall,
            "by_group": mf.by_group.to_dict(),
            "ratio": mf.ratio()  # 최소/최대 비율
        }
        return self

    def audit_fairness(self):
        """공정성 지표 감사"""
        from fairlearn.metrics import demographic_parity_difference
        y_pred = self.model.predict(self.X_test)
        self.results["fairness"] = {
            "SPD": demographic_parity_difference(
                self.y_test, y_pred, sensitive_features=self.sensitive
            )
        }
        return self

    def audit_robustness(self, epsilon=0.03):
        """적대적 강건성 감사 (개념적)"""
        # ra-07의 평가 프로토콜 적용
        self.results["robustness"] = {
            "clean_accuracy": 0.891,
            "fgsm_accuracy": 0.742,
            "pgd_accuracy": 0.681
        }
        return self

    def generate_report(self) -> dict:
        """감사 보고서 생성"""
        report = {
            "timestamp": datetime.now().isoformat(),
            "model": str(self.model.__class__.__name__),
            "audit_results": self.results,
            "pass_fail": self._evaluate_thresholds()
        }
        return report

    def _evaluate_thresholds(self) -> dict:
        checks = {}
        if "fairness" in self.results:
            checks["fairness"] = abs(self.results["fairness"]["SPD"]) < 0.1
        if "performance" in self.results:
            checks["performance_parity"] = self.results["performance"]["ratio"] > 0.8
        return checks

# 실행
auditor = ModelAuditor(model, X_test, y_test, sensitive_features)
report = auditor.audit_performance().audit_fairness().generate_report()
```

## 3. 리스크 관리

### 3.1 AI 리스크 매트릭스

| | 영향: 낮음 | 영향: 중간 | 영향: 높음 |
|---|---|---|---|
| **발생 확률: 높음** | 중간 위험 | 높은 위험 | 극심한 위험 |
| **발생 확률: 중간** | 낮은 위험 | 중간 위험 | 높은 위험 |
| **발생 확률: 낮음** | 최소 위험 | 낮은 위험 | 중간 위험 |

### 3.2 AI 특화 리스크 항목

| 리스크 | 발생 확률 | 영향 | 완화 전략 |
|--------|-----------|------|-----------|
| 데이터 드리프트로 성능 저하 | 높음 | 중간 | 모니터링 (mo-06) |
| 편향된 의사결정 | 중간 | 높음 | 공정성 테스트 (ra-02) |
| 적대적 공격 | 낮음~중간 | 높음 | 적대적 학습 (ra-07) |
| 프라이버시 침해 | 중간 | 높음 | DP, 연합 학습 (ra-06) |
| 설명 불가 결정 | 높음 | 중간 | 해석 가능 모델 (ra-04) |
| 모델 고장/장애 | 낮음 | 매우 높음 | 폴백 시스템 (mo-08) |

> **핵심 직관**: AI 리스크 관리에서 가장 간과되는 것은 "피드백 루프 리스크"입니다. 모델의 예측이 미래 데이터에 영향을 미치면, 편향이 시간이 지남에 따라 증폭됩니다(ra-03). 이를 사전에 식별하고 모니터링 계획에 포함해야 합니다.

## 4. 규제 준수

### 4.1 EU AI Act 준수 체크리스트 (고위험 시스템)

```
┌──────────────────────────────────────────────────┐
│      EU AI Act 고위험 시스템 준수 체크리스트       │
├──────────────────────────────────────────────────┤
│                                                  │
│  □ 리스크 관리 시스템 수립 (Article 9)            │
│  □ 데이터 거버넌스 (Article 10)                   │
│     ├── 학습 데이터 품질 관리                     │
│     ├── 편향 검사 수행                           │
│     └── 데이터 출처 문서화                        │
│  □ 기술 문서화 (Article 11)                       │
│     └── Model Card 작성                          │
│  □ 기록 보존 (Article 12)                         │
│     └── 자동 로깅 시스템 (mo-05)                  │
│  □ 투명성 (Article 13)                            │
│     └── 사용자에게 AI 사용 고지                   │
│  □ 인간 감독 (Article 14)                         │
│     └── 인간-인-더-루프 또는 인간-온-더-루프       │
│  □ 정확성, 강건성, 보안 (Article 15)              │
│     └── 성능/강건성 벤치마크 (ra-07)              │
│  □ 적합성 평가 완료                               │
│                                                  │
└──────────────────────────────────────────────────┘
```

### 시나리오: 금융 규제 대응

한 핀테크 기업이 AI 기반 신용평가 시스템을 유럽에서 운영합니다.

1. **위험 분류**: 금융 서비스 → 고위험 (EU AI Act Annex III)
2. **문서화**: 모델 카드 작성, 학습 데이터 출처/전처리 기록
3. **공정성 평가**: 보호 속성(인종, 성별, 연령)별 공정성 지표 산출 및 보고
4. **설명 의무**: 거절 시 개인별 설명 제공 (ra-05 반사실적 설명)
5. **인간 감독**: 고액 대출은 반드시 인간 심사관 검토
6. **지속 모니터링**: 모델 성능과 공정성 지표의 실시간 대시보드 (mo-07)

## 5. 거버넌스 도구와 인프라

### 5.1 모델 레지스트리 통합

```python
# MLflow + Model Card 통합 (mo-05 참조)
import mlflow

with mlflow.start_run(run_name="loan_model_v2.1"):
    mlflow.log_params({"model_type": "xgboost", "max_depth": 6})
    mlflow.log_metrics({"auc": 0.891, "accuracy": 0.847})

    # 공정성 지표 로깅
    mlflow.log_metrics({
        "spd_gender": -0.03,
        "eod_gender": -0.02,
        "dir_race": 0.85
    })

    # Model Card 아티팩트 저장
    mlflow.log_artifact("model_card.md")

    # 감사 보고서 저장
    mlflow.log_artifact("audit_report.json")

    # 거버넌스 태그
    mlflow.set_tags({
        "risk_level": "HIGH",
        "audit_status": "PASSED",
        "next_audit_date": "2025-06-01",
        "human_oversight": "required"
    })
```

### 시나리오: 모델 거버넌스 실패 사례에서 배우기

한 채용 플랫폼이 이력서 심사 AI를 배포했으나, 모델 카드 없이 운영한 결과:
- 모델이 어떤 데이터로 학습되었는지 추적 불가
- 공정성 테스트가 수행되지 않아 성별 편향 발견 지연
- 문제 발생 후 이전 버전으로 롤백할 근거 부재

이 사례는 거버넌스의 부재가 기술적 문제보다 더 큰 위험을 초래할 수 있음을 보여줍니다.

> **핵심 직관**: 모델 거버넌스는 모델 개발 "이후"가 아니라 "처음부터" 설계되어야 합니다. MLOps 파이프라인(mo-03)에 거버넌스 게이트를 내장하면, 거버넌스가 개발 속도를 늦추지 않으면서도 지속적으로 작동합니다.

## 핵심 정리

- Model Card는 모델의 목적, 성능, 공정성, 한계를 표준화된 형식으로 기록하며, 고위험 시스템의 투명성 의무를 충족합니다
- 모델 감사는 성능, 공정성, 설명 가능성, 프라이버시, 강건성의 5개 축으로 체계적으로 수행되어야 합니다
- AI 리스크 관리는 발생 확률과 영향도의 매트릭스로 리스크를 분류하고, 피드백 루프 리스크를 특별히 주의해야 합니다
- EU AI Act 등 규제 준수를 위해 데이터 거버넌스, 기술 문서화, 인간 감독, 적합성 평가가 필수적입니다
- 거버넌스는 MLOps 파이프라인에 처음부터 내장되어야 하며, 모델 레지스트리와 감사 도구의 통합이 이를 가능하게 합니다
