# 해석 가능한 모델

## 왜 해석 가능성이 중요한가

모델의 예측을 사람이 이해할 수 있는가는 단순한 선호의 문제가 아닙니다. EU AI Act(ra-01)는 고위험 AI 시스템에 대해 설명 가능성을 법적으로 요구하며, 의료, 금융, 사법 도메인에서는 "왜 이런 결정을 내렸는가"에 대한 답변이 필수적입니다. 해석 가능한 모델은 설계 자체가 투명하여 별도의 설명 기법(ra-05) 없이도 의사결정 과정을 파악할 수 있습니다.

> **핵심 직관**: "해석 가능성"과 "설명 가능성"은 다릅니다. 해석 가능한 모델(이 강의)은 구조 자체가 투명하고, 설명 가능한 모델(ra-05)은 블랙박스 모델에 사후적으로 설명을 부여합니다. 본질적 투명성이 사후 설명보다 신뢰도가 높습니다.

## 1. 해석 가능성의 스펙트럼

```
┌──────────────────────────────────────────────────────────┐
│              해석 가능성 - 성능 스펙트럼                   │
├──────────────────────────────────────────────────────────┤
│                                                          │
│  해석성 높음                            해석성 낮음       │
│  ◄─────────────────────────────────────────────►         │
│                                                          │
│  규칙 목록   선형모델   GAM   결정트리   앙상블   DNN     │
│  (Rules)    (Linear)  (GAM)  (Tree)   (RF/XGB) (Neural) │
│                                                          │
│  성능 낮음(?)*                         성능 높음          │
│                                                          │
│  * 항상 성립하지는 않음 - 도메인과 데이터에 의존            │
└──────────────────────────────────────────────────────────┘
```

> **핵심 직관**: Rudin(2019)은 "고위험 의사결정에서 블랙박스 + 사후 설명보다 본질적 해석 가능 모델을 우선 사용해야 한다"고 주장합니다. 많은 실제 응용에서 해석 가능 모델이 블랙박스와 동등한 성능을 달성합니다.

## 2. 선형 모델과 로지스틱 회귀

가장 기본적인 해석 가능 모델입니다. 각 피처의 계수가 예측에 대한 기여를 직접 나타냅니다.

$$\hat{y} = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_p x_p$$

| 장점 | 한계 |
|------|------|
| 계수의 직관적 해석 | 비선형 관계 포착 불가 |
| 통계적 유의성 검정 가능 | 피처 간 상호작용 표현 불가 |
| 계산 효율성 | 고차원 데이터에서 성능 한계 |

```python
from sklearn.linear_model import LogisticRegression
import numpy as np

# 시나리오: 대출 승인 모델 - 해석 가능한 선형 모델
model = LogisticRegression(penalty="l1", C=0.1, solver="saga", max_iter=5000)
model.fit(X_train, y_train)

# 계수 해석: 각 피처의 승인 확률에 대한 기여
feature_importance = dict(zip(feature_names, model.coef_[0]))
for feat, coef in sorted(feature_importance.items(), key=lambda x: abs(x[1]), reverse=True):
    direction = "승인↑" if coef > 0 else "승인↓"
    print(f"  {feat}: {coef:+.3f} ({direction})")
# 예: income: +1.23 (승인↑), debt_ratio: -0.89 (승인↓)
```

## 3. 일반화 가법 모델 (GAM)

GAM은 선형 모델의 해석 가능성을 유지하면서 비선형 관계를 포착합니다.

$$g(E[y]) = \beta_0 + f_1(x_1) + f_2(x_2) + \cdots + f_p(x_p)$$

각 $f_j$는 개별 피처에 대한 형태 함수(shape function)로, 비선형일 수 있지만 피처별로 독립적입니다.

### 3.1 Explainable Boosting Machine (EBM)

InterpretML의 EBM은 부스팅 기반 GAM으로, 높은 성능과 해석 가능성을 동시에 제공합니다.

```python
from interpret.glassbox import ExplainableBoostingClassifier
from interpret import show

# EBM 학습
ebm = ExplainableBoostingClassifier(
    max_bins=256,
    interactions=10,  # 상위 10개 2차 상호작용 자동 탐지
    outer_bags=8,
    inner_bags=4
)
ebm.fit(X_train, y_train)

# 글로벌 설명: 각 피처의 형태 함수 시각화
ebm_global = ebm.explain_global()
show(ebm_global)  # 각 피처별 비선형 기여 패턴 확인

# 로컬 설명: 개별 예측의 피처별 기여
ebm_local = ebm.explain_local(X_test[:5], y_test[:5])
show(ebm_local)   # 특정 대출 신청의 승인/거절 근거
```

### 3.2 GAM의 장단점

| 장점 | 한계 |
|------|------|
| 피처별 비선형 관계 학습 | 고차 상호작용 제한적 |
| 형태 함수 시각화 가능 | 피처 수 매우 많으면 해석 어려움 |
| 통계적 신뢰구간 제공 | 이미지/텍스트 등 비정형 데이터에 부적합 |
| 블랙박스 수준 성능 가능 | 상호작용 항 추가 시 해석 복잡도 증가 |

## 4. 결정 트리와 규칙 기반 모델

### 4.1 최적 결정 트리

전통적 CART 트리는 탐욕적(greedy) 분할을 사용하지만, 최적 결정 트리는 전체 트리 구조를 동시에 최적화하여 더 간결하면서도 정확한 트리를 생성합니다.

```python
# 최적 분류 트리 (학술적 예시)
from sklearn.tree import DecisionTreeClassifier, export_text

# 깊이를 제한하여 해석 가능성 확보
tree = DecisionTreeClassifier(max_depth=4, min_samples_leaf=50)
tree.fit(X_train, y_train)

# 규칙 출력
rules = export_text(tree, feature_names=feature_names)
print(rules)
# |--- income <= 45000.00
# |   |--- debt_ratio <= 0.35
# |   |   |--- class: approved
# |   |--- debt_ratio > 0.35
# |   |   |--- class: denied
```

### 4.2 규칙 목록 (Rule Lists)

IF-THEN 규칙의 순서 있는 목록으로, 각 규칙은 순차적으로 평가됩니다.

```
┌──────────────────────────────────────────┐
│           대출 심사 규칙 목록              │
├──────────────────────────────────────────┤
│                                          │
│  IF debt_ratio > 0.50                    │
│     THEN deny  (신뢰도: 92%)             │
│  ELSE IF income > 80,000 AND             │
│          credit_score > 700              │
│     THEN approve  (신뢰도: 95%)          │
│  ELSE IF employment_years < 1            │
│     THEN deny  (신뢰도: 78%)             │
│  ELSE                                    │
│     THEN approve  (신뢰도: 65%)          │
│                                          │
│  ※ 규칙은 순서대로 적용, 먼저 매칭되는    │
│    규칙이 최종 결정                       │
└──────────────────────────────────────────┘
```

### 시나리오: 의료 진단에서의 해석 가능 모델 선택

응급실 트리아지 시스템에서 환자의 중증도를 분류합니다. 의료진이 모델의 판단 근거를 즉시 이해할 수 있어야 합니다.

- **규칙 목록**: 간결하지만 성능 한계 → 바이탈 사인 기반 초기 분류에 적합
- **GAM (EBM)**: 비선형 관계 포착 + 해석 가능 → 종합 중증도 점수 산출에 적합
- **딥러닝 + SHAP**: 최고 성능이지만 해석 비용 높음 → 의료 영상 분석에만 제한 사용 (ra-05)

## 5. 해석성-성능 트레이드오프의 실체

최근 연구는 이 트레이드오프가 항상 존재하지는 않음을 보여줍니다.

```python
from sklearn.metrics import accuracy_score, roc_auc_score

# 모델별 성능 비교 (실제 태뷸러 데이터 벤치마크 결과 예시)
results = {
    "Logistic Regression": {"AUC": 0.842, "Interpretable": True},
    "EBM (GAM)":           {"AUC": 0.891, "Interpretable": True},
    "Rule List":           {"AUC": 0.823, "Interpretable": True},
    "Random Forest":       {"AUC": 0.887, "Interpretable": False},
    "XGBoost":             {"AUC": 0.895, "Interpretable": False},
    "Deep Neural Net":     {"AUC": 0.892, "Interpretable": False},
}

# EBM이 RF/DNN과 비교해 1~2% 이내 성능 차이
# 태뷸러 데이터에서 해석 가능 모델의 경쟁력 확인 (ms-03)
```

| 데이터 유형 | 해석 가능 모델 추천 | 성능 격차 |
|------------|-------------------|-----------|
| 태뷸러 (정형) | EBM, 최적 트리 | 작음 (1-3%) |
| 시계열 | GAM + 시간 피처 | 중간 (3-5%) |
| 텍스트 | 규칙 기반 (제한적) | 큼 |
| 이미지 | 사후 설명 필요 (ra-05) | 매우 큼 |

> **핵심 직관**: 태뷸러 데이터에서 EBM 같은 현대적 해석 가능 모델은 XGBoost, 딥러닝과 1~3% 이내의 성능 차이를 보입니다. 고위험 도메인에서 이 작은 차이보다 해석 가능성의 가치가 훨씬 큽니다.

## 6. 모델 선택 의사결정 프레임워크

```
┌──────────────────────────────────────────────────┐
│         해석 가능 모델 선택 플로우                  │
├──────────────────────────────────────────────────┤
│                                                  │
│  고위험 의사결정인가? (ra-01 위험 분류)            │
│     ├── YES → 해석 가능 모델 우선                 │
│     │        데이터 유형은?                       │
│     │        ├── 태뷸러 → EBM 또는 최적 트리      │
│     │        ├── 텍스트 → 어텐션 기반 + 설명       │
│     │        └── 이미지 → 블랙박스 + ra-05 설명    │
│     └── NO  → 성능 최우선                         │
│              블랙박스 허용, 필요 시 ra-05 적용     │
│                                                  │
└──────────────────────────────────────────────────┘
```

## 핵심 정리

- 해석 가능한 모델은 구조 자체가 투명하여 별도의 사후 설명 기법 없이도 의사결정 과정을 파악할 수 있습니다
- GAM(특히 EBM)은 피처별 비선형 관계를 학습하면서도 형태 함수 시각화를 통해 높은 해석 가능성을 제공합니다
- 규칙 목록과 최적 결정 트리는 가장 직관적인 해석 가능 모델이며, 의료/금융 등 규제 도메인에 적합합니다
- 태뷸러 데이터에서 현대적 해석 가능 모델(EBM)은 블랙박스 모델과 1~3% 이내의 성능 차이를 보이므로, 고위험 도메인에서 우선 사용이 권장됩니다
- 모델 선택은 위험 수준(ra-01)과 데이터 유형을 종합적으로 고려하며, 해석 가능 모델이 먼저 검토되어야 합니다 (ms-01)
