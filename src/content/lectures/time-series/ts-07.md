# 다변량 시계열: VAR — 벡터 자기회귀, Granger 인과성, 충격 반응

## 왜 다변량 시계열 분석이 필요한가

현실에서는 여러 시계열이 서로 영향을 주고받습니다. GDP와 금리, 환율과 수출 등은 독립적으로 움직이지 않습니다. ts-02에서 배운 AR 모델을 다변량으로 확장한 VAR(Vector Autoregression)은 여러 시계열 간의 상호 의존 관계를 동시에 모델링하며, Granger 인과성 검정과 충격 반응 함수라는 강력한 분석 도구를 제공합니다.

---

## 1. VAR(p) 모델의 정의

$K$개의 시계열을 벡터 $\mathbf{Y}_t = (Y_{1t}, Y_{2t}, \ldots, Y_{Kt})^\top$로 놓으면:

$$\mathbf{Y}_t = \mathbf{c} + \mathbf{A}_1 \mathbf{Y}_{t-1} + \mathbf{A}_2 \mathbf{Y}_{t-2} + \cdots + \mathbf{A}_p \mathbf{Y}_{t-p} + \mathbf{u}_t$$

여기서 $\mathbf{u}_t \sim N(\mathbf{0}, \boldsymbol{\Sigma}_u)$이고, $\mathbf{A}_i$는 $K \times K$ 계수 행렬입니다.

### VAR(1) 이변량 예시

$$\begin{pmatrix} Y_{1t} \\ Y_{2t} \end{pmatrix} = \begin{pmatrix} c_1 \\ c_2 \end{pmatrix} + \begin{pmatrix} a_{11} & a_{12} \\ a_{21} & a_{22} \end{pmatrix} \begin{pmatrix} Y_{1,t-1} \\ Y_{2,t-1} \end{pmatrix} + \begin{pmatrix} u_{1t} \\ u_{2t} \end{pmatrix}$$

| 요소 | 차원 | 의미 |
|------|------|------|
| $\mathbf{A}_i$ | $K \times K$ | 시차 $i$의 교차 영향 |
| $a_{12}$ | 스칼라 | $Y_2$가 $Y_1$에 미치는 영향 |
| $\boldsymbol{\Sigma}_u$ | $K \times K$ | 동시적 상관 |
| 파라미터 수 | $K^2 p + K$ | 빠르게 증가 |

> **핵심 직관**: VAR의 $\mathbf{A}$ 행렬의 비대각 원소가 시계열 간의 **교차 영향**을 포착합니다. 대각 원소만 있으면 독립적인 AR 모델과 같습니다.

```python
import numpy as np
import pandas as pd
from statsmodels.tsa.api import VAR

# 이변량 시계열 데이터
np.random.seed(42)
T = 500
y1 = np.zeros(T)
y2 = np.zeros(T)
for t in range(1, T):
    y1[t] = 0.5 * y1[t-1] + 0.3 * y2[t-1] + np.random.randn()
    y2[t] = 0.2 * y1[t-1] + 0.6 * y2[t-1] + np.random.randn()

data = pd.DataFrame({'Y1': y1, 'Y2': y2})
```

---

## 2. VAR 모델의 추정과 차수 선택

### 2.1 OLS 추정

VAR의 각 방정식은 개별적으로 OLS로 추정할 수 있습니다. la-04에서 다룬 최소제곱법이 직접 적용됩니다.

### 2.2 차수 선택

| 기준 | 수식 | 특징 |
|------|------|------|
| AIC | $\ln\lvert\hat{\Sigma}_u\rvert + \frac{2pK^2}{T}$ | 예측 중심 |
| BIC | $\ln\lvert\hat{\Sigma}_u\rvert + \frac{pK^2 \ln T}{T}$ | 일치 추정량 |
| HQ | $\ln\lvert\hat{\Sigma}_u\rvert + \frac{2pK^2 \ln\ln T}{T}$ | 중간적 |
| FPE | $\left(\frac{T+Kp+1}{T-Kp-1}\right)^K \lvert\hat{\Sigma}_u\rvert$ | 소표본 조정 |

```python
model = VAR(data)
results = model.select_order(maxlags=8)
print(results.summary())

# 최적 차수로 추정
var_result = model.fit(maxlags=results.aic, ic='aic')
print(var_result.summary())
```

> **핵심 직관**: VAR의 파라미터 수는 $K^2 p$로 빠르게 증가하므로, 변수가 많을 때는 차수를 낮게 유지하거나 변수 선택이 필요합니다.

---

## 3. Granger 인과성 검정

### 3.1 개념

$Y_2$가 $Y_1$을 **Granger-인과**한다는 것은, $Y_2$의 과거 정보가 $Y_1$의 예측을 유의미하게 개선한다는 의미입니다.

$$H_0: a_{12,1} = a_{12,2} = \cdots = a_{12,p} = 0$$

즉, $\mathbf{A}_1, \ldots, \mathbf{A}_p$에서 $Y_2 \to Y_1$에 해당하는 계수가 모두 0인지 검정합니다.

### 3.2 주의사항

| 특성 | 설명 |
|------|------|
| 방향성 | $Y_2 \to Y_1$과 $Y_1 \to Y_2$는 별도 검정 |
| 인과 ≠ 원인 | 예측적 선행일 뿐, 진정한 인과관계가 아닐 수 있음 |
| 정상성 필요 | 비정상 시계열에는 직접 적용 불가 (ts-08 참조) |
| 생략 변수 | 제3의 변수가 진짜 원인일 수 있음 |

> **핵심 직관**: Granger 인과성은 "예측에 도움이 되는가"를 검정하는 것이지, 진정한 **원인-결과 관계**를 증명하는 것이 아닙니다.

```python
# Granger 인과성 검정
from statsmodels.tsa.stattools import grangercausalitytests

# Y2가 Y1을 Granger-인과하는가?
gc_result = grangercausalitytests(data[['Y1', 'Y2']], maxlag=4)
```

GDP 성장률은 실업률을 Granger-인과할 수 있지만, 이것이 GDP가 실업의 유일한 원인이라는 뜻은 아닙니다.

---

## 4. 충격 반응 함수 (Impulse Response Function)

### 4.1 MA(∞) 표현

정상 VAR(p)는 Wold 분해를 통해 무한 MA로 표현됩니다.

$$\mathbf{Y}_t = \boldsymbol{\mu} + \sum_{i=0}^{\infty} \boldsymbol{\Psi}_i \mathbf{u}_{t-i}$$

$\boldsymbol{\Psi}_i$의 $(j, k)$ 원소는 $Y_k$에 단위 충격이 가해졌을 때 $i$ 기간 후 $Y_j$에 미치는 영향입니다.

### 4.2 직교 충격 반응 (Orthogonalized IRF)

$\mathbf{u}_t$의 성분들이 상관되어 있으므로, 촐레스키 분해를 사용합니다.

$$\boldsymbol{\Sigma}_u = \mathbf{P} \mathbf{P}^\top$$

직교화된 충격 반응:

$$\boldsymbol{\Theta}_i = \boldsymbol{\Psi}_i \mathbf{P}$$

| IRF 유형 | 방법 | 특징 |
|---------|------|------|
| 일반 IRF | $\boldsymbol{\Psi}_i$ | 상관된 충격 |
| 직교 IRF | $\boldsymbol{\Psi}_i \mathbf{P}$ | 촐레스키, 순서 의존 |
| 일반화 IRF | Pesaran-Shin | 순서 비의존 |

> **핵심 직관**: 충격 반응 함수는 "한 변수에 충격이 가해졌을 때, 시간이 지남에 따라 다른 변수들이 어떻게 반응하는가"를 추적합니다.

```python
# 충격 반응 함수
irf = var_result.irf(periods=20)
irf.plot(orth=True)
plt.suptitle('직교 충격 반응 함수')

# 신뢰 구간 포함
irf.plot_cum_effects(orth=True)
```

---

## 5. 분산 분해 (Forecast Error Variance Decomposition)

예측 오차 분산 중 각 변수의 충격이 기여하는 비율을 분석합니다.

$$\text{FEVD}_{jk}(h) = \frac{\sum_{i=0}^{h-1} (\boldsymbol{\Theta}_i)_{jk}^2}{\sum_{i=0}^{h-1} \sum_{m=1}^{K} (\boldsymbol{\Theta}_i)_{jm}^2}$$

| 해석 예시 | 의미 |
|----------|------|
| $\text{FEVD}_{11}(10) = 0.7$ | $Y_1$의 10기 예측 오차 중 70%가 자신의 충격 |
| $\text{FEVD}_{12}(10) = 0.3$ | 나머지 30%가 $Y_2$의 충격에 의한 것 |

```python
# 분산 분해
fevd = var_result.fevd(periods=20)
fevd.summary()
fevd.plot()
```

> **핵심 직관**: 분산 분해는 "각 변수가 다른 변수의 변동을 얼마나 설명하는가"를 정량적으로 보여줍니다.

---

## 6. VAR 모델의 진단과 한계

### 6.1 진단 검정

| 검정 | 귀무가설 | 코드 |
|------|---------|------|
| Portmanteau | 잔차 자기상관 없음 | `var_result.test_whiteness(nlags=10)` |
| 정규성 | 잔차 정규 분포 | `var_result.test_normality()` |
| 안정성 | 고유값이 단위원 내부 | `var_result.is_stable()` |

```python
# 안정성 확인
print(f"안정적: {var_result.is_stable()}")

# 잔차 자기상관 검정
whiteness = var_result.test_whiteness(nlags=10)
print(f"Portmanteau p-value: {whiteness.pvalue:.4f}")
```

### 6.2 한계와 대안

| 한계 | 설명 | 대안 |
|------|------|------|
| 차원의 저주 | $K^2 p$개 파라미터 | 정규화 VAR, BVAR |
| 비정상 시계열 | 직접 적용 불가 | VECM (ts-08 참조) |
| 비선형 관계 | 포착 불가 | Threshold VAR, DL 모델 |
| 구조적 해석 | 촐레스키 순서에 의존 | SVAR (구조적 VAR) |

> **핵심 직관**: VAR는 강력하지만, 변수가 많아지면 파라미터 과다 문제가 심각해지므로, 핵심 변수만 선택하거나 베이지안 축소(BVAR)를 고려해야 합니다.

---

## 7. 예측

```python
# h-단계 예측
forecast = var_result.forecast(data.values[-var_result.k_ar:], steps=12)
forecast_df = pd.DataFrame(forecast, columns=['Y1', 'Y2'])

# 예측 구간
forecast_interval = var_result.forecast_interval(
    data.values[-var_result.k_ar:], steps=12, alpha=0.05
)
```

| 예측 특성 | VAR | 단변량 ARIMA |
|----------|-----|------------|
| 교차 정보 활용 | O | X |
| 파라미터 수 | 많음 | 적음 |
| 적합 상황 | 변수 간 관계 존재 | 독립적 시계열 |
| 과적합 위험 | 높음 | 낮음 |

> **핵심 직관**: VAR 예측이 단변량 모델보다 좋으려면, 변수 간에 **실제로 유의미한 교차 상관**이 존재해야 합니다.

---

## 핵심 정리

- **VAR(p)는 AR 모델의 다변량 확장으로, 여러 시계열 간의 상호 의존 관계를 동시에 모델링합니다.**
- **Granger 인과성은 한 변수의 과거 정보가 다른 변수의 예측을 개선하는지 검정하며, 진정한 인과관계와는 구별됩니다.**
- **충격 반응 함수는 한 변수의 충격이 시간에 따라 다른 변수들에 어떻게 전파되는지를 추적합니다.**
- **분산 분해는 각 변수의 예측 오차 중 어떤 변수의 충격이 얼마나 기여하는지를 정량화합니다.**
- **VAR의 파라미터 수는 $K^2p$로 빠르게 증가하므로, 변수 선택과 차수 제한이 실무에서 중요합니다.**
