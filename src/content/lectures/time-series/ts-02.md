# AR, MA, ARMA 모델: 자기회귀, 이동평균, 인과성, 가역성

## 왜 AR, MA, ARMA를 배우는가

시계열 모델링의 근간은 자기회귀(AR)와 이동평균(MA)입니다. 이 두 구성 요소를 결합한 ARMA 모델은 정상 시계열을 표현하는 가장 일반적인 선형 모델이며, 이후 ARIMA, SARIMA, VAR 등 모든 고전 시계열 모델의 기초가 됩니다. ts-01에서 배운 ACF/PACF 패턴이 이 모델들의 차수를 결정하는 데 직접 사용됩니다.

---

## 1. AR(p) 모델 — 자기회귀

AR(p) 모델은 현재 값을 과거 $p$개 값의 선형 결합으로 표현합니다.

$$Y_t = c + \phi_1 Y_{t-1} + \phi_2 Y_{t-2} + \cdots + \phi_p Y_{t-p} + \epsilon_t$$

여기서 $\epsilon_t \sim WN(0, \sigma^2)$이고, $c$는 상수항입니다.

### 후진 연산자 (Backshift Operator) 표현

후진 연산자 $B$를 $BY_t = Y_{t-1}$로 정의하면:

$$\Phi(B) Y_t = c + \epsilon_t, \quad \Phi(B) = 1 - \phi_1 B - \phi_2 B^2 - \cdots - \phi_p B^p$$

| AR 차수 | 모델 | 정상성 조건 |
|---------|------|-----------|
| AR(1) | $Y_t = \phi_1 Y_{t-1} + \epsilon_t$ | $\lvert\phi_1\rvert < 1$ |
| AR(2) | $Y_t = \phi_1 Y_{t-1} + \phi_2 Y_{t-2} + \epsilon_t$ | $\Phi(B)=0$의 근이 단위원 밖 |

> **핵심 직관**: AR 모델은 "과거의 나 자신이 현재의 나를 결정한다"는 **관성**을 표현합니다.

```python
import numpy as np
from statsmodels.tsa.arima_process import ArmaProcess

# AR(1) 시뮬레이션: phi = 0.8
ar_params = np.array([1, -0.8])  # 1 - 0.8B
ma_params = np.array([1])
ar1 = ArmaProcess(ar_params, ma_params)
y = ar1.generate_sample(nsample=500)
```

주식의 일간 수익률은 약한 AR(1) 구조를 보일 수 있습니다.

---

## 2. MA(q) 모델 — 이동평균

MA(q) 모델은 현재 값을 현재와 과거 $q$개의 백색 잡음의 선형 결합으로 표현합니다.

$$Y_t = \mu + \epsilon_t + \theta_1 \epsilon_{t-1} + \theta_2 \epsilon_{t-2} + \cdots + \theta_q \epsilon_{t-q}$$

후진 연산자 표현:

$$Y_t = \mu + \Theta(B) \epsilon_t, \quad \Theta(B) = 1 + \theta_1 B + \theta_2 B^2 + \cdots + \theta_q B^q$$

| MA 차수 | ACF 특성 | PACF 특성 |
|---------|---------|----------|
| MA(1) | 시차 1에서만 유의 | 지수적 감소 |
| MA(2) | 시차 1, 2에서 유의 | 지수적 감소 |
| MA(q) | 시차 q까지 유의, 이후 0 | 점진적 감소 |

> **핵심 직관**: MA 모델은 "과거의 충격이 현재에 잔향을 남긴다"는 **충격 전파**를 표현합니다.

```python
# MA(2) 시뮬레이션: theta1 = 0.6, theta2 = 0.3
ar_params = np.array([1])
ma_params = np.array([1, 0.6, 0.3])
ma2 = ArmaProcess(ar_params, ma_params)
y_ma = ma2.generate_sample(nsample=500)
```

---

## 3. ARMA(p, q) 모델

AR과 MA를 결합한 모델입니다.

$$\Phi(B) Y_t = c + \Theta(B) \epsilon_t$$

$$Y_t = c + \sum_{i=1}^{p} \phi_i Y_{t-i} + \epsilon_t + \sum_{j=1}^{q} \theta_j \epsilon_{t-j}$$

### Wold 분해 정리

모든 약정상 시계열은 MA($\infty$)로 표현할 수 있습니다.

$$Y_t = \mu + \sum_{j=0}^{\infty} \psi_j \epsilon_{t-j}, \quad \psi_0 = 1, \quad \sum_{j=0}^{\infty} \psi_j^2 < \infty$$

이는 ARMA가 정상 시계열의 **일반적 표현**임을 보장합니다.

| 비교 항목 | AR(p) | MA(q) | ARMA(p,q) |
|----------|-------|-------|-----------|
| 파라미터 수 | p + 1 | q + 1 | p + q + 1 |
| ACF | 점진적 감소 | 시차 q에서 절단 | 점진적 감소 |
| PACF | 시차 p에서 절단 | 점진적 감소 | 점진적 감소 |
| 절약성 | 높음 (MA가 길 때) | 높음 (AR가 길 때) | 가장 절약적 |

> **핵심 직관**: ARMA는 AR과 MA의 장점을 결합하여, 적은 파라미터로 복잡한 자기상관 구조를 표현합니다.

---

## 4. 인과성 (Causality)과 가역성 (Invertibility)

### 4.1 인과성

AR 과정이 **인과적(causal)**이란, $Y_t$를 현재와 과거의 백색 잡음으로만 표현할 수 있다는 것입니다.

$$Y_t = \sum_{j=0}^{\infty} \psi_j \epsilon_{t-j}$$

조건: $\Phi(z) = 0$의 모든 근이 단위원 **밖**에 있어야 합니다.

### 4.2 가역성

MA 과정이 **가역적(invertible)**이란, $\epsilon_t$를 현재와 과거의 $Y_t$로 표현할 수 있다는 것입니다.

$$\epsilon_t = \sum_{j=0}^{\infty} \pi_j Y_{t-j}$$

조건: $\Theta(z) = 0$의 모든 근이 단위원 **밖**에 있어야 합니다.

| 성질 | 대상 | 조건 | 의미 |
|------|------|------|------|
| 인과성 | AR 부분 | $\Phi(z)=0$ 근이 $\lvert z \rvert > 1$ | 미래에 의존하지 않음 |
| 가역성 | MA 부분 | $\Theta(z)=0$ 근이 $\lvert z \rvert > 1$ | MA → AR 변환 가능 |
| 정상성 | 전체 | 인과성과 동치 (AR) | 통계적 성질 불변 |

> **핵심 직관**: 인과성은 "미래를 모르고도 모델을 쓸 수 있음"을, 가역성은 "MA를 무한 AR로 바꿀 수 있음"을 보장합니다.

```python
# 인과성 확인: AR(1)의 근 계산
import numpy as np

phi = 0.8
roots = np.roots([1, -phi])  # 1 - 0.8z = 0 → z = 1.25
print(f"AR(1) 근: {roots}, 단위원 밖: {np.abs(roots) > 1}")
```

---

## 5. 모델 식별과 차수 선택

### 5.1 ACF/PACF 기반 식별

ts-01에서 배운 ACF/PACF 패턴을 사용합니다.

| 패턴 | 추정 모델 |
|------|----------|
| ACF 감소, PACF 시차 2에서 절단 | AR(2) |
| ACF 시차 1에서 절단, PACF 감소 | MA(1) |
| 둘 다 점진적 감소 | ARMA |

### 5.2 정보 기준 (Information Criteria)

$$\text{AIC} = -2 \ln L + 2k$$

$$\text{BIC} = -2 \ln L + k \ln T$$

여기서 $L$은 우도, $k$는 파라미터 수, $T$는 관측 수입니다. si-02에서 배운 MLE로 추정한 우도를 사용합니다.

```python
from statsmodels.tsa.arima.model import ARIMA
import warnings
warnings.filterwarnings('ignore')

# 여러 차수의 AIC 비교
best_aic = np.inf
best_order = None
for p in range(4):
    for q in range(4):
        try:
            model = ARIMA(y, order=(p, 0, q)).fit()
            if model.aic < best_aic:
                best_aic = model.aic
                best_order = (p, 0, q)
        except:
            continue
print(f"최적 차수: {best_order}, AIC: {best_aic:.2f}")
```

> **핵심 직관**: AIC는 예측력에, BIC는 올바른 모델 선택에 초점을 맞추며, BIC가 더 간결한 모델을 선호합니다.

---

## 6. AR/MA 모델의 성질 비교

### 6.1 충격 반응 함수 (Impulse Response)

$\epsilon_t$에 단위 충격이 가해졌을 때 $Y_{t+h}$에 미치는 영향:

- **AR(1)**: $\psi_h = \phi_1^h$ (지수적 감쇠)
- **MA(1)**: $\psi_0 = 1, \psi_1 = \theta_1, \psi_h = 0 \, (h \geq 2)$ (즉시 소멸)

### 6.2 예측

$h$-단계 앞 예측:

$$\hat{Y}_{T+h|T} = E[Y_{T+h} \mid Y_T, Y_{T-1}, \ldots]$$

| 모델 | 예측 특성 |
|------|---------|
| AR(1) | $\hat{Y}_{T+h} = \phi_1^h Y_T$ → 평균으로 수렴 |
| MA(1) | $h > 1$이면 $\hat{Y}_{T+h} = \mu$ (기억이 짧음) |
| ARMA(1,1) | AR과 MA 성질 혼합 |

> **핵심 직관**: AR은 긴 기억을, MA는 짧은 기억을 가집니다. 대부분의 실제 시계열은 두 성질이 혼합되어 있습니다.

---

## 핵심 정리

- **AR(p)는 현재 값을 과거 p개 값의 선형 결합으로 표현하며, PACF가 시차 p에서 절단되는 특징을 갖습니다.**
- **MA(q)는 현재와 과거 q개의 충격으로 현재 값을 표현하며, ACF가 시차 q에서 절단됩니다.**
- **ARMA(p,q)는 AR과 MA를 결합하여 적은 파라미터로 복잡한 자기상관 구조를 효율적으로 모델링합니다.**
- **인과성은 AR 다항식의 근이 단위원 밖에 있을 때, 가역성은 MA 다항식의 근이 단위원 밖에 있을 때 성립합니다.**
- **모델 차수는 ACF/PACF 패턴 분석과 AIC/BIC 정보 기준을 함께 사용하여 선택합니다.**
