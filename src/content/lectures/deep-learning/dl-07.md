# 확산 모델

## 왜 확산 모델을 이해해야 하는가

DALL-E, Stable Diffusion, Midjourney—현재 이미지 생성의 주류는 **확산 모델(Diffusion Model)**입니다. GAN의 불안정한 학습과 mode collapse를 피하면서 고품질 생성을 달성했습니다. 확산 모델은 **노이즈를 점진적으로 제거**하는 과정을 학습하며, 그 수학적 기반은 확률 미분방정식과 스코어 매칭입니다.

---

## 1. 핵심 직관

### 두 과정

1. **전방 과정 (Forward)**: 깨끗한 이미지에 노이즈를 점점 더 추가 → 순수 노이즈가 됨
2. **역방향 과정 (Reverse)**: 순수 노이즈에서 노이즈를 점점 제거 → 깨끗한 이미지 복원

```
깨끗한 이미지 → [+노이즈] → [+노이즈] → ... → [+노이즈] → 순수 노이즈
     x₀          x₁          x₂                  x_T

순수 노이즈 → [-노이즈] → [-노이즈] → ... → [-노이즈] → 생성된 이미지
     x_T         x_{T-1}     x_{T-2}              x₀
```

신경망은 **역방향 과정**—각 단계에서 노이즈를 예측하여 제거하는 것—을 학습합니다.

> **핵심 직관**: 이미지를 파괴하는 것은 쉽습니다 (노이즈 추가). 복원하는 것을 학습하면 생성 모델이 됩니다.

---

## 2. DDPM (Denoising Diffusion Probabilistic Models)

### 전방 과정

시간 $t$에서의 노이즈 추가:

$$
q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t}\, x_{t-1},\, \beta_t I)
$$

$\beta_t$는 **노이즈 스케줄**: 각 단계에서 추가하는 노이즈의 양입니다.

### 핵심 트릭: 임의의 $t$로 직접 점프

$\alpha_t = 1 - \beta_t$, $\bar{\alpha}_t = \prod_{s=1}^t \alpha_s$으로 정의하면:

$$
q(x_t | x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t}\, x_0,\, (1-\bar{\alpha}_t) I)
$$

즉, **중간 단계를 거치지 않고** $x_0$에서 임의의 $x_t$를 직접 샘플링할 수 있습니다:

$$
x_t = \sqrt{\bar{\alpha}_t}\, x_0 + \sqrt{1-\bar{\alpha}_t}\, \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)
$$

이것이 학습을 효율적으로 만듭니다.

---

## 3. 학습 목표

신경망 $\epsilon_\theta(x_t, t)$가 $x_t$에 추가된 **노이즈 $\epsilon$을 예측**하도록 학습합니다.

$$
L = \mathbb{E}_{t, x_0, \epsilon}\left[\|\epsilon - \epsilon_\theta(x_t, t)\|^2\right]
$$

### 학습 알고리즘

```python
def train_step(model, x_0):
    # 1. 랜덤 타임스텝 선택
    t = torch.randint(0, T, (batch_size,))

    # 2. 노이즈 생성
    epsilon = torch.randn_like(x_0)

    # 3. 노이즈 추가된 이미지 생성
    alpha_bar = get_alpha_bar(t)
    x_t = sqrt(alpha_bar) * x_0 + sqrt(1 - alpha_bar) * epsilon

    # 4. 모델이 노이즈를 예측
    epsilon_pred = model(x_t, t)

    # 5. 손실 계산
    loss = F.mse_loss(epsilon_pred, epsilon)
    return loss
```

---

## 4. 샘플링 (역방향 과정)

학습된 모델로 이미지를 생성합니다:

$$
x_{t-1} = \frac{1}{\sqrt{\alpha_t}}\left(x_t - \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\epsilon_\theta(x_t, t)\right) + \sigma_t z
$$

```python
def sample(model, shape):
    x = torch.randn(shape)  # 순수 노이즈에서 시작

    for t in reversed(range(T)):
        epsilon_pred = model(x, t)

        # 평균 계산
        alpha = get_alpha(t)
        alpha_bar = get_alpha_bar(t)
        mean = (1 / sqrt(alpha)) * (x - (1 - alpha) / sqrt(1 - alpha_bar) * epsilon_pred)

        # 분산 (t > 0일 때만 노이즈 추가)
        if t > 0:
            noise = torch.randn_like(x)
            x = mean + sqrt(beta[t]) * noise
        else:
            x = mean

    return x  # 생성된 이미지
```

---

## 5. 노이즈 스케줄

$\beta_t$의 선택이 생성 품질에 큰 영향을 미칩니다.

| 스케줄 | 공식 | 특성 |
|--------|------|------|
| 선형 | $\beta_t = \beta_{\min} + t(\beta_{\max} - \beta_{\min})/T$ | DDPM 원래 논문 |
| 코사인 | $\bar{\alpha}_t = \cos^2\left(\frac{t/T + s}{1+s} \cdot \frac{\pi}{2}\right)$ | 더 균일한 노이즈 추가 |

코사인 스케줄은 초기 단계에서 너무 빨리 노이즈가 추가되는 것을 방지하여 더 좋은 결과를 냅니다.

---

## 6. 스코어 매칭 관점

확산 모델은 **스코어 함수**(로그 확률의 그래디언트)를 학습하는 것으로도 해석됩니다:

$$
\nabla_{x_t} \log p(x_t) \approx -\frac{\epsilon_\theta(x_t, t)}{\sqrt{1-\bar{\alpha}_t}}
$$

노이즈를 예측하는 것과 스코어를 추정하는 것은 수학적으로 동치입니다.

### Langevin 역학과의 연결

스코어 함수를 알면, Langevin 역학으로 분포에서 샘플링할 수 있습니다:

$$
x_{t+1} = x_t + \frac{\delta}{2}\nabla_x \log p(x_t) + \sqrt{\delta}\, z
$$

이것이 확산 모델이 "노이즈를 따라가며 좋은 이미지로 이동"하는 원리입니다.

---

## 7. Classifier-Free Guidance (CFG)

조건부 생성의 품질을 크게 높이는 기법입니다.

$$
\tilde{\epsilon}_\theta(x_t, t, c) = (1 + w) \cdot \epsilon_\theta(x_t, t, c) - w \cdot \epsilon_\theta(x_t, t, \varnothing)
$$

- $c$: 조건 (텍스트 프롬프트 등)
- $\varnothing$: 빈 조건 (unconditional)
- $w$: guidance 스케일 (보통 3~15)

학습 시 일정 확률로 조건을 빈 값으로 대체하여, 하나의 모델이 조건부/비조건부 모두를 학습합니다.

```python
def guided_sample(model, x_t, t, text_embedding, guidance_scale=7.5):
    # 조건부 예측
    eps_cond = model(x_t, t, text_embedding)
    # 비조건부 예측
    eps_uncond = model(x_t, t, null_embedding)
    # CFG 적용
    eps = eps_uncond + guidance_scale * (eps_cond - eps_uncond)
    return eps
```

> **핵심 직관**: CFG는 "조건이 있을 때와 없을 때의 차이를 증폭"합니다. guidance_scale이 높을수록 조건에 더 충실하지만 다양성이 줄어듭니다.

---

## 8. U-Net과 DiT

### U-Net: 전통적 백본

확산 모델의 노이즈 예측기로 U-Net이 주로 사용됩니다. 다운샘플링-업샘플링 구조에 skip connection이 있습니다. 타임스텝 $t$는 사인파 임베딩으로 주입합니다.

### DiT (Diffusion Transformer)

U-Net 대신 **Transformer**를 백본으로 사용합니다. 이미지를 패치로 나누어 시퀀스로 처리합니다. Stable Diffusion 3, DALL-E 3 등에서 사용합니다.

---

## 9. DDIM: 빠른 샘플링

DDPM은 $T$ 단계 (보통 1000)가 필요하여 느립니다. **DDIM**은 결정론적 샘플링으로 단계 수를 줄입니다.

$$
x_{t-1} = \sqrt{\bar{\alpha}_{t-1}} \cdot \hat{x}_0 + \sqrt{1-\bar{\alpha}_{t-1}} \cdot \epsilon_\theta(x_t, t)
$$

여기서 $\hat{x}_0 = \frac{x_t - \sqrt{1-\bar{\alpha}_t}\,\epsilon_\theta}{\sqrt{\bar{\alpha}_t}}$

DDIM은 50~100 단계만으로도 좋은 결과를 냅니다.

---

## 핵심 정리

1. 확산 모델은 **노이즈 추가(전방)**와 **노이즈 제거(역방향)** 과정으로, 역방향에서 노이즈를 예측하는 신경망을 학습한다.
2. $x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1-\bar{\alpha}_t}\epsilon$으로 임의의 타임스텝에 직접 점프할 수 있어 학습이 효율적이다.
3. **노이즈 예측**과 **스코어 추정**은 수학적으로 동치이며, Langevin 역학을 통해 샘플링할 수 있다.
4. **Classifier-Free Guidance**는 조건부/비조건부 예측의 차이를 증폭하여 조건부 생성의 품질을 높인다.
5. **DDIM**은 결정론적 샘플링으로 단계 수를 줄이고, **DiT**는 U-Net을 Transformer로 대체한 최신 트렌드이다.
