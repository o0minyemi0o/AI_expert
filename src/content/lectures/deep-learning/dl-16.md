# 스케일링 법칙

## 왜 스케일링 법칙을 이해해야 하는가

"모델을 키우면 성능이 좋아진다"는 경험적 관찰을 넘어, **얼마나 키우면 얼마나 좋아지는가**를 예측할 수 있다면 수십억 원의 학습 비용을 최적으로 분배할 수 있습니다. **스케일링 법칙(Scaling Laws)**은 모델 크기, 데이터 양, 계산량과 성능의 **멱법칙(power law) 관계**를 밝혀, 대규모 학습의 설계를 과학으로 바꿨습니다.

---

## 1. 멱법칙 관계

언어 모델의 테스트 손실 $L$은 세 변수에 대해 멱법칙을 따릅니다:

$$
L(N) \approx \left(\frac{N_c}{N}\right)^{\alpha_N}, \quad L(D) \approx \left(\frac{D_c}{D}\right)^{\alpha_D}, \quad L(C) \approx \left(\frac{C_c}{C}\right)^{\alpha_C}
$$

- $N$: 모델 파라미터 수
- $D$: 학습 데이터 토큰 수
- $C$: 학습 계산량 (FLOPs)

### Kaplan et al. (2020)의 발견

$$
L(N, D) \approx \left[\left(\frac{N_c}{N}\right)^{\alpha_N / \alpha_D} + \frac{D_c}{D}\right]^{\alpha_D}
$$

로그-로그 스케일에서 **직선**입니다.

```
log(Loss)
    |
    |  \
    |   \
    |    \    ← 기울기 = -α
    |     \
    |      \
    +--------→ log(N 또는 D 또는 C)
```

> **핵심 직관**: 모델 크기를 10배 늘리면 손실이 일정 비율 줄어듭니다. 이 비율이 멱법칙의 지수 $\alpha$이며, 놀랍도록 안정적입니다.

---

## 2. Kaplan 스케일링 법칙 (OpenAI, 2020)

### 핵심 발견

| 변수 | 지수 $\alpha$ | 해석 |
|------|-------------|------|
| 파라미터 $N$ | ~0.076 | 모델 10배 → 손실 ~17% 감소 |
| 데이터 $D$ | ~0.095 | 데이터 10배 → 손실 ~20% 감소 |
| 계산량 $C$ | ~0.050 | 계산 10배 → 손실 ~11% 감소 |

### 결론: 모델을 키워라

Kaplan의 법칙은 "고정 계산 예산에서, 모델을 크게 하되 데이터는 상대적으로 적게 써도 된다"고 주장했습니다. 구체적으로:

$$
N_{opt} \propto C^{0.73}, \quad D_{opt} \propto C^{0.27}
$$

계산량이 10배 늘면: 모델은 ~5.4배, 데이터는 ~1.9배 키우는 것이 최적.

---

## 3. Chinchilla 스케일링 법칙 (DeepMind, 2022)

### Kaplan과의 차이

Chinchilla(Hoffmann et al.)는 Kaplan의 결론을 수정합니다:

$$
N_{opt} \propto C^{0.50}, \quad D_{opt} \propto C^{0.50}
$$

**모델과 데이터를 동등하게 스케일**해야 합니다.

### 핵심 법칙

$$
L(N, D) = \frac{A}{N^a} + \frac{B}{D^b} + L_\infty
$$

- $A/N^a$: 모델이 유한해서 발생하는 오차
- $B/D^b$: 데이터가 유한해서 발생하는 오차
- $L_\infty$: 자연어 자체의 불가능한 엔트로피 (약 1.69 nats)

### 실전 규칙

**Chinchilla-optimal**: 파라미터당 약 20개의 학습 토큰

| 모델 크기 | 최적 학습 토큰 | 비교: GPT-3 |
|----------|--------------|------------|
| 7B | 140B | — |
| 70B | 1.4T | GPT-3 175B는 300B 토큰 (**부족**) |
| 175B | 3.5T | — |

GPT-3는 Chinchilla 기준으로 **데이터가 10배 이상 부족**했습니다. 같은 계산량을 70B 모델 + 1.4T 토큰에 쓰면 175B보다 나았을 것입니다.

> **핵심 직관**: Chinchilla의 메시지는 "대부분의 대형 모델은 과대하고 과소학습되어 있다"입니다. 모델 크기와 데이터 양을 균형 있게 늘려야 합니다.

---

## 4. Compute-Optimal Training

### 예산 분배 문제

학습 예산 $C$가 주어졌을 때:
- 계산량: $C \approx 6ND$ (근사, FLOPs)
- 손실: $L(N, D)$를 최소화하는 $N^*$, $D^*$를 찾아야 함

$$
\min_{N, D} L(N, D) \quad \text{subject to} \quad 6ND \leq C
$$

### 실전 계산 예시

예산이 $C = 10^{22}$ FLOPs라면:
- $N^* \approx 1.3 \times 10^{10}$ (13B 파라미터)
- $D^* \approx 2.6 \times 10^{11}$ (260B 토큰)
- 파라미터당 토큰: ~20

---

## 5. 스케일링 법칙의 실전 활용

### 작은 실험으로 큰 실험 예측

```python
# 작은 모델들로 스케일링 법칙을 피팅
small_runs = [
    (125e6,  5e9,  3.2),   # 125M 파라미터, 5B 토큰, loss=3.2
    (350e6,  15e9, 2.9),
    (760e6,  30e9, 2.7),
    (1.3e9,  50e9, 2.5),
]

# 멱법칙 피팅
# L(N, D) = A/N^a + B/D^b + L∞
# → 10B 모델의 최적 데이터양과 예상 loss를 예측
```

이 방법으로 10B, 70B, 175B 모델의 성능을 **학습 전에** 예측할 수 있습니다.

### 모델 크기 결정

"예산이 X FLOPs이면, 모델은 Y 파라미터, 데이터는 Z 토큰이 최적"을 계산합니다.

---

## 6. 다운스트림 태스크 스케일링

사전학습 손실이 감소하면 다운스트림 태스크(벤치마크) 성능도 **예측 가능하게** 향상됩니다.

$$
\text{Benchmark score} \approx f(L_{pretrain})
$$

대부분의 벤치마크에서 사전학습 손실과 다운스트림 성능은 **단조 관계**입니다. 사전학습 손실이 좋으면 거의 모든 작업에서 좋습니다.

---

## 7. Emergent Abilities

### 갑작스러운 능력 출현

일부 능력은 모델 크기가 **임계점을 넘으면 갑자기** 나타나는 것처럼 보입니다.

- 산술 추론: 작은 모델에서는 랜덤, 큰 모델에서 갑자기 해결
- Few-shot learning: 일정 크기 이상에서만 작동
- Chain-of-thought: 특정 스케일에서 갑자기 효과적

### 논쟁

최근 연구(Schaeffer et al., 2023)는 emergent abilities가 **평가 지표의 비선형성** 때문일 수 있다고 주장합니다. 연속적 지표(예: Brier score)를 사용하면 성능 향상이 매끄럽게 보입니다. "갑작스러운 출현"은 이산적 지표(정확도)의 착시일 수 있습니다.

---

## 8. 스케일링을 넘어서

### 데이터 품질

같은 양의 데이터라도 품질이 다르면 성능이 크게 달라집니다. 중복 제거, 필터링, 다양성 확보가 중요합니다.

### 추론 시간 계산 (Inference-Time Compute)

모델 크기를 키우는 대신, 추론 시 더 많은 계산을 하는 접근입니다. Chain-of-thought, self-consistency, tree-of-thought 등.

### Post-Training의 효과

RLHF, DPO 등 사후 학습은 스케일링 법칙의 "기저" 위에서 추가적인 성능 향상을 제공하며, 이것도 고유한 스케일링 특성을 보입니다.

---

## 핵심 정리

1. 언어 모델의 손실은 파라미터 수 $N$, 데이터 양 $D$, 계산량 $C$에 대해 **멱법칙**을 따른다.
2. **Chinchilla 법칙**: 모델과 데이터를 동등하게 스케일해야 하며, 파라미터당 약 20개의 학습 토큰이 최적이다.
3. 작은 실험으로 멱법칙을 피팅하면, **큰 모델의 성능을 학습 전에 예측**할 수 있다.
4. $L_\infty$ (자연어의 엔트로피)가 존재하여, 무한히 스케일해도 달성 불가능한 하한이 있다.
5. **Emergent abilities**는 스케일링의 흥미로운 현상이지만, 평가 지표의 비선형성이 원인일 수 있다는 논쟁이 있다.
