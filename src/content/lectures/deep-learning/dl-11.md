# 손실 함수 심화

## 왜 손실 함수를 깊이 이해해야 하는가

손실 함수는 "모델이 무엇을 최적화하는가"를 정의합니다. 같은 아키텍처라도 손실 함수에 따라 완전히 다른 모델이 됩니다. Cross-Entropy의 정보 이론적 의미, Focal Loss의 설계 동기, 대조 학습의 기하학적 해석을 이해하면, 문제에 맞는 손실 함수를 **선택하거나 설계**할 수 있습니다.

---

## 1. Cross-Entropy Loss

### 정보 이론적 배경

**엔트로피**: 분포 $p$의 불확실성

$$
H(p) = -\sum_i p_i \log p_i
$$

**교차 엔트로피**: 분포 $p$를 $q$로 인코딩할 때의 비용

$$
H(p, q) = -\sum_i p_i \log q_i
$$

**KL 발산**: 교차 엔트로피 - 엔트로피

$$
D_{KL}(p \| q) = H(p, q) - H(p) = \sum_i p_i \log \frac{p_i}{q_i}
$$

$p$가 고정된 정답 분포이면, 교차 엔트로피를 최소화하는 것 = KL 발산을 최소화하는 것 = **모델 분포 $q$를 정답 분포 $p$에 가깝게** 만드는 것입니다.

### 분류에서의 Cross-Entropy

클래스가 $C$개이고 정답이 $y$일 때:

$$
L = -\log q_y = -\log \frac{e^{z_y}}{\sum_{j=1}^C e^{z_j}}
$$

여기서 $z$는 logit(softmax 전 값)입니다.

```python
# PyTorch: logit을 직접 입력 (내부에서 softmax 적용)
loss = F.cross_entropy(logits, targets)

# 수동 계산
log_probs = F.log_softmax(logits, dim=-1)
loss = F.nll_loss(log_probs, targets)
```

### 이진 Cross-Entropy

$$
L = -[y \log \hat{y} + (1-y) \log(1-\hat{y})]
$$

```python
loss = F.binary_cross_entropy_with_logits(logits, targets)
```

> **핵심 직관**: Cross-Entropy는 "모델이 정답에 얼마나 높은 확률을 부여하는가"를 측정합니다. 정답의 로그 확률을 최대화하는 것과 동일합니다. 이것이 Maximum Likelihood Estimation (MLE)입니다.

---

## 2. Label Smoothing

정답을 원-핫(hard target) 대신 **부드러운 분포(soft target)**로 만듭니다.

$$
y_i^{smooth} = \begin{cases} 1 - \epsilon + \epsilon/C & i = y_{true} \\ \epsilon/C & i \neq y_{true} \end{cases}
$$

$\epsilon = 0.1$, $C = 1000$이면: 정답 클래스 0.9001, 나머지 각각 0.0001.

```python
loss = F.cross_entropy(logits, targets, label_smoothing=0.1)
```

### 효과

- 모델이 **과도하게 확신하는 것**을 방지
- 로짓이 무한대로 커지지 않도록 정규화
- 일반화 성능 향상

---

## 3. Focal Loss

### 문제: 클래스 불균형

객체 탐지에서 배경(쉬운 예시)이 99%, 객체(어려운 예시)가 1%일 때, Cross-Entropy는 쉬운 예시에 의해 지배됩니다.

### Focal Loss

$$
L_{focal} = -\alpha_t (1 - p_t)^\gamma \log(p_t)
$$

- $p_t$: 정답 클래스의 예측 확률
- $\gamma$: focusing 파라미터 (보통 2)
- $\alpha_t$: 클래스 가중치

$(1 - p_t)^\gamma$가 핵심입니다:
- $p_t = 0.9$ (쉬운 예시): $(1-0.9)^2 = 0.01$ → 손실 100배 감소
- $p_t = 0.1$ (어려운 예시): $(1-0.1)^2 = 0.81$ → 거의 감소 없음

```python
def focal_loss(logits, targets, gamma=2.0, alpha=0.25):
    ce_loss = F.cross_entropy(logits, targets, reduction='none')
    pt = torch.exp(-ce_loss)  # p_t = exp(-CE)
    focal_weight = (1 - pt) ** gamma
    return (alpha * focal_weight * ce_loss).mean()
```

> **핵심 직관**: Focal Loss는 "이미 잘 맞추는 쉬운 예시의 손실을 줄여, 어려운 예시에 집중"시킵니다.

---

## 4. 대조 손실 (Contrastive Loss)

### 기본 아이디어

유사한 쌍은 가깝게, 다른 쌍은 멀게 임베딩합니다.

### InfoNCE / NT-Xent (SimCLR)

$$
L = -\log \frac{\exp(\text{sim}(z_i, z_j)/\tau)}{\sum_{k \neq i} \exp(\text{sim}(z_i, z_k)/\tau)}
$$

- $z_i, z_j$: 같은 이미지의 두 증강 뷰 (양성 쌍)
- $z_k$: 다른 이미지들 (음성 쌍)
- $\tau$: 온도 (temperature)
- $\text{sim}$: 코사인 유사도

```python
def info_nce_loss(features, temperature=0.07):
    # features: (2N, d) — N개 이미지의 2개 증강 뷰
    features = F.normalize(features, dim=1)
    similarity = features @ features.T / temperature

    N = features.shape[0] // 2
    labels = torch.cat([torch.arange(N, 2*N), torch.arange(N)])

    # 자기 자신과의 유사도 제외
    mask = torch.eye(2*N, dtype=bool)
    similarity.masked_fill_(mask, -float('inf'))

    return F.cross_entropy(similarity, labels)
```

### 온도($\tau$)의 역할

- $\tau \to 0$: 가장 유사한 음성에만 집중 (hard negative)
- $\tau \to \infty$: 모든 음성을 균등하게 고려

---

## 5. Triplet Loss

$$
L = \max(0, \|f(a) - f(p)\|^2 - \|f(a) - f(n)\|^2 + \text{margin})
$$

- $a$: anchor (기준)
- $p$: positive (같은 클래스)
- $n$: negative (다른 클래스)

"positive보다 negative가 margin 이상 멀어야 한다."

### Hard Negative Mining

쉬운 음성(이미 충분히 먼 것)은 손실이 0이므로 학습에 기여하지 않습니다. **가장 어려운 음성**(가까운 것)을 선택해야 효율적입니다.

---

## 6. 회귀 손실 함수

### MSE (L2)

$$
L = \frac{1}{n}\sum_i (y_i - \hat{y}_i)^2
$$

큰 오차에 큰 벌칙. 이상치에 민감합니다.

### MAE (L1)

$$
L = \frac{1}{n}\sum_i |y_i - \hat{y}_i|
$$

이상치에 강건합니다. 하지만 0에서 미분 불연속.

### Huber Loss (Smooth L1)

$$
L_\delta = \begin{cases} \frac{1}{2}(y - \hat{y})^2 & |y - \hat{y}| \leq \delta \\ \delta|y - \hat{y}| - \frac{1}{2}\delta^2 & |y - \hat{y}| > \delta \end{cases}
$$

MSE와 MAE의 장점을 결합합니다. 작은 오차에는 L2 (매끄러운 최적화), 큰 오차에는 L1 (이상치 강건).

```python
loss = F.huber_loss(predictions, targets, delta=1.0)
```

---

## 7. ML에서의 의미

### LLM의 손실 함수

자기회귀 언어 모델은 **다음 토큰 예측의 Cross-Entropy**를 사용합니다:

$$
L = -\frac{1}{T}\sum_{t=1}^T \log P(x_t | x_{<t})
$$

이것의 지수가 **perplexity**입니다: $\text{PPL} = e^L$.

### RLHF의 보상 모델

인간 선호 데이터로 학습하는 보상 모델은 **Bradley-Terry** 모델의 Cross-Entropy를 사용합니다:

$$
L = -\log \sigma(r_\theta(y_w) - r_\theta(y_l))
$$

선호되는 응답 $y_w$의 보상이 거부된 응답 $y_l$보다 높도록 학습합니다.

### 확산 모델의 노이즈 예측

확산 모델은 **MSE**로 노이즈를 예측합니다: $L = \|\epsilon - \epsilon_\theta(x_t, t)\|^2$.

---

## 핵심 정리

1. **Cross-Entropy**는 모델 분포를 정답 분포에 가깝게 만드는 것이며, Maximum Likelihood와 동치이다.
2. **Focal Loss**는 $(1-p_t)^\gamma$ 가중치로 쉬운 예시의 영향을 줄여, 클래스 불균형 문제를 해결한다.
3. **대조 손실**(InfoNCE)은 유사한 쌍은 가깝게, 다른 쌍은 멀게 하여 표현을 학습하며, 온도가 집중도를 조절한다.
4. **Label Smoothing**은 모델의 과도한 확신을 방지하여 일반화를 개선한다.
5. 회귀에서는 MSE(이상치 민감), MAE(이상치 강건), **Huber**(절충)를 상황에 따라 선택한다.
