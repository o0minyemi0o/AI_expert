# Python 성능 최적화

## 왜 Python 성능 최적화가 중요한가

Python은 AI/ML 생태계의 공용어이지만, 인터프리터 언어의 태생적 한계로 C/C++ 대비 10-100배 느릴 수 있습니다. 그러나 올바른 최적화 기법을 적용하면 Python의 생산성을 유지하면서도 네이티브에 근접한 성능을 달성할 수 있습니다. "느리다고 느끼기 전에 측정하라"는 원칙이 가장 중요합니다.

> **핵심 직관**: Python 최적화의 80%는 "올바른 라이브러리 선택"이고, 15%는 "알고리즘 개선"이며, 나머지 5%만이 "저수준 최적화"입니다. 프로파일링 없이 최적화하는 것은 지도 없이 보물을 찾는 것과 같습니다.

## 1. 프로파일링: 측정이 먼저입니다

최적화의 첫 단계는 병목 지점을 정확히 식별하는 것입니다(se-08 성능 엔지니어링 참조).

| 도구 | 측정 대상 | 오버헤드 | 사용 시점 |
|------|----------|---------|----------|
| `time.perf_counter` | 벽시계 시간 | 거의 없음 | 간단한 구간 측정 |
| `cProfile` | 함수별 호출 시간 | 중간 | 전체 프로필 파악 |
| `line_profiler` | 라인별 실행 시간 | 높음 | 핫스팟 분석 |
| `memory_profiler` | 메모리 사용량 | 높음 | 메모리 누수 탐지 |
| `py-spy` | 샘플링 기반 | 매우 낮음 | 프로덕션 프로파일링 |

```python
# cProfile 사용 예시
import cProfile
import pstats

def process_data(data):
    result = [x ** 2 for x in data]
    return sorted(result)

# 프로파일링 실행
profiler = cProfile.Profile()
profiler.enable()
process_data(range(1_000_000))
profiler.disable()

stats = pstats.Stats(profiler)
stats.sort_stats('cumulative')
stats.print_stats(10)  # 상위 10개 함수

# line_profiler: 라인 단위 분석
# kernprof -l -v script.py
# @profile 데코레이터를 핫스팟 함수에 적용
```

## 2. 벡터화: 루프를 제거하라

Python 루프는 인터프리터 오버헤드가 매 반복마다 발생합니다. NumPy 벡터화로 루프를 C 수준 연산으로 대체합니다(nm-02 벡터 연산 참조).

```python
import numpy as np

# 나쁜 예: Python 루프
def normalize_loop(data):
    result = np.empty_like(data)
    mean = np.mean(data)
    std = np.std(data)
    for i in range(len(data)):
        result[i] = (data[i] - mean) / std
    return result

# 좋은 예: 벡터화
def normalize_vectorized(data):
    return (data - data.mean()) / data.std()

# 성능 차이: 100x 이상 (n=1,000,000 기준)
data = np.random.randn(1_000_000)
```

## 3. Numba: JIT 컴파일

Numba는 Python 함수를 LLVM을 통해 네이티브 머신 코드로 JIT 컴파일합니다(py-08 고급 성능 참조).

```python
from numba import njit, prange
import numpy as np

# @njit: nopython 모드 JIT 컴파일
@njit
def pairwise_distance(X):
    n = X.shape[0]
    D = np.empty((n, n), dtype=np.float64)
    for i in range(n):
        for j in range(i + 1, n):
            d = 0.0
            for k in range(X.shape[1]):
                d += (X[i, k] - X[j, k]) ** 2
            D[i, j] = D[j, i] = np.sqrt(d)
        D[i, i] = 0.0
    return D

# 병렬 실행: prange 사용
@njit(parallel=True)
def parallel_pairwise_distance(X):
    n = X.shape[0]
    D = np.empty((n, n), dtype=np.float64)
    for i in prange(n):  # prange: 자동 병렬화
        for j in range(i + 1, n):
            d = 0.0
            for k in range(X.shape[1]):
                d += (X[i, k] - X[j, k]) ** 2
            D[i, j] = D[j, i] = np.sqrt(d)
        D[i, i] = 0.0
    return D
```

> **핵심 직관**: Numba는 "Python 문법으로 작성하되, C 속도로 실행"을 가능하게 합니다. 단, NumPy 배열과 기본 자료형만 지원하므로, 복잡한 객체를 사용하는 코드에는 적합하지 않습니다.

## 4. Cython: 정적 타이핑으로 성능 확보

Cython은 Python에 C 수준 타입 선언을 추가하여 컴파일하는 방식입니다.

```python
# cython_example.pyx
# cython: boundscheck=False, wraparound=False
import numpy as np
cimport numpy as np

def fast_sum(np.ndarray[np.float64_t, ndim=1] arr):
    cdef:
        int i, n = arr.shape[0]
        double total = 0.0
    for i in range(n):
        total += arr[i]
    return total

# setup.py에서 빌드
# from Cython.Build import cythonize
# ext_modules = cythonize("cython_example.pyx")
```

## 5. 메모리 최적화

메모리 사용량을 줄이는 것은 속도 향상과 직결됩니다(sp-01 메모리 계층과 캐시 참조).

| 기법 | 효과 | 적용 대상 |
|------|------|----------|
| `__slots__` | 인스턴스 메모리 30-50% 감소 | 대량 객체 |
| 제너레이터 | 메모리 O(1) | 순차 처리 |
| `np.float32` | 메모리 50% 감소 | 수치 데이터 |
| `del` + `gc.collect()` | 즉시 해제 | 대용량 임시 객체 |
| 메모리 매핑 | 디스크 데이터 지연 로딩 | 초대형 데이터셋 |

```python
import numpy as np

# dtype 최적화
data_f64 = np.random.randn(10_000_000)            # 80 MB
data_f32 = data_f64.astype(np.float32)             # 40 MB
data_f16 = data_f64.astype(np.float16)             # 20 MB

# __slots__로 메모리 절약
class Point:
    __slots__ = ['x', 'y', 'z']  # dict 미생성 → 메모리 절약
    def __init__(self, x, y, z):
        self.x, self.y, self.z = x, y, z

# 제너레이터로 메모리 효율적 처리
def process_large_file(path):
    with open(path) as f:
        for line in f:  # 한 줄씩 처리 → 메모리 O(1)
            yield transform(line)
```

```
┌───────────────────────────────────────────┐
│       Python 성능 최적화 의사결정 흐름       │
├───────────────────────────────────────────┤
│                                           │
│     성능 문제 감지                          │
│         │                                 │
│         ▼                                 │
│     프로파일링 수행                         │
│         │                                 │
│    ┌────┴────┐                            │
│    ▼         ▼                            │
│ CPU 병목   메모리 병목                      │
│    │         │                            │
│    ▼         ▼                            │
│ 벡터화    dtype 축소                       │
│ 가능?     / 제너레이터                      │
│    │                                      │
│  ┌─┴─┐                                   │
│  ▼   ▼                                   │
│ Yes  No                                  │
│  │    │                                   │
│  ▼    ▼                                   │
│ NumPy  Numba/Cython                      │
│ 연산   JIT 컴파일                          │
│         │                                 │
│    ┌────┴────┐                            │
│    ▼         ▼                            │
│  충분?    GPU 필요?                        │
│  Yes      → sp-04 CUDA                   │
│                                           │
└───────────────────────────────────────────┘
```

## 6. 실전 시나리오

**시나리오 1: 특성 엔지니어링 파이프라인 최적화**

수천만 행의 데이터에서 특성을 추출할 때, Pandas의 `apply`를 사용하면 수 시간이 걸리지만, Numba로 벡터화된 연산으로 변환하면 수 분으로 단축됩니다. 프로파일링으로 `apply` 호출이 전체 시간의 90%를 차지함을 확인하는 것이 첫 단계입니다(mo-02 데이터 파이프라인 참조).

**시나리오 2: 추론 서버의 전처리 최적화**

이미지 전처리(리사이즈, 정규화)가 추론 지연의 40%를 차지하는 상황에서, OpenCV의 C++ 백엔드를 직접 활용하고, 배치 전처리를 NumPy 벡터화로 구현하면 전처리 시간을 5배 단축할 수 있습니다.

```python
import numpy as np

# 배치 이미지 정규화 - 벡터화
def normalize_batch(images, mean, std):
    # images: (B, H, W, C), mean/std: (3,)
    return (images.astype(np.float32) / 255.0 - mean) / std
```

> **핵심 직관**: Python 성능 최적화에서 가장 큰 실수는 "프로파일링 없이 감으로 최적화하는 것"입니다. 실제 병목은 예상과 다른 곳에 있는 경우가 대부분이며, 측정 데이터에 기반한 최적화만이 효과적입니다.

## 핵심 정리

- 성능 최적화의 첫 단계는 반드시 프로파일링이며, cProfile로 전체 병목을 파악하고 line_profiler로 핫스팟을 정밀 분석하는 2단계 접근이 효과적입니다
- NumPy 벡터화는 Python 루프를 C 수준 연산으로 대체하여 100배 이상의 속도 향상을 가져오며, AI 파이프라인에서 가장 먼저 시도해야 할 최적화입니다
- Numba의 @njit는 수치 연산 코드를 LLVM으로 JIT 컴파일하여 C 수준 성능을 달성하며, prange를 사용하면 자동 병렬화도 가능합니다
- 메모리 최적화(dtype 축소, __slots__, 제너레이터)는 캐시 효율을 높이고 GC 압력을 줄여 간접적으로 속도를 향상시킵니다
- 최적화 의사결정은 "프로파일링 → 벡터화 → JIT 컴파일 → 저수준 최적화" 순서로 진행하며, 각 단계에서 충분한 성능이 확보되면 멈추는 것이 현명합니다
