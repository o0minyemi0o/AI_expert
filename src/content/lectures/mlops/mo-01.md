# ML 시스템 아키텍처

## 왜 ML 시스템 아키텍처가 중요한가

머신러닝 모델을 연구 환경에서 학습시키는 것과 프로덕션 시스템으로 운영하는 것은 완전히 다른 문제입니다. Google의 유명한 논문 "Hidden Technical Debt in Machine Learning Systems"에 따르면, 실제 ML 시스템에서 모델 코드는 전체의 5% 미만을 차지합니다. 나머지 95%는 데이터 수집, 검증, 피처 엔지니어링, 서빙, 모니터링 등 인프라 구성 요소로 이루어져 있습니다.

> **핵심 직관**: ML 시스템 아키텍처를 설계한다는 것은 "모델을 어떻게 학습시킬까"가 아니라 "모델이 가치를 지속적으로 전달하려면 어떤 시스템이 필요한가"를 답하는 것입니다.

## 1. ML 시스템의 구성 요소

프로덕션 ML 시스템은 다음과 같은 핵심 구성 요소로 이루어집니다.

| 구성 요소 | 역할 | 대표 도구 |
|-----------|------|-----------|
| 데이터 수집/저장 | 원시 데이터 확보 및 관리 | Kafka, S3, BigQuery |
| 데이터 변환 | 피처 엔지니어링, 전처리 | Spark, dbt, Pandas |
| 실험 관리 | 학습 추적, 하이퍼파라미터 기록 | MLflow, W&B |
| 모델 학습 | 모델 훈련 및 검증 | PyTorch, TensorFlow |
| 모델 레지스트리 | 모델 버전 관리, 승인 워크플로 | MLflow, Vertex AI |
| 서빙 인프라 | 예측 API 제공 | TFServing, Triton |
| 모니터링 | 성능 추적, 드리프트 감지 | Prometheus, Evidently |

```
[데이터 소스] → [수집/검증] → [피처 변환] → [학습 파이프라인]
                                    ↓                ↓
                              [피처 스토어]     [모델 레지스트리]
                                    ↓                ↓
                              [서빙 인프라] ← [배포 파이프라인]
                                    ↓
                              [모니터링/알림] → [재학습 트리거]
```

## 2. 기술 부채의 유형

ML 시스템에서 발생하는 기술 부채는 전통적 소프트웨어와는 다른 양상을 보입니다.

**데이터 의존성 부채**: 불안정한 데이터 소스에 의존하거나, 사용하지 않는 피처가 누적되는 문제입니다. 피처 간 상관관계가 높아지면 하나의 피처 변경이 전체 시스템에 영향을 줍니다.

**파이프라인 정글**: 데이터 전처리 과정이 스크립트 단위로 관리되면서 "글루 코드"가 급격히 증가하는 현상입니다.

> **핵심 직관**: 기술 부채는 시스템이 "동작하는 것처럼 보이는" 상태에서 가장 빠르게 축적됩니다. 정기적인 코드 리뷰와 파이프라인 감사가 필수적입니다.

**시나리오: 피처 부채 누적**
추천 시스템에서 초기에 50개의 피처를 사용했고, 1년 후 200개로 증가했습니다. 분석 결과 실제 예측에 유의미한 피처는 30개뿐이었고, 나머지 170개는 연산 비용만 증가시키고 있었습니다. 피처 중요도 분석과 정기적 정리가 필요한 사례입니다.

## 3. 온라인 아키텍처 패턴

온라인 서빙은 실시간 요청에 대해 즉시 예측을 반환하는 패턴입니다.

```python
# FastAPI 기반 온라인 서빙 예시
from fastapi import FastAPI
import mlflow.pyfunc

app = FastAPI()
model = mlflow.pyfunc.load_model("models:/fraud_detector/Production")

@app.post("/predict")
async def predict(features: dict):
    prediction = model.predict([features])
    return {"score": float(prediction[0]), "model_version": "v2.3"}
```

온라인 아키텍처의 핵심 고려사항은 다음과 같습니다.

- **지연시간(Latency)**: p99 기준 100ms 이하 유지
- **처리량(Throughput)**: 초당 요청 수(QPS) 확보
- **가용성(Availability)**: 99.9% 이상 SLA 보장
- **일관성**: 피처 저장소와 서빙 시점의 데이터 일관성

## 4. 오프라인 아키텍처 패턴

오프라인(배치) 아키텍처는 대량의 데이터를 주기적으로 처리하여 예측 결과를 미리 생성하는 방식입니다.

```
[스케줄러(Airflow)]
       ↓
[배치 데이터 로드] → [피처 생성] → [배치 추론] → [결과 저장(DB/Cache)]
                                                       ↓
                                                [서빙 API에서 조회]
```

| 비교 항목 | 온라인 서빙 | 오프라인 서빙 |
|-----------|------------|--------------|
| 지연시간 | ms 단위 | 분~시간 단위 |
| 데이터 신선도 | 실시간 | 배치 주기에 의존 |
| 인프라 비용 | 상시 운영 (높음) | 주기적 실행 (상대적 저렴) |
| 장애 영향 | 즉시 사용자 영향 | 지연된 영향 |
| 적합한 유스케이스 | 실시간 사기 탐지 | 일일 추천 목록 생성 |

## 5. 하이브리드 아키텍처

실제 프로덕션에서는 온라인과 오프라인을 결합한 하이브리드 아키텍처가 가장 널리 사용됩니다.

**시나리오: 이커머스 추천 시스템**
사용자의 과거 행동 데이터 기반 추천 후보는 오프라인에서 배치 생성하고, 현재 세션의 클릭 이벤트를 반영한 실시간 리랭킹은 온라인 서빙으로 처리합니다. 이를 통해 비용 효율성과 실시간성을 동시에 확보할 수 있습니다.

```
[오프라인 배치 추론] → 후보 100개 생성 → [Redis Cache]
                                              ↓
[사용자 요청] → [온라인 서빙] → 후보 100개 로드 → 실시간 리랭킹 → Top 10 반환
                    ↑
            [실시간 피처(세션 데이터)]
```

> **핵심 직관**: 아키텍처 선택은 "최신 기술을 쓰느냐"가 아니라 "비즈니스 요구사항과 팀 역량에 맞는 가장 단순한 구조"를 찾는 것입니다. 모델 성능(dl-01 참조)보다 시스템 안정성이 먼저입니다.

## 6. 아키텍처 결정 프레임워크

ML 시스템 아키텍처를 결정할 때 다음 흐름을 참고할 수 있습니다.

```
실시간 예측이 필요한가?
├── Yes → 지연시간 요구사항이 10ms 이하인가?
│         ├── Yes → 엣지 배포 또는 임베디드 모델 고려
│         └── No  → 온라인 서빙 + 피처 스토어
└── No  → 배치 주기가 1시간 이내인가?
          ├── Yes → 마이크로배치 / 스트리밍 파이프라인
          └── No  → 전통적 배치 파이프라인 (Airflow + Spark)
```

## 핵심 정리

- ML 시스템에서 모델 코드는 전체의 5% 미만이며, 나머지는 데이터/인프라/모니터링 등 지원 시스템으로 구성됩니다
- 기술 부채는 데이터 의존성, 파이프라인 정글, 글루 코드 등의 형태로 누적되며, 정기적 감사가 필수적입니다
- 온라인 서빙은 실시간 예측, 오프라인 서빙은 배치 예측에 적합하며, 대부분의 프로덕션 시스템은 하이브리드 방식을 채택합니다
- 아키텍처 선택의 핵심 기준은 지연시간 요구사항, 데이터 신선도, 팀 역량, 비용 제약 조건입니다
- 단순한 아키텍처에서 시작하여 필요에 따라 점진적으로 복잡도를 높이는 것이 가장 안전한 전략입니다
