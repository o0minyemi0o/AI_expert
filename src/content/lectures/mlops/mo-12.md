# MLOps 성숙도와 조직

## 왜 MLOps 성숙도 모델이 중요한가

MLOps는 하루아침에 완성되는 것이 아니라, 조직의 역량과 필요에 맞게 점진적으로 구축해야 합니다. Google은 MLOps 성숙도를 0~2단계로, Microsoft는 0~4단계로 정의하고 있습니다. 성숙도 모델은 조직이 현재 어디에 있고, 다음에 어디로 가야 하는지를 가이드합니다. 과도한 엔지니어링은 비용 낭비이고, 부족한 엔지니어링은 기술 부채(mo-01 참조)를 축적시킵니다.

> **핵심 직관**: MLOps 성숙도는 "최고 레벨을 달성하는 것"이 목표가 아닙니다. 조직의 ML 활용 규모와 비즈니스 요구에 맞는 적절한 수준을 유지하는 것이 핵심입니다. 모델 1개를 운영하는 팀에 레벨 4 인프라는 과잉 투자입니다.

## 1. MLOps 성숙도 레벨

| 레벨 | 명칭 | 특징 | 모델 수 | 팀 규모 |
|------|------|------|---------|---------|
| 0 | 수동 프로세스 | 노트북에서 수동 학습/배포, 버전 관리 없음 | 1~2개 | 1~2명 |
| 1 | ML 파이프라인 자동화 | 자동화된 학습 파이프라인, 실험 추적 시작 | 3~5개 | 3~5명 |
| 2 | CI/CD 통합 | 자동 테스트, 모델 검증 게이트, 모니터링 | 5~15개 | 5~10명 |
| 3 | 자동 재학습 | 드리프트 기반 자동 재학습, 피처 스토어 | 15~50개 | 10~20명 |
| 4 | 완전 자동화 | 셀프서비스 플랫폼, 자동 스케일링, 거버넌스 | 50개+ | 20명+ |

```
성숙도 레벨별 투자 영역:

Level 0 → Level 1:
  [실험 추적(mo-03)] + [학습 자동화(mo-04)] + [기본 서빙(mo-05)]

Level 1 → Level 2:
  [CI/CD(mo-07)] + [컨테이너화(mo-06)] + [기본 모니터링(mo-08)]

Level 2 → Level 3:
  [피처 스토어(mo-09)] + [드리프트 감지(mo-08)] + [A/B 테스트(mo-10)]

Level 3 → Level 4:
  [셀프서비스 플랫폼] + [비용 최적화(mo-11)] + [거버넌스 자동화]
```

## 2. 단계별 구축 로드맵

각 레벨로 진입하기 위해 필요한 핵심 역량과 도구를 상세히 살펴봅니다.

**Level 0 → Level 1: 기초 자동화**

```python
# Level 1 최소 요구사항: 실험 추적 + 재현 가능한 파이프라인
import mlflow

# 1. 모든 실험을 추적
mlflow.set_experiment("my_first_tracked_experiment")
with mlflow.start_run():
    mlflow.log_params(config)
    mlflow.log_metrics(metrics)
    mlflow.sklearn.log_model(model, "model")

# 2. 파이프라인을 코드로 정의 (노트북 → 스크립트)
# train.py
if __name__ == "__main__":
    data = load_data(config["data_path"])
    features = transform(data)
    model = train(features, config["model_params"])
    evaluate(model, test_data)
```

**Level 1 → Level 2: CI/CD 통합**

```yaml
# Level 2: 자동 테스트가 포함된 배포 파이프라인
# .github/workflows/ml-pipeline.yaml
name: ML Pipeline
on: push
jobs:
  test-and-deploy:
    runs-on: ubuntu-latest
    steps:
      - run: pytest tests/ -v
      - run: python train.py --config configs/smoke_test.yaml
      - run: python evaluate.py --threshold 0.85
      - run: docker build -t model-server .
      - run: kubectl apply -f k8s/deployment.yaml
```

## 3. ML 팀 구조

ML 시스템을 운영하는 팀의 구조는 조직의 ML 성숙도에 따라 달라집니다.

| 역할 | 핵심 역량 | Level 0~1 | Level 2~3 | Level 4 |
|------|----------|-----------|-----------|---------|
| 데이터 사이언티스트 | 모델링, 실험 설계 | 겸임 | 전담 | 전담 |
| ML 엔지니어 | 파이프라인, 서빙 | 없음 | 전담 | 전담 |
| 데이터 엔지니어 | 데이터 파이프라인 | 없음 | 겸임 | 전담 |
| MLOps 엔지니어 | 인프라, CI/CD, 모니터링 | 없음 | 없음/겸임 | 전담 |
| 플랫폼 엔지니어 | 셀프서비스 플랫폼 구축 | 없음 | 없음 | 전담 |

```
팀 구조 진화:

[초기] 풀스택 DS 1~2명이 모든 것 담당
  ↓
[성장] DS + ML Engineer 분리 (모델링 vs 엔지니어링)
  ↓
[확장] 기능별 전문화 (데이터 / 모델 / 인프라 / 플랫폼)
  ↓
[성숙] 프로덕트 팀 내 임베디드 ML + 중앙 플랫폼 팀
```

> **핵심 직관**: 조직 구조는 Conway의 법칙을 따릅니다. "시스템의 설계는 그것을 만든 조직의 커뮤니케이션 구조를 반영한다." ML 플랫폼의 구조가 팀의 소통 방식과 일치해야 효율적으로 운영됩니다.

**시나리오: 스타트업의 ML 팀 구성 전략**
시리즈 A 스타트업이 ML을 도입합니다. 초기 팀: 시니어 ML 엔지니어 1명 + 데이터 사이언티스트 1명. ML 엔지니어가 인프라(Docker, CI/CD, 서빙)를 담당하고, DS가 모델링에 집중합니다. 6개월 후 모델 수가 5개로 증가하면 ML 엔지니어 추가 채용, 데이터 엔지니어는 데이터 팀에서 파트타임 지원받는 구조로 전환합니다.

## 4. 플랫폼 엔지니어링

ML 플랫폼은 데이터 사이언티스트가 인프라 걱정 없이 모델 개발에 집중할 수 있도록 추상화된 도구와 인터페이스를 제공합니다.

```yaml
# ML 플랫폼 셀프서비스 인터페이스 예시
# model_config.yaml (DS가 작성)
model:
  name: churn_predictor
  owner: ds-team@company.com
  framework: sklearn

training:
  schedule: "weekly"
  data_source: "feature_store://user_engagement_features"
  compute: "cpu-medium"  # 플랫폼이 인프라 자동 할당
  experiment_tracking: true

serving:
  type: online
  sla_latency_ms: 50
  min_replicas: 2
  max_replicas: 10
  autoscale_metric: cpu

monitoring:
  data_drift: true
  performance_tracking: true
  alert_channel: "#ml-alerts"
```

```
ML 플랫폼 아키텍처:

┌─────────────────────────────────────────────────┐
│            셀프서비스 인터페이스 (UI/CLI/YAML)       │
├─────────────────────────────────────────────────┤
│  [실험 관리]  [학습 파이프라인]  [서빙]  [모니터링]   │
├─────────────────────────────────────────────────┤
│  [피처 스토어]  [모델 레지스트리]  [메타데이터 스토어]  │
├─────────────────────────────────────────────────┤
│  [오케스트레이션]  [컨테이너 관리]  [GPU 스케줄링]    │
├─────────────────────────────────────────────────┤
│           인프라 (K8s / Cloud / On-prem)          │
└─────────────────────────────────────────────────┘
```

DS가 YAML 설정 파일만 작성하면, 플랫폼이 자동으로 학습 파이프라인 생성, 컨테이너 빌드, 서빙 배포, 모니터링 설정을 수행합니다. 이것이 Level 4 성숙도의 핵심입니다.

## 5. ML 거버넌스

ML 거버넌스는 모델의 개발, 배포, 운영 전 과정에서 책임성, 투명성, 규제 준수를 보장하는 프레임워크입니다.

| 거버넌스 영역 | 핵심 질문 | 구현 방법 |
|-------------|----------|-----------|
| 모델 카탈로그 | 어떤 모델이 운영 중인가? | 중앙 모델 레지스트리(mo-03) |
| 접근 제어 | 누가 모델을 배포할 수 있는가? | RBAC, 승인 워크플로 |
| 감사 추적 | 언제 누가 무엇을 변경했는가? | 변경 이력 로깅 |
| 공정성 | 모델이 특정 그룹을 차별하지 않는가? | 편향 검증 자동화(mo-07) |
| 설명가능성 | 모델의 예측 근거를 설명할 수 있는가? | SHAP, LIME (ms-05 참조) |
| 규제 준수 | 관련 법규를 준수하는가? | 규제 매핑, 정기 감사 |

```python
# 모델 거버넌스 자동화 예시
class ModelGovernanceGate:
    """모델 배포 전 거버넌스 검증 게이트"""

    def __init__(self, model_name: str, model_version: str):
        self.model_name = model_name
        self.model_version = model_version
        self.checks = []

    def check_performance(self, metrics: dict) -> bool:
        passed = metrics["f1"] >= 0.85 and metrics["auc"] >= 0.90
        self.checks.append(("performance", passed))
        return passed

    def check_fairness(self, group_metrics: dict) -> bool:
        max_gap = max(group_metrics.values()) - min(group_metrics.values())
        passed = max_gap < 0.05
        self.checks.append(("fairness", passed))
        return passed

    def check_documentation(self) -> bool:
        """모델 카드(Model Card) 작성 여부 확인"""
        model_card = load_model_card(self.model_name, self.model_version)
        passed = all([
            model_card.get("intended_use"),
            model_card.get("limitations"),
            model_card.get("training_data_description"),
            model_card.get("evaluation_results"),
        ])
        self.checks.append(("documentation", passed))
        return passed

    def approve(self) -> bool:
        all_passed = all(passed for _, passed in self.checks)
        log_governance_decision(self.model_name, self.model_version, self.checks)
        return all_passed
```

> **핵심 직관**: 거버넌스는 "속도를 늦추는 관료주의"가 아니라 "실패의 비용을 줄이는 안전장치"입니다. 금융, 의료, 채용 등 고위험 영역에서는 자동화된 거버넌스가 조직을 법적 위험과 평판 리스크로부터 보호합니다.

## 6. 성숙도 자가 진단

현재 조직의 MLOps 성숙도를 진단하기 위한 체크리스트입니다.

```
성숙도 자가 진단:

□ 모든 실험이 추적되고 재현 가능한가?           → Level 1
□ 학습 파이프라인이 코드로 정의되어 있는가?      → Level 1
□ 모델 배포에 자동화된 테스트가 포함되어 있는가?  → Level 2
□ CI/CD 파이프라인이 ML에 맞게 구축되어 있는가?  → Level 2
□ 모델 성능 모니터링이 자동화되어 있는가?        → Level 2
□ 데이터 드리프트 감지가 작동하고 있는가?        → Level 3
□ 피처 스토어가 운영되고 있는가?                → Level 3
□ A/B 테스트 인프라가 갖추어져 있는가?           → Level 3
□ DS가 셀프서비스로 모델을 배포할 수 있는가?     → Level 4
□ 모델 거버넌스가 자동화되어 있는가?             → Level 4
```

**시나리오: 성숙도 레벨 2에서 3으로의 전환**
중견 이커머스 회사가 15개 모델을 운영하면서 수동 재학습의 한계에 부딪혔습니다. 모니터링 대시보드에서 드리프트를 발견해도 재학습까지 평균 5일이 걸렸습니다. Feast 기반 피처 스토어 도입(3개월), Evidently 기반 자동 드리프트 감지 + Airflow 재학습 트리거 연동(2개월), A/B 테스트 인프라 구축(2개월)을 통해 7개월 만에 Level 3에 도달했습니다. 재학습 소요 시간이 5일에서 4시간으로 단축되었습니다.

## 핵심 정리

- MLOps 성숙도는 0(수동)에서 4(완전 자동화)까지 5단계이며, 조직의 ML 규모에 맞는 적절한 레벨을 목표로 합니다
- 팀 구조는 초기 풀스택 DS에서 시작하여, 성장에 따라 ML 엔지니어, 데이터 엔지니어, 플랫폼 엔지니어로 전문화됩니다
- ML 플랫폼은 데이터 사이언티스트에게 셀프서비스 인터페이스를 제공하여 인프라 복잡도를 추상화합니다
- ML 거버넌스는 모델 카탈로그, 접근 제어, 감사 추적, 공정성 검증, 설명가능성을 자동화하여 조직 리스크를 줄입니다
- 성숙도 향상은 점진적으로 이루어져야 하며, 각 레벨의 기초가 튼튼해야 다음 레벨로 안전하게 전환할 수 있습니다
