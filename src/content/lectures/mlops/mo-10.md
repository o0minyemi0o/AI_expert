# A/B 테스트와 점진적 배포

## 왜 A/B 테스트가 중요한가

오프라인 평가(ms-03 참조)에서 우수한 성능을 보인 모델이 실제 프로덕션에서도 동일한 효과를 보장하지 않습니다. 사용자 행동, 시스템 상호작용, 비즈니스 메트릭에 대한 영향은 실제 트래픽으로만 측정할 수 있습니다. A/B 테스트는 두 가지 이상의 모델 변형을 실제 사용자에게 노출하여 통계적으로 유의미한 비교를 수행하는 방법입니다. 점진적 배포는 새 모델을 전체 트래픽에 한 번에 적용하는 대신 단계적으로 확대하여 위험을 최소화합니다.

> **핵심 직관**: A/B 테스트는 "이 모델이 더 좋은가?"에 대한 과학적 답변을 제공합니다. 직관이나 오프라인 메트릭이 아니라, 실제 사용자 데이터에 기반한 의사결정을 가능하게 합니다.

## 1. 온라인 실험 설계

A/B 테스트의 핵심 요소는 다음과 같습니다.

| 설계 요소 | 설명 | 고려사항 |
|-----------|------|----------|
| 실험 단위 | 무작위 배정의 기본 단위 | 사용자, 세션, 요청 |
| 표본 크기 | 통계적 유의성을 위한 최소 관측 수 | 검정력 분석으로 사전 결정 |
| 실험 기간 | 테스트 실행 기간 | 요일 효과, 계절성 고려 |
| 주요 메트릭 | 의사결정 기준 메트릭 | CTR, 매출, 체류시간 등 |
| 가드레일 메트릭 | 악화되면 안 되는 메트릭 | 지연시간, 오류율, 이탈률 |

```python
# A/B 테스트 표본 크기 계산
from scipy import stats
import numpy as np

def calculate_sample_size(baseline_rate, mde, alpha=0.05, power=0.8):
    """
    최소 표본 크기 계산
    baseline_rate: 기존 전환율 (예: 0.05)
    mde: 최소 감지 효과 (Minimum Detectable Effect, 예: 0.005)
    """
    effect_size = mde / np.sqrt(baseline_rate * (1 - baseline_rate))
    analysis = stats.TTestIndPower()
    sample_size = analysis.solve_power(
        effect_size=effect_size, alpha=alpha, power=power, alternative="two-sided"
    )
    return int(np.ceil(sample_size))

# 예: 기존 CTR 5%, 0.5%p 개선을 탐지하려면?
n = calculate_sample_size(baseline_rate=0.05, mde=0.005)
print(f"그룹당 필요 표본 크기: {n:,}")  # 약 31,000
```

## 2. 트래픽 분배와 실험 인프라

```python
# 해시 기반 트래픽 분배 (일관된 사용자 배정)
import hashlib

def assign_experiment_group(user_id: str, experiment_name: str, num_groups: int = 2) -> int:
    """사용자를 실험 그룹에 결정적으로 배정"""
    hash_input = f"{experiment_name}:{user_id}".encode()
    hash_value = int(hashlib.md5(hash_input).hexdigest(), 16)
    return hash_value % num_groups

def get_model_for_user(user_id: str) -> str:
    group = assign_experiment_group(user_id, "recommender_v3_test")
    if group == 0:
        return "recommender_v2"  # 대조군 (현재 모델)
    else:
        return "recommender_v3"  # 실험군 (새 모델)
```

```
A/B 테스트 트래픽 분배:

전체 트래픽 (100%)
├── 대조군 A (50%) → 현재 모델 v2
└── 실험군 B (50%) → 새 모델 v3
     │
     ├── 주요 메트릭: CTR, 구매 전환율
     ├── 가드레일: 지연시간, 이탈률
     └── 기간: 2주 (요일 효과 포함)
```

> **핵심 직관**: 실험 그룹 배정은 반드시 결정적(deterministic)이어야 합니다. 동일 사용자가 방문할 때마다 다른 모델을 보게 되면 사용자 경험이 불일치하고, 실험 결과의 신뢰성이 떨어집니다. 해시 기반 배정이 이를 보장합니다.

## 3. 카나리 배포 (Canary Deployment)

카나리 배포는 새 모델을 소수의 트래픽에만 먼저 노출하고, 문제가 없으면 점진적으로 확대하는 전략입니다.

```yaml
# Kubernetes 기반 카나리 배포 설정 (Istio)
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: model-serving
spec:
  http:
    - route:
        - destination:
            host: model-v2  # 현재 모델
            port:
              number: 8080
          weight: 95
        - destination:
            host: model-v3  # 새 모델 (카나리)
            port:
              number: 8080
          weight: 5
```

```
카나리 배포 단계별 확대:

Day 1-2:  [█░░░░░░░░░░░░░░░░░░░] 5%  → 기본 메트릭 확인
Day 3-4:  [███░░░░░░░░░░░░░░░░░] 15% → 성능 메트릭 비교
Day 5-7:  [██████░░░░░░░░░░░░░░] 30% → 통계적 유의성 검증
Day 8-10: [██████████░░░░░░░░░░] 50% → A/B 테스트 결과 분석
Day 11:   [████████████████████] 100% → 전체 전환

  ⚠ 어느 단계에서든 이상 감지 시 → 즉시 0%로 롤백
```

```python
# 자동 카나리 배포 로직
class CanaryDeployer:
    STAGES = [5, 15, 30, 50, 100]

    def __init__(self, experiment_name: str):
        self.experiment = experiment_name
        self.current_stage = 0

    def evaluate_and_promote(self, metrics: dict) -> str:
        """메트릭 평가 후 승격/롤백 결정"""
        if metrics["error_rate"] > 0.01:
            return self.rollback("에러율 1% 초과")

        if metrics["p99_latency_ms"] > 100:
            return self.rollback("지연시간 SLA 초과")

        if self.current_stage > 1 and metrics["conversion_rate_delta"] < -0.02:
            return self.rollback("전환율 2% 이상 하락")

        # 다음 단계로 승격
        self.current_stage += 1
        if self.current_stage >= len(self.STAGES):
            return "full_rollout"

        new_weight = self.STAGES[self.current_stage]
        update_traffic_weight(self.experiment, new_weight)
        return f"promoted_to_{new_weight}%"

    def rollback(self, reason: str) -> str:
        update_traffic_weight(self.experiment, 0)
        send_alert(f"카나리 롤백: {reason}")
        return f"rolled_back: {reason}"
```

## 4. 블루-그린 배포

블루-그린 배포는 두 개의 동일한 프로덕션 환경을 유지하고, 트래픽을 한 번에 전환하는 방식입니다.

| 비교 항목 | 카나리 배포 | 블루-그린 배포 |
|-----------|-----------|---------------|
| 트래픽 전환 | 점진적 (5% → 100%) | 즉시 전환 (0% → 100%) |
| 롤백 속도 | 즉시 | 즉시 |
| 리소스 비용 | 추가 인프라 최소 | 2배의 인프라 필요 |
| 테스트 범위 | 실제 트래픽 일부 | 전체 트래픽 (전환 후) |
| 적합한 상황 | 점진적 검증 필요 | 빠른 전환, 즉시 롤백 필요 |

```
블루-그린 배포 흐름:

[로드 밸런서]
     │
     ├──→ [Blue 환경: Model v2] ← 현재 트래픽 100%
     │
     └──→ [Green 환경: Model v3] ← 대기 (0%)
              │
              └── 검증 완료 후 ──→ [로드 밸런서] 전환
                                      │
                                      ├──→ [Blue 환경: Model v2] ← 대기 (롤백용)
                                      │
                                      └──→ [Green 환경: Model v3] ← 현재 트래픽 100%
```

## 5. 멀티암드 밴딧 (Multi-Armed Bandit)

전통적 A/B 테스트는 실험 기간 동안 최적이 아닌 변형에도 동일한 트래픽을 할당합니다. 멀티암드 밴딧은 실험 중에도 더 나은 변형에 더 많은 트래픽을 할당하여 기회 비용을 줄입니다.

```python
# Thompson Sampling 기반 멀티암드 밴딧
import numpy as np
from scipy.stats import beta

class ThompsonSamplingBandit:
    def __init__(self, n_arms: int):
        self.successes = np.ones(n_arms)  # Beta prior: alpha=1
        self.failures = np.ones(n_arms)   # Beta prior: beta=1

    def select_arm(self) -> int:
        """각 팔(모델)의 성공률을 Beta 분포에서 샘플링하여 최대값 선택"""
        samples = [
            beta.rvs(self.successes[i], self.failures[i])
            for i in range(len(self.successes))
        ]
        return int(np.argmax(samples))

    def update(self, arm: int, reward: float):
        """결과 관측 후 분포 업데이트"""
        if reward > 0:
            self.successes[arm] += 1
        else:
            self.failures[arm] += 1

# 사용 예시
bandit = ThompsonSamplingBandit(n_arms=3)  # 3개 모델 비교

for request in incoming_requests:
    model_idx = bandit.select_arm()
    prediction = models[model_idx].predict(request)
    reward = observe_outcome(request, prediction)  # 클릭 여부 등
    bandit.update(model_idx, reward)
```

| 비교 항목 | A/B 테스트 | 멀티암드 밴딧 |
|-----------|-----------|--------------|
| 트래픽 분배 | 고정 (50/50) | 동적 (성과 기반 조정) |
| 기회 비용 | 높음 (열등한 변형에도 50%) | 낮음 (점진적 최적 변형 집중) |
| 통계적 엄밀성 | 높음 (p-value 명확) | 상대적 낮음 |
| 실험 종료 시점 | 사전 결정 | 수렴 기반 |
| 적합한 상황 | 엄밀한 인과 추론 필요 | 빠른 최적화, 다수 변형 |

> **핵심 직관**: A/B 테스트와 멀티암드 밴딧은 대립하는 것이 아니라 보완적입니다. 엄밀한 인과 추론이 필요하면 A/B 테스트를, 빠른 최적화가 필요하면 밴딧을 사용합니다. 실무에서는 카나리 배포(안전) → A/B 테스트(검증) → 밴딧(최적화) 순서로 결합하는 경우가 많습니다.

**시나리오: 추천 모델 A/B 테스트**
이커머스 플랫폼에서 새로운 딥러닝 기반 추천 모델(dl-05 참조)을 기존 협업 필터링 모델과 비교합니다. 2주간 사용자 50만 명을 대상으로 A/B 테스트를 수행한 결과: CTR +8.2%(p<0.01), 구매 전환율 +3.1%(p<0.05), 평균 주문 금액 변화 없음(p=0.42). 가드레일 메트릭(지연시간, 이탈률)에 부정적 영향이 없어 새 모델 전면 배포를 결정했습니다.

**시나리오: 밴딧 기반 실시간 광고 최적화**
5개의 광고 크리에이티브 변형을 테스트합니다. 전통적 A/B 테스트는 2주 동안 모든 변형에 20%씩 배정하지만, Thompson Sampling 밴딧은 3일 만에 상위 2개 변형에 트래픽을 집중시켜 전체 광고 수익을 15% 향상시켰습니다.

## 핵심 정리

- A/B 테스트는 오프라인 평가를 보완하여 실제 사용자 데이터 기반의 모델 비교를 가능하게 하며, 사전 표본 크기 계산이 필수입니다
- 카나리 배포는 5% → 15% → 30% → 50% → 100%로 점진적 확대하며, 각 단계에서 메트릭 검증과 자동 롤백 메커니즘을 갖춥니다
- 블루-그린 배포는 즉시 전환과 롤백이 가능하지만 2배의 인프라 비용이 필요합니다
- 멀티암드 밴딧은 탐색-활용(Exploration-Exploitation) 균형을 통해 A/B 테스트 대비 기회 비용을 줄입니다
- 실무에서는 카나리(안전) → A/B 테스트(검증) → 밴딧(최적화)을 상황에 맞게 조합하여 사용합니다
