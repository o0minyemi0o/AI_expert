# MCMC와 계산적 베이즈

## 왜 MCMC가 필요한가

si-03에서 다룬 베이즈 추론의 핵심은 사후 분포 $p(\theta|x)$를 계산하는 것입니다. 그러나 대부분의 실제 문제에서 사후 분포의 정규화 상수를 해석적으로 구할 수 없습니다. MCMC(Markov Chain Monte Carlo)는 사후 분포에서 직접 표본을 추출하여, 적분을 시뮬레이션으로 대체하는 혁명적 방법입니다. 현대 베이즈 통계학의 실용적 근간을 이룹니다.

---

## 1. 몬테카를로 적분의 기본 원리

사후 기대값 $E[g(\theta)|x]$를 계산하고 싶을 때:

$$E[g(\theta)|x] = \int g(\theta) p(\theta|x) \, d\theta \approx \frac{1}{N}\sum_{i=1}^{N} g(\theta^{(i)}), \quad \theta^{(i)} \sim p(\theta|x)$$

| 방법 | 적분 차원 영향 | 수렴 속도 |
|------|-------------|---------|
| 수치 적분 (구적법) | 차원의 저주 ($O(n^{-2/d})$) | 매우 느림 (고차원) |
| 몬테카를로 | 차원 무관 | $O(N^{-1/2})$ |
| 준몬테카를로 | 약한 의존 | $O(N^{-1}(\log N)^d)$ |

문제: $p(\theta|x)$에서 직접 표본 추출이 어려움 $\to$ MCMC!

> **핵심 직관**: 몬테카를로의 핵심 장점은 수렴 속도가 차원에 의존하지 않는다는 것입니다. 100차원 적분이든 1차원 적분이든, $N$개 표본의 오차는 $O(1/\sqrt{N})$입니다.

```python
import numpy as np

# 몬테카를로 적분 예시: E[X^2], X ~ Beta(2, 5)
from scipy.stats import beta

a, b = 2, 5
true_val = a*(a+1) / ((a+b)*(a+b+1))  # E[X^2] for Beta

Ns = [100, 1000, 10000, 100000]
for N in Ns:
    samples = beta.rvs(a, b, size=N)
    mc_estimate = np.mean(samples**2)
    print(f"N={N:6d}: MC 추정={mc_estimate:.6f}, 참값={true_val:.6f}, "
          f"오차={abs(mc_estimate - true_val):.6f}")
```

---

## 2. Metropolis-Hastings 알고리즘

**Metropolis-Hastings (MH)** 알고리즘은 목표 분포 $\pi(\theta)$에서 표본을 추출하는 MCMC의 기본 알고리즘입니다.

**알고리즘**:
1. 초기값 $\theta^{(0)}$ 설정
2. $t = 1, 2, \dots$에 대해:
   - 제안 분포에서 후보 생성: $\theta^* \sim q(\theta^* | \theta^{(t-1)})$
   - 채택 확률 계산: $\alpha = \min\left(1, \frac{\pi(\theta^*) q(\theta^{(t-1)}|\theta^*)}{\pi(\theta^{(t-1)}) q(\theta^*|\theta^{(t-1)})}\right)$
   - $U \sim \text{Uniform}(0,1)$: $U < \alpha$이면 $\theta^{(t)} = \theta^*$, 아니면 $\theta^{(t)} = \theta^{(t-1)}$

| 제안 분포 유형 | 특징 |
|-------------|------|
| 랜덤 워크 | $q(\theta^*|\theta) = q(\theta^*-\theta)$, 대칭이면 Metropolis |
| 독립 제안 | $q(\theta^*|\theta) = q(\theta^*)$, 중요도 표집과 관련 |
| 랑주뱅 | 그래디언트 정보 활용, MALA |

> **핵심 직관**: MH는 "제안하고 확률적으로 채택/기각"하는 방식으로, 정규화 상수를 모르더라도 $\pi(\theta^*)/\pi(\theta)$의 비만 계산하면 됩니다. 이것이 베이즈 추론에서 결정적으로 유용한 이유입니다.

```python
# Metropolis-Hastings: 이봉 분포에서 표본 추출
def target_log_pdf(x):
    """이봉 혼합 정규 분포"""
    return np.log(0.3 * np.exp(-0.5*(x+3)**2) + 0.7 * np.exp(-0.5*(x-2)**2))

def metropolis_hastings(n_samples, proposal_sd=1.5, x0=0):
    samples = [x0]
    accepts = 0
    for _ in range(n_samples):
        x_current = samples[-1]
        x_proposal = x_current + np.random.normal(0, proposal_sd)
        log_alpha = target_log_pdf(x_proposal) - target_log_pdf(x_current)
        if np.log(np.random.uniform()) < log_alpha:
            samples.append(x_proposal)
            accepts += 1
        else:
            samples.append(x_current)
    return np.array(samples), accepts / n_samples

samples, accept_rate = metropolis_hastings(10000)
print(f"채택률: {accept_rate:.4f}")
print(f"사후 평균: {np.mean(samples[1000:]):.4f}")  # burn-in 제거
print(f"사후 표준편차: {np.std(samples[1000:]):.4f}")
```

---

## 3. 깁스 표본추출 (Gibbs Sampling)

**깁스 표본추출**은 다변수 분포에서 각 변수를 조건부 분포로부터 순차적으로 추출합니다.

$\boldsymbol{\theta} = (\theta_1, \dots, \theta_d)$에 대해:

1. $\theta_1^{(t)} \sim p(\theta_1 | \theta_2^{(t-1)}, \dots, \theta_d^{(t-1)}, x)$
2. $\theta_2^{(t)} \sim p(\theta_2 | \theta_1^{(t)}, \theta_3^{(t-1)}, \dots, \theta_d^{(t-1)}, x)$
3. $\vdots$
4. $\theta_d^{(t)} \sim p(\theta_d | \theta_1^{(t)}, \dots, \theta_{d-1}^{(t)}, x)$

| 비교 | MH | Gibbs |
|------|-----|-------|
| 채택/기각 | 있음 | 없음 (항상 채택) |
| 적용 조건 | 범용 | 조건부 분포를 알아야 함 |
| 고차원 | 제안 설계 어려움 | 자연스러운 차원 분할 |
| 켤레 모델 | — | 조건부가 닫힌 형태 |

> **핵심 직관**: 깁스 표본추출은 "한 번에 하나의 변수만 갱신"하는 전략입니다. si-03의 켤레 사전을 사용하면 각 조건부가 닫힌 형태로 주어져 매우 효율적입니다.

```python
# 깁스 표본추출: 이변량 정규 분포
def gibbs_bivariate_normal(n_samples, rho=0.8, mu=np.array([0, 0]), x0=np.array([0, 0])):
    samples = [x0.copy()]
    x = x0.copy()
    for _ in range(n_samples):
        # x1 | x2 ~ N(mu1 + rho*(x2-mu2), 1-rho^2)
        x[0] = np.random.normal(mu[0] + rho*(x[1]-mu[1]), np.sqrt(1-rho**2))
        # x2 | x1 ~ N(mu2 + rho*(x1-mu1), 1-rho^2)
        x[1] = np.random.normal(mu[1] + rho*(x[0]-mu[0]), np.sqrt(1-rho**2))
        samples.append(x.copy())
    return np.array(samples)

samples = gibbs_bivariate_normal(5000, rho=0.8)
print(f"추정된 평균: {samples[500:].mean(axis=0)}")
print(f"추정된 상관: {np.corrcoef(samples[500:, 0], samples[500:, 1])[0,1]:.4f}")
```

---

## 4. 수렴 진단 (Convergence Diagnostics)

MCMC 체인이 목표 분포에 수렴했는지 확인하는 것은 필수적입니다.

**(1) 트레이스 플롯 (Trace plot)**: 체인의 궤적을 시각적으로 확인합니다.

**(2) Gelman-Rubin 진단** ($\hat{R}$): 여러 체인의 체인 간 분산(B)과 체인 내 분산(W)을 비교합니다.

$$\hat{R} = \sqrt{\frac{\hat{V}}{W}} \quad \text{where } \hat{V} = \frac{n-1}{n}W + \frac{1}{n}B$$

| 진단 방법 | 기준 | 판단 |
|-----------|------|------|
| $\hat{R}$ (Gelman-Rubin) | $\hat{R} < 1.01$ | 수렴 |
| 유효 표본 크기 (ESS) | ESS $> 400$ | 충분한 표본 |
| 자기상관 함수 (ACF) | 빠르게 감소 | 좋은 혼합 |

**(3) 유효 표본 크기 (Effective Sample Size)**:

$$\text{ESS} = \frac{N}{1 + 2\sum_{k=1}^{\infty} \rho_k}$$

여기서 $\rho_k$는 lag-$k$ 자기상관입니다.

> **핵심 직관**: MCMC 표본은 독립이 아니므로, 10,000개의 표본이 있어도 유효 표본은 1,000개일 수 있습니다. $\hat{R} \approx 1$은 "여러 출발점에서 같은 곳에 도달했다"는 증거입니다.

```python
# 수렴 진단 시뮬레이션
def run_multiple_chains(n_chains=4, n_samples=5000):
    chains = []
    for _ in range(n_chains):
        x0 = np.random.uniform(-10, 10)
        samples, _ = metropolis_hastings(n_samples, x0=x0)
        chains.append(samples[1000:])  # burn-in 제거
    return chains

chains = run_multiple_chains()

# Gelman-Rubin R-hat 계산
n = len(chains[0])
m = len(chains)
chain_means = [np.mean(c) for c in chains]
overall_mean = np.mean(chain_means)
B = n * np.var(chain_means, ddof=1)
W = np.mean([np.var(c, ddof=1) for c in chains])
V_hat = (n-1)/n * W + B/n
R_hat = np.sqrt(V_hat / W)
print(f"R-hat: {R_hat:.4f} ({'수렴' if R_hat < 1.01 else '미수렴'})")

# 유효 표본 크기 (간이 계산)
from statsmodels.tsa.stattools import acf
acf_vals = acf(chains[0], nlags=50, fft=True)
ess = n / (1 + 2*np.sum(acf_vals[1:]))
print(f"ESS: {ess:.0f} / {n}")
```

---

## 5. Hamiltonian Monte Carlo (HMC)

**HMC**는 목표 분포의 그래디언트를 활용하여 효율적인 제안을 생성합니다.

해밀턴 역학:

$$H(\theta, r) = -\log p(\theta|x) + \frac{1}{2}r^T M^{-1} r$$

| 구성 요소 | 물리적 비유 |
|-----------|-----------|
| $\theta$ | 위치 |
| $r$ | 운동량 |
| $-\log p(\theta\|x)$ | 위치 에너지 |
| $\frac{1}{2}r^T M^{-1}r$ | 운동 에너지 |

**NUTS(No-U-Turn Sampler)**: HMC의 경로 길이를 자동으로 결정합니다.

| 알고리즘 | 그래디언트 | 튜닝 | 효율 |
|---------|----------|------|------|
| 랜덤 워크 MH | 불필요 | 제안 분산 | 낮음 |
| MALA | 1차 | 스텝 크기 | 중간 |
| HMC | 1차 | 스텝 크기, 경로 길이 | 높음 |
| NUTS | 1차 | 자동 | 매우 높음 |

> **핵심 직관**: HMC는 "공을 경사면에서 굴리는 것"과 같습니다. 그래디언트를 따라 멀리 이동하면서도 높은 채택률을 유지합니다. Stan, PyMC 등 현대 베이즈 소프트웨어의 기본 알고리즘입니다.

```python
# PyMC를 사용한 베이즈 추론 (NUTS 자동 사용)
# 설치: pip install pymc
# import pymc as pm
#
# with pm.Model() as model:
#     mu = pm.Normal('mu', mu=0, sigma=10)
#     sigma = pm.HalfNormal('sigma', sigma=5)
#     obs = pm.Normal('obs', mu=mu, sigma=sigma, observed=data)
#     trace = pm.sample(2000, return_inferencedata=True)
#
# print(pm.summary(trace))

# 간단한 HMC 구현 (1D)
def hmc_1d(log_prob, grad_log_prob, n_samples, step_size=0.1, n_leapfrog=20, x0=0):
    samples = [x0]
    x = x0
    accepts = 0
    for _ in range(n_samples):
        r = np.random.normal()
        x_new, r_new = x, r
        # 리프프로그 적분
        r_new = r_new + 0.5 * step_size * grad_log_prob(x_new)
        for _ in range(n_leapfrog - 1):
            x_new = x_new + step_size * r_new
            r_new = r_new + step_size * grad_log_prob(x_new)
        x_new = x_new + step_size * r_new
        r_new = r_new + 0.5 * step_size * grad_log_prob(x_new)
        # MH 채택
        H_current = -log_prob(x) + 0.5*r**2
        H_new = -log_prob(x_new) + 0.5*r_new**2
        if np.log(np.random.uniform()) < H_current - H_new:
            x = x_new
            accepts += 1
        samples.append(x)
    return np.array(samples), accepts / n_samples

log_p = lambda x: -0.5*x**2  # 표준 정규
grad_log_p = lambda x: -x
hmc_samples, hmc_accept = hmc_1d(log_p, grad_log_p, 5000)
print(f"HMC 채택률: {hmc_accept:.4f}")
print(f"HMC 표본 평균: {hmc_samples[500:].mean():.4f}, 분산: {hmc_samples[500:].var():.4f}")
```

---

## 6. 실용적 MCMC 워크플로

| 단계 | 설명 |
|------|------|
| 1. 모델 지정 | 우도, 사전 분포 설정 |
| 2. 초기값 선택 | MLE 근처 또는 여러 랜덤 초기값 |
| 3. 워밍업/번인 | 초기 표본 버림 (보통 전체의 50%) |
| 4. 수렴 진단 | $\hat{R}$, ESS, 트레이스 플롯 |
| 5. 사후 요약 | 평균, 중앙값, HPD 구간 |
| 6. 사후 예측 검증 | 모델 적합도 확인 |

> **핵심 직관**: MCMC는 "돌리면 된다"가 아닙니다. 수렴 진단 없이 결과를 보고하는 것은 수렴하지 않은 최적화의 결과를 보고하는 것과 같습니다. si-10에서 다룰 변분 추론은 수렴 문제를 다르게 접근합니다.

---

## 7. MCMC의 한계와 대안

| 한계 | 설명 | 대안 |
|------|------|------|
| 느린 수렴 | 고차원, 강한 상관 | HMC, 리만 HMC |
| 다봉 분포 | 봉 사이 이동 어려움 | 병렬 템퍼링 |
| 계산 비용 | 매 반복마다 우도 계산 | 변분 추론 (si-10) |
| 수렴 보장 없음 | 유한 시간에는 근사 | 진단 도구 활용 |
| 대규모 데이터 | 전체 데이터 우도 비용 | 확률적 그래디언트 MCMC |

> **핵심 직관**: MCMC는 정확하지만 느리고, si-10의 변분 추론은 빠르지만 근사적입니다. 문제의 특성에 따라 적절한 방법을 선택해야 합니다.

---

## 핵심 정리

- **MCMC는 정규화 상수를 모르는 사후 분포에서 표본을 추출하여, 베이즈 적분을 몬테카를로 근사로 대체합니다**
- **Metropolis-Hastings는 제안-채택/기각 메커니즘으로, 목표 분포의 비만 알면 되며 정규화 상수가 불필요합니다**
- **깁스 표본추출은 조건부 분포에서 순차적으로 추출하며, 켤레 모델에서 특히 효율적입니다**
- **수렴 진단($\hat{R} < 1.01$, 충분한 ESS, ACF 감소)은 MCMC 결과의 신뢰성을 보장하는 필수 단계입니다**
- **HMC/NUTS는 그래디언트 정보를 활용하여 고차원에서도 효율적인 표본 추출을 가능하게 하며, 현대 확률 프로그래밍의 기반입니다**
