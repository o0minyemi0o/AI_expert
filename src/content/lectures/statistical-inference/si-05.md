# 가설 검정의 기초

## 왜 가설 검정이 필요한가

추정만으로는 "효과가 있는가?", "두 그룹이 다른가?"와 같은 의사결정 문제에 답할 수 없습니다. 가설 검정은 데이터에 기반하여 주장의 타당성을 판단하는 통계적 의사결정 프레임워크입니다. si-01에서 다룬 추정 이론이 "얼마인가?"에 답한다면, 가설 검정은 "맞는가?"에 답합니다.

---

## 1. 가설 검정의 구조

**귀무가설(null hypothesis)** $H_0$와 **대립가설(alternative hypothesis)** $H_1$을 설정합니다.

$$H_0: \theta \in \Theta_0 \quad \text{vs} \quad H_1: \theta \in \Theta_1$$

**검정(test)**은 데이터를 기각역(rejection region) $R$에 따라 판단하는 함수입니다.

$$\phi(x) = \begin{cases} 1 & x \in R \quad (\text{기각}) \\ 0 & x \notin R \quad (\text{기각하지 않음}) \end{cases}$$

| 용어 | 정의 |
|------|------|
| 제1종 오류 (Type I) | $H_0$이 참인데 기각 |
| 제2종 오류 (Type II) | $H_1$이 참인데 기각하지 않음 |
| 유의 수준 $\alpha$ | 제1종 오류의 최대 허용 확률 |
| 검정력 (Power) | $H_1$이 참일 때 기각할 확률 |

> **핵심 직관**: 가설 검정은 "무죄 추정 원칙"과 비슷합니다. $H_0$를 기각하려면 충분한 증거가 필요하며, 기각하지 않는 것이 $H_0$를 "증명"하는 것은 아닙니다.

```python
import numpy as np
from scipy.stats import norm, ttest_1samp

# 단일 표본 t-검정: 평균이 0인가?
np.random.seed(42)
data = np.random.normal(0.5, 1, 30)  # 실제로 평균은 0.5

stat, pvalue = ttest_1samp(data, 0)
print(f"t-통계량: {stat:.4f}")
print(f"p-value: {pvalue:.4f}")
print(f"alpha=0.05에서 기각 여부: {'기각' if pvalue < 0.05 else '기각하지 않음'}")
```

---

## 2. Neyman-Pearson 보조정리

**단순 가설** $H_0: \theta = \theta_0$ vs $H_1: \theta = \theta_1$에서 유의 수준 $\alpha$의 **최강력 검정(Most Powerful Test)**은 우도비에 기반합니다.

$$\phi(x) = \begin{cases} 1 & \frac{f(x; \theta_1)}{f(x; \theta_0)} > k \\ 0 & \frac{f(x; \theta_1)}{f(x; \theta_0)} < k \end{cases}$$

여기서 $k$는 $E_{\theta_0}[\phi(X)] = \alpha$를 만족하도록 설정합니다.

| 구성 요소 | 설명 |
|-----------|------|
| $\Lambda(x) = f(x;\theta_1)/f(x;\theta_0)$ | 우도비 통계량 |
| $k$ | 임계값 ($\alpha$에 의해 결정) |
| 최강력 | 유의 수준 $\alpha$에서 검정력이 최대 |

> **핵심 직관**: Neyman-Pearson은 "어떤 통계량으로 검정해야 가장 강력한가?"에 대한 최적 해답입니다. 우도비가 클수록 데이터가 $H_1$을 더 지지합니다.

```python
# Neyman-Pearson: 정규 분포 단순 가설
# H0: mu = 0 vs H1: mu = 1, sigma = 1 (알려짐)
from scipy.stats import norm

n = 25
alpha = 0.05

# 검정 통계량: sqrt(n) * xbar ~ N(0,1) under H0
# 기각역: Z > z_alpha
z_alpha = norm.ppf(1 - alpha)
print(f"임계값: {z_alpha:.4f}")

# 검정력 계산: P(Z > z_alpha | mu = 1)
power = 1 - norm.cdf(z_alpha - np.sqrt(n) * 1)
print(f"검정력 (mu=1): {power:.4f}")
```

---

## 3. 유의 수준, 크기, 검정력

**크기(size)**는 검정의 실제 제1종 오류율입니다.

$$\text{size} = \sup_{\theta \in \Theta_0} E_\theta[\phi(X)]$$

**검정력 함수(power function)**는 모수의 함수입니다.

$$\beta(\theta) = E_\theta[\phi(X)] = P_\theta(X \in R)$$

| $\theta$ 위치 | $\beta(\theta)$의 의미 |
|---------------|----------------------|
| $\theta \in \Theta_0$ | 제1종 오류율 ($\leq \alpha$여야 함) |
| $\theta \in \Theta_1$ | 검정력 (클수록 좋음) |

검정력에 영향을 미치는 요인:

| 요인 | 효과 |
|------|------|
| 표본 크기 $n$ 증가 | 검정력 증가 |
| 유의 수준 $\alpha$ 증가 | 검정력 증가 (Type I 오류 증가) |
| 효과 크기 증가 | 검정력 증가 |
| 분산 감소 | 검정력 증가 |

> **핵심 직관**: 검정력은 "실제 효과가 있을 때 발견할 확률"입니다. 표본이 작으면 효과가 있어도 감지하지 못합니다. si-11에서 다룰 다중 검정에서는 검정력 관리가 더욱 중요해집니다.

```python
# 표본 크기에 따른 검정력 변화
effect_size = 0.5  # mu_1 - mu_0 = 0.5, sigma = 1
ns = [10, 20, 50, 100, 200, 500]

for n in ns:
    z_crit = norm.ppf(1 - 0.05)
    power = 1 - norm.cdf(z_crit - effect_size * np.sqrt(n))
    print(f"n={n:3d}: 검정력 = {power:.4f}")
```

---

## 4. p-value의 정의와 해석

**p-value**는 귀무가설 하에서 관측된 통계량만큼 극단적이거나 더 극단적인 값을 얻을 확률입니다.

$$p = P_{\theta_0}(T(X) \geq T(x_{\text{obs}}))$$

| 올바른 해석 | 잘못된 해석 |
|------------|------------|
| $H_0$ 하에서 이 데이터만큼 극단적인 결과의 확률 | $H_0$가 참일 확률 |
| 데이터와 $H_0$의 양립 가능성 측도 | 효과의 크기 |
| 연속적인 증거 강도 | 이분법적 결론 |

p-value와 유의 수준의 관계:

$$\text{기각} \iff p \leq \alpha$$

> **핵심 직관**: p-value는 "$H_0$가 참이라면, 이 데이터는 얼마나 놀라운가?"를 측정합니다. p = 0.03은 "$H_0$ 하에서 이런 결과가 3%의 확률로 발생한다"는 뜻이지, "$H_0$가 틀릴 확률이 97%"라는 뜻이 아닙니다.

```python
# p-value 계산 예시
from scipy.stats import ttest_ind

# 두 그룹 비교
group_a = np.random.normal(100, 15, 50)
group_b = np.random.normal(108, 15, 50)

stat, p = ttest_ind(group_a, group_b)
print(f"t-통계량: {stat:.4f}")
print(f"p-value: {p:.4f}")

# 효과 크기 (Cohen's d)
pooled_std = np.sqrt((np.var(group_a, ddof=1) + np.var(group_b, ddof=1)) / 2)
cohens_d = (np.mean(group_b) - np.mean(group_a)) / pooled_std
print(f"Cohen's d: {cohens_d:.4f}")
```

---

## 5. 균일 최강력 검정 (UMP Test)

**복합 대립가설**에서 모든 $\theta \in \Theta_1$에 대해 최강력인 검정을 **UMP(Uniformly Most Powerful)** 검정이라 합니다.

**단조 우도비(Monotone Likelihood Ratio)** 성질을 가진 분포족에서 UMP 검정이 존재합니다.

$$\frac{f(x; \theta_1)}{f(x; \theta_0)} \text{가 } T(x)\text{에 대해 단조 증가} \quad (\theta_1 > \theta_0)$$

| 가설 | UMP 존재 | 기각역 |
|------|---------|--------|
| $H_0: \theta \leq \theta_0$ vs $H_1: \theta > \theta_0$ | 단측이면 존재 | $T > c$ |
| $H_0: \theta = \theta_0$ vs $H_1: \theta \neq \theta_0$ | 일반적으로 불존재 | — |

> **핵심 직관**: UMP 검정은 "어떤 대립가설이 참이든 최선인 검정"입니다. 양측 검정에서는 일반적으로 UMP가 존재하지 않으므로, si-06에서 다룰 우도비 검정과 같은 대안을 사용합니다.

```python
# UMP 검정: 지수 분포의 단측 검정
# H0: lambda <= 1 vs H1: lambda > 1
from scipy.stats import chi2

n = 20
alpha = 0.05
# T = 2*lambda_0*sum(X_i) ~ chi2(2n) under H0 (lambda = lambda_0)
# 기각역: T < chi2_alpha (작은 값 → 큰 lambda)
lambda_0 = 1.0
data = np.random.exponential(1/1.5, n)  # 실제 lambda = 1.5
T = 2 * lambda_0 * np.sum(data)
critical = chi2.ppf(alpha, 2*n)
print(f"T = {T:.4f}, 임계값 = {critical:.4f}")
print(f"기각: {T < critical}")
```

---

## 6. 오류 확률과 표본 크기 설계

주어진 유의 수준 $\alpha$와 검정력 $1 - \beta$를 달성하기 위한 **필요 표본 크기**:

정규 분포 평균 검정 ($H_0: \mu = \mu_0$ vs $H_1: \mu = \mu_1$):

$$n = \left(\frac{z_\alpha + z_\beta}{\delta / \sigma}\right)^2$$

여기서 $\delta = |\mu_1 - \mu_0|$이고 $z_q$는 표준 정규 분위수입니다.

| 원하는 검정력 | $\delta/\sigma = 0.2$ (소) | $\delta/\sigma = 0.5$ (중) | $\delta/\sigma = 0.8$ (대) |
|-------------|------------------------|------------------------|------------------------|
| 80% | 393 | 64 | 25 |
| 90% | 527 | 85 | 34 |
| 95% | 651 | 105 | 42 |

> **핵심 직관**: 표본 크기 설계는 실험 전에 "이 실험으로 의미 있는 효과를 감지할 수 있는가?"를 확인하는 필수 단계입니다. si-12에서 다룰 A/B 테스트의 핵심이기도 합니다.

```python
from statsmodels.stats.power import TTestPower

# 표본 크기 계산
analysis = TTestPower()
effect_sizes = [0.2, 0.5, 0.8]
for d in effect_sizes:
    n_needed = analysis.solve_power(effect_size=d, alpha=0.05, power=0.8,
                                     alternative='two-sided')
    print(f"효과 크기 d={d}: 필요 표본 크기 = {n_needed:.0f}")
```

---

## 7. 베이즈 검정과의 비교

| 관점 | 빈도주의 검정 | 베이즈 검정 |
|------|-------------|------------|
| 판단 기준 | p-value, 기각역 | 사후 확률, 베이즈 인자 |
| $P(H_0 \text{ 참})$ | 정의되지 않음 | $P(H_0 \| x)$ |
| 베이즈 인자 | — | $BF_{10} = \frac{P(x\|H_1)}{P(x\|H_0)}$ |
| 표본 크기 영향 | 크면 항상 기각 | 증거 강도 수렴 |

**베이즈 인자(Bayes Factor)**의 해석:

| $BF_{10}$ | $H_1$ 지지 강도 |
|-----------|----------------|
| 1 ~ 3 | 미약 |
| 3 ~ 10 | 중간 |
| 10 ~ 30 | 강함 |
| > 100 | 매우 강함 |

> **핵심 직관**: 빈도주의 검정은 "이 데이터가 $H_0$에서 나올 수 있는가?"를, 베이즈 검정은 "데이터가 $H_0$과 $H_1$ 중 어디를 더 지지하는가?"를 묻습니다. si-03에서 다룬 베이즈 프레임워크의 자연스러운 확장입니다.

---

## 핵심 정리

- **가설 검정은 제1종 오류(유의 수준 $\alpha$)를 통제하면서 제2종 오류를 최소화(검정력 최대화)하는 의사결정 프레임워크입니다**
- **Neyman-Pearson 보조정리는 단순 가설에서 우도비에 기반한 최강력 검정의 존재와 형태를 보장합니다**
- **p-value는 $H_0$ 하에서 관측 데이터만큼 극단적인 결과의 확률이며, $H_0$가 참일 확률이 아닙니다**
- **UMP 검정은 단조 우도비 조건 하에서 단측 복합 대립가설에 대해 존재하며, 양측에서는 일반적으로 존재하지 않습니다**
- **표본 크기 설계는 유의 수준, 검정력, 효과 크기의 관계를 사전에 분석하여 실험의 타당성을 보장합니다**
