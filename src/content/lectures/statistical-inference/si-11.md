# 다중 검정과 FDR

## 왜 다중 검정 보정이 필요한가

단일 가설 검정에서 유의 수준 $\alpha = 0.05$는 제1종 오류를 5%로 통제합니다. 하지만 수천 개의 유전자를 동시에 검정하거나, 여러 하위 그룹을 비교할 때 같은 $\alpha$를 적용하면 거짓 발견이 폭증합니다. si-05에서 다룬 단일 검정의 오류 통제를 다중 검정 상황으로 확장하는 것은 현대 통계학과 ML의 필수 과제입니다.

---

## 1. 다중 검정 문제의 구조

$m$개의 가설 $H_{01}, H_{02}, \dots, H_{0m}$을 동시에 검정할 때:

| 결과 | $H_0$ 참 | $H_0$ 거짓 | 합계 |
|------|---------|-----------|------|
| 기각하지 않음 | $U$ | $T$ | $m - R$ |
| 기각 (발견) | $V$ (거짓 발견) | $S$ (참 발견) | $R$ |
| 합계 | $m_0$ | $m_1$ | $m$ |

$V$는 **거짓 발견의 수(false discoveries)**, $R$은 총 발견 수입니다.

**문제**: 각 검정을 $\alpha = 0.05$로 수행하면

$$P(\text{하나 이상 거짓 발견}) = 1 - (1 - 0.05)^m \approx 1 - e^{-0.05m}$$

$m = 100$이면 이 확률은 $99.4\%$입니다.

> **핵심 직관**: 20개의 검정을 수행하면 평균적으로 1개는 거짓 양성입니다. 10,000개의 유전자를 검정하면 500개의 거짓 발견이 예상됩니다. 보정 없이는 "발견"의 대부분이 노이즈일 수 있습니다.

```python
import numpy as np
from scipy.stats import norm, ttest_1samp

# 다중 검정 문제 시뮬레이션
np.random.seed(42)
m = 1000      # 검정 수
m0 = 900      # 귀무가설이 참인 수
m1 = 100      # 대립가설이 참인 수
alpha = 0.05

p_values = []
# 귀무가설이 참인 경우: 효과 없음
for _ in range(m0):
    data = np.random.normal(0, 1, 30)
    _, p = ttest_1samp(data, 0)
    p_values.append(p)
# 대립가설이 참인 경우: 효과 있음
for _ in range(m1):
    data = np.random.normal(0.5, 1, 30)
    _, p = ttest_1samp(data, 0)
    p_values.append(p)

p_values = np.array(p_values)
naive_discoveries = np.sum(p_values < alpha)
false_discoveries = np.sum(p_values[:m0] < alpha)
print(f"보정 없이: 총 발견={naive_discoveries}, 거짓 발견={false_discoveries}")
print(f"거짓 발견 비율: {false_discoveries/naive_discoveries:.4f}")
```

---

## 2. 가족별 오류율 (FWER)

**FWER(Family-Wise Error Rate)**은 하나 이상의 거짓 발견이 있을 확률입니다.

$$\text{FWER} = P(V \geq 1)$$

### Bonferroni 보정

가장 보수적이고 단순한 방법: 각 검정의 유의 수준을 $\alpha/m$으로 조정합니다.

$$\text{기각: } p_i < \frac{\alpha}{m}$$

**증명** (Boole 부등식):

$$\text{FWER} = P\left(\bigcup_{i: H_{0i} \text{ 참}} \{p_i < \alpha/m\}\right) \leq \sum_{i: H_{0i} \text{ 참}} \frac{\alpha}{m} \leq m_0 \cdot \frac{\alpha}{m} \leq \alpha$$

| FWER 방법 | 보정 | 보수성 |
|-----------|------|--------|
| Bonferroni | $p_i < \alpha/m$ | 매우 보수적 |
| Sidak | $p_i < 1-(1-\alpha)^{1/m}$ | 약간 덜 보수적 (독립 가정) |
| Holm (step-down) | 순차적 보정 | Bonferroni보다 강력 |
| Hochberg (step-up) | 순차적 보정 | Holm보다 강력 (독립 가정) |

> **핵심 직관**: Bonferroni는 "가장 안전한" 보정이지만, $m$이 크면 거의 아무것도 발견하지 못합니다. 100개 검정에서 $p < 0.0005$만 유의하다고 하면, 실제 효과도 놓칩니다.

```python
from statsmodels.stats.multitest import multipletests

# Bonferroni vs Holm
bonf_reject, bonf_pvals, _, _ = multipletests(p_values, alpha=0.05, method='bonferroni')
holm_reject, holm_pvals, _, _ = multipletests(p_values, alpha=0.05, method='holm')

print(f"Bonferroni: 발견={bonf_reject.sum()}, "
      f"거짓 발견={bonf_reject[:m0].sum()}")
print(f"Holm:      발견={holm_reject.sum()}, "
      f"거짓 발견={holm_reject[:m0].sum()}")
```

---

## 3. 거짓 발견률 (FDR)

**FDR(False Discovery Rate)**은 발견 중 거짓 발견의 기대 비율입니다.

$$\text{FDR} = E\left[\frac{V}{R \vee 1}\right] = E\left[\frac{V}{\max(R, 1)}\right]$$

| 오류율 | 정의 | 통제 강도 |
|--------|------|---------|
| 개별 $\alpha$ | $P(\text{기각}\|H_0)$ | 각 검정별 |
| FWER | $P(V \geq 1)$ | 매우 엄격 |
| FDR | $E[V/R]$ | 중간 |
| pFDR | $E[V/R \| R > 0]$ | FDR과 유사 |

**왜 FDR인가?**

- FWER은 너무 보수적 → 검정력 손실
- FDR은 "발견의 질"을 직접 통제 → 더 많은 발견 허용
- 탐색적 분석에 적합

> **핵심 직관**: FDR = 0.05는 "내 발견 목록 중 약 5%가 거짓 양성이다"를 의미합니다. FWER = 0.05는 "거짓 양성이 하나라도 있을 확률이 5%"입니다. 유전체학, 뇌영상 등 대규모 검정에서 FDR이 표준입니다.

---

## 4. Benjamini-Hochberg (BH) 절차

**BH 절차** (1995):

1. p-value를 오름차순으로 정렬: $p_{(1)} \leq p_{(2)} \leq \cdots \leq p_{(m)}$
2. $k = \max\{i : p_{(i)} \leq \frac{i}{m} \alpha\}$를 찾음
3. $p_{(1)}, \dots, p_{(k)}$에 대응하는 가설을 기각

**정리** (Benjamini-Hochberg, 1995): 독립인 p-value에 대해

$$\text{FDR} \leq \frac{m_0}{m} \alpha \leq \alpha$$

| 단계 | $i$ | $p_{(i)}$ | $i \cdot \alpha / m$ | 기각 여부 |
|------|-----|----------|---------------------|---------|
| 1 | 1 | 0.001 | 0.005 | 기각 |
| 2 | 2 | 0.008 | 0.010 | 기각 |
| 3 | 3 | 0.012 | 0.015 | 기각 |
| 4 | 4 | 0.030 | 0.020 | 기각 안 함 |
| 5 | 5 | 0.150 | 0.025 | 기각 안 함 |

> **핵심 직관**: BH 절차는 "p-value가 균등 분포 직선 아래에 있는 것들을 기각"하는 것으로 시각화할 수 있습니다. $p_{(i)}$가 $i\alpha/m$ 직선 아래이면 유의합니다.

```python
# BH 절차 구현 및 적용
def benjamini_hochberg(p_values, alpha=0.05):
    m = len(p_values)
    sorted_idx = np.argsort(p_values)
    sorted_p = p_values[sorted_idx]
    thresholds = np.arange(1, m+1) * alpha / m
    # 가장 큰 k where p_(k) <= k*alpha/m
    below = sorted_p <= thresholds
    if not np.any(below):
        return np.zeros(m, dtype=bool)
    k = np.max(np.where(below)[0])
    reject = np.zeros(m, dtype=bool)
    reject[sorted_idx[:k+1]] = True
    return reject

bh_reject = benjamini_hochberg(p_values, 0.05)
print(f"BH 절차: 발견={bh_reject.sum()}, "
      f"거짓 발견={bh_reject[:m0].sum()}")
print(f"실제 FDR: {bh_reject[:m0].sum() / max(bh_reject.sum(), 1):.4f}")

# statsmodels 사용
bh_reject2, bh_pvals, _, _ = multipletests(p_values, alpha=0.05, method='fdr_bh')
print(f"statsmodels BH: 발견={bh_reject2.sum()}")
```

---

## 5. q-value와 지역 FDR

**q-value**: 각 검정의 FDR 기반 유의성 측도입니다.

$$q_i = \min_{t \geq p_i} \text{FDR}(t)$$

q-value는 "이 검정을 유의하다고 선언하면, 발견 목록의 FDR이 최소 얼마인가?"를 나타냅니다.

**지역 FDR (local FDR)**:

$$\text{lfdr}(z) = P(H_0 | Z = z) = \frac{\pi_0 f_0(z)}{f(z)}$$

여기서 $f(z) = \pi_0 f_0(z) + (1-\pi_0) f_1(z)$는 혼합 분포입니다.

| 측도 | 해석 | 수준 |
|------|------|------|
| p-value | $H_0$ 하에서 극단성 | 개별 검정 |
| q-value | 기각 시 FDR | 발견 목록 |
| lfdr | 개별 귀무 확률 | 개별 검정 |

> **핵심 직관**: p-value는 빈도주의적, q-value는 FDR 기반, lfdr은 베이즈적 해석을 제공합니다. si-03의 베이즈 프레임워크에서 lfdr은 사후 귀무 확률과 직결됩니다.

```python
# q-value 계산 (BH 보정된 p-value가 q-value의 근사)
_, q_values, _, _ = multipletests(p_values, method='fdr_bh')

# pi_0 추정 (Storey 방법의 간이 버전)
lambda_val = 0.5
pi_0_hat = np.mean(p_values > lambda_val) / (1 - lambda_val)
print(f"pi_0 추정값: {pi_0_hat:.4f} (참값: {m0/m:.4f})")

# q-value 분포
print(f"q < 0.05인 검정 수: {np.sum(q_values < 0.05)}")
print(f"q < 0.01인 검정 수: {np.sum(q_values < 0.01)}")
```

---

## 6. 의존적 p-value에서의 FDR 통제

현실에서 검정들은 종종 상관되어 있습니다 (유전자 공발현, 공간적 상관 등).

| 의존성 구조 | BH 절차 유효 | 보정 |
|------------|------------|------|
| 독립 | FDR $\leq \alpha$ | 불필요 |
| 양의 회귀 의존 (PRDS) | FDR $\leq \alpha$ | 불필요 |
| 일반적 의존 | FDR $\leq \alpha \cdot \sum_{i=1}^m 1/i$ | BY 보정 |

**Benjamini-Yekutieli (BY) 절차**: 일반적 의존 구조에서

$$p_{(i)} \leq \frac{i}{m \cdot \sum_{j=1}^{m} 1/j} \alpha$$

> **핵심 직관**: 양의 상관(PRDS)에서 BH는 여전히 유효합니다. 유전체학에서 흔한 양의 상관 구조가 이에 해당합니다. 임의의 의존 구조에서는 BY가 필요하지만, 매우 보수적입니다.

```python
# BY 보정 비교
by_reject, by_pvals, _, _ = multipletests(p_values, alpha=0.05, method='fdr_by')

print(f"BH: 발견={bh_reject2.sum()}")
print(f"BY: 발견={by_reject.sum()} (더 보수적)")
print(f"harmonic sum c(m) = {sum(1/i for i in range(1, m+1)):.4f}")
```

---

## 7. 실용 가이드와 ML 응용

| 상황 | 권장 방법 | 이유 |
|------|---------|------|
| 소수 검정 (< 20) | Bonferroni/Holm | FWER 통제 |
| 대규모 탐색 | BH (FDR) | 검정력 보존 |
| 확인적 연구 | FWER | 거짓 발견 0 목표 |
| 순차적 검정 | Alpha spending | 중간 분석 |
| 적응적 실험 | si-12의 A/B 테스트 참조 | 온라인 FDR |

ML에서의 다중 검정 응용:

| 응용 | 다중 검정 요소 |
|------|-------------|
| 특성 선택 | 수천 개 특성의 유의성 |
| 하이퍼파라미터 튜닝 | 여러 설정 비교 |
| A/B 테스트 (si-12) | 여러 변형 동시 비교 |
| 공정성 검사 | 여러 하위 그룹 비교 |

> **핵심 직관**: ML에서도 여러 모델, 특성, 하위 그룹을 비교할 때 다중 검정 문제가 발생합니다. "최고 성능 모델"이 단지 운이 좋았을 수 있으며, cm-12에서 다룬 교차 검증과 함께 다중 비교 보정이 필요합니다.

```python
# 특성 선택에서의 다중 검정
from scipy.stats import spearmanr

np.random.seed(42)
n = 100
n_features = 500
X = np.random.randn(n, n_features)
y = np.random.randn(n)  # 실제 관련 특성 없음 (모두 귀무)

# 각 특성과 y의 상관 검정
p_vals = []
for j in range(n_features):
    _, p = spearmanr(X[:, j], y)
    p_vals.append(p)
p_vals = np.array(p_vals)

naive_sig = np.sum(p_vals < 0.05)
bh_rej, _, _, _ = multipletests(p_vals, alpha=0.05, method='fdr_bh')

print(f"보정 없이 유의한 특성: {naive_sig} (모두 거짓 발견!)")
print(f"BH 보정 후 유의한 특성: {bh_rej.sum()}")
```

---

## 핵심 정리

- **$m$개 검정을 보정 없이 수행하면 거짓 발견 확률이 $1-(1-\alpha)^m$으로 급증하며, 다중 검정 보정은 필수입니다**
- **FWER(Bonferroni/Holm)은 $P(V \geq 1) \leq \alpha$를 통제하며, 소수의 확인적 검정에 적합하지만 대규모에서 보수적입니다**
- **FDR은 $E[V/R] \leq \alpha$를 통제하며, 대규모 탐색적 분석에서 검정력과 오류 통제의 균형을 제공합니다**
- **Benjamini-Hochberg 절차는 정렬된 p-value를 $i\alpha/m$ 임계선과 비교하며, 독립 또는 PRDS 하에서 FDR을 통제합니다**
- **q-value는 개별 검정의 FDR 기반 유의성이고, local FDR은 개별 귀무 확률의 베이즈 추정이며, 대규모 추론에서 해석력을 높입니다**
