# 대규모 그래프 처리

## 왜 대규모 그래프 처리가 중요한가

Facebook은 30억 사용자와 수천억 간선, Google의 웹 그래프는 수조 페이지를 다룹니다. 단일 머신 메모리에 들어오지 않는 그래프를 어떻게 처리할까요? ga-01~10의 알고리즘은 단일 머신 가정이었지만, 실무에서는 **분산 그래프 처리 프레임워크**가 필수입니다. 이 강의에서는 Pregel의 "Think Like a Vertex" 패러다임부터 스트리밍 그래프까지 다룹니다.

> **핵심 직관**: 대규모 그래프 처리의 핵심 패러다임은 **"각 노드가 이웃과 메시지를 교환"**하는 것입니다. 전역적 알고리즘을 지역적 메시지 교환으로 분해하면 분산 처리가 자연스럽습니다. 이 패턴은 ga-12의 GNN에서도 동일하게 나타납니다.

## 1. 그래프 처리의 도전과제

```
대규모 그래프의 특징:

  규모:
  ├─ Facebook: ~3B 노드, ~400B 간선
  ├─ 웹 그래프: ~1T+ 페이지
  ├─ 단백질 상호작용: ~20K 노드, ~300K 간선 (작지만 분석 복잡)
  └─ 추천: ~100M 사용자 × ~10M 아이템

  도전과제:
  1. 메모리: 그래프가 RAM에 안 들어감
  2. 통신: 간선이 머신 간에 걸쳐 있으면 네트워크 비용
  3. 불균형: 멱법칙 → 허브 노드에 부하 집중
  4. 반복 계산: PageRank, 커뮤니티 탐지 → 여러 라운드
  5. 랜덤 접근: 그래프 순회는 캐시 비친화적

  단일 머신 한계:
  10억 노드 × 8바이트 = ~8GB (노드만)
  100억 간선 × 16바이트 = ~160GB (간선만)
  → 단일 머신으로는 부족
```

## 2. Pregel과 BSP 모델

```
Pregel (Google, 2010):

  "Think Like a Vertex" — 정점 중심 프로그래밍

  BSP (Bulk Synchronous Parallel) 모델:
  1. 각 정점이 독립적으로 계산 (Compute)
  2. 이웃에게 메시지 전송 (Send)
  3. 동기화 장벽 (Barrier)
  4. 다음 슈퍼스텝에서 수신된 메시지로 계산
  → 수렴까지 반복

  슈퍼스텝 0:  [계산] → [메시지] → 장벽
  슈퍼스텝 1:  [계산] → [메시지] → 장벽
  ...
  슈퍼스텝 K:  모든 정점 비활성 → 종료
```

```python
# Pregel 프로그래밍 모델 (개념적 코드)
class PageRankVertex:
    def compute(self, messages):
        if self.superstep == 0:
            self.value = 1.0 / NUM_VERTICES
        else:
            total = sum(messages)
            self.value = 0.15 / NUM_VERTICES + 0.85 * total

        if self.superstep < MAX_ITERATIONS:
            # 이웃에게 내 값 / 나가는 간선 수 전송
            out_value = self.value / len(self.out_edges)
            for edge in self.out_edges:
                self.send_message(edge.target, out_value)
        else:
            self.vote_to_halt()  # 비활성화
```

```
Pregel로 구현 가능한 알고리즘:

  ├─ PageRank: 반복적 값 전파 (위 예시)
  ├─ SSSP: 최단 거리 전파 (Dijkstra의 분산 버전)
  ├─ 연결 요소: 최소 ID 전파
  ├─ 이분 그래프 판별: 색깔 전파 (ga-01)
  └─ MST: Borůvka 방식 (ga-03, 병렬 친화적)

  장점:
  - 직관적 프로그래밍 모델
  - 동기적 → 디버깅 용이
  - 정점 비활성화로 수렴 자동 감지

  단점:
  - 동기 장벽: 가장 느린 파티션이 병목
  - 슈퍼허브: 메시지 폭주 (멱법칙 그래프)
  - 메시지 오버헤드: 작은 메시지 대량 전송
```

> **핵심 직관**: Pregel의 "Think Like a Vertex"는 **전역 알고리즘을 지역 관점으로 재해석**하는 것입니다. 각 노드는 자신의 상태와 이웃 메시지만 보고 판단합니다. 이는 물리학의 "각 입자가 이웃과만 상호작용" 관점과 같으며, ga-12의 GNN 메시지 패싱과 정확히 동일한 패러다임입니다.

## 3. 분산 그래프 프레임워크

```
주요 프레임워크:

  Apache Giraph (Pregel 오픈소스):
  ├─ BSP 모델, Hadoop 위에서 동작
  ├─ Facebook이 사용 (친구 추천)
  └─ 대규모에서 검증됨

  GraphX (Apache Spark):
  ├─ RDD 기반 그래프 추상화
  ├─ Pregel API + 관계형 연산 결합
  ├─ Spark 에코시스템과 통합
  └─ 반복 계산에서 Giraph보다 빠를 수 있음

  graph = Graph(vertices_rdd, edges_rdd)
  # PageRank
  result = graph.pageRank(tol=0.01)
  # Triangle Count
  tc = graph.triangleCount()

  PowerGraph (GraphLab):
  ├─ GAS (Gather-Apply-Scatter) 모델
  ├─ 허브 노드를 여러 머신에 분산 (vertex-cut)
  ├─ 멱법칙 그래프에 최적화
  └─ Gather: 이웃 정보 수집
     Apply: 정점 상태 갱신
     Scatter: 이웃에 갱신 알림
```

| 프레임워크 | 모델 | 허브 처리 | 생태계 |
|-----------|------|----------|-------|
| Giraph | BSP/Pregel | edge-cut | Hadoop |
| GraphX | BSP + RDD | edge-cut | Spark |
| PowerGraph | GAS | vertex-cut | 독립 |
| Pregel+ | BSP (비동기) | 미러링 | 독립 |

## 4. 그래프 파티셔닝

```
그래프 파티셔닝: 분산 처리의 핵심 전처리

  목표: 노드를 K개 파티션에 분배
  제약: 각 파티션 크기 균등
  최적화: 파티션 간 간선(cross-edge) 최소화

  간선-컷 (Edge-Cut):
  각 노드가 하나의 파티션에 속함
  파티션 간 간선 = 통신 비용
  → Metis, KaHIP 등의 알고리즘

  정점-컷 (Vertex-Cut):
  간선을 파티션에 배분, 양 끝 노드가 다르면 복제
  → 허브 노드가 여러 파티션에 복제됨
  → 멱법칙 그래프에서 edge-cut보다 효과적

  파티셔닝 전략:
  ├─ Hash: hash(node_id) % K → 간단하지만 품질 낮음
  ├─ Range: ID 범위로 분할 → 지역성 없으면 비효율
  ├─ Metis: 다단계 축소-분할-확장 → 품질 높지만 느림
  └─ Streaming: 노드 도착 순 할당 → 실시간 그래프

  실무 선택:
  정적 그래프 + 반복 분석: Metis (전처리 1회)
  동적/스트리밍 그래프: Hash 또는 스트리밍 파티셔닝
```

## 5. 스트리밍 그래프

```
스트리밍 그래프 알고리즘:

  간선이 스트림으로 도착 → 한 번만 보고 처리
  전체 그래프를 메모리에 저장할 수 없음

  Semi-Streaming Model:
  메모리 제한: O(N × polylog(N)) — 노드 수에 비례
  → 간선은 저장 못하지만 노드별 정보는 저장 가능

  가능한 문제:
  ├─ 연결 요소: Union-Find로 O(N) 메모리
  ├─ MST 근사: O(N) 간선만 유지 (최소 가중치)
  ├─ 삼각형 추정: 샘플링 기반 근사
  └─ PageRank 근사: 난수 행보 시뮬레이션

  불가능한 문제:
  ├─ 정확한 최단 경로: 전체 그래프 필요
  └─ 정확한 이분 매칭: 다중 패스 필요

  실용적 접근:
  ├─ 슬라이딩 윈도우: 최근 W개 간선만 유지
  ├─ 스케치: ads-04의 확률적 자료구조 활용
  │   (Bloom Filter: 간선 존재, HyperLogLog: 차수 추정)
  └─ 그래프 스패너: 간선 일부만 유지, 거리 근사
```

> **핵심 직관**: 스트리밍 그래프의 핵심 제약은 **"간선을 한 번만 볼 수 있다"**는 것입니다. 이는 dp-03의 스트림 처리와 같은 패러다임이며, ads-04의 확률적 자료구조(Bloom Filter, Count-Min Sketch)가 핵심 도구가 됩니다.

## 6. 실전 응용과 선택 가이드

```
응용 1: 소셜 그래프 분석
  Facebook/Twitter의 친구 추천
  → Giraph/GraphX에서 2-hop 이웃 계산
  → "공통 친구 많은 사람" 추천

응용 2: 웹 그래프 PageRank
  수조 페이지에서 중요도 계산
  → Pregel 모델로 반복 수렴
  → 20~50 슈퍼스텝에서 수렴

응용 3: 지식 그래프 추론
  수십억 트리플에서 경로 탐색
  → 그래프 데이터베이스 (Neo4j, JanusGraph)
  → 또는 임베딩 기반 접근 (ga-12 연결)

선택 가이드:
  그래프 크기 < 1M 간선: 단일 머신 (NetworkX, igraph)
  1M~1B 간선: 단일 머신 최적화 (CSR, 외부 메모리)
  > 1B 간선: 분산 프레임워크 (GraphX, Giraph)
  실시간 쿼리: 그래프 DB (Neo4j)
  ML 파이프라인: GraphX (Spark 통합)
```

대규모 그래프 처리는 dp-02의 분산 처리 패러다임(MapReduce, Spark)을 그래프에 적용한 것이며, ga-12의 GNN 학습에서도 미니배치 그래프 샘플링이라는 형태로 활용됩니다.

## 핵심 정리

- 대규모 그래프는 단일 머신 메모리를 초과하므로, **분산 처리 프레임워크**(Pregel, GraphX, PowerGraph)가 필수입니다
- **Pregel의 BSP 모델**은 "각 정점이 이웃과 메시지 교환"하는 패러다임으로, PageRank/SSSP/연결 요소 등을 분산 구현합니다
- **그래프 파티셔닝**에서 edge-cut은 노드를 분배하고, vertex-cut은 간선을 분배하며, 멱법칙 그래프에서는 vertex-cut이 유리합니다
- **스트리밍 그래프**는 간선을 한 번만 보고 $O(N \cdot \text{polylog}(N))$ 메모리로 처리하며, 확률적 자료구조가 핵심 도구입니다
- 실무 선택은 그래프 크기에 따라 결정되며, 1B 간선 이하는 단일 머신 최적화, 이상은 분산 프레임워크를 사용합니다
