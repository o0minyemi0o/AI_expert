# 스펙트럴 그래프 이론

## 왜 스펙트럴 그래프 이론이 중요한가

그래프를 행렬로 표현하고 그 **고유값(eigenvalue)**을 분석하는 것이 스펙트럴 그래프 이론입니다. "그래프의 구조가 고유값에 어떻게 반영되는가?"가 핵심 질문입니다. la-05의 고유값 분해가 그래프에 적용되면, 클러스터링(ga-09), 랜덤 워크 분석, 그래프 연결성 측정이 가능해집니다. 특히 **스펙트럴 클러스터링**은 K-Means가 실패하는 비볼록 클러스터에서도 작동하는 강력한 기법입니다.

> **핵심 직관**: 그래프의 라플라시안 행렬의 두 번째로 작은 고유값(**Fiedler 값**)이 그래프의 **연결 강도**를 나타냅니다. 이 값이 0이면 그래프가 분리되어 있고, 클수록 "잘 연결"되어 있습니다. 대응하는 고유벡터(**Fiedler 벡터**)가 최적의 이분할을 알려줍니다.

## 1. 그래프의 행렬 표현

```
인접 행렬 (Adjacency Matrix) A:
  A[i][j] = 1 (간선 존재), 0 (없음)
  가중 그래프: A[i][j] = w(i,j)

  예: 경로 그래프 1—2—3—4
  A = [[0,1,0,0],
       [1,0,1,0],
       [0,1,0,1],
       [0,0,1,0]]

차수 행렬 (Degree Matrix) D:
  D = diag(d₁, d₂, ..., dₙ)
  dᵢ = 노드 i의 차수

  D = [[1,0,0,0],
       [0,2,0,0],
       [0,0,2,0],
       [0,0,0,1]]

라플라시안 (Laplacian) L = D - A:
  L = [[ 1,-1, 0, 0],
       [-1, 2,-1, 0],
       [ 0,-1, 2,-1],
       [ 0, 0,-1, 1]]

  성질:
  1. 대칭 양반정치(positive semi-definite)
  2. 모든 행/열의 합 = 0
  3. 최소 고유값 = 0 (고유벡터 = [1,1,...,1])
  4. 0인 고유값의 개수 = 연결 요소 수
```

```
정규화된 라플라시안:

  대칭 정규화: L_sym = D^{-1/2} L D^{-1/2} = I - D^{-1/2} A D^{-1/2}
  랜덤 워크:   L_rw = D^{-1} L = I - D^{-1} A

  D^{-1}A = 전이 행렬 (Transition Matrix)
  → 랜덤 워크에서 다음 노드 확률 분포

  정규화의 효과:
  차수가 큰 노드의 영향을 줄임
  → 차수 분포가 불균일한 그래프에서 더 좋은 클러스터링
```

## 2. 고유값과 그래프 성질

```
라플라시안 스펙트럼: 0 = λ₁ ≤ λ₂ ≤ ... ≤ λₙ

  λ₁ = 0: 항상 (L의 행 합이 0이므로)
  연결 요소 수 = λᵢ = 0인 개수

  λ₂ (Fiedler 값, 대수적 연결도):
  ├─ λ₂ = 0 → 그래프가 분리됨 (2개 이상 연결 요소)
  ├─ λ₂ > 0 → 연결 그래프
  ├─ λ₂ 큼 → "잘 연결됨" (자르기 어려움)
  └─ λ₂ ≈ 0 → "거의 분리" (좋은 이분할 존재)

  λₙ (최대 고유값):
  ├─ λₙ ≤ 2 × max(degree)
  ├─ λₙ = n → 완전 이분 그래프 K_{n/2,n/2}
  └─ 스펙트럴 갭 (λₙ - λₙ₋₁): 그래프의 확장 성질

  인접 행렬 스펙트럼:
  최대 고유값 ≈ 최대 차수
  고유값 분포 → 그래프 구조의 "지문"
```

| 스펙트럴 양 | 의미 | 응용 |
|-----------|------|------|
| $\lambda_2 = 0$ | 비연결 | 연결 요소 탐지 |
| $\lambda_2$ (Fiedler) | 연결 강도 | 그래프 이분할 |
| Fiedler 벡터 | 최적 분할 방향 | 스펙트럴 클러스터링 |
| 0의 중복도 | 연결 요소 수 | 구조 분석 |

## 3. Fiedler 벡터와 그래프 분할

```
Fiedler 벡터: λ₂에 대응하는 고유벡터 v₂

  그래프 이분할 (Graph Bisection):
  v₂의 부호로 노드를 두 그룹으로 나눔

  v₂[i] < 0 → 그룹 A
  v₂[i] ≥ 0 → 그룹 B

  예: 바벨 그래프 (두 클리크를 다리로 연결)

  클리크1: {1,2,3}  —bridge—  클리크2: {4,5,6}

  Fiedler 벡터: [-0.4, -0.4, -0.4, 0.4, 0.4, 0.4]
  → 부호로 정확히 두 클리크 분리!

  왜 작동하는가?
  λ₂ = min_{x⊥1} (x^T L x) / (x^T x)

  x^T L x = Σ_{(i,j)∈E} (xᵢ - xⱼ)²

  이 값을 최소화하는 x = 연결된 노드에 비슷한 값 부여
  → 자연스러운 클러스터 경계에서 값이 크게 변함
```

> **핵심 직관**: $x^T L x = \sum_{(i,j) \in E} (x_i - x_j)^2$이 라플라시안의 이차형식입니다. 이를 최소화하는 벡터 $x$는 **연결된 노드에 비슷한 값을 배정**합니다. Fiedler 벡터가 "가장 부드러운 비상수 함수"이므로, 값이 급변하는 곳이 자연스러운 분할 경계입니다.

## 4. 스펙트럴 클러스터링

```python
import numpy as np
from scipy.sparse.linalg import eigsh
from sklearn.cluster import KMeans

def spectral_clustering(W, k):
    """
    W: 가중 인접 행렬 (유사도 행렬)
    k: 클러스터 수
    """
    n = W.shape[0]
    # 1. 라플라시안 계산
    D = np.diag(W.sum(axis=1))
    L = D - W

    # 2. 정규화된 라플라시안
    D_inv_sqrt = np.diag(1.0 / np.sqrt(np.diag(D) + 1e-10))
    L_sym = D_inv_sqrt @ L @ D_inv_sqrt

    # 3. 가장 작은 k개 고유벡터
    eigenvalues, eigenvectors = eigsh(L_sym, k=k, which='SM')

    # 4. 행 정규화
    U = eigenvectors
    U = U / (np.linalg.norm(U, axis=1, keepdims=True) + 1e-10)

    # 5. K-Means 클러스터링
    labels = KMeans(n_clusters=k, n_init=10).fit_predict(U)
    return labels
```

```
스펙트럴 클러스터링의 과정:

  1. 유사도 그래프 구축
     ├─ ε-이웃: 거리 < ε이면 간선
     ├─ KNN 그래프: K-최근접 이웃 연결
     └─ 가우시안 커널: w(i,j) = exp(-||xᵢ-xⱼ||²/2σ²)

  2. 라플라시안 고유분해
     k개의 최소 고유벡터 → N×k 행렬 U

  3. 고유벡터 공간에서 K-Means
     N개 점이 k차원 공간에서 잘 분리됨!

  왜 K-Means보다 좋은가?

  원래 공간:        고유벡터 공간:
  ○○○              •••
  ○  ○             •  •
  ○○○              •••
  (동심원 → K-Means 실패)  (분리됨 → K-Means 성공!)

  비볼록 클러스터도 처리 가능!
```

## 5. Cheeger 부등식

```
Cheeger 부등식: 스펙트럴 분할의 품질 보장

  Cheeger 상수 (등주 상수):
  h(G) = min_S  |E(S, S̄)| / min(vol(S), vol(S̄))

  S: 노드 부분집합, S̄: 나머지
  E(S, S̄): S와 S̄ 사이 간선 수
  vol(S): S 내 노드들의 차수 합

  직관: h(G)가 작을수록 "좋은 분할"이 존재
        (적은 간선을 잘라서 비슷한 크기로 나눌 수 있음)

  Cheeger 부등식:
  λ₂/2 ≤ h(G) ≤ √(2λ₂)

  의미:
  - λ₂가 작으면 h(G)도 작음 → 좋은 분할 존재
  - λ₂가 크면 h(G)도 큼 → 분할하기 어려움
  - Fiedler 벡터 분할은 최적의 √(2λ₂) 근사

  NP-hard인 최소 분할 문제를
  고유값 하나로 근사할 수 있다는 강력한 결과!
```

> **핵심 직관**: Cheeger 부등식은 **"대수적 양(고유값)과 조합적 양(분할)의 관계"**를 정량화합니다. 고유값 계산은 다항 시간이고 최소 분할은 NP-hard이지만, 고유값이 분할 품질의 상하한을 제공합니다. 이것이 스펙트럴 방법이 실용적인 이유입니다.

## 6. 실전 응용과 확장

```
응용 1: 이미지 분할 (Normalized Cut)
  픽셀 → 노드, 유사도 → 가중치
  스펙트럴 클러스터링으로 의미 있는 영역 분할
  → ga-04의 최소 컷과 비교: 스펙트럴이 더 균형 잡힌 분할

응용 2: 커뮤니티 탐지 (ga-09 연결)
  소셜 네트워크의 라플라시안 고유벡터
  → 자연스러운 커뮤니티 경계 발견

응용 3: 그래프 임베딩
  고유벡터를 좌표로 사용하여 그래프를 저차원 공간에 배치
  → ga-12의 그래프 신경망과 연결

응용 4: 랜덤 워크와 수렴 속도
  D⁻¹A의 고유값 → 랜덤 워크의 혼합 시간(mixing time)
  스펙트럴 갭이 클수록 빠른 수렴
  → PageRank, MCMC(pt-14)의 수렴 분석

주의:
  - 대규모 그래프: 전체 고유분해 O(N³) → 비현실적
  - 해결: Lanczos, 근사 고유분해, 랜덤화 SVD
  - 실무: scipy.sparse.linalg.eigsh (희소 행렬 전용)
```

스펙트럴 그래프 이론은 la-05의 고유값 분해를 그래프에 적용한 것이며, ga-09의 커뮤니티 탐지와 ga-12의 그래프 신경망의 이론적 기반입니다.

## 핵심 정리

- **라플라시안** $L = D - A$의 고유값이 그래프 구조를 반영하며, 0인 고유값의 개수가 연결 요소 수입니다
- **Fiedler 값**($\lambda_2$)은 그래프의 연결 강도를 나타내며, **Fiedler 벡터**의 부호로 최적에 가까운 이분할을 얻습니다
- **스펙트럴 클러스터링**은 라플라시안의 $k$개 최소 고유벡터 공간에서 K-Means를 적용하여, 비볼록 클러스터도 탐지합니다
- **Cheeger 부등식** $\lambda_2/2 \leq h(G) \leq \sqrt{2\lambda_2}$이 고유값과 최소 분할의 관계를 보장합니다
- $x^T L x = \sum_{(i,j) \in E}(x_i - x_j)^2$이 라플라시안의 핵심이며, 이를 최소화하는 벡터가 "부드러운 분할"을 나타냅니다
