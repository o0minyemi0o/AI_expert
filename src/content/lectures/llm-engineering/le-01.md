# LLM 기초와 생태계

## 왜 LLM 기초가 중요한가

대규모 언어 모델(LLM)은 현대 AI 시스템의 핵심 구성 요소입니다. LLM 엔지니어링의 첫 단계는 이 모델들이 어떤 원리로 작동하고, 생태계가 어떻게 구성되어 있는지를 정확히 이해하는 것입니다. Transformer 아키텍처의 핵심 메커니즘부터 스케일링 법칙, 그리고 실무에서 어떤 모델을 선택해야 하는지까지 체계적으로 살펴보겠습니다.

## 1. Transformer 아키텍처 복습

LLM의 근간은 Transformer입니다 ([dl-07](/lectures/deep-learning/dl-07) 참조). 핵심 구성 요소를 다시 정리합니다.

### Self-Attention 메커니즘

$$\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V$$

여기서 $Q$, $K$, $V$는 각각 Query, Key, Value 행렬이며, $d_k$는 Key의 차원입니다. 이 연산의 시간 복잡도는 $O(n^2 \cdot d)$로, 시퀀스 길이 $n$에 대해 이차적으로 증가합니다.

> **핵심 직관**: Self-Attention은 "모든 토큰이 다른 모든 토큰을 참조할 수 있는 동적 가중 평균"입니다. 이것이 RNN 대비 LLM의 강력한 문맥 이해 능력의 원천입니다.

### Decoder-Only 아키텍처

현대 LLM 대부분은 Decoder-Only 구조를 채택합니다. Causal Masking을 통해 현재 위치 이후의 토큰을 참조하지 못하게 하며, 이를 통해 자기회귀적(autoregressive) 텍스트 생성이 가능합니다.

| 구성 요소 | 역할 | GPT-4급 규모 |
|-----------|------|-------------|
| 임베딩 레이어 | 토큰 → 벡터 변환 | ~100K 어휘 |
| Attention 블록 | 문맥 정보 통합 | 96~120 레이어 |
| FFN 블록 | 비선형 변환 | 숨겨진 차원 ~12K+ |
| LM Head | 다음 토큰 확률 출력 | softmax over vocab |

## 2. 스케일링 법칙 (Scaling Laws)

Kaplan et al. (2020)과 Hoffmann et al. (2022, Chinchilla)의 연구는 LLM 성능이 세 가지 요소에 의해 예측 가능하게 향상됨을 보여줍니다.

$$L(N, D) \approx \left(\frac{N_c}{N}\right)^{\alpha_N} + \left(\frac{D_c}{D}\right)^{\alpha_D} + L_\infty$$

- $N$: 모델 파라미터 수
- $D$: 학습 데이터 토큰 수
- $L$: 크로스 엔트로피 손실

> **핵심 직관**: Chinchilla 법칙에 따르면, 파라미터 수와 학습 데이터는 거의 1:20 비율로 함께 증가시켜야 컴퓨트 효율이 최적화됩니다. 즉, 70B 모델에는 약 1.4T 토큰이 필요합니다.

### 스케일링 의사결정 흐름

```
[컴퓨트 예산 결정]
       │
       ▼
┌─────────────────┐
│ Chinchilla 최적  │
│ N:D 비율 계산    │
└────────┬────────┘
         │
    ┌────▼────┐
    │ 추론 비용 │
    │ 제약?    │
    └────┬────┘
     Yes │    No
    ┌────▼──┐ ┌──▼────┐
    │소형 모델│ │대형 모델│
    │+더 많은 │ │Chinch.│
    │데이터   │ │최적    │
    └───────┘ └───────┘
```

## 3. 주요 모델 비교

2024-2025년 기준 주요 LLM을 비교합니다.

| 모델 | 제공사 | 파라미터 | 라이선스 | 강점 |
|------|--------|---------|---------|------|
| GPT-4o | OpenAI | 비공개 | 폐쇄형 | 멀티모달, 범용 추론 |
| Claude 3.5 Sonnet | Anthropic | 비공개 | 폐쇄형 | 긴 문맥, 코딩 |
| Gemini 1.5 Pro | Google | 비공개 | 폐쇄형 | 1M 토큰 컨텍스트 |
| Llama 3.1 405B | Meta | 405B | 오픈소스 | 성능/개방성 균형 |
| Mistral Large | Mistral | 비공개 | 일부 오픈 | 유럽 규제 친화 |
| Qwen 2.5 72B | Alibaba | 72B | 오픈소스 | 다국어, 코딩 |

## 4. 오픈소스 vs 폐쇄형 모델

모델 선택은 엔지니어링의 첫 번째 의사결정입니다 ([ms-01](/lectures/model-selection/ms-01) 참조).

| 기준 | 오픈소스 | 폐쇄형 API |
|------|---------|-----------|
| 커스터마이징 | 완전한 파인튜닝 가능 | 제한적 (API 파인튜닝) |
| 데이터 프라이버시 | 온프레미스 배포 가능 | 데이터가 외부로 전송 |
| 비용 구조 | GPU 인프라 비용 | 토큰 당 과금 |
| 유지보수 | 자체 관리 필요 | 제공사 관리 |
| 최신 성능 | 일반적으로 뒤처짐 | 최고 성능 선도 |

### 시나리오 1: 의료 기록 요약 시스템

병원에서 환자 기록을 요약하는 시스템을 구축한다고 가정합니다. 환자 데이터는 외부로 전송할 수 없으므로 오픈소스 모델(예: Llama 3.1 70B)을 온프레미스에 배포하고, 의료 도메인 데이터로 파인튜닝하는 전략이 적합합니다 ([le-05](/lectures/llm-engineering/le-05) 참조).

### 시나리오 2: 고객 서비스 챗봇

스타트업에서 빠르게 고객 응대 챗봇을 구축해야 합니다. 초기에는 GPT-4o API로 프로토타입을 만들고, 사용자 패턴이 축적되면 오픈소스 모델로 전환하는 점진적 전략이 비용 효율적입니다 ([le-12](/lectures/llm-engineering/le-12) 참조).

## 5. LLM의 학습 단계

LLM은 일반적으로 세 단계로 학습됩니다.

```python
# 단계별 학습 파이프라인 개념도
from transformers import AutoModelForCausalLM, AutoTokenizer

# 1단계: 사전학습 (Pre-training) - 수조 토큰
# 목표: 다음 토큰 예측으로 언어와 세계 지식 학습
model = AutoModelForCausalLM.from_pretrained("meta-llama/Llama-3.1-8B")

# 2단계: 지도 미세조정 (SFT) - 수만~수십만 예제 (le-05)
# 목표: 지시 따르기, 대화 형식 학습

# 3단계: 인간 피드백 강화학습 (RLHF) - 수만 비교 쌍 (le-06)
# 목표: 인간 선호도에 맞는 출력 정렬
```

```python
# 토크나이저 기본 동작 확인
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("meta-llama/Llama-3.1-8B")
text = "LLM 엔지니어링은 실무 역량입니다."
tokens = tokenizer.encode(text)
print(f"토큰 수: {len(tokens)}")
print(f"토큰 목록: {tokenizer.convert_ids_to_tokens(tokens)}")
```

> **핵심 직관**: 사전학습은 "지식 습득", SFT는 "행동 교정", RLHF는 "가치 정렬"에 해당합니다. 각 단계는 이전 단계 위에 쌓이며, 엔지니어가 개입할 수 있는 단계는 주로 SFT와 RLHF입니다.

## 핵심 정리

- Transformer의 Self-Attention은 $O(n^2)$ 복잡도를 가지며, 이것이 긴 문맥 처리의 핵심 병목입니다
- Chinchilla 스케일링 법칙에 따라 파라미터와 데이터를 균형 있게 증가시키는 것이 컴퓨트 효율의 핵심입니다
- 오픈소스 모델은 커스터마이징과 프라이버시에서, 폐쇄형 모델은 성능과 편의성에서 각각 강점을 가집니다
- LLM 학습은 사전학습 → SFT → RLHF의 3단계로 구성되며, 실무에서는 주로 2-3단계에 개입합니다
- 모델 선택은 성능뿐 아니라 비용, 규제, 데이터 민감도를 종합적으로 고려해야 하는 엔지니어링 의사결정입니다
