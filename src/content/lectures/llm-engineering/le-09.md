# 멀티모달 LLM

## 왜 멀티모달이 중요한가

현실 세계의 정보는 텍스트만으로 구성되지 않습니다. 이미지, 오디오, 비디오를 함께 이해하고 생성하는 멀티모달 LLM은 AI 시스템의 적용 범위를 획기적으로 확장합니다. GPT-4o, Claude 3.5, Gemini 1.5 등 최신 모델들은 모두 멀티모달을 지원하며([le-01](/lectures/llm-engineering/le-01) 참조), 이를 활용한 애플리케이션 설계 역량은 LLM 엔지니어의 핵심 경쟁력입니다.

## 1. 멀티모달 아키텍처

### 비전-언어 모델 (VLM) 구조

비전-언어 모델은 이미지 인코더와 언어 모델을 연결하는 구조입니다.

```
[이미지 입력]              [텍스트 입력]
     │                         │
     ▼                         ▼
┌──────────┐             ┌──────────┐
│ Vision   │             │ Text     │
│ Encoder  │             │ Tokenizer│
│(ViT/CLIP)│             │          │
└────┬─────┘             └────┬─────┘
     │                        │
     ▼                        │
┌──────────┐                  │
│Projection│                  │
│ Layer    │                  │
└────┬─────┘                  │
     │      ┌─────────┐      │
     └─────▶│ 결합    │◀─────┘
             │(Concat) │
             └────┬────┘
                  ▼
          ┌──────────────┐
          │ Language     │
          │ Model (LLM)  │
          └──────────────┘
```

| 아키텍처 | 대표 모델 | 이미지 인코더 | 특징 |
|---------|----------|-------------|------|
| 교차 어텐션 | Flamingo | NFNet | 이미지-텍스트 교차 참조 |
| 프로젝션 | LLaVA | CLIP ViT-L | 단순, 효율적 |
| Q-Former | BLIP-2 | EVA-CLIP | 학습 가능한 쿼리 |
| 네이티브 | GPT-4o, Gemini | 통합 | 처음부터 멀티모달 설계 |

> **핵심 직관**: 멀티모달 모델의 핵심 과제는 "시각 정보를 언어 모델이 이해할 수 있는 토큰 공간으로 변환"하는 것입니다. Projection Layer의 품질이 전체 멀티모달 성능을 좌우합니다.

## 2. 이미지 입력 활용

### API를 통한 이미지 분석

```python
from openai import OpenAI
import base64

client = OpenAI()

# 이미지를 base64로 인코딩
def encode_image(image_path: str) -> str:
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")

# 이미지 분석 요청
response = client.chat.completions.create(
    model="gpt-4o",
    messages=[{
        "role": "user",
        "content": [
            {"type": "text", "text": "이 차트에서 매출이 가장 높은 분기를 알려주세요."},
            {"type": "image_url", "image_url": {
                "url": f"data:image/png;base64,{encode_image('chart.png')}",
                "detail": "high",  # low/high/auto
            }},
        ],
    }],
)
print(response.choices[0].message.content)
```

### 이미지 해상도와 토큰 비용

| detail 설정 | 최대 해상도 | 토큰 비용 (GPT-4o) | 적합한 용도 |
|------------|-----------|-------------------|-----------|
| low | 512x512 | ~85 토큰 | 간단한 분류 |
| high | 2048x2048 | ~1,105 토큰 | OCR, 상세 분석 |
| auto | 자동 선택 | 가변 | 범용 |

## 3. 오디오 입력과 처리

```python
# Whisper를 활용한 오디오 전사 + LLM 분석
from openai import OpenAI

client = OpenAI()

# 1단계: 오디오를 텍스트로 전사
with open("meeting.mp3", "rb") as audio_file:
    transcript = client.audio.transcriptions.create(
        model="whisper-1",
        file=audio_file,
        language="ko",
        response_format="verbose_json",
        timestamp_granularities=["segment"],
    )

# 2단계: 전사 결과를 LLM으로 분석
analysis = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {"role": "system", "content": "회의록을 분석하여 핵심 안건과 결정사항을 정리하세요."},
        {"role": "user", "content": transcript.text},
    ],
)
```

> **핵심 직관**: 멀티모달 파이프라인은 "감각 기관(인코더) → 이해(LLM) → 행동(출력)"의 구조입니다. 각 모달리티의 전처리 품질이 최종 성능을 결정하므로, 이미지 해상도, 오디오 품질, 텍스트 정제에 충분한 주의를 기울여야 합니다.

## 4. 멀티모달 RAG

텍스트 기반 RAG([le-03](/lectures/llm-engineering/le-03))를 확장하여 이미지, 테이블, 차트를 포함하는 문서를 처리합니다.

```
[PDF/문서 입력]
       │
  ┌────▼────────┐
  │ 모달리티     │
  │ 분리         │
  └────┬────────┘
       │
  ┌────▼────┬───────────┬──────────┐
  │ 텍스트   │ 이미지     │ 테이블    │
  │ 청크     │ 추출       │ 추출     │
  └────┬────┘└─────┬─────┘└────┬────┘
       │          │           │
       ▼          ▼           ▼
  ┌──────────────────────────────────┐
  │ 각 모달리티를 텍스트 설명으로 변환 │
  │ (VLM으로 이미지/테이블 캡셔닝)    │
  └──────────────┬───────────────────┘
                 ▼
          [벡터 DB에 저장]
                 │
          [검색 + 생성]
```

```python
# 멀티모달 RAG: 이미지 포함 문서 처리
from langchain_community.document_loaders import PyMuPDFLoader
from langchain_openai import ChatOpenAI
import fitz  # PyMuPDF

def extract_images_and_describe(pdf_path: str) -> list[dict]:
    doc = fitz.open(pdf_path)
    results = []
    llm = ChatOpenAI(model="gpt-4o")

    for page in doc:
        # 텍스트 추출
        text = page.get_text()
        results.append({"type": "text", "content": text, "page": page.number})

        # 이미지 추출 및 VLM으로 설명 생성
        for img in page.get_images():
            xref = img[0]
            pix = fitz.Pixmap(doc, xref)
            # VLM으로 이미지 설명 생성 후 텍스트로 저장
            description = describe_image_with_vlm(pix)
            results.append({"type": "image_desc", "content": description, "page": page.number})

    return results
```

## 5. 멀티모달 응용 사례

### 시나리오 1: 제조업 품질 검사 자동화

제조 라인에서 촬영된 제품 이미지를 VLM으로 분석하여 결함을 자동 탐지합니다. 정상/불량 이미지 데이터로 프롬프트를 최적화하고([le-02](/lectures/llm-engineering/le-02)), few-shot 예시로 결함 유형을 분류합니다. 기존 전통적 CV 모델([dl-06](/lectures/deep-learning/dl-06))과 VLM을 앙상블하여 정밀도를 높이는 전략이 효과적입니다.

```python
# 품질 검사 VLM 파이프라인
def inspect_product(image_path: str, reference_images: list[str]) -> dict:
    prompt = """제품 이미지를 분석하여 다음 결함 유형을 검사하세요:
1. 표면 스크래치
2. 색상 불균일
3. 형태 변형

JSON 형식으로 결과를 반환하세요:
{"defects": [{"type": "결함유형", "severity": "low/medium/high", "location": "위치"}], "pass": true/false}"""

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{
            "role": "user",
            "content": [
                {"type": "text", "text": prompt},
                {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{encode_image(image_path)}"}},
            ],
        }],
        response_format={"type": "json_object"},
    )
    return response.choices[0].message.content
```

### 시나리오 2: 부동산 매물 자동 분석

부동산 매물 사진(외관, 내부, 평면도)과 텍스트 설명을 결합하여 자동 매물 분석 보고서를 생성합니다. 평면도에서 면적을 추출하고, 내부 사진에서 인테리어 상태를 평가하며, 주변 환경 사진에서 입지 조건을 분석합니다. 멀티모달 RAG로 유사 매물 거래 이력을 검색하여 가격 적정성을 판단합니다.

> **핵심 직관**: 멀티모달 LLM은 "범용 시각 이해"에 강하지만, 정밀한 픽셀 수준 분석(의료 영상, 위성 사진)에서는 전문 CV 모델이 여전히 우위입니다. 최적 전략은 VLM의 범용 이해력과 특화 모델의 정밀성을 결합하는 것입니다.

## 핵심 정리

- 비전-언어 모델은 이미지 인코더(ViT/CLIP)와 LLM을 Projection Layer로 연결하며, 이 연결 품질이 성능을 좌우합니다
- 이미지 입력 시 detail 설정(low/high)에 따라 토큰 비용이 크게 달라지므로, 태스크에 맞는 해상도를 선택해야 합니다
- 멀티모달 RAG는 이미지와 테이블을 VLM으로 텍스트 설명 변환 후 벡터 DB에 저장하는 전략이 실용적입니다
- 오디오 처리는 Whisper 등 전사 모델로 텍스트 변환 후 LLM 분석하는 2단계 파이프라인이 표준입니다
- 프로덕션에서는 VLM의 범용 이해력과 도메인 특화 CV 모델의 정밀성을 앙상블하는 전략이 최적입니다
