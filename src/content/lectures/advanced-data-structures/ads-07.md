# 해시 테이블 심화

## 왜 해시 테이블 내부를 알아야 하는가

해시 테이블은 가장 많이 사용되는 자료구조이지만, 평균 $O(1)$이라는 성능 뒤에는 **충돌 해결, 리사이징, 해시 함수 품질**이라는 복잡한 설계 결정이 숨어 있습니다. Python의 dict, Java의 HashMap이 왜 그런 성능 특성을 보이는지, dbi-07의 Consistent Hashing이 왜 필요한지를 이해하려면 해시 테이블 내부를 알아야 합니다.

> **핵심 직관**: 해시 테이블의 성능은 **해시 함수의 품질**과 **충돌 해결 전략**에 의해 결정됩니다. 좋은 해시 함수는 키를 균등 분포시키고, 좋은 충돌 해결은 클러스터링을 방지합니다.

## 1. 충돌 해결: 체이닝 vs Open Addressing

```
체이닝 (Separate Chaining):
  각 슬롯에 연결 리스트 (또는 트리)
  [0] → (k1, v1) → (k5, v5)
  [1] → (k2, v2)
  [2] → null
  [3] → (k3, v3) → (k7, v7) → (k9, v9)

  장점: 부하율 > 1 가능, 삭제 쉬움
  단점: 포인터 오버헤드, 캐시 비친화적
  사용: Java HashMap (리스트 → 트리 변환, 8개 이상)

Open Addressing:
  모든 원소를 테이블 내에 저장
  충돌 시 다른 슬롯을 탐색 (probing)

  Linear Probing: h(k), h(k)+1, h(k)+2, ...
  Quadratic Probing: h(k), h(k)+1², h(k)+2², ...
  Double Hashing: h(k), h(k)+h2(k), h(k)+2·h2(k), ...

  장점: 캐시 친화적 (연속 메모리)
  단점: 부하율 0.7 이상이면 성능 급락, 삭제 복잡
  사용: Python dict, Rust HashMap
```

| 방식 | 캐시 | 부하율 | 삭제 | 최악 |
|------|------|--------|------|------|
| 체이닝 | 나쁨 | >1 가능 | 쉬움 | $O(N)$ 체인 |
| Linear Probing | 좋음 | <0.7 | tombstone | 클러스터링 |
| Double Hashing | 중간 | <0.8 | tombstone | 2차 클러스터링 |

## 2. Robin Hood Hashing

```
Robin Hood Hashing:

  "부자(짧은 탐색 거리)에게서 빼앗아 빈자(긴 거리)에게"

  삽입 시: 현재 슬롯의 원소보다 내가 더 멀리 왔으면 교체
  → 탐색 거리의 분산을 최소화

  예: 슬롯 5에 삽입, 거리 3
  슬롯 5의 기존 원소: 거리 1
  → 기존 원소를 밀어내고 내가 차지
  → 기존 원소는 다음 슬롯에서 계속 탐색

  효과:
  - 탐색 거리의 최대값 감소 → 최악 경우 개선
  - 기대 최대 탐색 거리: O(log log N)
  - Rust std::collections::HashMap이 사용
```

## 3. Cuckoo Hashing

```
Cuckoo Hashing:

  2개 해시 함수, 2개 테이블 → 최악 O(1) 조회!

  삽입(x):
  T1[h1(x)]가 비었으면 → 저장
  아니면 → 기존 원소 y를 쫓아냄
  y를 T2[h2(y)]에 → 거기도 차있으면 → 또 쫓아냄
  반복 (무한 루프 감지 → 리해시)

  조회(x):
  T1[h1(x)]에 있는가? OR T2[h2(x)]에 있는가?
  → 최대 2번 확인 → O(1) 최악!

  예:
  T1: [_] [a] [_] [c]
  T2: [b] [_] [d] [_]

  삽입(e), h1(e)=1 → T1[1]=a, 충돌!
  a를 쫓아냄 → T2[h2(a)]=0 → T2[0]=b, 충돌!
  b를 쫓아냄 → T1[h1(b)] ...
```

> **핵심 직관**: Cuckoo Hashing의 최악 $O(1)$ 조회는 **실시간 시스템**에서 매우 가치 있습니다. 네트워크 패킷 처리처럼 지연 시간의 분산이 중요한 경우, 평균 $O(1)$보다 최악 $O(1)$이 더 중요합니다.

## 4. 완전 해싱 (Perfect Hashing)

```
정적 집합에 대한 O(1) 최악 조회:

  FKS (Fredman-Komlós-Szemerédi):
  1차 해시 → 버킷별 2차 해시 (버킷 크기² 테이블)
  → 2차에서 충돌 0 보장

  공간: O(N), 구축: O(N) 기대

  적합: 키 집합이 고정 (예: 예약어, 상수 테이블)

  최소 완전 해싱 (Minimal Perfect):
  N개 키 → 크기 N 테이블에 충돌 없이 매핑
  → 공간 최적, 구축에 추가 시간
```

## 5. 해시 함수 선택

```
좋은 해시 함수의 조건:
  1. 균등 분포 (Uniform distribution)
  2. 눈사태 효과 (1비트 변경 → 50% 비트 변경)
  3. 빠른 계산

  실무 해시 함수:
  ├─ MurmurHash3: 범용, 빠름
  ├─ xxHash: 매우 빠름, 대용량 데이터
  ├─ SipHash: DoS 방지 (Python 3.3+, Rust 기본)
  └─ CityHash/FarmHash: Google, 문자열 특화

  Hash DoS 공격:
  공격자가 같은 해시값을 가진 키를 대량 삽입
  → O(N²) 처리 시간 → 서비스 장애
  → 대응: 랜덤 시드 해시 (SipHash)
```

> **핵심 직관**: Python이 SipHash를 사용하는 이유는 **Hash DoS 방지**입니다. 매번 프로세스 시작 시 랜덤 시드를 생성하여, 공격자가 충돌 키를 예측할 수 없게 합니다.

## 6. 리사이징 전략

```
부하율(Load Factor):
  α = n / m (원소 수 / 테이블 크기)
  α > 임계값 → 테이블 확장 (보통 2배)

  확장 비용: O(N) (전체 재해시)
  상각 비용: O(1) per insertion

  점진적 리사이징 (Incremental Rehashing):
  └─ Redis가 사용하는 방식
     새 테이블 생성 후, 매 연산마다 일부만 이동
     완전 이동 전까지 두 테이블 모두 조회
     → 한 번에 O(N) 블로킹 방지
```

해시 테이블은 ads-04의 확률적 자료구조(Bloom Filter), dbi-08의 해시 파티셔닝, dp-03의 Kafka 파티셔닝의 기반입니다.

## 핵심 정리

- **체이닝**은 구현이 쉽고 부하율 제한이 없지만, **Open Addressing**은 캐시 친화적이어서 더 빠릅니다
- **Robin Hood Hashing**은 탐색 거리 분산을 최소화하여 최악 경우를 개선합니다
- **Cuckoo Hashing**은 최악 $O(1)$ 조회를 보장하며 실시간 시스템에 적합합니다
- **SipHash** 등 랜덤 시드 해시는 Hash DoS 공격을 방지하며, Python과 Rust의 기본 해시입니다
- 리사이징은 상각 $O(1)$이며, Redis처럼 **점진적 리해시**로 순간 블로킹을 방지할 수 있습니다
