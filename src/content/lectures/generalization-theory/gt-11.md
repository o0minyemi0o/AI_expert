# PAC-Bayes 이론: 사전 지식과 사후 학습의 결합

## 왜 PAC-Bayes가 현대 일반화 이론의 핵심인가

gt-03의 VC bound와 gt-05의 Rademacher bound는 과매개변수 신경망에 적용하면 자명한(trivial) 결과를 줍니다. **PAC-Bayes 이론**은 McAllester(1999)가 도입한 프레임워크로, 학습 전의 **사전 분포(prior)** 와 학습 후의 **사후 분포(posterior)** 사이의 거리를 통해 일반화를 제어합니다. 이 접근은 현재까지 심층 신경망에 대해 가장 타이트한 비자명(non-vacuous) 일반화 bound를 제공합니다.

---

## 1. PAC-Bayes bound의 진술

**정리 (McAllester, 1999; Catoni, 2007):** 손실 $\ell \in [0,1]$에 대해, 데이터를 보기 전에 고정된 사전 분포 $P$ (가설 위의 분포)에 대해, 확률 $1-\delta$ 이상으로 **모든** 사후 분포 $Q$에 대해 동시에:

$$\mathbb{E}_{h \sim Q}[R(h)] \leq \mathbb{E}_{h \sim Q}[\hat{R}_S(h)] + \sqrt{\frac{\text{KL}(Q\|P) + \ln(n/\delta)}{2n}}$$

| 구성 요소 | 의미 | 역할 |
|---------|------|------|
| $P$ | 사전 분포 | 데이터 독립적 사전 지식 |
| $Q$ | 사후 분포 | 학습 후 가설 분포 |
| $\text{KL}(Q\|P)$ | KL 발산 | 학습의 "대가" |
| $\mathbb{E}_{h\sim Q}[R(h)]$ | 확률적 분류기의 위험 | Gibbs 분류기 성능 |

**핵심 구조:** bound는 모든 $Q$에 대해 동시에 성립하므로, 데이터를 본 후 최적의 $Q$를 자유롭게 선택할 수 있습니다.

```python
import numpy as np

def pac_bayes_bound(empirical_risks, kl_divergence, n, delta=0.05):
    """PAC-Bayes bound 계산
    empirical_risks: Q 하에서의 기대 경험적 위험
    kl_divergence: KL(Q||P)
    """
    complexity = np.sqrt((kl_divergence + np.log(n / delta)) / (2 * n))
    return empirical_risks + complexity

def kl_gaussians(mu_q, sigma_q, mu_p, sigma_p):
    """두 가우시안 사이의 KL 발산"""
    d = len(mu_q)
    kl = 0.5 * (np.sum(sigma_q**2 / sigma_p**2)
                + np.sum((mu_p - mu_q)**2 / sigma_p**2)
                - d + d * np.log(np.prod(sigma_p**2) / np.prod(sigma_q**2)))
    return kl
```

> **핵심 직관**: PAC-Bayes는 "학습이 사전 지식을 얼마나 수정했는가"(KL 발산)로 일반화를 측정합니다. 사전 지식이 좋으면 적은 수정으로 좋은 해를 찾을 수 있어 bound가 타이트합니다.

---

## 2. PAC-Bayes의 증명 스케치

증명의 핵심 기법은 **변화량 부등식(change of measure inequality)** 입니다.

**1단계: Donsker-Varadhan 부등식**

임의의 측정 가능한 함수 $\phi(h)$에 대해:

$$\mathbb{E}_{h\sim Q}[\phi(h)] \leq \text{KL}(Q\|P) + \ln\mathbb{E}_{h\sim P}[e^{\phi(h)}]$$

**2단계: $\phi(h) = n(R(h) - \hat{R}_S(h))^2 / 2$로 설정**

$\mathbb{E}_{h\sim P}[e^{\phi(h)}]$를 제어해야 합니다. 각 $h$에 대해 (고정된 $h$에서):

$$\mathbb{E}_S\left[e^{n(R(h)-\hat{R}_S(h))^2/2}\right] \leq ?$$

Hoeffding 보조정리에 의해:

$$\mathbb{E}_S[e^{\lambda(R(h)-\hat{R}_S(h))}] \leq e^{\lambda^2/(8n)}$$

**3단계: Markov 부등식과 결합**

$$\Pr_S\left[\mathbb{E}_Q[R(h) - \hat{R}_S(h)] > \epsilon\right] \leq \delta$$

를 풀면 최종 bound를 얻습니다.

| 증명 단계 | 도구 | 역할 |
|---------|------|------|
| 1단계 | Donsker-Varadhan | $Q$에서 $P$로 측도 변환 |
| 2단계 | Hoeffding/CGF | 개별 $h$의 집중 |
| 3단계 | Markov/union | 고확률 보장 |

> **핵심 직관**: PAC-Bayes 증명의 핵심 트릭은 "합집합 한계 대신 적분"을 사용한다는 것입니다. VC bound가 $|\mathcal{H}|$개의 이산적 합집합 한계를 사용하는 반면, PAC-Bayes는 연속적인 분포 위의 기대값을 사용하여 훨씬 효율적입니다.

---

## 3. 가우시안 사전/사후에의 적용

가장 많이 사용되는 설정인 가우시안 분포의 경우를 상세히 분석합니다.

$P = \mathcal{N}(0, \sigma_P^2 I)$, $Q = \mathcal{N}(w_S, \sigma_Q^2 I)$로 설정하면:

$$\text{KL}(Q\|P) = \frac{p}{2}\left(\frac{\sigma_Q^2}{\sigma_P^2} - 1 - \ln\frac{\sigma_Q^2}{\sigma_P^2}\right) + \frac{\|w_S\|^2}{2\sigma_P^2}$$

$\sigma_Q \ll \sigma_P$이면 (결정적 해에 가까움):

$$\text{KL}(Q\|P) \approx \frac{\|w_S\|^2}{2\sigma_P^2} + \frac{p}{2}\ln\frac{\sigma_P^2}{\sigma_Q^2}$$

| 항 | 의미 | 제어 방법 |
|----|------|---------|
| $\|w_S\|^2/(2\sigma_P^2)$ | 원점으로부터의 거리 | L2 정규화 |
| $\frac{p}{2}\ln(\sigma_P^2/\sigma_Q^2)$ | 사후 불확실성 | 파라미터 수 감소 |

**비자명 bound 조건:** bound가 1 미만이려면:

$$\frac{\|w_S\|^2}{2\sigma_P^2} + \frac{p}{2}\ln\frac{\sigma_P^2}{\sigma_Q^2} \ll 2n$$

```python
import numpy as np

def pac_bayes_gaussian_bound(w_learned, sigma_prior, sigma_post,
                              train_error, n, delta=0.05):
    """가우시안 PAC-Bayes bound"""
    p = len(w_learned)
    # KL divergence
    kl = (p/2 * (sigma_post**2/sigma_prior**2 - 1
                  - np.log(sigma_post**2/sigma_prior**2))
          + np.sum(w_learned**2) / (2 * sigma_prior**2))

    # 섭동된 모델의 기대 훈련 오차 (몬테카를로 추정 필요)
    complexity = np.sqrt((kl + np.log(n/delta)) / (2*n))
    return train_error + complexity, kl
```

> **핵심 직관**: 가우시안 PAC-Bayes에서 $\|w_S\|^2$는 L2 정규화와 동일한 역할을 합니다. PAC-Bayes는 L2 정규화의 일반화 효과를 자연스럽게 설명합니다.

---

## 4. 압축 관점의 PAC-Bayes

PAC-Bayes를 **정보 압축**의 관점에서 재해석합니다.

**비트 단위 해석:** KL 발산의 정보 이론적 의미:

$$\text{KL}(Q\|P) = \text{최소 추가 비트 수 (}P\text{를 }Q\text{로 업데이트하는 데 필요한)}$$

따라서 PAC-Bayes bound는:

$$\text{일반화 갭} \leq O\left(\sqrt{\frac{\text{모델 기술 비트 수}}{n}}\right)$$

**양자화를 통한 bound:**

가중치를 $b$ 비트로 양자화하면:

$$\text{KL}(Q_{\text{quant}}\|P) \leq b \cdot p_{\text{eff}}$$

여기서 $p_{\text{eff}}$는 유효 파라미터 수입니다.

| 압축 방법 | KL 기여 | 비자명 bound 조건 |
|---------|---------|----------------|
| 전체 정밀도 ($b=32$) | $32p$ | $p \ll n/32$ |
| 양자화 ($b=4$) | $4p_{\text{eff}}$ | $p_{\text{eff}} \ll n/4$ |
| 프루닝 + 양자화 | $b \cdot s + s\log p$ | $s \ll n/b$ |
| 저랭크 근사 | $O(r(d_1+d_2))$ | $r(d_1+d_2) \ll n$ |

```python
import numpy as np

def compression_pac_bayes(w_original, w_compressed, n_bits,
                           train_error, n, delta=0.05):
    """압축 기반 PAC-Bayes bound"""
    # 압축된 모델의 기술 길이 (비트)
    n_nonzero = np.sum(w_compressed != 0)
    description_length = n_nonzero * n_bits + n_nonzero * np.log2(len(w_original))
    # 비트를 nats로 변환
    kl_nats = description_length * np.log(2)
    complexity = np.sqrt((kl_nats + np.log(n/delta)) / (2*n))
    return train_error + complexity
```

> **핵심 직관**: 일반화가 좋은 모델은 압축 가능한 모델입니다. 모델을 적은 비트로 기술할 수 있다면, KL 항이 작아 PAC-Bayes bound가 타이트합니다. 이는 오컴의 면도날의 형식화입니다.

---

## 5. 신경망에 대한 비자명 PAC-Bayes bound

실제 심층 신경망에 PAC-Bayes를 적용한 결과를 소개합니다.

**Dziugaite & Roy (2017)의 선구적 결과:**

MNIST에서 2층 네트워크 (600-600)에 대해:

| 측도 | 값 |
|------|-----|
| 훈련 오차 | 0% |
| 테스트 오차 | ~2% |
| VC bound | > 100% (자명) |
| PAC-Bayes bound (최적화 전) | ~50% |
| PAC-Bayes bound (최적화 후) | ~17% |
| 실제 일반화 갭 | ~2% |

bound 최적화: $Q$의 파라미터를 조정하여 bound를 직접 최소화합니다:

$$\min_Q \left[\mathbb{E}_Q[\hat{R}_S(h)] + \sqrt{\frac{\text{KL}(Q\|P) + \ln(n/\delta)}{2n}}\right]$$

**PAC-Bayes with Backprop (PBB):**

| 기법 | MNIST bound | CIFAR-10 bound |
|------|-----------|---------------|
| VC/Rademacher | 자명 (> 1) | 자명 (> 1) |
| PAC-Bayes (기본) | ~50% | 자명 |
| PAC-Bayes (최적화) | ~17% | ~60% |
| PAC-Bayes + 데이터 의존 사전 | ~10% | ~40% |
| 실제 테스트 오차 | ~2% | ~10% |

> **핵심 직관**: PAC-Bayes bound는 여전히 실제 테스트 오차보다 느슨하지만, VC나 Rademacher와 달리 비자명한 결과를 제공하는 유일한 접근법입니다. 갭을 줄이는 것은 활발한 연구 분야입니다.

---

## 6. 데이터 의존적 사전 분포

사전 분포 $P$의 선택이 bound의 타이트함을 크게 좌우합니다.

**문제:** $P$는 데이터를 보기 전에 고정되어야 합니다.

**해법 1: 데이터 분할**

훈련 데이터를 $S_1, S_2$로 분할:
- $S_1$으로 "데이터 의존적 사전" $P_{S_1}$을 학습
- $S_2$로 PAC-Bayes bound를 평가

$$\mathbb{E}_Q[R(h)] \leq \mathbb{E}_Q[\hat{R}_{S_2}(h)] + \sqrt{\frac{\text{KL}(Q\|P_{S_1}) + \ln(|S_2|/\delta)}{2|S_2|}}$$

**해법 2: 차등 프라이버시 기반**

$\epsilon$-차등 프라이버시를 만족하는 사전이면:

$$\text{KL}(Q\|P_S) \leq \text{KL}(Q\|P_0) + O(\epsilon n)$$

| 사전 분포 선택 | KL 크기 | 데이터 비용 | 총 bound |
|-------------|---------|-----------|---------|
| 표준 가우시안 $\mathcal{N}(0,I)$ | 큼 ($\|w_S\|^2/2$) | 없음 | 느슨 |
| 사전 학습 모델 $\mathcal{N}(w_{\text{pre}}, I)$ | 작음 | 외부 데이터 | 타이트 |
| 데이터 분할 사전 | 매우 작음 | $|S_1|$개 손실 | 보통 |

> **핵심 직관**: 좋은 사전은 "대략적으로 어디를 봐야 하는지" 알려줍니다. 사전 학습(pretraining)은 정보 이론적으로 KL 항을 줄여 일반화를 개선합니다. 이것이 전이 학습과 파인튜닝의 이론적 근거입니다.

---

## 7. PAC-Bayes와 다른 bound의 관계

PAC-Bayes는 여러 고전적 bound를 통합합니다.

| 고전 bound | PAC-Bayes에서의 유도 | 사전/사후 선택 |
|-----------|-------------------|-------------|
| Hoeffding | $Q = \delta_h$ (결정적), $P$ = 균일 | $\text{KL} = \ln|\mathcal{H}|$ |
| VC bound | $Q = \delta_h$, $P$ = Sauer 적용 | $\text{KL} = d\ln(en/d)$ |
| Occam bound | $Q = \delta_h$, $P$ = 코딩 사전 | $\text{KL} = L(h)\ln 2$ |
| 안정성 bound | $Q$ = 알고리즘 출력 분포 | $\text{KL}$ = 상호 정보량 |

**PAC-Bayes ↔ 정보 이론:**

$$\text{KL}(Q\|P) \geq I(S; h_S) \quad \text{(데이터 처리 부등식)}$$

여기서 $I(S; h_S)$는 훈련 데이터와 학습된 가설 사이의 상호 정보량입니다.

> **핵심 직관**: PAC-Bayes는 일반화 이론의 "대통합 프레임워크"입니다. 적절한 사전/사후를 선택하면 거의 모든 기존 bound를 특수 경우로 회복합니다.

---

## 핵심 정리

- **PAC-Bayes bound는 사전 분포 $P$와 사후 분포 $Q$ 사이의 KL 발산으로 일반화를 제어하며, 모든 사후 분포에 대해 동시에 성립합니다**
- **증명의 핵심은 Donsker-Varadhan 변화량 부등식으로, 이산적 합집합 한계 대신 연속적 적분을 사용하여 효율적입니다**
- **압축 관점에서 PAC-Bayes bound는 "모델의 기술 길이(비트)/$\sqrt{n}$"으로 해석되며, 오컴의 면도날을 형식화합니다**
- **신경망에 대해 PAC-Bayes는 현재까지 유일하게 비자명한 일반화 bound를 제공하며, bound 최적화를 통해 타이트함을 개선합니다**
- **데이터 의존적 사전(데이터 분할, 사전 학습)은 KL 항을 대폭 줄여 bound를 타이트하게 하며, 전이 학습의 이론적 근거를 제공합니다**
