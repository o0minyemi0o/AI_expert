# 일반화의 본질: 학습 오차와 테스트 오차

## 왜 일반화를 이해해야 하는가

기계학습의 궁극적 목표는 **훈련 데이터에서 본 적 없는 새로운 데이터**에 대해 정확한 예측을 수행하는 것입니다. 훈련 오차가 0에 수렴하더라도 테스트 오차가 크다면 그 모델은 무용합니다. 일반화 이론은 "왜 어떤 모델은 일반화하고 어떤 모델은 실패하는가"라는 근본 질문에 수학적으로 답하려는 시도입니다.

---

## 1. 학습 문제의 형식적 정의

데이터 생성 분포 $\mathcal{D}$가 $\mathcal{X} \times \mathcal{Y}$ 위에 존재한다고 가정합니다. 우리는 이 분포에서 독립 동일 분포(i.i.d.)로 추출된 훈련 집합 $S = \{(x_i, y_i)\}_{i=1}^{n}$을 관측합니다.

가설 공간 $\mathcal{H}$에서 함수 $h: \mathcal{X} \to \mathcal{Y}$를 선택하며, 손실 함수 $\ell: \mathcal{Y} \times \mathcal{Y} \to \mathbb{R}_{\geq 0}$를 통해 성능을 측정합니다.

| 기호 | 의미 | 예시 |
|------|------|------|
| $\mathcal{D}$ | 데이터 생성 분포 | MNIST 이미지-레이블 결합 분포 |
| $S$ | 훈련 집합 | $n=1000$개 샘플 |
| $\mathcal{H}$ | 가설 공간 | 깊이 3 신경망의 집합 |
| $\ell$ | 손실 함수 | 0-1 손실, 교차 엔트로피 |

> **핵심 직관**: 우리는 $\mathcal{D}$를 직접 관측할 수 없으며, 오직 $S$를 통해 간접적으로 접근합니다. 이 "창문의 크기"가 일반화의 본질적 한계를 결정합니다.

---

## 2. 참위험과 경험적 위험

**참위험(true risk)** 은 분포 전체에 대한 기대 손실입니다:

$$R(h) = \mathbb{E}_{(x,y) \sim \mathcal{D}}[\ell(h(x), y)]$$

**경험적 위험(empirical risk)** 은 훈련 집합에 대한 평균 손실입니다:

$$\hat{R}_S(h) = \frac{1}{n}\sum_{i=1}^{n}\ell(h(x_i), y_i)$$

경험적 위험 최소화(ERM) 원리는 다음을 수행합니다:

$$h_S = \arg\min_{h \in \mathcal{H}} \hat{R}_S(h)$$

```python
import numpy as np

def empirical_risk(h, X, y, loss_fn):
    """경험적 위험 계산"""
    predictions = h(X)
    losses = loss_fn(predictions, y)
    return np.mean(losses)

def true_risk_estimate(h, X_test, y_test, loss_fn):
    """테스트 셋을 이용한 참위험 추정"""
    return empirical_risk(h, X_test, y_test, loss_fn)
```

> **핵심 직관**: ERM은 $\hat{R}_S(h)$를 $R(h)$의 대리(proxy)로 사용합니다. 이 대리가 얼마나 신뢰할 수 있는가가 일반화 이론의 핵심 질문입니다.

---

## 3. 일반화 갭의 정의

**일반화 갭(generalization gap)** 은 참위험과 경험적 위험의 차이입니다:

$$\text{Gen}(h_S) = R(h_S) - \hat{R}_S(h_S)$$

이 양은 확률 변수입니다 — $S$의 무작위성에 의존합니다. 우리의 목표는 높은 확률로 이 갭을 제어하는 것입니다:

$$\Pr\left[\sup_{h \in \mathcal{H}} |R(h) - \hat{R}_S(h)| > \epsilon\right] \leq \delta$$

| 일반화 갭 크기 | 해석 | 전형적 상황 |
|--------------|------|-----------|
| $\approx 0$ | 완벽한 일반화 | 단순 모델, 충분한 데이터 |
| 양수이지만 작음 | 양호한 일반화 | 적절한 정규화 |
| 매우 큼 | 과적합 | 복잡한 모델, 적은 데이터 |

MNIST에서 100만 파라미터 모델이 1000개 샘플로도 일반화하는 이유는 이 강의 시리즈 전체에서 탐구할 핵심 미스터리입니다.

---

## 4. 과적합의 수학적 정의

과적합은 다음 두 조건이 동시에 성립할 때 발생합니다:

$$\hat{R}_S(h_S) \approx 0 \quad \text{그리고} \quad R(h_S) \gg 0$$

더 형식적으로, 가설 $h_S$가 **$\epsilon$-과적합**한다고 정의합니다:

$$R(h_S) - \inf_{h \in \mathcal{H}} R(h) > \epsilon$$

과적합의 분해를 통해 원인을 파악할 수 있습니다:

$$\underbrace{R(h_S)}_{\text{테스트 오차}} = \underbrace{\hat{R}_S(h_S)}_{\text{훈련 오차}} + \underbrace{(R(h_S) - \hat{R}_S(h_S))}_{\text{일반화 갭}}$$

```python
import numpy as np
from sklearn.polynomial_features import PolynomialFeatures
from sklearn.linear_model import LinearRegression

def demonstrate_overfitting(X_train, y_train, X_test, y_test, degrees):
    """다항식 차수에 따른 과적합 시연"""
    results = []
    for d in degrees:
        poly = PolynomialFeatures(degree=d)
        X_poly_train = poly.fit_transform(X_train)
        X_poly_test = poly.transform(X_test)
        model = LinearRegression().fit(X_poly_train, y_train)
        train_err = np.mean((model.predict(X_poly_train) - y_train)**2)
        test_err = np.mean((model.predict(X_poly_test) - y_test)**2)
        results.append((d, train_err, test_err, test_err - train_err))
    return results  # (차수, 훈련오차, 테스트오차, 일반화갭)
```

> **핵심 직관**: 과적합은 모델이 데이터의 신호(signal)뿐 아니라 잡음(noise)까지 학습할 때 발생합니다. gt-02에서 다룰 편향-분산 분해가 이를 정량화합니다.

---

## 5. 균일 수렴과 일반화

가장 고전적인 일반화 보장은 **균일 수렴(uniform convergence)** 에 기반합니다:

$$\Pr\left[\sup_{h \in \mathcal{H}} |R(h) - \hat{R}_S(h)| \leq \epsilon(n, \mathcal{H}, \delta)\right] \geq 1 - \delta$$

유한 가설 클래스 $|\mathcal{H}| < \infty$의 경우, 합집합 한계(union bound)와 Hoeffding 부등식을 결합하면:

$$\epsilon(n, \mathcal{H}, \delta) = \sqrt{\frac{\ln|\mathcal{H}| + \ln(2/\delta)}{2n}}$$

이 결과의 의미를 표로 정리합니다:

| 요인 | 일반화 갭에 미치는 영향 | 방향 |
|------|---------------------|------|
| 가설 공간 크기 $\|\mathcal{H}\|$ 증가 | 갭 증가 | $\uparrow$ |
| 훈련 샘플 수 $n$ 증가 | 갭 감소 | $\downarrow$ |
| 신뢰도 $1-\delta$ 증가 | 갭 증가 | $\uparrow$ |

---

## 6. ERM의 일관성과 학습 가능성

ERM이 성공하기 위한 충분조건은 **균일 수렴 성질**입니다. 가설 클래스 $\mathcal{H}$가 균일 Glivenko-Cantelli 클래스이면:

$$\hat{R}_S(h) \xrightarrow{n \to \infty} R(h) \quad \text{균일하게 (uniformly)}$$

학습 가능성의 근본 정리(Fundamental Theorem of Learning)는 다음 조건들의 동치성을 보여줍니다:

1. $\mathcal{H}$가 PAC 학습 가능하다
2. $\mathcal{H}$의 VC 차원이 유한하다
3. $\mathcal{H}$에 대해 균일 수렴이 성립한다

$$\text{VC}(\mathcal{H}) < \infty \iff \mathcal{H} \text{는 PAC 학습 가능}$$

이 동치성은 gt-03과 gt-04에서 깊이 다루게 됩니다.

> **핵심 직관**: 학습 가능성은 가설 공간의 "크기"에 의해 결정됩니다. 그러나 이 "크기"는 단순한 파라미터 수가 아닌 VC 차원이라는 조합론적 측도입니다.

---

## 7. 일반화 이론의 지형도

이 강좌에서 다룰 일반화 이론의 주요 접근법을 조감합니다:

| 강의 | 접근법 | 핵심 도구 | 시대 |
|------|--------|----------|------|
| gt-03 | VC 이론 | 성장 함수, VC 차원 | 1970s |
| gt-04 | PAC 학습 | 표본 복잡도 | 1984 |
| gt-05 | Rademacher 복잡도 | 데이터 의존적 bound | 2000s |
| gt-06 | 정규화 이론 | 벌점화, 조기 종료 | 고전~현대 |
| gt-07-08 | 이중 하강/양성 과적합 | 보간 이론 | 2019~ |
| gt-09-10 | NTK/암묵적 편향 | 최적화 경로 분석 | 2018~ |
| gt-11 | PAC-Bayes | 사전/사후 분포 | 1999~ |

> **핵심 직관**: 고전 이론(VC, PAC)은 "과매개변수 모델은 일반화할 수 없다"고 예측하지만, 현대 딥러닝은 이를 정면으로 반박합니다. 이 모순을 해결하는 것이 현대 일반화 이론의 핵심 과제입니다.

---

## 핵심 정리

- **일반화 갭 $R(h_S) - \hat{R}_S(h_S)$는 모델이 훈련 데이터 너머로 얼마나 잘 외삽하는지를 정량화하는 핵심 지표입니다**
- **경험적 위험 최소화(ERM)는 관측 불가능한 참위험 대신 경험적 위험을 최적화하는 기본 학습 원리입니다**
- **과적합은 훈련 오차와 테스트 오차의 괴리로 정의되며, 모델이 잡음을 신호로 착각할 때 발생합니다**
- **균일 수렴은 가설 공간의 모든 함수에 대해 동시에 경험적 위험이 참위험에 수렴함을 보장합니다**
- **학습 가능성의 근본 정리는 VC 차원의 유한성과 PAC 학습 가능성의 동치를 확립합니다**
