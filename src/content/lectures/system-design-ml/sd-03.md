# 검색 시스템 설계

## 왜 검색 시스템 설계가 중요한가

검색은 인터넷의 근간이자, ML 시스템 설계 면접의 단골 주제입니다. 구글, 빙 같은 웹 검색뿐 아니라 이커머스 상품 검색, 사내 문서 검색 등 **거의 모든 서비스에 검색이 존재**합니다. 전통적인 키워드 검색에서 시맨틱 검색으로의 진화는 ML 엔지니어의 핵심 역량입니다.

> **핵심 직관**: 검색 시스템의 핵심 도전은 "사용자의 의도를 정확히 파악하고, 수십억 문서 중에서 가장 관련 있는 결과를 밀리초 안에 반환하는 것"입니다.

## 1. 검색 시스템 아키텍처

```
검색 시스템 전체 아키텍처:

  [사용자 쿼리]
       │
       ▼
  [쿼리 이해 Query Understanding]
  ├─ 오타 교정
  ├─ 쿼리 확장
  └─ 의도 분류
       │
       ▼
  [문서 검색 Retrieval]
  ├─ 역인덱스 (키워드)     ─┐
  └─ ANN 검색 (시맨틱)    ─┴─→ 후보 문서 (수천)
       │
       ▼
  [랭킹 Ranking]
  ├─ L1: 경량 랭킹 (수천 → 수백)
  └─ L2: 정밀 랭킹 (수백 → 수십)
       │
       ▼
  [후처리]
  ├─ 스니펫 생성
  ├─ 중복 제거
  └─ 결과 다양화
       │
       ▼
  [검색 결과 반환]
```

## 2. 역인덱스와 키워드 검색

역인덱스(Inverted Index)는 전통적 검색의 핵심 자료구조입니다.

```
역인덱스 구조:

  문서 1: "머신러닝은 데이터를 학습한다"
  문서 2: "딥러닝은 머신러닝의 한 분야다"
  문서 3: "데이터 엔지니어링은 파이프라인을 구축한다"

  역인덱스:
  ┌────────────┬─────────────────┐
  │ 토큰       │ 포스팅 리스트      │
  ├────────────┼─────────────────┤
  │ 머신러닝    │ [문서1, 문서2]     │
  │ 데이터     │ [문서1, 문서3]     │
  │ 딥러닝     │ [문서2]           │
  │ 학습       │ [문서1]           │
  │ 파이프라인  │ [문서3]           │
  └────────────┴─────────────────┘

  쿼리 "머신러닝 데이터"
  → 교집합: [문서1] (AND)
  → 합집합: [문서1, 문서2, 문서3] (OR)
```

**BM25 랭킹**: TF-IDF를 개선한 검색 표준 알고리즘입니다.

$$\text{BM25}(q, d) = \sum_{t \in q} \text{IDF}(t) \cdot \frac{f(t,d) \cdot (k_1 + 1)}{f(t,d) + k_1 \cdot (1 - b + b \cdot \frac{|d|}{avgdl})}$$

| 파라미터 | 의미 | 일반적 값 |
|---------|------|----------|
| $k_1$ | TF 포화 속도 | 1.2 ~ 2.0 |
| $b$ | 문서 길이 보정 | 0.75 |
| $f(t,d)$ | 문서 d에서 토큰 t의 빈도 | — |
| $avgdl$ | 평균 문서 길이 | — |

## 3. 쿼리 이해

사용자 쿼리를 그대로 사용하면 검색 품질이 떨어집니다. **쿼리 이해** 단계가 필수입니다.

| 기법 | 설명 | 예시 |
|------|------|------|
| 오타 교정 | 편집 거리 기반 교정 | "머신렁닝" → "머신러닝" |
| 쿼리 확장 | 동의어/관련어 추가 | "ML" → "ML OR 머신러닝" |
| 의도 분류 | 쿼리 의도 파악 | "파이썬 설치" → How-to 의도 |
| 쿼리 재작성 | 자연어 → 검색 최적 형태 | "가장 좋은 노트북" → "노트북 추천 2024" |

```python
# 간단한 오타 교정 (편집 거리 기반)
def spell_correct(query: str, vocab: set[str]) -> str:
    words = query.split()
    corrected = []
    for word in words:
        if word in vocab:
            corrected.append(word)
        else:
            # 편집 거리 1 이내의 후보 찾기
            candidates = [v for v in vocab if edit_distance(word, v) <= 1]
            if candidates:
                # 빈도 기반 선택
                corrected.append(max(candidates, key=lambda c: word_freq[c]))
            else:
                corrected.append(word)
    return " ".join(corrected)
```

## 4. 시맨틱 검색

dl-12에서 배운 트랜스포머 임베딩을 활용하여 **의미 기반 검색**을 수행합니다.

```
시맨틱 검색 파이프라인:

  [오프라인] 문서 인덱싱:
  문서 → 인코더(BERT) → 문서 임베딩 → ANN 인덱스(FAISS)

  [온라인] 쿼리 처리:
  쿼리 → 인코더(BERT) → 쿼리 임베딩 → ANN 검색 → Top-K 결과

  키워드 검색 vs 시맨틱 검색:
  ─────────────────────────────────────────
  쿼리: "자동차 연비 좋은 차"
  키워드: "연비"가 포함된 문서만 반환
  시맨틱: "fuel efficiency", "하이브리드", "경제적인 차" 문서도 반환
```

| 검색 방식 | 장점 | 단점 |
|----------|------|------|
| 키워드 (BM25) | 빠름, 정확한 키워드 매칭 | 의미적 유사성 못 잡음 |
| 시맨틱 (Dense) | 의미 기반 매칭 | 키워드 정확도 낮을 수 있음 |
| 하이브리드 | 양쪽 장점 결합 | 점수 통합 방법 필요 |

> **핵심 직관**: 실무에서는 키워드 검색과 시맨틱 검색을 **하이브리드**로 결합합니다. 키워드 매칭의 정확성과 시맨틱 매칭의 일반화 능력을 동시에 활용하는 것이 최적입니다.

## 5. Learning to Rank

검색 랭킹은 ML 모델을 통해 학습할 수 있습니다.

```
Learning to Rank 접근법:

  Pointwise          Pairwise           Listwise
  ──────────         ──────────         ──────────
  문서별 점수 예측    문서 쌍 비교        전체 리스트 최적화
  (회귀/분류)        (A > B?)           (NDCG 직접 최적화)

  예: 로지스틱 회귀    예: RankNet         예: LambdaMART
                        LambdaRank         ListNet

  난이도: 쉬움        난이도: 중간         난이도: 높음
  성능: 낮음          성능: 중간          성능: 높음
```

| 메트릭 | 설명 | 수식 |
|--------|------|------|
| MRR | 첫 정답의 역순위 평균 | $\frac{1}{Q}\sum \frac{1}{rank_i}$ |
| NDCG@K | 순위별 관련도 반영 | 정규화된 DCG |
| Precision@K | 상위 K개 중 정답 비율 | $\frac{relevant \cap top\text{-}K}{K}$ |
| MAP | 평균 정밀도 | Precision의 면적 |

## 6. 실전 시나리오: 이커머스 상품 검색

**문제**: "대규모 이커머스 플랫폼의 상품 검색 시스템을 설계하세요."

```
설계 요약:

  1. 요구사항 (sd-01 프레임워크 적용)
     - 상품 수: 1억 개, QPS: 10,000
     - 지연시간: p99 < 200ms

  2. 아키텍처
     쿼리 → [쿼리 이해] → [하이브리드 검색] → [L2 랭킹] → [결과]
                           ├─ BM25 (역인덱스)
                           └─ Dense (ANN)

  3. 피처 설계
     - 쿼리-상품 관련도 (텍스트 매칭)
     - 상품 품질 (리뷰 점수, 반품률)
     - 개인화 (과거 구매 이력, 클릭 이력)
     - 비즈니스 (광고 여부, 재고 상태)

  4. 트레이드오프
     - 관련도 vs 매출 최적화 (광고 상품 노출)
     - 인기도 편향 vs 신규 상품 노출
```

> **핵심 직관**: 이커머스 검색에서는 "관련도"와 "수익성"의 균형이 핵심 트레이드오프입니다. 광고 상품을 과도하게 노출하면 사용자 경험이 저하되고, 반대로 순수 관련도만 최적화하면 비즈니스 목표를 달성할 수 없습니다.

## 핵심 정리

- 검색 시스템은 **쿼리 이해 → 문서 검색 → 랭킹 → 후처리** 파이프라인으로 구성됩니다
- **역인덱스 + BM25**는 키워드 검색의 표준이며, 시맨틱 검색과 하이브리드로 결합하는 것이 실무 추세입니다
- 쿼리 이해(오타 교정, 쿼리 확장, 의도 분류)는 검색 품질에 **결정적 영향**을 미칩니다
- Learning to Rank는 **Pointwise → Pairwise → Listwise** 순으로 복잡하지만 성능이 높아집니다
- 검색 평가 메트릭(MRR, NDCG, MAP)은 **순위가 중요한 문제**에서 정확도/재현율보다 적합합니다
