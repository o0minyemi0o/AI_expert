# 자연어 처리 시스템

## 왜 NLP 시스템 설계가 중요한가

자연어 처리는 챗봇, 감성 분석, 문서 분류, 번역 등 **사용자와 직접 상호작용하는 ML 시스템**의 핵심입니다. dl-12에서 배운 트랜스포머 아키텍처가 NLP 시스템의 기반이 되며, LLM의 등장으로 NLP 시스템 설계 패러다임이 근본적으로 변화하고 있습니다.

> **핵심 직관**: NLP 시스템 설계의 핵심 결정은 "직접 학습 vs 사전학습 모델 활용 vs LLM API 호출" 중 어떤 접근을 택할 것인가입니다. 비용, 지연시간, 정확도, 데이터 프라이버시가 이 결정을 좌우합니다.

## 1. NLP 시스템 접근법 비교

```
NLP 시스템 접근법 스펙트럼:

  규칙 기반        전통 ML          파인튜닝         LLM API
  ─────────      ─────────       ─────────       ─────────
  키워드 매칭      TF-IDF + SVM    BERT 파인튜닝    GPT-4 프롬프팅

  정확도: 낮음     정확도: 중간     정확도: 높음     정확도: 높음
  비용: 최저       비용: 낮음      비용: 중간       비용: 높음 (추론)
  지연시간: 최저   지연시간: 낮음   지연시간: 중간   지연시간: 높음
  유연성: 낮음     유연성: 중간     유연성: 높음     유연성: 최고
```

| 접근법 | 적합한 상황 | 부적합한 상황 |
|--------|-----------|-------------|
| 규칙 기반 | 패턴 명확, 도메인 한정 | 복잡한 언어 이해 |
| 전통 ML | 데이터 충분, 비용 제한 | 미묘한 의미 차이 |
| BERT 파인튜닝 | 도메인 특화, 높은 정확도 필요 | 데이터 부족 |
| LLM API | 빠른 프로토타입, 다양한 태스크 | 비용 민감, 지연시간 엄격 |

## 2. 챗봇 시스템 설계

```
챗봇 아키텍처:

  [사용자 입력]
       │
       ▼
  [의도 분류 Intent Classification]
  ├─ FAQ 질문 → [검색 기반 응답]
  ├─ 작업 요청 → [태스크 처리 엔진]
  │               ├─ 슬롯 채우기 (NER)
  │               └─ API 호출
  └─ 잡담     → [생성 모델 / LLM]
       │
       ▼
  [응답 생성]
       │
       ▼
  [안전성 필터] → [사용자 응답]


  대화 관리 (Dialog State Tracking):
  ┌─────────────────────────────────┐
  │ 현재 상태:                        │
  │ intent: "항공편_예약"              │
  │ slots:                           │
  │   출발지: "서울" (확정)             │
  │   도착지: "도쿄" (확정)             │
  │   날짜: ? (미확정 → 질문 필요)      │
  └─────────────────────────────────┘
```

```python
# 의도 분류 + 슬롯 추출 파이프라인 (간소화)
class ChatbotPipeline:
    def __init__(self):
        self.intent_model = load_model("intent_classifier")
        self.ner_model = load_model("slot_extractor")
        self.dialog_state = {}

    def process(self, user_input: str) -> str:
        # 1. 의도 분류
        intent = self.intent_model.predict(user_input)

        # 2. 엔티티 추출 (슬롯 채우기)
        entities = self.ner_model.extract(user_input)
        self.dialog_state.update(entities)

        # 3. 미완성 슬롯 확인
        missing = self.get_missing_slots(intent)
        if missing:
            return f"{missing[0]}을(를) 알려주세요."

        # 4. 모든 슬롯 완성 → 작업 실행
        return self.execute_action(intent, self.dialog_state)
```

## 3. 감성 분석 시스템

```
감성 분석 파이프라인:

  [텍스트 입력]
       │
       ▼
  [전처리]
  ├─ 텍스트 정규화 (이모지, 축약어)
  ├─ 언어 감지
  └─ 토큰화
       │
       ▼
  [감성 예측]
  ├─ 문서 레벨: 전체 긍정/부정/중립
  ├─ 문장 레벨: 문장별 감성
  └─ 속성 기반: "배터리는 좋지만 카메라는 별로"
       │
       ▼
  [후처리 & 집계]
  ├─ 신뢰도 필터링
  └─ 대시보드 / 알림
```

| 감성 분석 유형 | 난이도 | 출력 | 사용 사례 |
|-------------|--------|------|----------|
| 이진 분류 | 쉬움 | 긍정/부정 | 리뷰 요약 |
| 다중 분류 | 중간 | 매우부정~매우긍정 | 만족도 점수 |
| 속성 기반 | 어려움 | 속성별 감성 | 제품 피드백 |
| 감정 탐지 | 어려움 | 기쁨/분노/슬픔/... | 고객 서비스 |

> **핵심 직관**: 감성 분석에서 가장 어려운 것은 **풍자와 맥락 의존적 표현**입니다. "정말 대단하네요"가 진심인지 비꼬는 것인지는 맥락 없이 판단할 수 없습니다. 이것이 LLM 기반 접근의 강점이 드러나는 영역입니다.

## 4. 문서 분류 시스템

대규모 문서를 자동으로 분류하는 시스템입니다.

```
문서 분류 유형:

  단일 레이블 (Multi-class)
  └─ "이 뉴스는 스포츠 / 정치 / 경제 중 하나"

  다중 레이블 (Multi-label)
  └─ "이 논문은 NLP + 딥러닝 + 교육에 해당"

  계층적 분류 (Hierarchical)
  └─ "전자제품 > 모바일 > 스마트폰 > 안드로이드"

  계층적 분류 전략:
  ├─ Flat: 모든 리프 노드를 동시에 분류 (단순)
  ├─ Top-down: 상위 → 하위 순서로 분류 (오류 전파 위험)
  └─ Local per node: 각 노드에 별도 모델 (정확, 복잡)
```

## 5. 다국어 NLP 시스템

글로벌 서비스에서는 다국어 지원이 필수입니다.

```
다국어 NLP 전략:

  전략 1: 번역 후 처리 (Translate-then-Process)
  └─ 입력 → 영어로 번역 → 영어 모델 → 결과
     장점: 영어 모델 재사용  |  단점: 번역 오류 전파

  전략 2: 다국어 모델 (Multilingual Model)
  └─ mBERT, XLM-R 등으로 직접 처리
     장점: 번역 불필요  |  단점: 자원 부족 언어 성능 낮음

  전략 3: 언어별 모델 (Per-Language)
  └─ 각 언어에 특화된 모델 운영
     장점: 최고 성능  |  단점: 유지보수 비용 높음
```

| 전략 | 지원 언어 수 | 성능 | 유지보수 |
|------|-----------|------|---------|
| 번역 후 처리 | 100+ | 중간 | 낮음 |
| 다국어 모델 | 100+ | 중~상 | 중간 |
| 언어별 모델 | 5-10 | 최고 | 높음 |

> **핵심 직관**: 다국어 전략 선택은 "지원 언어 수 × 언어별 데이터량 × 성능 요구사항"으로 결정됩니다. 5개 언어 이내라면 언어별 모델이 최적이고, 100개 이상이면 다국어 모델이 현실적입니다.

## 6. NLP 평가 메트릭

| 태스크 | 메트릭 | 설명 |
|--------|--------|------|
| 분류 | F1, Accuracy | 클래스 불균형 시 F1 사용 |
| 생성 (번역) | BLEU | n-gram 정밀도 기반 |
| 생성 (요약) | ROUGE | n-gram 재현율 기반 |
| 검색 | MRR, NDCG | 순위 품질 (sd-03) |
| 대화 | 만족도, 해결률 | 사람 평가 필수 |

```
BLEU vs ROUGE:

  BLEU (Bilingual Evaluation Understudy)
  └─ "생성된 텍스트의 n-gram이 참조에 얼마나 포함되는가" (정밀도 중심)
     → 번역 품질 평가

  ROUGE (Recall-Oriented Understudy for Gisting Evaluation)
  └─ "참조의 n-gram이 생성된 텍스트에 얼마나 포함되는가" (재현율 중심)
     → 요약 품질 평가
```

NLP 시스템은 dl-12의 트랜스포머를 실전에 적용하는 대표적 사례이며, sd-11에서 다룰 LLM 애플리케이션 설계의 기초가 됩니다.

## 핵심 정리

- NLP 시스템의 핵심 결정은 **규칙 vs 전통ML vs 파인튜닝 vs LLM API** 중 접근법 선택입니다
- 챗봇은 **의도 분류 + 슬롯 채우기 + 대화 상태 관리**의 파이프라인으로 구성됩니다
- 감성 분석은 이진 분류에서 **속성 기반 분석**까지 다양한 수준이 있으며, 풍자가 가장 큰 도전입니다
- 다국어 지원은 **언어 수와 성능 요구사항**에 따라 번역, 다국어 모델, 언어별 모델 중 선택합니다
- NLP 평가는 태스크별로 **적합한 메트릭**(F1, BLEU, ROUGE, MRR)이 다르며, 생성 태스크는 사람 평가가 필수입니다
