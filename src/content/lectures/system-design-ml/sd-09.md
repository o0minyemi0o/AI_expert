# 데이터 파이프라인 설계

## 왜 데이터 파이프라인 설계가 중요한가

ML 모델은 데이터 품질에 전적으로 의존합니다. 아무리 정교한 모델도 **잘못된 데이터가 들어가면 잘못된 결과**가 나옵니다(Garbage In, Garbage Out). 데이터 파이프라인은 원시 데이터를 수집, 정제, 변환하여 모델이 소비할 수 있는 형태로 만드는 시스템이며, mlops 과정에서 다룬 프로덕션 ML의 핵심 인프라입니다.

> **핵심 직관**: ML 엔지니어의 시간 중 80%가 데이터 파이프라인에 소요됩니다. 모델 아키텍처보다 데이터 파이프라인의 품질이 최종 성능에 더 큰 영향을 미치는 경우가 대부분입니다.

## 1. 배치 vs 스트리밍 아키텍처

```
배치 처리 (Batch Processing):

  [데이터 소스] → [일/시간 단위 수집] → [배치 처리] → [데이터 저장소]
                                         │
                                    MapReduce / Spark

  적합: 일일 리포트, 모델 재학습, 대규모 ETL
  지연: 시간~일 단위


스트리밍 처리 (Stream Processing):

  [이벤트 소스] → [메시지 큐(Kafka)] → [스트림 처리] → [실시간 저장소]
                                         │
                                    Flink / Spark Streaming

  적합: 실시간 피처, 알림, 사기 탐지 (sd-06)
  지연: 밀리초~초 단위
```

| 특성 | 배치 | 스트리밍 |
|------|------|---------|
| 지연시간 | 시간~일 | 밀리초~초 |
| 데이터 정합성 | 강함 (재처리 가능) | 약함 (at-least-once) |
| 처리량 | 매우 높음 | 중간 |
| 복잡도 | 낮음 | 높음 |
| 비용 | 낮음 | 높음 |
| 오류 복구 | 쉬움 (재실행) | 어려움 |

## 2. Lambda와 Kappa 아키텍처

```
Lambda 아키텍처:

  [데이터 소스]
       │
       ├──→ [배치 레이어]     → [배치 뷰]  ─┐
       │     (일 1회 전체 처리)                ├──→ [서빙 레이어]
       └──→ [스피드 레이어]   → [실시간 뷰] ─┘
             (실시간 증분 처리)

  장점: 정확성(배치) + 실시간성(스트림) 동시 확보
  단점: 동일 로직을 두 번 구현 → 유지보수 부담


Kappa 아키텍처:

  [데이터 소스] → [메시지 큐] → [스트림 처리만] → [서빙 레이어]

  장점: 단일 파이프라인, 유지보수 간편
  단점: 대규모 재처리 시 비용 증가

  선택 기준:
  ├─ 실시간 + 정확성 모두 필요 → Lambda
  └─ 실시간이면 충분 → Kappa (최근 추세)
```

## 3. 데이터 품질 모니터링

```
데이터 품질 4대 차원:

  ┌─────────────┬─────────────────────────────────┐
  │ 완전성       │ 필수 필드에 NULL이 없는가?          │
  │ Completeness │ 예: user_id NULL 비율 < 0.01%    │
  ├─────────────┼─────────────────────────────────┤
  │ 일관성       │ 값이 유효한 범위 내인가?            │
  │ Consistency  │ 예: 나이 0-150, 금액 > 0          │
  ├─────────────┼─────────────────────────────────┤
  │ 신선도       │ 데이터가 제때 도착하는가?            │
  │ Freshness    │ 예: 지연 < 5분 (SLA)              │
  ├─────────────┼─────────────────────────────────┤
  │ 정확성       │ 값이 실제를 반영하는가?              │
  │ Accuracy     │ 예: 분포 드리프트 감지              │
  └─────────────┴─────────────────────────────────┘
```

```python
# 데이터 품질 검증 파이프라인 (간소화)
class DataQualityChecker:
    def __init__(self, config: dict):
        self.rules = config["rules"]

    def validate(self, dataframe) -> dict:
        results = {}
        for rule in self.rules:
            if rule["type"] == "null_check":
                null_rate = dataframe[rule["column"]].isnull().mean()
                results[rule["name"]] = {
                    "passed": null_rate < rule["threshold"],
                    "value": null_rate,
                }
            elif rule["type"] == "range_check":
                out_of_range = (
                    (dataframe[rule["column"]] < rule["min"]) |
                    (dataframe[rule["column"]] > rule["max"])
                ).mean()
                results[rule["name"]] = {
                    "passed": out_of_range < rule["threshold"],
                    "value": out_of_range,
                }
            elif rule["type"] == "freshness":
                max_delay = (datetime.now() - dataframe["timestamp"].max())
                results[rule["name"]] = {
                    "passed": max_delay < timedelta(minutes=rule["max_minutes"]),
                    "value": str(max_delay),
                }
        return results
```

> **핵심 직관**: 데이터 품질 문제는 모델 성능 저하로 나타나지만, 디버깅할 때 모델을 먼저 의심하게 됩니다. **데이터 품질 모니터링을 모델 모니터링보다 먼저** 구축해야 합니다.

## 4. 스키마 진화

데이터 스키마는 시간에 따라 변합니다. 호환성을 유지하면서 스키마를 진화시키는 전략이 필요합니다.

```
스키마 호환성 유형:

  하위 호환 (Backward Compatible):
  └─ 새 스키마로 기존 데이터를 읽을 수 있음
     예: 필드 추가 (기본값 지정), 선택적 필드 제거

  상위 호환 (Forward Compatible):
  └─ 기존 스키마로 새 데이터를 읽을 수 있음
     예: 선택적 필드 추가

  완전 호환 (Full Compatible):
  └─ 양방향 모두 호환
     가장 안전하지만 변경 범위 제한적
```

| 변경 유형 | 하위 호환 | 상위 호환 | 권장 |
|----------|----------|----------|------|
| 필드 추가 (기본값) | O | O | 안전 |
| 필드 삭제 (선택적) | O | X | 주의 |
| 필드 타입 변경 | X | X | 위험 |
| 필드 이름 변경 | X | X | 새 필드로 대체 |

## 5. 데이터 레이크하우스

```
데이터 저장 아키텍처 진화:

  데이터 웨어하우스              데이터 레이크
  ─────────────              ──────────
  - 구조화 데이터               - 비구조화 포함
  - 스키마 선정의              - 스키마 후정의
  - SQL 쿼리 최적화             - 저비용 대용량 저장
  - 비용 높음                  - 거버넌스 약함

                  │
                  ▼
          데이터 레이크하우스
          ─────────────
          - 레이크의 저비용 저장 + 웨어하우스의 쿼리 성능
          - ACID 트랜잭션 지원
          - 스키마 적용 가능
          - 대표 기술: Delta Lake, Apache Iceberg, Apache Hudi
```

> **핵심 직관**: 레이크하우스는 "데이터 레이크에 데이터 웨어하우스의 관리 기능을 추가한 것"입니다. ML 파이프라인에서는 비구조화 데이터(이미지, 텍스트)와 구조화 피처를 한 곳에서 관리할 수 있어 특히 유리합니다.

## 6. 피처 스토어와 데이터 버전 관리

```
피처 스토어 아키텍처:

  [배치 파이프라인] ──→ [오프라인 스토어]  → 모델 학습
                           │
                      [동기화]
                           │
  [스트림 파이프라인] ──→ [온라인 스토어]  → 모델 서빙

  핵심 기능:
  ├─ 피처 공유: 여러 모델이 같은 피처 재사용
  ├─ 시점 정합성: 학습 시 미래 데이터 누수 방지
  ├─ 온라인 서빙: 저지연 피처 조회
  └─ 피처 카탈로그: 검색, 문서화, 거버넌스
```

데이터 파이프라인은 sd-02~sd-08의 모든 ML 시스템이 공유하는 기반 인프라이며, sd-10에서 다룰 모델 서빙과 함께 ML 시스템의 양대 기둥입니다.

## 핵심 정리

- 데이터 파이프라인은 **배치**(정확, 저비용)와 **스트리밍**(실시간, 고비용)으로 나뉘며, 요구사항에 맞게 선택합니다
- **Lambda 아키텍처**는 양쪽을 결합하지만 유지보수가 복잡하고, **Kappa**는 단순하지만 재처리가 비쌉니다
- 데이터 품질은 **완전성, 일관성, 신선도, 정확성** 4대 차원으로 모니터링하며, 모델보다 먼저 구축합니다
- 스키마 진화는 **하위 호환성**을 유지하는 것이 원칙이며, 타입 변경은 가능한 피합니다
- **피처 스토어**는 피처 공유, 시점 정합성, 저지연 서빙을 통해 ML 파이프라인의 효율성을 높입니다
