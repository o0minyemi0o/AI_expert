# 로깅과 에러 처리

## 왜 로깅과 에러 처리가 중요한가

ML 파이프라인은 데이터 로딩, 전처리, 학습, 평가, 서빙 등 여러 단계를 거칩니다. 어느 단계에서 문제가 발생했는지, 어떤 데이터로 어떤 결과가 나왔는지를 추적하지 않으면 디버깅이 사실상 불가능합니다. 특히 프로덕션에서 모델이 잘못된 예측을 하고 있을 때, 로그가 없다면 원인을 파악할 방법이 없습니다.

> **핵심 직관**: `print()`로 디버깅하는 단계를 넘어서야 합니다. 구조화된 로깅은 프로덕션에서 장애를 진단하는 유일한 수단입니다.

## 1. 구조화된 로깅 (Structured Logging)

전통적인 텍스트 로그는 사람이 읽기엔 좋지만, 기계가 파싱하기 어렵습니다. 구조화된 로깅은 JSON 형태로 로그를 남겨 검색과 분석을 용이하게 합니다.

| 방식 | 형태 | 검색 용이성 | 적합한 단계 |
|------|------|-----------|-----------|
| print() | 비구조화 텍스트 | 매우 낮음 | 절대 사용 금지 (프로덕션) |
| logging | 텍스트/포맷 가능 | 보통 | 개발/소규모 프로젝트 |
| structlog | JSON 구조화 | 높음 | 프로덕션 시스템 |

```python
# 표준 logging 설정
import logging

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler("training.log"),
    ],
)
logger = logging.getLogger(__name__)

# 학습 루프에서의 로깅
logger.info("Training started", extra={"model": "xgboost", "epochs": 100})
logger.warning("Low validation accuracy: %.4f", val_acc)
```

```python
# structlog — 구조화된 로깅
import structlog

structlog.configure(
    processors=[
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.add_log_level,
        structlog.processors.JSONRenderer(),
    ],
)
logger = structlog.get_logger()

# 구조화된 컨텍스트와 함께 로깅
logger.info("training_started", model="xgboost", epochs=100, lr=0.001)
# 출력: {"event": "training_started", "model": "xgboost", "epochs": 100, "lr": 0.001, "level": "info", "timestamp": "2024-..."}

logger.info("epoch_completed", epoch=42, train_loss=0.234, val_loss=0.312)
```

## 2. 로깅 레벨 전략

```
로깅 레벨 선택 흐름:
┌──────────────────────────────────┐
│ 이 로그는 누가 볼 것인가?        │
├──────────┬───────────────────────┤
│ 개발자    │     운영팀/모니터링    │
│          │                       │
│ DEBUG    │  INFO: 정상 흐름       │
│ 변수값,   │  WARNING: 주의 필요    │
│ 중간결과  │  ERROR: 기능 실패      │
│          │  CRITICAL: 시스템 중단  │
└──────────┴───────────────────────┘
```

```python
# ML 파이프라인에서의 로깅 레벨 사용 예시
logger.debug("Batch tensor shape: %s", batch.shape)
logger.info("Epoch %d completed, loss=%.4f", epoch, loss)
logger.warning("GPU memory usage exceeds 90%%: %dMB", mem_mb)
logger.error("Model checkpoint save failed: %s", str(e))
logger.critical("Training data corrupted, aborting pipeline")
```

> **핵심 직관**: 프로덕션에서는 INFO 이상만 기록하고, 디버깅 시 DEBUG로 전환합니다. 로그 레벨을 환경 변수로 제어하면 코드 변경 없이 상세도를 조절할 수 있습니다.

## 3. 에러 계층 설계

ML 프로젝트에서 발생하는 에러를 체계적으로 분류하면 에러 처리와 복구가 간결해집니다.

```python
# 에러 계층 정의
class MLPipelineError(Exception):
    """ML 파이프라인 최상위 예외"""

class DataError(MLPipelineError):
    """데이터 관련 예외"""

class DataNotFoundError(DataError):
    """데이터 파일을 찾을 수 없음"""

class DataValidationError(DataError):
    """데이터 스키마/품질 검증 실패"""

class ModelError(MLPipelineError):
    """모델 관련 예외"""

class ModelTrainingError(ModelError):
    """학습 중 발생하는 예외 (NaN loss 등)"""

class ModelLoadError(ModelError):
    """모델 로드 실패"""

class ConfigError(MLPipelineError):
    """설정 관련 예외 (se-04 참조)"""
```

```python
# 에러 계층 활용
def load_training_data(path: str) -> pd.DataFrame:
    if not Path(path).exists():
        raise DataNotFoundError(f"Data file not found: {path}")

    df = pd.read_csv(path)
    if df.isnull().any().any():
        raise DataValidationError(
            f"Null values found in columns: {df.columns[df.isnull().any()].tolist()}"
        )
    return df
```

## 4. 재시도 패턴

네트워크 요청, 외부 API 호출 등 일시적 실패가 발생할 수 있는 작업에는 재시도 패턴을 적용합니다.

```python
import time
import functools
from typing import TypeVar, Callable

T = TypeVar("T")

def retry(
    max_attempts: int = 3,
    delay: float = 1.0,
    backoff: float = 2.0,
    exceptions: tuple[type[Exception], ...] = (Exception,),
) -> Callable:
    """지수 백오프 재시도 데코레이터 (se-02 Decorator 패턴 참조)"""
    def decorator(func: Callable[..., T]) -> Callable[..., T]:
        @functools.wraps(func)
        def wrapper(*args, **kwargs) -> T:
            last_exception = None
            for attempt in range(max_attempts):
                try:
                    return func(*args, **kwargs)
                except exceptions as e:
                    last_exception = e
                    wait = delay * (backoff ** attempt)
                    logger.warning(
                        "retry_attempt",
                        function=func.__name__,
                        attempt=attempt + 1,
                        max_attempts=max_attempts,
                        wait_seconds=wait,
                        error=str(e),
                    )
                    time.sleep(wait)
            raise last_exception
        return wrapper
    return decorator

@retry(max_attempts=3, delay=2.0, exceptions=(ConnectionError, TimeoutError))
def download_model_weights(url: str) -> bytes:
    ...
```

### 시나리오: 학습 중 NaN loss 발생

학습 도중 loss가 NaN이 되는 것은 ML에서 흔히 발생하는 문제입니다. 이를 감지하고 적절히 대응하는 에러 처리가 필요합니다.

```python
import math

def train_epoch(model, dataloader, optimizer) -> float:
    total_loss = 0.0
    for batch_idx, (X, y) in enumerate(dataloader):
        loss = compute_loss(model(X), y)

        if math.isnan(loss.item()):
            logger.error(
                "nan_loss_detected",
                batch_idx=batch_idx,
                last_lr=optimizer.param_groups[0]["lr"],
            )
            raise ModelTrainingError(
                f"NaN loss at batch {batch_idx}. "
                "Consider reducing learning rate or checking data."
            )

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    return total_loss / len(dataloader)
```

## 5. 디버깅 전략

### 시나리오: 프로덕션에서 모델 성능 저하 디버깅

배포된 모델의 정확도가 갑자기 떨어졌습니다. 구조화된 로그를 활용한 디버깅 전략입니다.

```python
# 추론 시 입력/출력 로깅 (모니터링용)
def predict_with_logging(model, input_data: dict) -> dict:
    logger.info(
        "inference_request",
        input_features=list(input_data.keys()),
        input_shape={k: v.shape for k, v in input_data.items()},
    )

    prediction = model.predict(input_data)

    logger.info(
        "inference_response",
        prediction=prediction.tolist(),
        confidence=float(prediction.max()),
    )

    if prediction.max() < 0.5:
        logger.warning(
            "low_confidence_prediction",
            confidence=float(prediction.max()),
        )

    return {"prediction": prediction.tolist()}
```

```
디버깅 단계:
┌────────────────────────────────┐
│ 1. 로그에서 에러 패턴 검색     │
│    → 특정 시간대? 특정 입력?    │
│         ↓                      │
│ 2. 데이터 드리프트 확인         │
│    → 입력 분포 변화? (mo-06)    │
│         ↓                      │
│ 3. 모델 체크포인트 비교         │
│    → 특정 버전부터 저하?        │
│         ↓                      │
│ 4. 재현 가능한 최소 케이스 생성 │
│    → 실패 입력으로 유닛 테스트   │
│       작성 (se-03 참조)         │
└────────────────────────────────┘
```

> **핵심 직관**: 좋은 에러 메시지는 "무엇이 잘못되었는지"뿐만 아니라 "어떻게 해결할 수 있는지"도 알려줍니다. 에러 메시지에 가능한 원인과 해결 방안을 포함하십시오.

## 핵심 정리

- **구조화된 로깅**: structlog 등을 활용하여 JSON 형태의 로그를 남기면 검색, 필터링, 분석이 용이해집니다
- **로깅 레벨**: DEBUG(개발), INFO(정상 흐름), WARNING(주의), ERROR(실패), CRITICAL(시스템 중단)을 목적에 맞게 사용합니다
- **에러 계층**: DataError, ModelError 등 도메인별 예외 클래스를 정의하여 에러 처리를 체계화합니다
- **재시도 패턴**: 일시적 실패에 대해 지수 백오프 재시도를 적용하되, 최대 시도 횟수를 반드시 제한합니다
- **디버깅 전략**: 로그 기반 패턴 분석 → 데이터 드리프트 확인 → 최소 재현 케이스 생성의 단계를 따릅니다
