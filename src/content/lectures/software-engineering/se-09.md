# 리팩토링 패턴

## 왜 리팩토링이 중요한가

ML 프로젝트는 탐색적으로 시작합니다. 노트북에서 빠르게 프로토타이핑하고, 동작하면 다음 실험으로 넘어갑니다. 이 과정에서 축적된 기술 부채는 시간이 지날수록 새로운 실험의 속도를 떨어뜨립니다. 리팩토링은 외부 동작을 변경하지 않으면서 내부 구조를 개선하여, 코드의 이해 가능성과 변경 용이성을 높이는 작업입니다.

> **핵심 직관**: 리팩토링은 "나중에 한꺼번에"가 아니라 "작업할 때마다 조금씩" 하는 것입니다. 보이스카우트 규칙 — 코드를 발견했을 때보다 더 깨끗하게 남겨놓으십시오.

## 1. ML 코드에서 자주 발견되는 코드 스멜

| 코드 스멜 | 증상 | ML 맥락 예시 | 해결 패턴 |
|----------|------|-------------|----------|
| 장대한 함수 | 수백 줄 함수 | 전처리+학습+평가 한 함수 | 함수 추출 |
| 매직 넘버 | 하드코딩된 상수 | `if len(data) > 10000:` | 상수/설정 추출 |
| 중복 코드 | 복사-붙여넣기 | 학습/추론 전처리 중복 | 공통 함수 추출 |
| 긴 매개변수 목록 | 5개 이상 인자 | `train(X, y, lr, bs, ep, wd, ...)` | 설정 객체 도입 |
| 전역 상태 | 전역 변수 의존 | `global model, tokenizer` | 의존성 주입 |
| 죽은 코드 | 사용되지 않는 코드 | 이전 실험의 주석 처리된 코드 | 삭제 (Git이 기억함) |

## 2. 안전한 리팩토링 절차

리팩토링에서 가장 중요한 것은 "동작을 바꾸지 않는다"는 보장입니다.

```
안전한 리팩토링 흐름:
┌──────────────────────────────┐
│ 1. 테스트 확인               │
│    기존 테스트가 모두 통과?   │
│    없다면 먼저 테스트 작성    │
│    (se-03 참조)              │
│         ↓                    │
│ 2. 작은 단위로 변경          │
│    한 번에 하나의 리팩토링만  │
│         ↓                    │
│ 3. 테스트 재실행             │
│    변경 후 즉시 확인          │
│         ↓                    │
│ 4. 커밋                      │
│    리팩토링 커밋과 기능       │
│    커밋을 분리                │
│         ↓                    │
│ 5. 반복                      │
│    다음 리팩토링 수행         │
└──────────────────────────────┘
```

> **핵심 직관**: 리팩토링과 기능 변경을 절대 같은 커밋에 섞지 마십시오. 리팩토링 커밋은 동작 변경이 없어야 하고, 기능 커밋은 구조 변경이 없어야 합니다.

## 3. 핵심 리팩토링 기법

### 함수 추출 (Extract Function)

가장 빈번하게 사용되는 리팩토링입니다.

```python
# Before: 장대한 함수
def train_pipeline(config):
    # 데이터 로딩 (30줄)
    df = pd.read_csv(config["data_path"])
    df = df.dropna()
    df["feature_1"] = df["feature_1"].clip(0, 100)
    X = df.drop("target", axis=1).values
    y = df["target"].values
    X_train, X_test = X[:800], X[800:]
    y_train, y_test = y[:800], y[800:]
    # 학습 (20줄) ...
    # 평가 (20줄) ...

# After: 관심사별 함수 추출
def load_and_split(path: str, split_idx: int = 800):
    df = pd.read_csv(path)
    df = df.dropna()
    df["feature_1"] = df["feature_1"].clip(0, 100)
    X = df.drop("target", axis=1).values
    y = df["target"].values
    return X[:split_idx], X[split_idx:], y[:split_idx], y[split_idx:]

def train_model(X: np.ndarray, y: np.ndarray, config: dict) -> BaseModel:
    model = ModelFactory.create(config["model_name"])
    return model.fit(X, y)

def evaluate(model: BaseModel, X: np.ndarray, y: np.ndarray) -> dict:
    predictions = model.predict(X)
    return {"accuracy": accuracy_score(y, predictions)}
```

### 매개변수 객체 도입 (Introduce Parameter Object)

```python
# Before: 긴 매개변수 목록
def train(X, y, learning_rate, batch_size, epochs, weight_decay,
          warmup_steps, gradient_clip, dropout, seed):
    ...

# After: 설정 객체로 그룹화 (se-04 Pydantic 참조)
from dataclasses import dataclass

@dataclass(frozen=True)
class TrainingConfig:
    learning_rate: float = 0.001
    batch_size: int = 32
    epochs: int = 100
    weight_decay: float = 0.01
    warmup_steps: int = 100
    gradient_clip: float = 1.0
    dropout: float = 0.1
    seed: int = 42

def train(X: np.ndarray, y: np.ndarray, config: TrainingConfig):
    ...
```

### 조건문을 다형성으로 대체

```python
# Before: 분기문으로 모델 선택
def create_model(model_type: str, **kwargs):
    if model_type == "xgboost":
        return XGBClassifier(**kwargs)
    elif model_type == "lightgbm":
        return LGBMClassifier(**kwargs)
    elif model_type == "random_forest":
        return RandomForestClassifier(**kwargs)
    else:
        raise ValueError(f"Unknown model: {model_type}")

# After: Factory + Registry 패턴 (se-02 참조)
model = ModelFactory.create(model_type, **kwargs)
```

## 4. 레거시 ML 코드 개선

### 시나리오: 3000줄짜리 노트북을 패키지로 전환

연구팀이 1년간 사용해온 거대한 노트북을 프로덕션 가능한 패키지로 전환해야 합니다.

```
노트북 → 패키지 전환 전략:
┌────────────────────────────────────┐
│ Phase 1: 이해 (1주)                │
│ - 노트북 전체 실행 확인             │
│ - 입출력 데이터 흐름 매핑           │
│ - 하드코딩된 경로/상수 목록 작성     │
│                                    │
│ Phase 2: 테스트 작성 (1주)          │
│ - 핵심 함수의 입출력 캡처           │
│ - 골든 테스트 (스냅샷) 작성         │
│ - 전체 파이프라인 E2E 테스트        │
│                                    │
│ Phase 3: 추출 (2주)                │
│ - 셀 → 함수 → 모듈 순차 추출       │
│ - 매 추출마다 테스트 실행           │
│ - 설정 외부화 (se-04 참조)          │
│                                    │
│ Phase 4: 정리 (1주)                │
│ - 타입 힌트 추가 (se-05)           │
│ - 문서화, CI 구축 (se-08)          │
│ - 패키징 (se-06)                   │
└────────────────────────────────────┘
```

```python
# 골든 테스트: 기존 동작을 캡처
def test_preprocessing_matches_notebook_output():
    """노트북의 전처리 결과와 리팩토링된 코드의 결과가 동일한지 확인"""
    input_data = load_fixture("raw_input.csv")
    expected = load_fixture("preprocessed_golden.npy")

    result = preprocess(input_data)

    np.testing.assert_allclose(result, expected, rtol=1e-5)
```

## 5. 점진적 개선 전략

### 시나리오: 매주 30분 리팩토링

대규모 리팩토링을 한 번에 하기보다, 매주 30분씩 점진적으로 개선하는 것이 현실적입니다.

| 주차 | 작업 | 소요 시간 |
|------|------|----------|
| 1주 | 매직 넘버를 상수/설정으로 추출 | 30분 |
| 2주 | 가장 큰 함수 하나를 3개로 분리 | 30분 |
| 3주 | 중복된 전처리 코드 통합 | 30분 |
| 4주 | 타입 힌트 추가 (핵심 모듈) | 30분 |
| 5주 | 글로벌 상태를 의존성 주입으로 전환 | 30분 |

```python
# 리팩토링 전: 매직 넘버
if confidence > 0.7:
    return "positive"
elif len(tokens) > 512:
    tokens = tokens[:512]

# 리팩토링 후: 의미 있는 상수
CONFIDENCE_THRESHOLD = 0.7
MAX_TOKEN_LENGTH = 512

if confidence > CONFIDENCE_THRESHOLD:
    return "positive"
elif len(tokens) > MAX_TOKEN_LENGTH:
    tokens = tokens[:MAX_TOKEN_LENGTH]
```

> **핵심 직관**: 완벽한 리팩토링을 목표로 하지 마십시오. "어제보다 조금 더 나은 코드"를 매일 만드는 것이 현실적이고 효과적입니다.

프로젝트 구조 설계에 대한 종합적인 가이드는 se-10을, 리팩토링 중 코드 품질 유지 도구는 se-05를, 리팩토링 후 테스트 전략은 se-03을 참조하십시오.

## 핵심 정리

- **코드 스멜 식별**: 장대한 함수, 매직 넘버, 중복 코드, 전역 상태 등 ML 코드에서 흔히 발견되는 문제를 인식합니다
- **안전한 절차**: 테스트 확인 → 작은 변경 → 테스트 재실행 → 커밋의 순서를 반드시 지키며, 리팩토링과 기능 변경을 분리합니다
- **함수 추출**: 장대한 함수를 관심사별로 분리하는 것이 가장 효과적이고 빈번한 리팩토링 기법입니다
- **레거시 전환**: 노트북에서 패키지로의 전환은 이해 → 테스트 작성 → 추출 → 정리의 단계를 따릅니다
- **점진적 개선**: 매주 30분씩 작은 리팩토링을 꾸준히 수행하는 것이 대규모 일괄 리팩토링보다 현실적이고 안전합니다
