# 데이터 레이크하우스

## 왜 레이크하우스가 등장했는가

**데이터 레이크**는 저렴하지만 품질과 성능이 떨어지고, **데이터 웨어하우스**는 성능이 좋지만 비싸고 유연하지 않습니다. **레이크하우스(Lakehouse)**는 레이크의 저렴한 스토리지 위에 웨어하우스 수준의 ACID 트랜잭션, 스키마 관리, 성능을 올려놓은 아키텍처입니다. Delta Lake, Apache Iceberg, Apache Hudi가 이 패러다임의 핵심 기술입니다.

> **핵심 직관**: 레이크하우스의 핵심 혁신은 "저렴한 오브젝트 스토리지(S3) 위에 트랜잭션 레이어를 올린 것"입니다. 이를 통해 데이터 레이크의 비용 장점과 데이터 웨어하우스의 안정성을 동시에 얻습니다.

## 1. 데이터 레이크의 문제

```
데이터 레이크 (Data Lake):

  S3/GCS에 파일을 그대로 저장
  Parquet, JSON, CSV 등 다양한 형식

  문제점 (Data Swamp):
  ├─ ACID 없음: 쓰기 중 실패 → 반쪽 데이터
  ├─ 스키마 관리 없음: 파일마다 스키마 다를 수 있음
  ├─ 동시 쓰기 불안전: 여러 작업이 동시에 쓰면 충돌
  ├─ Time Travel 불가: 과거 상태 복원 불가능
  └─ 작은 파일 문제: 많은 작은 파일 → 느린 쿼리

  데이터 웨어하우스:
  ├─ ACID ✅, 스키마 ✅, 동시성 ✅
  └─ 비쌈, 폐쇄적, 비정형 데이터 불가

  레이크하우스:
  └─ 레이크 위에 트랜잭션/스키마/성능 레이어 추가
     → 두 세계의 장점을 결합
```

## 2. 테이블 포맷의 핵심 아이디어

```
핵심: 메타데이터 레이어

  기존 레이크:
  s3://data/orders/
  ├── part-0001.parquet
  ├── part-0002.parquet
  └── part-0003.parquet
  → 어떤 파일이 "현재" 유효한지 모름

  레이크하우스 (Delta Lake 예):
  s3://data/orders/
  ├── _delta_log/              ← 트랜잭션 로그
  │   ├── 00000.json           ← 커밋 1: add file1, file2
  │   ├── 00001.json           ← 커밋 2: add file3, remove file1
  │   └── 00002.json           ← 커밋 3: add file4
  ├── part-0001.parquet        (삭제됨, 하지만 Time Travel용 보존)
  ├── part-0002.parquet
  ├── part-0003.parquet
  └── part-0004.parquet

  트랜잭션 로그가 "어떤 파일이 현재 테이블에 속하는지" 관리
  → ACID, Time Travel, 스키마 관리 모두 가능
```

## 3. Delta Lake

```
Delta Lake (Databricks):

  핵심 기능:
  ├─ ACID 트랜잭션: 낙관적 동시성 제어
  ├─ Time Travel: 과거 버전 조회/롤백
  ├─ 스키마 관리: Schema Enforcement + Evolution
  ├─ MERGE (Upsert): CDC 적용에 최적
  └─ Z-Order: 다차원 데이터 클러스터링
```

```sql
-- Delta Lake 기본 사용 (Spark SQL)
CREATE TABLE orders
USING DELTA
LOCATION 's3://lakehouse/orders/';

-- Upsert (MERGE)
MERGE INTO orders AS target
USING new_orders AS source
ON target.order_id = source.order_id
WHEN MATCHED THEN UPDATE SET *
WHEN NOT MATCHED THEN INSERT *;

-- Time Travel
SELECT * FROM orders VERSION AS OF 5;
SELECT * FROM orders TIMESTAMP AS OF '2024-01-15 10:00:00';

-- 롤백
RESTORE TABLE orders TO VERSION AS OF 3;

-- 최적화
OPTIMIZE orders ZORDER BY (customer_id, order_date);
-- → customer_id와 order_date 기반 쿼리 성능 향상
```

## 4. Apache Iceberg

```
Apache Iceberg (Netflix 기원):

  핵심 차별점:
  ├─ 벤더 중립: Spark, Trino, Flink, Dremio 모두 지원
  ├─ Hidden Partitioning: 파티션 컬럼을 사용자가 몰라도 됨
  ├─ 파티션 진화: 파티셔닝 전략을 데이터 재작성 없이 변경
  └─ 대규모 테이블: 수억 파일도 효율적 관리

  Hidden Partitioning:
  -- 사용자는 그냥 쿼리
  SELECT * FROM orders WHERE order_date = '2024-01-15';

  -- Iceberg가 내부적으로 파티션 프루닝 수행
  -- 사용자는 파티션 구조를 알 필요 없음

  파티션 진화:
  -- 초기: 월별 파티셔닝
  ALTER TABLE orders ADD PARTITION FIELD month(order_date);

  -- 데이터 증가 → 일별로 변경 (기존 데이터 재작성 불필요!)
  ALTER TABLE orders ADD PARTITION FIELD day(order_date);
  ALTER TABLE orders DROP PARTITION FIELD month(order_date);
```

> **핵심 직관**: Iceberg의 가장 큰 강점은 **벤더 중립성**입니다. Delta Lake는 Databricks에 최적화되어 있지만, Iceberg는 어떤 엔진에서든 동일하게 동작합니다. 멀티 엔진 환경이라면 Iceberg가 더 유리합니다.

## 5. Apache Hudi

```
Apache Hudi (Uber 기원):

  핵심: 증분 처리에 특화

  Copy-on-Write (CoW):
  └─ 쓰기 시 전체 파일 재작성
     읽기 빠름, 쓰기 느림
     적합: 읽기 중심 워크로드

  Merge-on-Read (MoR):
  └─ 변경분을 delta log에 기록, 읽기 시 병합
     쓰기 빠름, 읽기 시 병합 비용
     적합: 쓰기 중심, 실시간 파이프라인
```

| 특성 | Delta Lake | Iceberg | Hudi |
|------|-----------|---------|------|
| 기원 | Databricks | Netflix | Uber |
| 강점 | Databricks 통합 | 벤더 중립 | 증분 처리 |
| 엔진 지원 | Spark 중심 | 다양 | Spark, Flink |
| 파티션 진화 | 제한적 | 강력 | 지원 |
| CDC 적합 | MERGE | MERGE | 네이티브 |
| 커뮤니티 | 크고 활발 | 빠르게 성장 | 중간 |

## 6. 레이크하우스 아키텍처 설계

```
전형적인 레이크하우스 아키텍처:

  [원천] → [CDC/Batch] → [Bronze] → [Silver] → [Gold]
                          (Raw)     (Cleaned)  (Business)

  Bronze: Iceberg 테이블, 원본 그대로
  Silver: Iceberg 테이블, 스타 스키마
  Gold:   Iceberg 테이블, 집계/마트

  쿼리 엔진 선택:
  ├─ Spark: 대규모 변환, ML
  ├─ Trino/Presto: 인터랙티브 분석
  ├─ Flink: 실시간 적재
  └─ dbt: SQL 변환 (Spark/Trino 위에서)

  비용 최적화:
  ├─ 스토리지: S3 ($0.023/GB/월) ← 매우 저렴
  ├─ 컴퓨팅: 필요할 때만 (서버리스 Spark)
  ├─ 오래된 데이터 → S3 Glacier ($0.004/GB/월)
  └─ 작은 파일 병합 (OPTIMIZE) → I/O 비용 절감
```

> **핵심 직관**: 레이크하우스의 가장 큰 가치는 **"컴퓨팅과 스토리지의 분리"**입니다. 데이터는 S3에 한 번 저장하고, Spark, Trino, ML 엔진이 각각 필요할 때 접근합니다. DW처럼 데이터를 복사할 필요가 없습니다.

레이크하우스는 dp-05의 데이터 모델이 물리적으로 저장되는 곳이며, dp-10의 피처 스토어와 dp-11의 거버넌스가 이 위에서 동작합니다.

## 핵심 정리

- **레이크하우스**는 데이터 레이크의 비용 효율성과 데이터 웨어하우스의 ACID/성능을 결합한 아키텍처입니다
- **트랜잭션 로그**가 핵심이며, 어떤 파일이 현재 테이블에 속하는지 관리하여 ACID와 Time Travel을 제공합니다
- **Delta Lake**는 Databricks 생태계에, **Iceberg**는 벤더 중립 환경에, **Hudi**는 CDC/증분 처리에 강점이 있습니다
- **Hidden Partitioning**(Iceberg)과 **파티션 진화**는 레이크의 작은 파일 문제와 파티셔닝 변경 비용을 해결합니다
- 컴퓨팅-스토리지 분리가 레이크하우스의 핵심 가치이며, 데이터를 한 곳에 저장하고 **여러 엔진이 접근**합니다
