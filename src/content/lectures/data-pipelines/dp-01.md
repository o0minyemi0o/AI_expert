# ETL vs ELT

## 왜 ETL/ELT를 이해해야 하는가

데이터는 원천 시스템(DB, API, 로그)에서 분석 가능한 형태로 변환되어야 합니다. **ETL(Extract-Transform-Load)**은 20년간 데이터 웨어하우스의 표준이었지만, 클라우드 DW의 등장으로 **ELT(Extract-Load-Transform)**가 현대적 표준이 되었습니다. 이 패러다임 전환의 이유와 각각의 적합한 상황을 이해하는 것이 데이터 파이프라인의 출발점입니다.

> **핵심 직관**: ETL과 ELT의 차이는 "변환을 어디서 하느냐"입니다. ETL은 파이프라인이 변환을 담당하고, ELT는 데이터 웨어하우스가 변환을 담당합니다. 클라우드 DW의 컴퓨팅 파워가 폭발적으로 증가하면서 ELT가 유리해졌습니다.

## 1. ETL 아키텍처

```
전통적 ETL:

  [Source DB] ──Extract──→ [ETL Server] ──Transform──→ ──Load──→ [DW]
  [API]       ──Extract──→ [ETL Server] ──Transform──→ ──Load──→ [DW]
  [Files]     ──Extract──→ [ETL Server] ──Transform──→ ──Load──→ [DW]

  Extract: 원천에서 데이터 추출
  Transform: 클렌징, 매핑, 집계 (ETL 서버에서)
  Load: 변환된 데이터를 DW에 적재

  특징:
  - 변환이 ETL 서버에서 실행 → 서버 리소스 필요
  - DW에는 정제된 데이터만 적재
  - 원본 데이터는 보존되지 않음
  - 도구: Informatica, Talend, SSIS
```

| 장점 | 단점 |
|------|------|
| DW 저장 공간 절약 | ETL 서버 스케일링 필요 |
| 깨끗한 데이터만 DW에 | 원본 데이터 손실 |
| PII 사전 마스킹 가능 | 변환 로직 변경 시 재처리 어려움 |

## 2. ELT 아키텍처

```
현대적 ELT:

  [Source DB] ──Extract+Load──→ [Cloud DW] ──Transform──→ [마트]
  [API]       ──Extract+Load──→ [Cloud DW] ──Transform──→ [마트]
  [Files]     ──Extract+Load──→ [Cloud DW] ──Transform──→ [마트]

  Extract + Load: 원본 데이터를 그대로 DW에 적재
  Transform: DW 내에서 SQL로 변환 (dbt 등)

  왜 가능해졌나:
  ├─ BigQuery: 서버리스, 페타바이트급 처리
  ├─ Snowflake: 컴퓨팅-스토리지 분리, 탄력적 확장
  ├─ Redshift: MPP, 컬럼 스토리지
  └─ 스토리지 비용 급감 → 원본 보존 가능

  적재 도구: Fivetran, Airbyte, Stitch
  변환 도구: dbt (Data Build Tool)
```

## 3. dbt (Data Build Tool)

```
dbt의 역할:
  ELT의 "T"를 담당
  SQL SELECT 문으로 변환 로직 작성
  → dbt가 CREATE TABLE/VIEW로 변환하여 실행

  프로젝트 구조:
  models/
  ├── staging/          -- 원본 데이터 정리
  │   ├── stg_orders.sql
  │   └── stg_customers.sql
  ├── intermediate/     -- 중간 변환
  │   └── int_order_items.sql
  └── marts/            -- 최종 비즈니스 테이블
      ├── fct_orders.sql
      └── dim_customers.sql
```

```sql
-- models/staging/stg_orders.sql
WITH source AS (
    SELECT * FROM {{ source('raw', 'orders') }}
)
SELECT
    id AS order_id,
    user_id AS customer_id,
    CAST(created_at AS TIMESTAMP) AS ordered_at,
    status,
    amount
FROM source
WHERE status != 'deleted'  -- 소프트 삭제 필터링

-- models/marts/fct_orders.sql
SELECT
    o.order_id,
    o.customer_id,
    c.customer_segment,
    o.ordered_at,
    o.amount,
    DATE_DIFF(o.ordered_at, c.first_order_at, DAY) AS days_since_first
FROM {{ ref('stg_orders') }} o
JOIN {{ ref('dim_customers') }} c USING (customer_id)
```

> **핵심 직관**: dbt의 혁신은 "데이터 변환을 소프트웨어 엔지니어링처럼" 만든 것입니다. 버전 관리, 테스트, 문서화, CI/CD가 모두 가능합니다. SQL만 알면 데이터 변환 파이프라인을 구축할 수 있습니다.

## 4. 추출 패턴

```
전체 추출 (Full Extract):
  매번 전체 데이터를 추출
  └─ 단순하지만 비효율적
     적합: 작은 테이블, 참조 데이터

증분 추출 (Incremental Extract):
  마지막 추출 이후 변경된 데이터만
  ├─ 타임스탬프 기반: WHERE updated_at > last_run
  ├─ ID 기반: WHERE id > last_max_id
  └─ CDC 기반: 트랜잭션 로그에서 변경 캡처

CDC (Change Data Capture):
  [Source DB] → [WAL/Binlog] → [Debezium] → [Kafka] → [DW]

  장점:
  - 원천 DB 부하 최소
  - 실시간에 가까운 동기화
  - DELETE도 캡처 가능

  Debezium:
  └─ 오픈소스 CDC 플랫폼
     MySQL binlog, PostgreSQL WAL 지원
     Kafka Connect 기반
```

## 5. 적재 패턴

```
적재 전략:

  Truncate + Load (전체 교체):
  └─ 대상 테이블 비우고 전체 적재
     단순하지만 적재 중 데이터 없음

  Append (추가):
  └─ 기존 데이터에 새 데이터만 추가
     이벤트/로그 데이터에 적합

  Upsert (MERGE):
  └─ 키 기준으로 있으면 UPDATE, 없으면 INSERT
     마스터 데이터에 적합

  dbt incremental 모델:
  {{ config(materialized='incremental', unique_key='order_id') }}

  SELECT * FROM {{ ref('stg_orders') }}
  {% if is_incremental() %}
  WHERE ordered_at > (SELECT MAX(ordered_at) FROM {{ this }})
  {% endif %}
```

> **핵심 직관**: 증분 적재에서 가장 흔한 실수는 **"늦게 도착하는 데이터(late-arriving data)"를 놓치는 것**입니다. updated_at 기반 증분 추출 시, 시간 윈도우에 여유를 두거나(overlap) CDC를 사용해야 합니다.

## 6. ETL vs ELT 선택 기준

```
선택 의사결정 트리:

  [클라우드 DW를 사용하는가?]
  ├─ Yes → ELT 우선 고려
  │   ├─ PII 마스킹이 필수? → 추출 단계에서 마스킹 후 ELT
  │   └─ 변환이 매우 복잡? → 일부는 ETL (Python), 나머지 ELT
  │
  └─ No (온프레미스)
      ├─ DW 리소스 충분? → ELT 가능
      └─ DW 리소스 부족? → ETL (별도 서버에서 변환)
```

| 기준 | ETL | ELT |
|------|-----|-----|
| 변환 위치 | 파이프라인 서버 | DW 내부 |
| 원본 보존 | 아니오 | 예 |
| DW 부하 | 낮음 | 높음 |
| 유연성 | 낮음 (재처리 어려움) | 높음 (원본에서 재변환) |
| 도구 | Informatica, Talend | dbt + Fivetran |
| 적합 | 온프레미스, PII 사전처리 | 클라우드, 분석 중심 |

ELT의 적재 단계에서 dp-03의 Kafka가 실시간 소스로, dp-05의 데이터 모델링이 변환 설계의 기반이 됩니다.

## 핵심 정리

- **ETL**은 파이프라인에서 변환, **ELT**는 DW에서 변환하며, 클라우드 DW의 발전으로 ELT가 현대적 표준입니다
- **dbt**는 SQL 기반 변환 도구로 버전 관리, 테스트, 문서화를 지원하며 ELT의 "T"를 담당합니다
- **CDC(Change Data Capture)**는 WAL/Binlog를 읽어 실시간에 가까운 증분 추출을 가능하게 합니다
- **증분 적재**는 Upsert(MERGE)가 기본이며, 늦게 도착하는 데이터에 대한 처리 전략이 필수입니다
- ELT는 원본 데이터를 보존하므로 **변환 로직 변경 시 재처리가 용이**한 것이 가장 큰 장점입니다
