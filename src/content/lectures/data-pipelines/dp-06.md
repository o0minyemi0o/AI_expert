# 데이터 품질과 검증

## 왜 데이터 품질이 중요한가

"Garbage in, garbage out." ML 모델이 아무리 정교해도 입력 데이터가 잘못되면 결과는 쓰레기입니다. dp-05에서 아름답게 설계한 데이터 모델도, 원천 데이터의 품질 문제가 전파되면 무용지물입니다. 데이터 품질 검증은 파이프라인의 **안전망**이며, 문제를 소비자가 발견하기 전에 잡아야 합니다.

> **핵심 직관**: 데이터 품질 문제는 **발견이 늦을수록 비용이 기하급수적으로 증가**합니다. 원천에서 잡으면 수정 1분, 대시보드에서 발견하면 몇 시간, 비즈니스 의사결정 후 발견하면 되돌릴 수 없습니다.

## 1. 데이터 품질의 차원

```
6가지 품질 차원:

  완전성 (Completeness):
  └─ NULL이 허용되지 않는 곳에 NULL이 없는가?
     예: 주문 테이블에 amount가 NULL

  유일성 (Uniqueness):
  └─ 중복 행이 없는가?
     예: 같은 order_id가 2건

  유효성 (Validity):
  └─ 값이 정의된 범위/형식에 맞는가?
     예: age = -5, email = 'not_an_email'

  정확성 (Accuracy):
  └─ 값이 실제 세계를 올바르게 반영하는가?
     예: 실제 가격 10000원인데 1000원으로 기록

  일관성 (Consistency):
  └─ 여러 시스템/테이블 간 값이 일치하는가?
     예: 주문 DB는 100건, DW는 98건

  적시성 (Timeliness):
  └─ 데이터가 예상 시간 내에 도착하는가?
     예: 일일 배치가 3시간 지연
```

## 2. dbt Tests

```
dbt 내장 테스트:

  schema.yml:
  models:
    - name: fct_orders
      columns:
        - name: order_id
          tests:
            - unique        # 유일성
            - not_null      # 완전성
        - name: status
          tests:
            - accepted_values:  # 유효성
                values: ['pending', 'paid', 'shipped', 'cancelled']
        - name: customer_id
          tests:
            - relationships:    # 참조 무결성
                to: ref('dim_customers')
                field: customer_key


커스텀 테스트 (singular test):

  -- tests/assert_positive_amounts.sql
  -- 금액이 음수인 주문이 없어야 함
  SELECT order_id, amount
  FROM {{ ref('fct_orders') }}
  WHERE amount < 0

  -- 결과가 0행이면 통과, 1행 이상이면 실패
```

```
dbt test 실행:

  dbt test                    # 모든 테스트
  dbt test --select fct_orders # 특정 모델만
  dbt test --severity warn    # 경고만 (파이프라인 중단 안 함)

  CI/CD 통합:
  1. PR 생성 → dbt test 자동 실행
  2. 테스트 실패 → PR 머지 차단
  3. 일일 배치 후 → dbt test 실행 → Slack 알림
```

> **핵심 직관**: dbt test의 강점은 **"데이터 변환과 검증이 같은 도구, 같은 코드베이스"**에 있다는 것입니다. 변환 로직을 바꿀 때 관련 테스트도 함께 업데이트되므로, 테스트가 코드와 괴리되지 않습니다.

## 3. Great Expectations

```
Great Expectations:
  Python 기반 데이터 품질 프레임워크
  dbt보다 세밀한 통계적 검증 가능

  Expectation 예시:
  ├─ expect_column_values_to_not_be_null
  ├─ expect_column_values_to_be_between(min=0, max=1000000)
  ├─ expect_column_mean_to_be_between(min=50, max=150)
  ├─ expect_table_row_count_to_be_between(min=1000, max=100000)
  └─ expect_column_proportion_of_unique_values_to_be_between
```

```python
# Great Expectations 기본 사용
import great_expectations as gx

context = gx.get_context()
batch = context.get_batch("orders_dataset")

# 기대치 정의
batch.expect_column_values_to_not_be_null("order_id")
batch.expect_column_values_to_be_between("amount", min_value=0)
batch.expect_table_row_count_to_be_between(min_value=10000)
batch.expect_column_mean_to_be_between(
    "amount", min_value=40, max_value=60  # 평균 금액 범위
)

# 검증 실행
results = batch.validate()
if not results.success:
    alert_slack(results)  # 실패 시 알림
```

## 4. 이상 탐지

```
통계적 이상 탐지:

  일일 주문 수 모니터링:
  평소: 10,000 ± 2,000
  오늘: 2,000 → 이상!

  방법:
  ├─ Z-Score: |x - μ| / σ > 3이면 이상
  │   단점: 정규 분포 가정
  │
  ├─ IQR: Q1 - 1.5*IQR 미만 또는 Q3 + 1.5*IQR 초과
  │   장점: 분포 무관
  │
  └─ 이동 평균 대비: 최근 7일 평균 대비 50% 이상 차이
     가장 실용적, 트렌드 반영

  자동화:
  ├─ 일일 배치 후 주요 지표 자동 검증
  ├─ 임계값 초과 시 Slack/PagerDuty 알림
  └─ 대시보드에 품질 지표 시계열 표시
```

## 5. 데이터 계약 (Data Contract)

```
데이터 계약이란:
  Producer(데이터 생성자)와 Consumer(소비자) 간의
  데이터 스키마, 품질, SLA에 대한 명시적 합의

  문제 상황 (계약 없이):
  백엔드 팀: "status 컬럼에 'active'를 'enabled'로 바꿨어"
  데이터 팀: "... 파이프라인 전부 깨졌는데요?"

  데이터 계약 예시 (YAML):
  contract:
    name: orders
    owner: backend-team
    schema:
      - name: order_id
        type: bigint
        not_null: true
        unique: true
      - name: status
        type: string
        allowed_values: [pending, paid, shipped, cancelled]
      - name: amount
        type: decimal(10,2)
        min: 0
    sla:
      freshness: 1 hour
      row_count_min: 1000
    breaking_changes:
      notification: 7 days advance
      approval: data-team
```

> **핵심 직관**: 데이터 계약은 "**스키마 변경이 하류 파이프라인을 깨뜨리지 않도록**" 하는 조직적 프로세스입니다. 기술적 해결책(스키마 검증)과 조직적 해결책(커뮤니케이션 프로세스)이 함께 필요합니다.

## 6. 품질 모니터링 체계

```
계층별 검증:

  [원천 시스템]
  └─ CDC 스키마 검증, 소스 카운트 비교

  [Bronze → Silver]
  └─ 스키마 일치, NULL 비율, 중복 검사

  [Silver → Gold]
  └─ 비즈니스 규칙, 참조 무결성, 이상 탐지

  [Gold → 소비자]
  └─ SLA (적시성), 행 수 범위, 주요 KPI 범위


  데이터 품질 대시보드:
  ┌──────────────────────────────┐
  │ 데이터 품질 스코어: 97.2%     │
  ├──────────────────────────────┤
  │ ✅ 완전성: 99.8%             │
  │ ✅ 유일성: 100%              │
  │ ⚠️ 적시성: 92% (2건 지연)    │
  │ ✅ 유효성: 99.5%             │
  └──────────────────────────────┘
```

데이터 품질은 dp-07의 스키마 진화에서 호환성 검증으로, dp-11의 거버넌스에서 조직 차원의 품질 관리로 확장됩니다.

## 핵심 정리

- 데이터 품질은 **완전성, 유일성, 유효성, 정확성, 일관성, 적시성** 6가지 차원으로 측정합니다
- **dbt tests**는 변환 코드와 같은 위치에서 관리되어 코드-테스트 괴리를 방지합니다
- **Great Expectations**는 통계적 검증(평균, 분포)까지 지원하여 dbt보다 세밀한 검증이 가능합니다
- **이상 탐지**는 이동 평균 대비 비교가 가장 실용적이며, 자동 알림으로 조기 대응합니다
- **데이터 계약**은 Producer-Consumer 간의 스키마/품질/SLA 합의이며, 스키마 변경 사고를 예방합니다
