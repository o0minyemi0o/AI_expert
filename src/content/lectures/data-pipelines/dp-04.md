# 스트림 처리 엔진

## 왜 스트림 처리 엔진을 이해해야 하는가

dp-03의 Kafka가 "데이터를 흘려보내는 파이프"라면, 스트림 처리 엔진은 "흐르는 데이터 위에서 연산하는 공장"입니다. 5분간의 평균 지표, 세션별 집계, 실시간 이상 탐지 등은 단순히 메시지를 읽는 것으로는 불가능하며, **윈도우 연산, 상태 관리, 시간 의미론**을 다루는 처리 엔진이 필요합니다.

> **핵심 직관**: 스트림 처리에서 가장 어려운 문제는 "시간"입니다. 이벤트가 발생한 시간(Event Time)과 처리 시스템에 도착한 시간(Processing Time)이 다르며, 늦게 도착하는 데이터를 어떻게 처리할지가 핵심 설계 결정입니다.

## 1. Event Time vs Processing Time

```
시간의 두 가지 의미:

  Event Time: 이벤트가 실제 발생한 시간
  Processing Time: 이벤트가 시스템에서 처리되는 시간

  예시: 모바일 앱 사용자 이벤트
  - 14:00:00 이벤트 발생 (Event Time)
  - 14:00:03 서버 도착 (네트워크 지연)
  - 14:00:05 Kafka 도착
  - 14:00:07 Flink에서 처리 (Processing Time)

  왜 중요한가:
  "14:00~14:05의 클릭 수"를 계산할 때
  ├─ Processing Time 기준: 도착 순서 → 부정확
  └─ Event Time 기준: 발생 순서 → 정확
     ⚠️ 14:05 이후에 도착하는 14:03 이벤트는?
```

## 2. 윈도우 연산

```
윈도우 종류:

  Tumbling Window (고정 윈도우):
  |──5분──|──5분──|──5분──|
  겹치지 않는 고정 크기 윈도우
  예: 5분마다 평균 트래픽

  Sliding Window (슬라이딩 윈도우):
  |──5분──|
     |──5분──|
        |──5분──|
  겹치는 윈도우 (크기 5분, 간격 1분)
  예: 최근 5분간 이동 평균

  Session Window (세션 윈도우):
  |──세션1──|  gap  |──세션2──|
  비활동 기간(gap)으로 구분
  예: 사용자 세션별 활동 집계 (gap=30분)

  Global Window:
  |────────── 전체 스트림 ──────────|
  트리거로 결과 출력 시점 결정
```

```python
# Flink (PyFlink) 윈도우 예시
from pyflink.table import TumbleWindow

result = (
    events_table
    .window(
        TumbleWindow.over(lit(5).minutes)
        .on(col("event_time"))
        .alias("w")
    )
    .group_by(col("w"), col("user_id"))
    .select(
        col("w").start.alias("window_start"),
        col("user_id"),
        col("amount").sum.alias("total")
    )
)
```

## 3. 워터마크 (Watermark)

```
문제: 윈도우를 언제 닫을 것인가?

  14:00~14:05 윈도우:
  14:05가 되었을 때 바로 닫으면?
  → 14:04에 발생했지만 14:06에 도착하는 이벤트를 놓침!

워터마크:
  "이 시점 이전의 모든 이벤트가 도착했다"는 선언

  Watermark(T) = max_event_time - allowed_lateness

  예: allowed_lateness = 10초
  현재 max event time = 14:05:30
  Watermark = 14:05:20
  → "14:05:20 이전 이벤트는 모두 도착했다고 간주"

  워터마크가 윈도우 끝을 넘으면 윈도우 트리거:
  14:00~14:05 윈도우:
  Watermark가 14:05:00을 넘으면 결과 출력

  늦게 도착한 데이터 (Late Data):
  Watermark 이후에 도착한 이벤트
  ├─ 무시 (Drop): 가장 단순
  ├─ 별도 처리: Side Output으로 분리
  └─ 윈도우 갱신: Allowed Lateness로 재계산
```

> **핵심 직관**: 워터마크의 지연 허용(allowed lateness)이 크면 정확하지만 결과가 늦게 나오고, 작으면 빠르지만 데이터를 놓칩니다. **"정확성 vs 지연시간"의 트레이드오프**이며, 비즈니스 요구에 따라 조정합니다.

## 4. Apache Flink

```
Flink 아키텍처:

  [JobManager]          ← 작업 조율, 체크포인트 관리
       │
  ┌────┼────┐
  │    │    │
  [TM1][TM2][TM3]      ← TaskManager (실행)
  각 TM은 여러 Task Slot 보유

  핵심 특성:
  - Event Time 처리 네이티브 지원
  - Exactly-once 상태 관리 (Checkpoint)
  - 밀리초 단위 지연시간
  - 대규모 상태 관리 (TB급)

  상태 관리 (State):
  ├─ Keyed State: 키별로 관리 (예: user_id별 카운트)
  ├─ Operator State: 오퍼레이터별 (예: Kafka offset)
  └─ State Backend:
      ├─ HashMapStateBackend: 메모리 (빠름, 크기 제한)
      └─ RocksDBStateBackend: 디스크 (느림, 대용량)
```

## 5. Spark Structured Streaming

```
Spark Structured Streaming:

  배치 Spark와 동일한 DataFrame API
  "마이크로 배치"로 스트림 처리

  동작:
  [Kafka] → [마이크로 배치 1 (100ms)] → [출력]
          → [마이크로 배치 2 (100ms)] → [출력]
          → ...

  장점:
  - 배치와 동일한 API → 학습 비용 낮음
  - 배치/스트림 통합 코드
  - Spark 에코시스템 (ML, SQL) 활용

  단점:
  - 마이크로 배치 → 지연 100ms~수 초
  - Flink보다 상태 관리 제한적
```

```python
# Spark Structured Streaming 예시
from pyspark.sql.functions import window

orders = (
    spark.readStream
    .format("kafka")
    .option("subscribe", "orders")
    .load()
    .select(from_json(col("value").cast("string"), schema).alias("data"))
    .select("data.*")
)

# 5분 텀블링 윈도우 집계
windowed = (
    orders
    .withWatermark("event_time", "10 seconds")
    .groupBy(window("event_time", "5 minutes"), "category")
    .agg(sum("amount").alias("total"))
)

windowed.writeStream.format("console").start()
```

## 6. Flink vs Spark Streaming 선택

| 특성 | Flink | Spark Streaming |
|------|-------|-----------------|
| 처리 모델 | 진정한 스트림 | 마이크로 배치 |
| 지연시간 | ~ms | ~100ms~수 초 |
| 상태 관리 | TB급, RocksDB | GB급, 메모리 |
| Event Time | 네이티브 | 지원 |
| API 난이도 | 중간 | 낮음 (배치와 동일) |
| 배치 겸용 | 가능하지만 Spark보다 약함 | 강력 |
| 적합 | 실시간 사기 탐지, CEP | 준실시간 분석, ML |

> **핵심 직관**: "실시간"의 정의가 ms냐 초냐에 따라 선택이 달라집니다. **밀리초 단위 반응이 필요하면 Flink**, **초 단위 준실시간이면 Spark Streaming**이 적합합니다. 이미 Spark를 사용 중이라면 Spark Streaming이 운영 비용 면에서 유리합니다.

스트림 처리의 결과는 dp-05의 데이터 모델로 적재되고, dp-06의 실시간 데이터 품질 검증과 연결됩니다.

## 핵심 정리

- **Event Time**은 이벤트 발생 시간으로 정확한 분석의 기반이며, Processing Time과의 차이가 스트림 처리의 핵심 복잡성입니다
- **윈도우**(Tumbling, Sliding, Session)로 무한 스트림을 유한 구간으로 분할하여 집계합니다
- **워터마크**는 "이 시점 이전 데이터는 모두 도착했다"는 선언이며, 정확성과 지연시간의 트레이드오프입니다
- **Flink**는 진정한 스트림 처리와 대규모 상태 관리에, **Spark Streaming**은 배치 겸용과 에코시스템에 강합니다
- Exactly-once는 **체크포인트 + 멱등한 출력**으로 달성하며, 외부 시스템까지 포함하면 end-to-end 설계가 필요합니다
