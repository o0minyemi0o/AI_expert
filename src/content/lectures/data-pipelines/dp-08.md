# 오케스트레이션

## 왜 오케스트레이션이 중요한가

데이터 파이프라인은 하나의 작업이 아닙니다. "원천 추출 → 클렌징 → 모델링 → 품질 검증 → 대시보드 갱신"이라는 **의존성 체인**입니다. dp-02의 배치 처리가 "무엇을 실행할지"라면, 오케스트레이션은 "**언제, 어떤 순서로, 실패 시 어떻게** 실행할지"를 관리합니다. Apache Airflow가 사실상 업계 표준입니다.

> **핵심 직관**: 오케스트레이션은 "cron의 진화형"입니다. cron은 시간에 따라 실행만 하지만, 오케스트레이터는 **의존성, 재시도, 백필, 모니터링, 알림**까지 처리합니다.

## 1. Apache Airflow

```
Airflow 핵심 개념:

  DAG (Directed Acyclic Graph):
  └─ 작업(Task)과 의존성의 방향 그래프

  extract_orders → transform_orders → load_orders
                                           ↓
  extract_customers → transform_customers → build_mart
                                           ↓
                                      run_dbt_tests

  주요 구성 요소:
  ├─ Scheduler: DAG를 파싱하고 실행 시점 결정
  ├─ Worker: Task를 실제 실행
  ├─ Metadata DB: DAG 실행 이력 (PostgreSQL)
  ├─ Web UI: 모니터링, 수동 트리거
  └─ Executor: 실행 방식 결정
      ├─ LocalExecutor: 단일 머신
      ├─ CeleryExecutor: 분산 Worker
      └─ KubernetesExecutor: K8s Pod에서 실행
```

```python
# Airflow DAG 예시
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.dbt.cloud.operators.dbt import DbtCloudRunJobOperator
from datetime import datetime, timedelta

default_args = {
    'retries': 2,
    'retry_delay': timedelta(minutes=5),
    'on_failure_callback': slack_alert,
}

with DAG(
    'daily_pipeline',
    schedule='0 2 * * *',  # 매일 02:00 UTC
    start_date=datetime(2024, 1, 1),
    catchup=False,  # 과거 미실행 DAG를 자동 실행하지 않음
    default_args=default_args,
) as dag:

    extract = PythonOperator(
        task_id='extract_orders',
        python_callable=extract_from_source,
    )
    transform = DbtCloudRunJobOperator(
        task_id='run_dbt',
        job_id=12345,
    )
    test = DbtCloudRunJobOperator(
        task_id='run_dbt_tests',
        job_id=12346,
    )

    extract >> transform >> test
```

## 2. DAG 설계 패턴

```
패턴 1: 추출 → 변환 → 검증 → 적재

  extract_* → staging_* → transform_* → test_* → publish_*

  각 단계가 실패하면 이후 단계 중단
  dp-06의 dbt test가 test_* 단계


패턴 2: 센서(Sensor)로 외부 이벤트 대기

  S3FileSensor(bucket='raw', prefix='orders/2024-01-15/')
  → 파일이 도착할 때까지 대기
  → 도착하면 하류 Task 트리거

  문제: Sensor가 Worker slot을 점유
  해결: Deferrable Operator (비동기 대기)


패턴 3: 동적 DAG (Dynamic Task Mapping)

  # 테이블 목록을 동적으로 가져와 병렬 처리
  @task
  def get_tables():
      return ['orders', 'customers', 'products']

  @task
  def process_table(table_name):
      run_dbt_model(table_name)

  tables = get_tables()
  process_table.expand(table_name=tables)
  # → 3개 Task가 동적으로 생성/병렬 실행
```

> **핵심 직관**: Airflow DAG는 **"데이터 파이프라인의 설계도"**입니다. DAG를 보면 파이프라인의 전체 흐름, 의존성, 병렬 처리 가능 구간을 한눈에 파악할 수 있습니다. 잘 설계된 DAG는 문서화 없이도 자기 설명적입니다.

## 3. 백필과 재처리

```
백필 (Backfill):
  과거 날짜의 파이프라인을 소급 실행

  상황: 2024-01-15에 변환 로직 버그 발견
       2024-01-01 ~ 2024-01-14 데이터 재처리 필요

  Airflow에서:
  airflow dags backfill daily_pipeline \
      --start-date 2024-01-01 \
      --end-date 2024-01-14

  핵심 전제:
  ├─ 멱등성: 같은 날짜를 여러 번 실행해도 같은 결과
  ├─ 날짜 파라미터화: {{ ds }}, {{ execution_date }}
  └─ 파티션 단위 덮어쓰기: OVERWRITE PARTITION

  예시:
  output_path = f"s3://data/orders/date={ds}/"
  # ds = '2024-01-01' → 해당 날짜 파티션만 덮어쓰기
```

```python
# 날짜 파라미터화로 멱등성 보장
@task
def extract_orders(**context):
    ds = context['ds']  # '2024-01-15'
    query = f"""
        SELECT * FROM orders
        WHERE DATE(created_at) = '{ds}'
    """
    df = run_query(query)
    df.to_parquet(f"s3://raw/orders/date={ds}/data.parquet")
```

## 4. 재시도와 에러 핸들링

```
재시도 전략:

  default_args = {
      'retries': 3,
      'retry_delay': timedelta(minutes=5),
      'retry_exponential_backoff': True,  # 5분 → 10분 → 20분
      'max_retry_delay': timedelta(hours=1),
  }

  Task별 재시도:
  extract_api = PythonOperator(
      task_id='extract_api',
      retries=5,              # API는 재시도 많이
      retry_delay=timedelta(seconds=30),
  )
  run_dbt = DbtOperator(
      task_id='run_dbt',
      retries=1,              # 변환은 적게
  )


  알림 설정:
  ├─ on_failure_callback: Task 실패 시
  ├─ on_retry_callback: 재시도 시
  ├─ sla_miss_callback: SLA 초과 시
  └─ dagrun_timeout: DAG 전체 타임아웃

  SLA (Service Level Agreement):
  └─ "이 Task는 30분 내에 완료되어야 함"
     초과 시 알림 → 병목 조기 발견
```

## 5. Dagster와 Prefect

```
차세대 오케스트레이터:

  Dagster:
  ├─ Asset 중심 (데이터 자산 기반)
  │   @asset
  │   def orders_silver(orders_bronze):
  │       return clean(orders_bronze)
  │   # 의존성이 자동으로 DAG 형성
  │
  ├─ 타입 시스템: 입출력 타입 검증
  ├─ 소프트웨어 정의 자산 (Software-Defined Assets)
  └─ 개발 경험 우수 (로컬 테스트 쉬움)


  Prefect:
  ├─ 코드 우선 (순수 Python, 데코레이터 기반)
  │   @flow
  │   def daily_pipeline():
  │       data = extract()
  │       cleaned = transform(data)
  │       load(cleaned)
  │
  ├─ 동적 워크플로: 런타임에 Task 생성
  ├─ 클라우드 네이티브 (Prefect Cloud)
  └─ 학습 곡선 낮음
```

| 특성 | Airflow | Dagster | Prefect |
|------|---------|---------|---------|
| 철학 | DAG 중심 | Asset 중심 | 코드 중심 |
| 학습 곡선 | 중간 | 중간 | 낮음 |
| 에코시스템 | 가장 큼 | 성장 중 | 성장 중 |
| 로컬 테스트 | 어려움 | 쉬움 | 쉬움 |
| 적합 | 대규모 팀 | 데이터 자산 관리 | 빠른 시작 |

> **핵심 직관**: Airflow는 "오케스트레이션의 PostgreSQL"입니다. 완벽하지 않지만, 에코시스템이 압도적이고 대부분의 문제에 대한 해결책이 존재합니다. **새 프로젝트에서도 Airflow가 안전한 선택**이며, Dagster는 데이터 자산 관리가 핵심인 팀에게 점점 더 좋은 대안이 되고 있습니다.

## 6. 실전 운영 팁

```
Airflow 운영 핵심:

  1. DAG 파일은 Git으로 관리 (CI/CD)
  2. 환경 분리: dev → staging → production
  3. Variable/Connection은 Secrets Manager 연동
  4. 무거운 작업은 Airflow 외부에서 실행
     Airflow → Spark submit → Spark 클러스터
     Airflow → K8s Job → 별도 Pod
  5. XCom 남용 금지 (메타데이터 DB에 저장됨)
     큰 데이터는 S3 경로만 전달
```

오케스트레이션은 dp-02의 배치 처리, dp-04의 스트림 처리를 스케줄링하고, dp-12의 종합 설계에서 전체 파이프라인을 엮는 접착제입니다.

## 핵심 정리

- **Airflow**는 DAG 기반 오케스트레이터의 사실상 표준이며, 의존성/재시도/모니터링을 통합 관리합니다
- **백필**은 과거 데이터를 소급 재처리하는 기능이며, **멱등성**과 날짜 파라미터화가 전제 조건입니다
- **재시도**는 지수 백오프가 기본이며, API 호출은 많이, 변환은 적게 재시도하는 것이 일반적입니다
- **Dagster**는 Asset 중심, **Prefect**는 코드 중심의 차세대 오케스트레이터이며, Airflow 대안으로 성장 중입니다
- 무거운 작업은 Airflow Worker가 아닌 **외부 시스템(Spark, K8s)에서 실행**하고, Airflow는 트리거만 담당해야 합니다
