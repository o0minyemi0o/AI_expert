# 스트림 처리 기초

## 왜 스트림 처리를 이해해야 하는가

dp-02의 배치 처리는 "하루치 데이터를 모아서 처리"합니다. 하지만 사기 탐지, 실시간 추천, 모니터링 알림처럼 **데이터가 발생하는 즉시 처리**해야 하는 경우가 있습니다. Apache Kafka는 이 실시간 데이터 흐름의 중심축이며, 현대 데이터 아키텍처에서 가장 중요한 인프라 중 하나입니다.

> **핵심 직관**: 배치와 스트림의 차이는 "경계가 있느냐 없느냐"입니다. 배치는 정해진 범위의 데이터를 처리하고, 스트림은 끝없이 흐르는 데이터를 처리합니다. Kafka는 이 무한한 흐름을 안정적으로 전달하는 파이프입니다.

## 1. 메시지 큐 vs 이벤트 스트림

```
메시지 큐 (RabbitMQ, SQS):

  Producer → [Queue] → Consumer
  - 메시지가 소비되면 큐에서 삭제
  - 1:1 전달 (하나의 Consumer만 처리)
  - 적합: 작업 분배 (Task Queue)


이벤트 스트림 (Kafka):

  Producer → [Topic/Partition] → Consumer Group A
                                → Consumer Group B
                                → Consumer Group C

  - 메시지가 소비 후에도 보존 (retention 기간)
  - 여러 Consumer Group이 독립적으로 읽기
  - 재처리 가능 (offset 되감기)
  - 적합: 이벤트 소싱, 실시간 분석, CDC
```

| 특성 | 메시지 큐 | 이벤트 스트림 |
|------|----------|-------------|
| 소비 후 | 삭제 | 보존 |
| 다중 소비자 | 경쟁 소비 | 독립 소비 |
| 재처리 | 불가 | 가능 |
| 순서 보장 | 큐 전체 | 파티션 내 |
| 대표 | RabbitMQ, SQS | Kafka, Pulsar |

## 2. Kafka 아키텍처

```
Kafka 클러스터 구조:

  ┌─────────────────────────────────────┐
  │ Kafka Cluster                       │
  │                                     │
  │ Topic: orders                       │
  │ ├─ Partition 0: [msg1][msg2][msg3]  │
  │ ├─ Partition 1: [msg4][msg5]        │
  │ └─ Partition 2: [msg6][msg7][msg8]  │
  │                                     │
  │ Broker 1: P0(leader), P1(replica)   │
  │ Broker 2: P1(leader), P2(replica)   │
  │ Broker 3: P2(leader), P0(replica)   │
  └─────────────────────────────────────┘

  핵심 개념:
  - Topic: 메시지의 카테고리 (테이블과 유사)
  - Partition: Topic의 분할 단위 (병렬 처리)
  - Broker: Kafka 서버 노드
  - Offset: 파티션 내 메시지의 순서 번호

  파티셔닝 키:
  └─ 같은 키 → 같은 파티션 → 순서 보장
     예: user_id가 키 → 같은 사용자의 이벤트 순서 보장
```

## 3. Producer와 Consumer

```python
# Producer 예시
from confluent_kafka import Producer

producer = Producer({'bootstrap.servers': 'kafka:9092'})

# 키 기반 파티셔닝: 같은 user_id는 같은 파티션으로
producer.produce(
    topic='orders',
    key=str(user_id).encode(),
    value=json.dumps(order_event).encode()
)
producer.flush()
```

```python
# Consumer Group 예시
from confluent_kafka import Consumer

consumer = Consumer({
    'bootstrap.servers': 'kafka:9092',
    'group.id': 'order-processor',
    'auto.offset.reset': 'earliest'
})
consumer.subscribe(['orders'])

while True:
    msg = consumer.poll(1.0)
    if msg is None:
        continue
    process_order(json.loads(msg.value()))
    consumer.commit()  # offset 커밋
```

```
Consumer Group과 파티션 할당:

  Topic: orders (3 partitions)

  Consumer Group "analytics" (3 consumers):
  Consumer A → Partition 0
  Consumer B → Partition 1
  Consumer C → Partition 2

  Consumer Group "notification" (2 consumers):
  Consumer X → Partition 0, 1
  Consumer Y → Partition 2

  규칙:
  - 파티션 수 >= Consumer 수 (초과 Consumer는 유휴)
  - 같은 그룹 내에서 파티션은 하나의 Consumer만 처리
  - Consumer 장애 시 자동 리밸런싱
```

> **핵심 직관**: Kafka의 병렬 처리 단위는 **파티션**입니다. 파티션 수가 Consumer 수의 상한이며, 처리량을 늘리려면 파티션 수를 늘려야 합니다. 단, 파티션 수를 줄이는 것은 불가능하므로 처음에 신중하게 결정해야 합니다.

## 4. 메시지 보장 수준

```
전달 보장 (Delivery Guarantee):

  At-most-once (최대 한 번):
  └─ 메시지 유실 가능, 중복 없음
     Consumer가 처리 전에 offset 커밋
     처리 중 실패 → 메시지 건너뜀

  At-least-once (최소 한 번):
  └─ 메시지 유실 없음, 중복 가능
     Consumer가 처리 후에 offset 커밋
     커밋 전 실패 → 재처리 (중복!)

  Exactly-once (정확히 한 번):
  └─ 유실도 중복도 없음
     Kafka: Idempotent Producer + Transactional API
     ⚠️ Kafka 내부에서만 보장, 외부 시스템은 별도 처리 필요


  실무 선택:
  ├─ 대부분: At-least-once + 멱등한 처리
  │   중복이 와도 결과가 같으면 OK
  │   예: UPSERT, dedupliation 테이블
  │
  └─ 금융/결제: Exactly-once 필수
      Kafka Transactions + 외부 시스템 멱등성
```

## 5. 이벤트 소싱

```
전통적 CRUD:

  [주문 생성] → DB: {id:1, status:"pending", amount:100}
  [결제 완료] → DB: {id:1, status:"paid", amount:100}
  [배송 시작] → DB: {id:1, status:"shipped", amount:100}

  → 현재 상태만 저장, 히스토리 없음


이벤트 소싱 (Event Sourcing):

  이벤트 로그 (Kafka):
  [OrderCreated {id:1, amount:100}]
  [PaymentCompleted {id:1}]
  [ShipmentStarted {id:1, tracking:"ABC"}]

  현재 상태 = 이벤트를 처음부터 재생한 결과

  장점:
  - 완전한 감사 추적 (Audit Trail)
  - 시점 복원 (Time Travel)
  - 이벤트 기반 아키텍처와 자연스러운 결합

  단점:
  - 이벤트 스키마 관리 복잡 (dp-07)
  - 현재 상태 조회에 Materialized View 필요
  - 이벤트 수정 불가 (보상 이벤트로 처리)
```

> **핵심 직관**: 이벤트 소싱에서 Kafka는 "진실의 원천(Source of Truth)"입니다. DB의 테이블은 이벤트 스트림의 **물화된 뷰(Materialized View)**일 뿐입니다. 이 관점의 전환이 이벤트 기반 아키텍처의 핵심입니다.

## 6. Kafka 운영 핵심

```
핵심 설정:

  Topic 설정:
  ├─ retention.ms: 메시지 보존 기간 (기본 7일)
  ├─ partitions: 파티션 수 (변경 시 키 재분배!)
  └─ replication.factor: 복제본 수 (최소 3 권장)

  Producer 설정:
  ├─ acks=all: 모든 복제본 확인 후 응답 (안전)
  ├─ acks=1: Leader만 확인 (빠름)
  └─ acks=0: 확인 안 함 (가장 빠름, 유실 가능)

  Consumer 설정:
  ├─ auto.offset.reset: earliest/latest
  └─ enable.auto.commit: false (수동 커밋 권장)


  모니터링 지표:
  ├─ Consumer Lag: 처리되지 않은 메시지 수
  │   → Lag이 계속 증가하면 처리량 부족
  ├─ Under-replicated Partitions: 복제 지연
  └─ Broker Disk Usage: 디스크 사용량
```

Kafka의 스트림 데이터는 dp-04의 Flink/Spark Streaming에서 처리되고, dp-08의 Airflow에서 트리거됩니다.

## 핵심 정리

- **Kafka**는 이벤트 스트림 플랫폼으로, 소비 후에도 메시지를 보존하여 재처리와 다중 소비가 가능합니다
- **파티션**이 병렬 처리의 단위이며, 같은 키는 같은 파티션으로 보내 순서를 보장합니다
- 실무에서는 **At-least-once + 멱등한 처리**가 가장 실용적인 메시지 보장 전략입니다
- **이벤트 소싱**은 상태 대신 이벤트를 저장하며, Kafka를 진실의 원천으로 사용합니다
- Consumer Lag 모니터링이 운영의 핵심이며, Lag 증가는 처리량 확장(파티션/Consumer 추가)이 필요하다는 신호입니다
