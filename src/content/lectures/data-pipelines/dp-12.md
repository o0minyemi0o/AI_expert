# 실전 파이프라인 설계

## 왜 종합 설계 연습이 필요한가

dp-01~11까지 개별 기술을 배웠습니다. 하지만 실전에서는 "ETL을 쓸까 ELT를 쓸까"가 아니라 "**이 비즈니스 요구사항에 어떤 아키텍처가 최적인가**"를 종합적으로 판단해야 합니다. 이 강의에서는 실제 시나리오를 통해 dp 과정 전체를 관통하는 설계 사고를 연습합니다.

> **핵심 직관**: 좋은 파이프라인 설계는 "가장 멋진 기술"이 아니라 "**가장 단순한 해결책**"을 선택하는 것입니다. Kafka + Flink + Iceberg가 항상 답은 아닙니다. cron + dbt + PostgreSQL로 충분한 경우가 훨씬 많습니다.

## 1. 시나리오 1: 이커머스 분석 플랫폼

```
요구사항:
  - 일일 매출, 주간 코호트, 월간 리텐션 리포트
  - 데이터 소스: PostgreSQL (주문, 고객, 상품)
  - 사용자: 비즈니스 분석가 10명
  - 데이터 규모: 일 50만 건 주문

아키텍처 선택:

  [PostgreSQL] → [Airbyte] → [BigQuery] → [dbt] → [Looker]
                  (추출)      (적재)      (변환)   (시각화)

  결정 근거:
  ├─ ELT (dp-01): 클라우드 DW 사용 → ELT 자연스러움
  ├─ 배치 (dp-02): 일일 리포트 → 배치 충분
  ├─ 스트림 불필요: 실시간 요구 없음
  ├─ dbt (dp-01): SQL 변환, 테스트, 문서화
  ├─ 스타 스키마 (dp-05): fct_orders + dim_*
  └─ Airflow (dp-08): 일일 스케줄링

  스케줄:
  02:00 Airbyte 동기화 (전체/증분)
  03:00 dbt run (Bronze → Silver → Gold)
  03:30 dbt test (dp-06)
  04:00 Looker 캐시 갱신

  비용: ~$500/월 (Airbyte + BigQuery + Looker)
```

## 2. 시나리오 2: 실시간 사기 탐지

```
요구사항:
  - 결제 이벤트 발생 후 500ms 내 사기 점수 반환
  - 피처: 최근 1시간 거래 횟수, 평균 금액, 위치 변화
  - 데이터 규모: 초당 10,000 결제

아키텍처 선택:

  [결제 서비스] → [Kafka] → [Flink] → [Redis]
                                         ↓
  [결제 API] ← [모델 서빙] ← [피처 조회 (Redis + 배치)]

  결정 근거:
  ├─ 스트림 (dp-03/04): 실시간 필수 → Kafka + Flink
  ├─ Flink (dp-04): ms 지연, 대규모 상태 관리
  ├─ 피처 스토어 (dp-10):
  │   실시간 피처 (1시간 거래): Flink → Redis
  │   배치 피처 (30일 평균): Spark → Redis
  ├─ 워터마크 (dp-04): 10초 허용 (늦은 이벤트)
  └─ At-least-once + 멱등 (dp-03): Redis UPSERT

  핵심 트레이드오프:
  ├─ 정확성 vs 지연: 더 긴 워터마크 = 더 정확, 더 느림
  └─ 비용 vs 성능: Flink 클러스터 24/7 운영 비용
```

## 3. 시나리오 3: ML 피처 플랫폼

```
요구사항:
  - 5개 ML 팀이 공유하는 피처 인프라
  - 학습 데이터: 과거 2년, 시점 정합성 보장
  - 서빙: p99 지연 10ms 이내
  - 피처 수: 500+, 매주 10개 추가

아키텍처 선택:

  [DW/Lake] → [Spark 배치] → [Feast 오프라인] → 학습
  [Kafka]   → [Flink]      → [Feast 온라인]  → 서빙

  결정 근거:
  ├─ Feast (dp-10): 오픈소스, 온/오프라인 통합
  ├─ Point-in-Time Join (dp-10): 학습 시 필수
  ├─ 레이크하우스 (dp-09): Iceberg로 피처 히스토리 저장
  ├─ 거버넌스 (dp-11): 피처 카탈로그, 소유권, PII 관리
  └─ 스키마 진화 (dp-07): 피처 추가/수정 호환성

  운영:
  ├─ Airflow (dp-08): 일일 피처 계산 스케줄
  ├─ dbt test (dp-06): 피처 품질 검증
  ├─ Feature Freshness 모니터링
  └─ A/B 테스트: 피처 버전별 모델 성능 비교
```

> **핵심 직관**: ML 피처 플랫폼의 성공은 기술보다 **조직**에 달려 있습니다. 피처 소유권, 리뷰 프로세스, 문서화 문화가 없으면 결국 "피처 스웜프(Feature Swamp)"가 됩니다.

## 4. 장애 대응 패턴

```
장애 유형별 대응:

  1. 원천 시스템 장애 (DB 다운):
     → 재시도 + 백오프 (dp-08)
     → Dead Letter Queue에 실패 이벤트 저장
     → 복구 후 백필 (dp-08)

  2. 스키마 변경 (breaking change):
     → Schema Registry가 차단 (dp-07)
     → 하류 영향 분석 (dp-11 리니지)
     → 마이그레이션 계획 수립

  3. 데이터 품질 이슈 (이상치, NULL 급증):
     → dbt test / Great Expectations 감지 (dp-06)
     → 파이프라인 중단 or 경고
     → 원인 분석 → 수정 → 백필

  4. 처리 지연 (Kafka Lag 증가):
     → Consumer 스케일 아웃 (dp-03)
     → 파티션 수 증가 (주의: 키 재분배)
     → 백프레셔: Producer 속도 제한

  5. 저장소 장애 (S3 일시 불가):
     → 쓰기 재시도 + 멱등성 보장
     → 로컬 버퍼에 임시 저장
     → 복구 후 플러시

  핵심 원칙: 멱등성 + 백필 가능 = 대부분의 장애 복구 가능
```

## 5. 비용 최적화

```
비용 구성:

  컴퓨팅:
  ├─ Spark 클러스터: 사용 시간 기반
  │   → Spot Instance 활용 (60-80% 절감)
  │   → 오토스케일링: 배치 시간에만 확장
  ├─ Flink: 24/7 운영
  │   → 최소 인스턴스로 유지, 피크 시 확장
  └─ DW 쿼리: 스캔 데이터 양 기반 (BigQuery)
     → 파티셔닝으로 스캔 범위 최소화

  스토리지:
  ├─ Hot: S3 Standard ($0.023/GB)
  ├─ Warm: S3 IA ($0.0125/GB)
  ├─ Cold: S3 Glacier ($0.004/GB)
  └─ 라이프사이클 정책으로 자동 전환

  데이터 전송:
  ├─ 같은 리전: 무료
  ├─ 리전 간: $0.02/GB
  └─ 가능하면 같은 리전에 배치

  최적화 우선순위:
  1. 불필요한 데이터 제거 (가장 효과 큼)
  2. 파티셔닝/프루닝 (DW 쿼리 비용)
  3. 압축 + 컬럼 포맷 (스토리지)
  4. 스케줄 최적화 (컴퓨팅)
```

## 6. 아키텍처 의사결정 프레임워크

```
파이프라인 설계 의사결정 트리:

  [데이터 규모는?]
  ├─ < 1GB/일 → PostgreSQL + cron + dbt
  ├─ 1-100GB/일 → Cloud DW + Airflow + dbt
  └─ > 100GB/일 → Spark + 레이크하우스

  [지연 요구사항은?]
  ├─ 일/시간 → 배치 (Spark/dbt)
  ├─ 분 → 마이크로 배치 (Spark Streaming)
  └─ 초/ms → 스트림 (Flink + Kafka)

  [팀 규모와 역량은?]
  ├─ 1-3명 → 관리형 서비스 (Fivetran + dbt Cloud + BigQuery)
  ├─ 5-10명 → 오픈소스 + 클라우드 (Airflow + Spark + Iceberg)
  └─ 10+명 → 플랫폼 팀 + 셀프서비스

  [예산은?]
  ├─ 최소 → 오픈소스 위주
  ├─ 중간 → 하이브리드 (핵심만 관리형)
  └─ 충분 → 완전 관리형 (운영 비용 절감)
```

> **핵심 직관**: **가장 흔한 실수는 오버엔지니어링**입니다. "우리도 Netflix처럼 Kafka + Flink 써야 하지 않나?"라는 유혹을 뿌리치고, 현재 규모와 요구사항에 맞는 가장 단순한 아키텍처를 선택해야 합니다. 복잡성은 필요할 때 점진적으로 추가할 수 있지만, 제거하기는 매우 어렵습니다.

이 강의는 dp-01~11의 모든 개념을 종합하며, 실전 인터뷰에서 시스템 설계 질문의 데이터 파이프라인 파트에 직접 활용됩니다.

## 핵심 정리

- 좋은 파이프라인 설계는 가장 멋진 기술이 아니라 **가장 단순한 해결책**을 선택하는 것입니다
- 대부분의 분석 파이프라인은 **Airbyte + dbt + Cloud DW**로 충분하며, 복잡성은 필요할 때 추가합니다
- **장애 복구의 핵심은 멱등성 + 백필**이며, 이 두 가지가 보장되면 대부분의 장애에서 복구 가능합니다
- 비용 최적화는 **불필요한 데이터 제거 → 파티셔닝 → 압축 → 스케줄 순서**로 접근합니다
- 팀 규모, 예산, 지연 요구사항을 기준으로 아키텍처를 선택하며, **오버엔지니어링이 가장 흔한 실수**입니다
