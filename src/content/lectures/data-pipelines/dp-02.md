# 배치 처리 아키텍처

## 왜 배치 처리를 이해해야 하는가

스트리밍이 아무리 인기를 얻어도, 전체 데이터 처리량의 **80% 이상은 여전히 배치**입니다. 일일 집계, 모델 학습, 대규모 ETL 모두 배치 처리입니다. MapReduce에서 Spark로의 진화를 이해하면 분산 처리의 핵심 원리—파티셔닝, 셔플, 내결함성—를 자연스럽게 파악할 수 있습니다.

> **핵심 직관**: 배치 처리의 핵심은 "데이터를 쪼개서 병렬로 처리하고, 결과를 합치는 것"입니다. 성능은 쪼개는 방식(파티셔닝)과 합치는 비용(셔플)에 의해 결정됩니다.

## 1. MapReduce 패러다임

```
MapReduce 동작:

  입력 데이터 (HDFS)
  ┌──────┬──────┬──────┐
  │Split1│Split2│Split3│
  └──┬───┴──┬───┴──┬───┘
     │      │      │
  [Map 1] [Map 2] [Map 3]    ← 각 Split에 함수 적용
     │      │      │
  ── Shuffle & Sort ──        ← 같은 키끼리 모음
     │      │
  [Reduce1] [Reduce2]         ← 키별 집계
     │      │
  ┌──┴──┬───┴──┐
  │Out 1│Out 2 │
  └─────┴──────┘


  Word Count 예시:
  Map("hello world hello") → [(hello,1), (world,1), (hello,1)]
  Shuffle → hello: [1,1], world: [1]
  Reduce → [(hello,2), (world,1)]

  한계:
  - 매 단계마다 디스크에 기록 → 느림
  - 반복 작업(ML 학습)에 비효율적
  - Java 코드가 장황함
```

## 2. Apache Spark

```
Spark가 MapReduce를 대체한 이유:

  MapReduce:
  [Disk] → Map → [Disk] → Reduce → [Disk]
  매 단계 디스크 I/O → 느림

  Spark:
  [Disk] → 메모리에 올림 → 연산1 → 연산2 → ... → [Disk]
  중간 결과를 메모리에 유지 → 10-100배 빠름

  Spark 아키텍처:
  ┌─────────────────────────────┐
  │ Driver Program              │
  │ (SparkContext, DAG 생성)     │
  └──────────┬──────────────────┘
             │
  ┌──────────┼──────────┐
  │          │          │
  [Executor] [Executor] [Executor]
  (Worker 1) (Worker 2) (Worker 3)
  │ Task 1  │ Task 2   │ Task 3
  │ Task 4  │ Task 5   │ Task 6
```

```python
# Spark 기본 예시
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("example").getOrCreate()

# 일일 매출 집계
orders = spark.read.parquet("s3://data/orders/")
daily_revenue = (
    orders
    .filter(col("status") == "completed")
    .groupBy(date_trunc("day", col("created_at")).alias("date"))
    .agg(sum("amount").alias("revenue"), count("*").alias("orders"))
    .orderBy("date")
)
daily_revenue.write.parquet("s3://data/daily_revenue/")
```

## 3. RDD, DataFrame, Dataset

```
Spark API 진화:

  RDD (Resilient Distributed Dataset):
  └─ 저수준 API, 타입 안전, 최적화 없음
     rdd.map(lambda x: x * 2).filter(lambda x: x > 10)

  DataFrame:
  └─ 스키마 있는 테이블, Catalyst 옵티마이저 활용
     df.select("name").filter(col("age") > 20)

  Dataset (Scala/Java):
  └─ 타입 안전 + Catalyst 최적화

  권장: DataFrame API (Python, SQL)
  → 옵티마이저가 실행 계획 최적화 → 성능 최고
```

| API | 타입 안전 | 최적화 | 사용 편의성 | 권장 |
|-----|----------|--------|-----------|------|
| RDD | 예 | 없음 | 낮음 | 특수 경우만 |
| DataFrame | 아니오 | Catalyst | 높음 | Python 기본 |
| Dataset | 예 | Catalyst | 중간 | Scala 기본 |

## 4. 파티셔닝과 셔플

```
파티셔닝 (Partitioning):

  데이터를 여러 파티션으로 나누어 병렬 처리
  파티션 수 = 병렬도 (일반적으로 코어 수의 2-3배)

  디스크 파티셔닝 (파일 레벨):
  s3://data/orders/
  ├── date=2024-01-01/
  │   ├── part-00000.parquet
  │   └── part-00001.parquet
  ├── date=2024-01-02/
  │   └── ...

  → 특정 날짜만 읽으면 해당 폴더만 스캔 (파티션 프루닝)


셔플 (Shuffle):

  데이터를 키 기준으로 재분배
  → 네트워크 전송 + 디스크 I/O → 가장 비싼 연산

  groupBy("user_id"): 같은 user_id를 같은 파티션으로 이동
  join(df2, "id"): 같은 id를 같은 파티션으로 이동

  셔플 최적화:
  ├─ 파티션 수 조정: spark.sql.shuffle.partitions (기본 200)
  ├─ Broadcast Join: 작은 테이블을 모든 노드에 복제
  │   big_df.join(broadcast(small_df), "id")
  └─ 데이터 편향 처리: Salting, AQE (Adaptive Query Execution)
```

> **핵심 직관**: Spark 작업의 **90% 이상의 성능 문제는 셔플**에서 발생합니다. 셔플을 줄이는 것이 Spark 튜닝의 핵심이며, Broadcast Join으로 작은 테이블의 셔플을 완전히 제거할 수 있습니다.

## 5. 내결함성과 Lazy Evaluation

```
Lazy Evaluation:

  Spark은 변환(Transformation)을 즉시 실행하지 않음
  액션(Action)이 호출될 때 전체 DAG를 최적화 후 실행

  변환: filter, select, groupBy, join → 실행 안 함
  액션: count, show, write, collect → 실행 트리거

  df.filter(...).select(...).groupBy(...)  # 아직 실행 안 함
  df.write.parquet(...)  # 이제 전체 파이프라인 실행!


내결함성 (Fault Tolerance):

  Task 실패 시:
  1. 해당 파티션의 리니지(DAG) 추적
  2. 필요한 입력 데이터에서 재계산
  3. 체크포인트: 중간 결과를 저장하여 리니지 단축

  RDD 리니지 예시:
  rdd1 = sc.textFile("data.txt")          # 입력
  rdd2 = rdd1.flatMap(lambda x: x.split()) # 변환 1
  rdd3 = rdd2.map(lambda x: (x, 1))       # 변환 2
  rdd4 = rdd3.reduceByKey(lambda a, b: a+b) # 변환 3

  rdd4의 파티션 2가 실패 → rdd1의 파티션 2부터 재계산
```

## 6. 실전 배치 파이프라인 패턴

```
전형적인 일일 배치 파이프라인:

  [00:00] Raw 데이터 추출 (Fivetran/Airbyte)
    ↓
  [01:00] Bronze 레이어: 원본 그대로 Parquet 저장
    ↓
  [02:00] Silver 레이어: 클렌징, 조인, 타입 변환
    ↓
  [03:00] Gold 레이어: 비즈니스 집계, 지표 계산
    ↓
  [04:00] 데이터 품질 검증 (dp-06)
    ↓
  [05:00] BI 대시보드 갱신

  멱등성 (Idempotency):
  └─ 같은 파이프라인을 여러 번 실행해도 같은 결과
     패턴: 날짜 파티션을 덮어쓰기
     spark.write.mode("overwrite")
          .partitionBy("date")
          .parquet(output_path)
```

> **핵심 직관**: 배치 파이프라인에서 **멱등성**은 가장 중요한 설계 원칙입니다. 실패 시 재실행하면 정확히 같은 결과가 나와야 합니다. 파티션 단위 덮어쓰기와 결정론적 변환이 핵심입니다.

배치 처리는 dp-03~04의 스트림 처리와 비교되며, dp-08의 Airflow에서 스케줄링됩니다.

## 핵심 정리

- **MapReduce**는 Map-Shuffle-Reduce 패턴의 원조이며, Spark는 인메모리 처리로 이를 10-100배 가속했습니다
- **DataFrame API**와 Catalyst 옵티마이저를 사용하면 RDD보다 훨씬 효율적인 실행 계획이 생성됩니다
- **셔플**은 Spark에서 가장 비싼 연산이며, Broadcast Join과 파티셔닝 전략으로 최소화해야 합니다
- Spark의 **Lazy Evaluation**은 전체 DAG를 최적화한 후 실행하며, 리니지 기반 내결함성을 제공합니다
- 배치 파이프라인은 **멱등성**이 핵심이며, 파티션 단위 덮어쓰기로 재실행 안전성을 보장합니다
