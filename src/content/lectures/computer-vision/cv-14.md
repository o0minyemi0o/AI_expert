# CV 시스템 실전 배포

## 왜 배포가 어려운가

연구에서 99%의 정확도를 달성한 모델이 실전에서 실패하는 경우가 빈번합니다. **조명 변화, 카메라 각도, 도메인 차이, 지연 시간 제약, 엣지 디바이스의 한정된 자원**—실전의 CV 시스템은 연구와 완전히 다른 도전을 마주합니다. 이 강의에서는 모델 경량화, 온디바이스 추론, 데이터 파이프라인, 모니터링까지 CV 시스템을 실전에 배포하는 전 과정을 다룹니다.

> **핵심 직관**: 실전 CV의 핵심 제약은 **"정확도 × 속도 × 비용의 삼각관계"**입니다. 정확도를 높이면 모델이 커져 느려지고, 속도를 높이면 정확도가 떨어지며, 비용을 줄이면 둘 다 제한됩니다. 성공적인 CV 시스템은 이 삼각관계에서 **응용에 맞는 최적점**을 찾습니다.

## 1. 모델 경량화

```
Knowledge Distillation:
  큰 Teacher → 작은 Student

  기본 형태:
  L = α·L_hard(student, label)
    + (1-α)·L_soft(student, teacher)

  L_soft = KL(softmax(z_s/T), softmax(z_t/T))
  T: 온도 (보통 4~20, 높을수록 부드러운 분포)

  Teacher의 "dark knowledge":
  "이건 고양이(0.9)지만 호랑이(0.05)와도 비슷"
  → 클래스 간 관계 정보가 Student에 전달

  CV 특화 증류:
  ├─ Feature Distillation: 중간 특징 맵도 모방
  ├─ Attention Transfer: 어텐션 맵 전달
  ├─ DeiT(cv-10): CNN Teacher → ViT Student
  └─ CLIP 증류: 큰 CLIP → 작은 CLIP

Pruning (가지치기):
  불필요한 파라미터/구조를 제거

  비구조적 가지치기:
  개별 가중치를 0으로 → 희소 행렬
  → 크기 감소는 되지만 실제 속도 향상 어려움

  구조적 가지치기:
  전체 채널/레이어/헤드를 제거
  → 실제 속도 향상! 하드웨어에 친화적
  → ResNet-50에서 30% 채널 제거해도 정확도 유지

양자화 (Quantization):
  FP32 → INT8 또는 INT4

  Post-Training Quantization (PTQ):
  학습 후 가중치를 양자화
  ├─ 캘리브레이션: 소량의 데이터로 스케일 결정
  ├─ FP32 → INT8: 4배 메모리 감소, ~1% 정확도 손실
  └─ 가장 실용적이고 널리 사용

  Quantization-Aware Training (QAT):
  학습 중에 양자화를 시뮬레이션
  ├─ Fake Quantization: 순방향에서 양자화, 역전파는 STE
  ├─ PTQ보다 높은 정확도
  └─ 학습 비용이 추가

  | 방법 | 비트 | 크기 감소 | 속도 향상 | 정확도 |
  |------|------|---------|---------|--------|
  | FP32 | 32 | 1× | 1× | 기준 |
  | FP16 | 16 | 2× | ~1.5× | ≈기준 |
  | INT8 (PTQ) | 8 | 4× | 2-3× | -0.5~1% |
  | INT8 (QAT) | 8 | 4× | 2-3× | -0.1~0.5% |
  | INT4 | 4 | 8× | 3-4× | -2~5% |
```

## 2. 효율적 아키텍처

```
모바일 네트워크:

  MobileNetV2 (Sandler et al., 2018):
  Inverted Residual + Depthwise Separable Conv
  ├─ 확장: 좁은 → 넓은 (확장 비율 6)
  ├─ Depthwise Conv: 채널별 독립 연산
  ├─ 축소: 넓은 → 좁은 (1×1 Conv)
  └─ 300M FLOPs로 ImageNet 72%

  MobileNetV3 (Howard et al., 2019):
  ├─ NAS(Neural Architecture Search)로 설계
  ├─ h-swish 활성화: x × ReLU6(x+3)/6
  ├─ SE(Squeeze-and-Excitation) 블록
  └─ Large/Small 변형 (모바일/IoT)

  EfficientNet (Tan & Le, 2019):
  깊이 × 너비 × 해상도를 동시 스케일링
  ├─ Compound Scaling: d=α^φ, w=β^φ, r=γ^φ
  ├─ α·β²·γ² ≈ 2 제약 하에 최적 비율 탐색
  ├─ B0~B7: 작은 것부터 큰 것까지
  └─ B0: 5.3M, 390M FLOPs, 77.1%

  | 모델 | 파라미터 | FLOPs | Top-1 | 용도 |
  |------|---------|-------|-------|------|
  | MobileNetV3-S | 2.9M | 56M | 67.4% | IoT |
  | MobileNetV3-L | 5.4M | 219M | 75.2% | 모바일 |
  | EfficientNet-B0 | 5.3M | 390M | 77.1% | 경량 |
  | EfficientNet-B4 | 19M | 4.2G | 82.9% | 균형 |
  | YOLOv8n | 3.2M | 8.7G | 37.3AP | 탐지 |

NAS (Neural Architecture Search):
  자동으로 최적 아키텍처 탐색

  ├─ 탐색 공간: 연산 유형, 커널 크기, 채널 수
  ├─ 탐색 전략: 강화학습, 진화 알고리즘, 미분 가능
  ├─ 성능 추정: 프록시 태스크, 초기 에폭
  └─ 하드웨어 인식: 실제 지연 시간을 제약에 포함
  → EfficientNet, MobileNetV3가 NAS로 설계됨
```

## 3. 온디바이스 추론

```
추론 프레임워크:

  ONNX Runtime:
  ├─ 크로스 프레임워크 표준 (PyTorch → ONNX)
  ├─ 그래프 최적화: 연산 융합, 상수 폴딩
  ├─ CPU/GPU/NPU 지원
  └─ 가장 범용적

  TensorRT (NVIDIA):
  ├─ NVIDIA GPU 전용 최적화
  ├─ 레이어 융합, 커널 자동 튜닝
  ├─ INT8/FP16 자동 양자화
  └─ GPU 추론의 표준 (2-5배 속도)

  Core ML (Apple):
  ├─ iOS/macOS 디바이스 최적화
  ├─ Neural Engine 활용
  └─ Swift/Objective-C 통합

  TFLite (Google):
  ├─ 안드로이드 최적화
  ├─ 마이크로컨트롤러 지원 (TFLite Micro)
  └─ 양자화 내장

최적화 기법:

  연산 융합 (Operator Fusion):
  Conv → BN → ReLU를 하나의 커널로
  → 메모리 읽기/쓰기 감소 → 속도 향상

  그래프 최적화:
  ├─ 상수 폴딩: 컴파일 시 계산 가능한 것은 미리
  ├─ 죽은 코드 제거: 사용하지 않는 연산 제거
  └─ 레이아웃 최적화: NCHW ↔ NHWC 변환

  배치 처리:
  ├─ 단일 이미지 추론: GPU 활용률 낮음
  ├─ 배치(4~32): GPU 활용률 극대화
  └─ 동적 배치: 요청을 모아서 처리

  | 플랫폼 | 프레임워크 | 최적 하드웨어 |
  |--------|----------|------------|
  | 서버 GPU | TensorRT | NVIDIA A100/H100 |
  | 엣지 GPU | TensorRT | Jetson Orin |
  | iOS | Core ML | Apple Neural Engine |
  | Android | TFLite | Qualcomm NPU |
  | 범용 | ONNX Runtime | CPU/GPU |
```

## 4. 데이터 파이프라인과 라벨링

```
데이터 수집 전략:

  주의사항:
  ├─ 배포 환경과 유사한 데이터 수집이 핵심
  ├─ 조명 조건: 밤/낮, 실내/실외
  ├─ 카메라: 해상도, 렌즈 왜곡, 화각
  ├─ 엣지 케이스: 가려진 물체, 극단적 포즈
  └─ 클래스 균형: 희귀 클래스 충분히

라벨링 효율화:

  자동 라벨링:
  ├─ SAM(cv-05): 자동 마스크 생성
  ├─ Grounded SAM(cv-11): 텍스트로 자동 라벨링
  ├─ CLIP: 이미지 분류 자동 라벨링
  └─ 교사 모델: 큰 모델의 예측을 라벨로

  반자동 워크플로우:
  1. 자동 라벨링 (80% 정확도)
  2. 인간 검수 + 수정 (98%+ 정확도)
  → 순수 수동 대비 5-10배 효율

  액티브 러닝:
  ├─ 모델이 불확실한 샘플을 우선 라벨링 요청
  ├─ 불확실성 기준: 예측 확률의 엔트로피
  ├─ 동일 라벨링 예산으로 더 높은 성능
  └─ 전체 데이터의 20-30%만 라벨링해도 충분

데이터 증강 실전:

  기본 증강:
  ├─ 랜덤 크롭/리사이즈/회전/반전
  ├─ 색상 지터: 밝기, 대비, 채도
  └─ 가우시안 블러, 모션 블러

  고급 증강:
  ├─ Mosaic: 4개 이미지를 합성 (YOLOv4)
  ├─ CutMix: 영역을 잘라서 교체
  ├─ Copy-Paste: 객체를 다른 배경에 붙이기
  └─ 합성 데이터: 3D 렌더링 + 도메인 랜덤화
```

## 5. 모니터링과 도메인 적응

```
배포 후 모니터링:

  성능 지표:
  ├─ 정확도/AP: 주기적 평가 셋에서 측정
  ├─ 지연 시간: P50, P95, P99 추적
  ├─ 처리량: 초당 처리 이미지 수
  └─ 자원 사용: GPU 메모리, CPU 사용률

  데이터 드리프트 감지:
  ├─ 입력 분포 변화: 밝기, 해상도, 구도
  ├─ 예측 분포 변화: 특정 클래스 비율 변화
  ├─ 신뢰도 분포: 평균 신뢰도 하락 = 경고
  └─ 임베딩 드리프트: CLIP 특징의 분포 변화

  모델 업데이트 전략:
  1. 주기적 재학습: 새 데이터로 주기적 갱신
  2. 연속 학습: 새 데이터가 올 때마다 점진적 학습
  3. A/B 테스팅: 새 모델을 일부 트래픽에서 검증
  → ms-14~15에서 다룬 모델 갱신 원칙 적용

도메인 적응:
  학습 도메인과 배포 도메인의 차이 극복

  문제:
  ImageNet(사진) → 의료(X-ray): 큰 도메인 차이
  실내 카메라 → 실외 카메라: 조명, 배경 변화

  비지도 도메인 적응:
  ├─ 특징 정렬: 소스/타겟의 특징 분포를 맞춤
  ├─ 적대적 학습: 도메인 분류기를 속이도록
  └─ Self-Training: 타겟에서 의사 라벨 생성

  파운데이션 모델 활용:
  ├─ CLIP/DINOv2의 범용 표현 → 파인튜닝
  ├─ SAM의 제로샷 → 도메인 무관 세그멘테이션
  └─ 도메인 특화 사전학습 → 전이학습
```

## 6. 실전 CV 시스템 아키텍처

```
서비스 아키텍처:

  실시간 영상 분석:
  카메라 → 프레임 추출 → 전처리 → 모델 추론
  → 후처리 → 결과 저장/알림

  배치 처리:
  이미지 저장소 → 큐 → 워커(GPU) → 결과 DB
  → 대규모 이미지 분류/태깅

  API 서비스:
  요청(이미지) → 로드밸런서 → 추론 서버(GPU)
  → 응답(결과)

  추론 서버:
  ├─ Triton (NVIDIA): 다중 모델, 동적 배치
  ├─ TorchServe: PyTorch 네이티브
  ├─ BentoML: ML 서빙 프레임워크
  └─ vLLM: 비전-언어 모델 서빙 (LLaVA 등)

비용 최적화:

  GPU 선택:
  ├─ 학습: A100/H100 (대규모, 고메모리)
  ├─ 추론: T4/L4 (비용 효율적)
  ├─ 엣지: Jetson Orin (전력 효율)
  └─ 클라우드: 스팟 인스턴스 활용

  모델 크기와 비용:
  ├─ ResNet-50 (25M): T4 1장으로 충분
  ├─ Swin-L (197M): 고성능 GPU 필요
  ├─ LLaVA-13B: A100 급 필요
  └─ 경량 모델 + INT8이 비용 대비 최적인 경우 많음

  전체 시스템 체크리스트:
  ├─ □ 정확도: 요구 수준 달성?
  ├─ □ 지연 시간: SLA 충족? (P99 < 100ms 등)
  ├─ □ 처리량: 피크 트래픽 처리 가능?
  ├─ □ 비용: 예산 내?
  ├─ □ 모니터링: 드리프트 감지 설정?
  ├─ □ 에러 처리: 모델 실패 시 폴백?
  ├─ □ 보안: 적대적 입력 방어?
  └─ □ 개인정보: 얼굴/번호판 등 처리?
```

## 핵심 정리

- **Knowledge Distillation**은 Teacher의 소프트 출력으로 Student를 학습시키며, **양자화**(INT8 PTQ)는 4배 크기 감소와 2-3배 속도 향상을 ~1% 정확도 손실로 달성합니다
- **MobileNet/EfficientNet**은 Depthwise Separable Conv과 Compound Scaling으로 모바일/엣지에 적합한 효율적 아키텍처이며, NAS로 하드웨어 인식 설계가 가능합니다
- **TensorRT**(GPU), **Core ML**(iOS), **TFLite**(Android)는 플랫폼별 최적화 프레임워크이며, 연산 융합과 그래프 최적화가 핵심 속도 향상 기법입니다
- **SAM/Grounded SAM 기반 자동 라벨링**과 **액티브 러닝**으로 라벨링 효율을 5-10배 높이며, 데이터 수집은 배포 환경과의 유사성이 핵심입니다
- 배포 후 **데이터 드리프트 감지**, **도메인 적응**, **A/B 테스팅**으로 모델 성능을 유지하며, 정확도-속도-비용의 삼각관계에서 응용에 맞는 최적점을 찾는 것이 실전 CV의 핵심입니다
