# 객체 탐지: Two-Stage

## 왜 객체 탐지가 중요한가

이미지 분류는 "이 이미지에 고양이가 있는가?"를 묻지만, 객체 탐지는 **"어디에, 몇 마리의 고양이가 있는가?"**를 묻습니다. 자율주행의 보행자 인식, 의료 영상의 병변 탐지, 제조업의 결함 검출—모두 객체 탐지 문제입니다. Two-Stage 탐지기는 "후보 영역 생성 → 분류/정제"의 2단계로 높은 정확도를 달성하며, 탐지 분야의 기초가 됩니다.

> **핵심 직관**: Two-Stage 탐지의 핵심은 **"어디를 볼 것인가(where)와 무엇인가(what)를 분리"**하는 것입니다. 이미지 전체를 모든 위치, 모든 크기로 검색하면 $O(W \times H \times S)$이지만, 먼저 유망한 영역만 제안하면 수천 개로 줄어듭니다. 이 "주의 집중(attention)"이 효율과 정확도의 핵심입니다.

## 1. R-CNN 계열의 시작

```
R-CNN (Girshick et al., 2014):
  최초의 딥러닝 기반 객체 탐지

  3단계 파이프라인:
  1. 영역 제안 (Region Proposal):
     Selective Search로 ~2000개 후보 영역 추출
     → 색상, 텍스처, 크기로 유사 영역 병합

  2. 특징 추출:
     각 후보 영역을 227×227로 리사이즈
     CNN(AlexNet)으로 특징 벡터 추출

  3. 분류 + 회귀:
     SVM으로 클래스 분류
     선형 회귀로 바운딩 박스 정제

  문제점:
  ├─ 2000개 영역 × CNN 포워드 = 극도로 느림 (47초/이미지)
  ├─ 리사이즈로 정보 손실/왜곡
  ├─ 학습 파이프라인이 분리됨 (CNN, SVM, 회귀 따로)
  └─ 디스크에 특징 저장 필요

Fast R-CNN (Girshick, 2015):
  핵심 개선: CNN을 이미지 전체에 한 번만 적용!

  1. 전체 이미지 → CNN → 특징 맵 (한 번만!)
  2. RoI Projection: 영역 제안을 특징 맵에 투영
  3. RoI Pooling: 가변 크기 영역 → 고정 크기 (7×7)
  4. FC → 분류 + 회귀 (end-to-end)

  속도: R-CNN 대비 ~25배 빠름
  but: Selective Search가 여전히 병목 (~2초/이미지)
```

## 2. Faster R-CNN

```
Faster R-CNN (Ren et al., 2015):
  Selective Search를 **Region Proposal Network(RPN)**으로 대체
  → 완전한 end-to-end 학습!

  구조:
  이미지 → Backbone(ResNet) → 특징 맵
                                  ↓
                              ┌── RPN → 영역 제안 (where?)
                              │
                              └── RoI Pooling → 분류 + 회귀 (what?)

Region Proposal Network (RPN):
  특징 맵의 각 위치에서:
  ├─ k개의 앵커 박스 (anchor boxes) 정의
  │   크기: {128², 256², 512²}
  │   비율: {1:1, 1:2, 2:1}
  │   → 9개 앵커/위치
  ├─ 3×3 Conv → 256d → 두 개의 1×1 Conv
  │   ├─ 객체 유무: 2k scores (object vs background)
  │   └─ 박스 조정: 4k coordinates (dx, dy, dw, dh)
  └─ NMS로 중복 제거 → 상위 ~300개 제안

  앵커의 직관:
  "이 위치에 이 크기/비율의 물체가 있을까?"
  → 다양한 크기/비율을 사전 정의하여 커버

  학습:
  ├─ 양성 앵커: IoU > 0.7인 GT와 매칭
  ├─ 음성 앵커: IoU < 0.3인 모든 GT
  ├─ 분류 손실: Cross-Entropy
  └─ 회귀 손실: Smooth L1 (이상치에 강건)

IoU (Intersection over Union):
  IoU = 교집합 면적 / 합집합 면적

  ┌────────┐
  │  ┌─────┼───┐
  │  │/////│   │   IoU = 겹침 / 전체
  └──┼─────┘   │
     └─────────┘

  IoU > 0.5: "탐지 성공" (PASCAL VOC 기준)
  IoU > 0.75: 엄격한 기준 (COCO)
```

```
RoI Pooling vs RoI Align:

  RoI Pooling (Fast/Faster R-CNN):
  영역을 7×7 그리드로 나누고 각 셀에서 max pooling
  문제: 정수 양자화로 위치 오차 발생
  → 작은 객체에서 성능 저하

  RoI Align (Mask R-CNN, He et al., 2017):
  이중선형 보간(bilinear interpolation)으로
  정확한 소수점 위치의 특징값을 계산
  → 양자화 오차 제거
  → 특히 세그멘테이션에서 큰 개선

  | 방법 | 양자화 | 작은 객체 | 사용 |
  |------|--------|----------|------|
  | RoI Pooling | 있음 | 약함 | Faster R-CNN |
  | RoI Align | 없음 | 강함 | Mask R-CNN+ |
```

> **핵심 직관**: Faster R-CNN의 혁신은 **"영역 제안 자체를 학습 가능하게 만든 것"**입니다. Selective Search는 수작업 규칙 기반이었지만, RPN은 "어디에 물체가 있을 법한가"를 데이터에서 학습합니다. 이것은 CV의 일반적 흐름—**수작업 특징에서 학습된 특징으로**—의 연장입니다.

## 3. Feature Pyramid Network (FPN)

```
다중 스케일 탐지의 문제:
  작은 물체: 고해상도 특징 맵에서 탐지
  큰 물체: 저해상도 특징 맵에서 탐지
  → 모든 크기를 동시에 잘 탐지하려면?

  기존 방법: 이미지 피라미드
  여러 크기로 리사이즈 → 각각 CNN → 느림!

FPN (Lin et al., 2017):
  CNN의 다단계 특징 맵을 피라미드로 활용

  Bottom-up (백본):
  C1(1/2) → C2(1/4) → C3(1/8) → C4(1/16) → C5(1/32)
  해상도 감소, 의미 정보 증가

  Top-down + Lateral:
  P5 = 1×1(C5)
  P4 = Upsample(P5) + 1×1(C4)
  P3 = Upsample(P4) + 1×1(C3)
  P2 = Upsample(P3) + 1×1(C2)

  각 레벨에서 3×3 Conv로 정제

  결과:
  ├─ P2: 작은 객체 (높은 해상도 + 의미 정보)
  ├─ P3: 중간 객체
  ├─ P4: 큰 객체
  └─ P5: 매우 큰 객체

  핵심: 고해상도(위치 정보) + 고수준(의미 정보) 결합
  → 모든 크기의 객체를 효과적으로 탐지
  → 현대 탐지기의 표준 구성요소

  FPN의 영향:
  Faster R-CNN + FPN = 표준 two-stage 탐지기
  RetinaNet, FCOS, DETR 등 one-stage에서도 사용
```

## 4. 탐지 학습과 손실 함수

```
학습 구성 요소:

  1. 앵커-GT 매칭:
     각 앵커를 Ground Truth(GT)에 배정
     ├─ 양성: IoU > 0.7 (또는 가장 높은 IoU)
     ├─ 음성: IoU < 0.3
     └─ 무시: 0.3~0.7 (학습에서 제외)

  2. 분류 손실:
     L_cls = CrossEntropy(pred_class, gt_class)

     클래스 불균형 문제:
     양성 앵커 ~10개 vs 음성 앵커 ~10,000개
     → 대부분이 배경! → 쉬운 음성이 손실을 지배

     해결:
     ├─ Hard Negative Mining: 어려운 음성만 사용
     ├─ OHEM: Online Hard Example Mining
     └─ Focal Loss (cv-03에서 상세히)

  3. 회귀 손실:
     바운딩 박스 좌표 (x, y, w, h)의 오프셋 예측

     t_x = (x - x_a) / w_a
     t_y = (y - y_a) / h_a
     t_w = log(w / w_a)
     t_h = log(h / h_a)

     Smooth L1 Loss:
     L1보다 이상치에 강건, L2보다 안정적

  4. 전체 손실:
     L = L_cls + λ × L_reg
     RPN과 Detection Head 각각 별도 손실
     → 멀티태스크 학습

NMS (Non-Maximum Suppression):
  중복 탐지 제거

  1. 신뢰도순 정렬
  2. 가장 높은 박스 선택
  3. 선택된 박스와 IoU > 0.5인 박스 제거
  4. 반복

  Soft-NMS: 제거 대신 점수 감소
  → 겹친 물체도 탐지 가능
```

## 5. Cascade R-CNN

```
Cascade R-CNN (Cai & Vasconcelos, 2018):
  IoU 임계값의 딜레마 해결

  문제:
  IoU > 0.5로 학습 → 부정확한 박스도 양성으로
  IoU > 0.7로 학습 → 양성 샘플 부족, 과적합

  해결: 점진적으로 임계값을 높이는 캐스케이드

  Stage 1: IoU > 0.5로 학습 → 박스 정제
  Stage 2: 정제된 박스에서 IoU > 0.6으로 재학습
  Stage 3: 더 정제된 박스에서 IoU > 0.7으로 재학습

  각 스테이지가 이전 스테이지의 출력을 입력으로!
  → 점진적으로 정밀한 탐지

  성능: Faster R-CNN 대비 AP +2-4%
  특히 AP_75 (엄격한 기준)에서 큰 개선

  | 모델 | AP | AP_50 | AP_75 |
  |------|-----|-------|-------|
  | Faster R-CNN | 36.2 | 58.0 | 38.5 |
  | Cascade R-CNN | 40.3 | 58.6 | 44.0 |
```

## 6. Two-Stage 탐지기 정리와 실전

```
Two-Stage 탐지기의 위치:

  장점:
  ├─ 높은 정확도 (특히 작은 객체)
  ├─ 유연한 구조 (다양한 확장 가능)
  ├─ 잘 확립된 학습 파이프라인
  └─ 다양한 사전학습 가중치 사용 가능

  단점:
  ├─ 상대적으로 느림 (RPN + Detection 2단계)
  ├─ NMS 후처리 필요
  ├─ 앵커 설계가 데이터에 의존
  └─ 구현 복잡도

  현대 two-stage의 표준 구성:
  Backbone: ResNet-50/101 또는 ConvNeXt
  Neck: FPN
  RPN: 3×3 Conv + 분류/회귀 헤드
  Detection Head: FC 또는 Conv 기반
  학습: SGD, 12-36 에폭 (1x/3x schedule)

  COCO 벤치마크 기준 (2024):
  ├─ Cascade R-CNN + ConvNeXt-L: AP ~54%
  ├─ 최고 성능은 Co-DETR(cv-03) 등 Transformer 기반
  └─ Two-stage는 여전히 경쟁력 있는 기준선

  실무 선택:
  정확도 우선 → Cascade R-CNN + FPN
  속도 우선 → One-stage (cv-03)
  유연성 → DETR 계열 (cv-03)
```

> **핵심 직관**: Two-Stage 탐지기의 설계 철학은 **"거칠게 찾고(coarse), 정밀하게 분류(fine)"**입니다. RPN이 "여기에 뭔가 있다"를 빠르게 판단하고, Detection Head가 "정확히 무엇이고 어디인가"를 정밀하게 결정합니다. 이 "거친→정밀" 패턴은 nlp-10의 RAG(검색→리랭킹)와 동일한 원리입니다.

## 핵심 정리

- **R-CNN → Fast R-CNN → Faster R-CNN**은 "개별 영역 CNN" → "공유 특징 맵" → "학습 가능한 RPN"으로 진화하며, 속도가 47초에서 0.2초로 단축되었습니다
- **RPN**은 앵커 박스 기반으로 영역을 제안하며, 다양한 크기/비율의 앵커가 다중 스케일 탐지를 가능하게 합니다
- **FPN**은 백본의 다단계 특징 맵을 Top-down으로 연결하여, 모든 크기의 객체를 효과적으로 탐지하는 표준 구성요소입니다
- **RoI Align**은 양자화 오차를 제거하여 작은 객체와 세그멘테이션에서 핵심적이며, **Cascade R-CNN**은 점진적 IoU 임계값으로 정밀도를 향상시킵니다
- Two-Stage의 **"영역 제안 → 분류/정제"** 패턴은 높은 정확도의 기준이며, One-Stage(cv-03)와 상호 보완적입니다
