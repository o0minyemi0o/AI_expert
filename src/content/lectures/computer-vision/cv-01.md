# CNN 아키텍처 진화

## 왜 CNN 아키텍처의 진화를 이해해야 하는가

dl-02에서 컨볼루션의 기초를 배웠다면, 이 강의에서는 **AlexNet부터 ConvNeXt까지 20년간의 설계 혁신**을 추적합니다. 각 아키텍처가 해결한 문제와 도입한 아이디어를 이해하면, 왜 현재의 설계가 이런 형태인지, 그리고 어떤 방향으로 진화할지를 예측할 수 있습니다. 모든 CV 모델의 뿌리가 되는 CNN의 역사는 곧 딥러닝의 역사입니다.

> **핵심 직관**: CNN 아키텍처의 진화는 **"더 깊게, 더 효율적으로, 더 유연하게"**라는 세 축을 따릅니다. AlexNet이 "깊이"의 시작이었고, ResNet이 "무한히 깊게"를 가능하게 했으며, EfficientNet이 "최소 비용으로 최대 성능"을, 그리고 ConvNeXt가 "Transformer의 설계 원칙을 CNN에"를 실현했습니다.

## 1. AlexNet과 딥러닝 혁명 (2012)

```
ImageNet Challenge (ILSVRC):
  1000 클래스, 120만 학습 이미지
  2011년 1등: 25.8% top-5 에러 (전통 CV)
  2012년 AlexNet: 16.4% → 10% 격차로 압승!
  → 딥러닝 혁명의 시작

AlexNet (Krizhevsky et al., 2012):
  구조: 5 Conv + 3 FC, 60M 파라미터

  혁신 요소:
  ├─ ReLU 활성화: tanh 대비 6배 빠른 수렴
  │   max(0, x) — 양수 그래디언트가 사라지지 않음
  ├─ GPU 학습: 2개 GTX 580 (3GB), 5-6일
  ├─ Dropout (p=0.5): FC 레이어 과적합 방지
  ├─ Data Augmentation: 랜덤 크롭, 수평 반전, 색상 변환
  └─ Local Response Normalization (LRN)
     → 이후 BatchNorm에 의해 대체

  이후의 기여:
  AlexNet 자체보다 "GPU + 대규모 데이터 + 깊은 네트워크"
  라는 레시피가 CV 전체를 바꿈

VGGNet (Simonyan & Zisserman, 2014):
  핵심 통찰: 3×3 필터만으로 충분!

  3×3 두 개 = 5×5의 수용 영역
  3×3 세 개 = 7×7의 수용 영역
  → 같은 수용 영역, 더 적은 파라미터, 더 깊은 비선형성

  VGG-16: 13 Conv + 3 FC, 138M 파라미터
  VGG-19: 16 Conv + 3 FC

  한계: 파라미터가 너무 많음 (FC 레이어 때문)
  레거시: 3×3 필터 = CNN의 표준이 됨
```

## 2. GoogLeNet/Inception과 네트워크 설계

```
GoogLeNet/Inception (Szegedy et al., 2014):
  핵심 질문: "적절한 필터 크기는?"
  답: "여러 크기를 동시에 쓰자!"

  Inception 모듈:
  입력 → ┬─ 1×1 Conv ──────────┐
         ├─ 1×1 → 3×3 Conv ────┤
         ├─ 1×1 → 5×5 Conv ────┤ → Concat
         └─ 3×3 Pool → 1×1 Conv┘

  1×1 컨볼루션의 역할:
  ├─ 채널 수 감소 (차원 축소) → 계산량 절감
  ├─ 비선형성 추가 (ReLU 포함)
  └─ la-04의 저랭크 근사와 유사한 효과

  GoogLeNet: 22 레이어, 단 5M 파라미터!
  (VGG-16의 138M 대비 1/27)
  → 깊으면서도 효율적인 설계 가능을 입증

  Inception v2/v3/v4:
  ├─ v2: BatchNorm 도입 (dl-07)
  ├─ v3: 5×5 → 두 개의 3×3, 비대칭 분해 (3×1 + 1×3)
  └─ v4: Inception + Residual 결합
```

## 3. ResNet과 잔차 학습 (2015)

```
깊이의 역설:
  VGG-19 (19층)보다 깊은 네트워크가 더 나쁜 성능?
  → 최적화 문제 (그래디언트 소실/폭발)
  → dl-03에서 다룬 핵심 문제

ResNet (He et al., 2015):
  "레이어가 입력을 그대로 통과시키기만 해도 되면,
   최소한 얕은 모델만큼은 좋아야 한다"

  잔차 블록:
  x → [Conv → BN → ReLU → Conv → BN] → + → ReLU
  └──────────── 숏컷 (identity) ─────────┘

  F(x) + x: "변화량(잔차)"만 학습!
  → 항등 매핑이 기본, 학습은 "차이"에 집중

  왜 작동하는가:
  ├─ 그래디언트가 숏컷을 통해 직접 흐름
  │   ∂L/∂x = ∂L/∂(F+x) × (∂F/∂x + 1)
  │   → "+1" 덕분에 그래디언트 소실 방지
  ├─ 앙상블 해석: 다양한 깊이의 경로 조합
  └─ 최적화 landscape가 더 매끄러움

  | 모델 | 레이어 | 파라미터 | Top-5 에러 |
  |------|--------|---------|-----------|
  | VGG-16 | 16 | 138M | 7.3% |
  | ResNet-50 | 50 | 25.6M | 5.25% |
  | ResNet-152 | 152 | 60.2M | 4.49% |

  Bottleneck 블록 (ResNet-50+):
  1×1(256→64) → 3×3(64→64) → 1×1(64→256)
  → 채널 축소 → 연산 → 채널 복원
  → 계산 효율적으로 깊은 네트워크 구성

후속 개선:
  Pre-activation ResNet (He et al., 2016):
  BN → ReLU → Conv (기존: Conv → BN → ReLU)
  → 더 안정적 학습, 더 깊은 네트워크 가능

  ResNeXt (Xie et al., 2017):
  "Split-Transform-Merge" — 그룹 컨볼루션
  32개의 4d 경로 vs 1개의 128d 경로 (같은 계산량)
  → 정확도 향상, Inception의 아이디어를 ResNet에
```

> **핵심 직관**: ResNet의 잔차 연결은 단순히 "그래디언트 문제 해결"이 아니라, **"네트워크를 얕은 모델들의 앙상블로 만드는 것"**입니다. 152층 ResNet은 152가지 깊이의 경로를 가지며, 학습은 이 중 유용한 경로를 활성화하는 과정입니다. 이 아이디어는 Transformer에도 그대로 적용됩니다.

## 4. 모바일/효율 아키텍처

```
MobileNet (Howard et al., 2017):
  모바일/엣지 디바이스를 위한 경량 설계

  Depthwise Separable Convolution:
  일반 Conv: H×W×C_in × K×K × C_out
  = K² × C_in × C_out × H × W FLOPs

  분리:
  1. Depthwise: 각 채널에 독립적 K×K 필터
     → K² × C_in × H × W
  2. Pointwise: 1×1 Conv로 채널 혼합
     → C_in × C_out × H × W

  비용 비율: 1/C_out + 1/K² ≈ 1/8~1/9 (K=3)
  → 연산량 8-9배 감소!

  MobileNetV2 (Sandler et al., 2018):
  Inverted Residual Block:
  좁은(thin) → 넓은(wide) → 좁은(thin) + 숏컷
  (ResNet의 반대: 넓은 → 좁은 → 넓은)

  이유: 높은 차원에서 비선형 적용이 정보 손실 적음
  → 저차원 숏컷, 고차원 연산

EfficientNet (Tan & Le, 2019):
  "깊이, 너비, 해상도를 동시에 스케일링"

  Compound Scaling:
  depth: d = α^φ
  width: w = β^φ
  resolution: r = γ^φ
  s.t. α × β² × γ² ≈ 2  (FLOPs 2배 제약)

  NAS (Neural Architecture Search)로 기본 구조 탐색
  → EfficientNet-B0 ~ B7

  | 모델 | 파라미터 | FLOPs | Top-1 |
  |------|---------|-------|-------|
  | ResNet-50 | 26M | 4.1B | 76.0% |
  | EfficientNet-B0 | 5.3M | 0.4B | 77.1% |
  | EfficientNet-B4 | 19M | 4.2B | 82.9% |
  | EfficientNet-B7 | 66M | 37B | 84.3% |

  핵심: 같은 FLOPs에서 ResNet보다 훨씬 높은 정확도
```

## 5. ConvNeXt: Transformer 시대의 CNN

```
ConvNeXt (Liu et al., 2022):
  "ViT가 CNN보다 나은 이유가 어텐션 때문인가,
   아니면 학습 레시피 때문인가?"

  ResNet-50에서 시작하여 하나씩 Transformer 요소 적용:

  1. 학습 레시피: 300 에폭, AdamW, 증강 → +2.7%
  2. 스테이지 비율: (3,4,6,3) → (3,3,9,3) → +0.6%
  3. Patchify stem: 4×4 stride 4 Conv → +0.1%
  4. 깊이별 Conv: 그룹=채널 (Depthwise) → +0.1%
  5. 커널 크기: 3×3 → 7×7 → +0.7%
  6. 활성화: ReLU → GELU → +0.2%
  7. 정규화: BN → LN → +0.1%
  8. 다운샘플: stride Conv → 별도 LN + Conv → +0.3%

  최종: ConvNeXt-T: 82.1% (Swin-T: 81.3%!)
  → CNN이 Transformer와 동등하거나 우위!

  교훈:
  ├─ 아키텍처 자체보다 학습 전략이 더 중요
  ├─ CNN의 귀납적 편향(지역성)은 여전히 가치 있음
  ├─ Transformer의 요소를 CNN에 이식 가능
  └─ "CNN vs Transformer"가 아닌 "좋은 설계 원칙"
```

> **핵심 직관**: ConvNeXt의 메시지는 **"이기는 건 아키텍처가 아니라 설계 원칙"**입니다. 큰 커널, GELU, LayerNorm, 더 나은 학습 레시피—이런 현대적 설계 원칙을 CNN에 적용하면 Transformer와 동등한 성능에 도달합니다. 중요한 것은 CNN이냐 Transformer냐가 아니라, 각 구성 요소의 역할을 이해하는 것입니다.

## 6. 아키텍처 선택 가이드

```
실무 아키텍처 선택:

  | 상황 | 추천 | 이유 |
  |------|------|------|
  | 모바일/엣지 | MobileNetV3 | 적은 연산, 낮은 지연 |
  | 서버 분류 | ConvNeXt/EfficientNet | 정확도/효율 균형 |
  | 전이 학습 | ResNet-50 | 사전학습 풍부, 안정적 |
  | 탐지 백본 | ResNet/ConvNeXt | FPN 호환, 다스케일 |
  | 연구 | ViT (cv-10) | 스케일링, 유연성 |

  사전학습 가중치의 중요성:
  ImageNet-1K: 128만 이미지, 1000 클래스
  ImageNet-21K: 1400만 이미지, 21K 클래스
  → 더 큰 사전학습 데이터 = 더 좋은 전이 학습

아키텍처 진화 요약:

  2012: AlexNet — GPU + 깊이
  2014: VGGNet — 3×3 필터 표준화
  2014: GoogLeNet — 다중 스케일, 1×1 Conv
  2015: ResNet — 잔차 학습, 무한 깊이
  2017: MobileNet — 경량화, Depthwise
  2019: EfficientNet — 복합 스케일링, NAS
  2020: ViT — CNN → Transformer (cv-10)
  2022: ConvNeXt — Transformer 설계를 CNN에

  진화의 주요 축:
  ├─ 깊이: 8 → 19 → 152 → 1000+
  ├─ 효율: 138M → 25M → 5M 파라미터
  ├─ 설계: 수동 → NAS → 원칙 기반
  └─ 패러다임: CNN → Transformer → 하이브리드
```

## 핵심 정리

- **AlexNet**(2012)이 GPU + ReLU + Dropout으로 딥러닝 혁명을 시작했고, **VGGNet**이 3×3 필터를 표준으로 확립했습니다
- **Inception**은 다중 스케일 + 1×1 Conv로 효율적 설계를, **ResNet**은 잔차 연결로 수백 층의 깊은 학습을 가능하게 했습니다
- **Depthwise Separable Conv**(MobileNet)은 연산량을 8-9배 줄이며, **EfficientNet**의 복합 스케일링은 깊이·너비·해상도를 동시에 최적화합니다
- **ConvNeXt**는 Transformer의 설계 원칙(큰 커널, GELU, LN)을 CNN에 적용하여, 아키텍처보다 **설계 원칙과 학습 레시피**가 중요함을 보여줬습니다
- 실무 선택은 **배포 환경**(모바일 vs 서버)과 **태스크**(분류 vs 탐지 vs 세그멘테이션)에 따라 결정됩니다
