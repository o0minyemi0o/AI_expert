# 이미지 생성: GAN

## 왜 이미지 생성이 중요한가

지금까지 CV는 "이미지를 이해"하는 것이었습니다. 이제 **"이미지를 만드는"** 생성 모델을 다룹니다. GAN(Generative Adversarial Network)은 2014년부터 이미지 생성을 혁신했으며, 존재하지 않는 사람의 얼굴, 예술 작품, 고해상도 이미지를 생성합니다. cv-07의 Diffusion Model에 자리를 넘겨주고 있지만, GAN의 아이디어는 여전히 강력합니다.

> **핵심 직관**: GAN의 핵심은 **"위조범과 감별사의 경쟁"**입니다. 생성기(G)는 진짜 같은 이미지를 만들고, 판별기(D)는 진짜와 가짜를 구분합니다. 이 경쟁이 양쪽을 모두 강하게 만들며, 평형에서 G가 만드는 이미지는 진짜와 구분 불가능합니다.

## 1. GAN 기초 이론

```
GAN (Goodfellow et al., 2014):

  목적 함수:
  min_G max_D V(D, G) =
    E_{x~p_data}[log D(x)] + E_{z~p_z}[log(1 - D(G(z)))]

  D(x): x가 진짜일 확률
  G(z): 잡음 z로부터 생성된 이미지

  판별기 D의 목표: V를 최대화
  → 진짜에 높은 확률, 가짜에 낮은 확률

  생성기 G의 목표: V를 최소화
  → D가 가짜를 진짜로 착각하게

  최적 판별기:
  D*(x) = p_data(x) / (p_data(x) + p_g(x))
  → 진짜와 가짜의 비율로 판별

  최적 생성기:
  p_g = p_data (생성 분포 = 실제 분포)
  → D*(x) = 1/2 (구분 불가능)

  학습 과정:
  for each iteration:
    1. D를 k 스텝 학습 (보통 k=1)
       진짜 → 1, 가짜 → 0으로 분류
    2. G를 1 스텝 학습
       G(z)가 D를 속이도록

  학습의 어려움:
  ├─ 모드 붕괴(Mode Collapse): G가 소수의 이미지만 생성
  ├─ 학습 불안정: D와 G의 균형이 깨지기 쉬움
  ├─ 그래디언트 소실: D가 너무 강하면 G의 그래디언트 0
  └─ 평가 어려움: 생성 품질의 객관적 측정이 어려움
```

## 2. GAN 아키텍처 진화

```
DCGAN (Radford et al., 2015):
  CNN 기반 안정적 GAN

  설계 지침:
  ├─ 풀링 대신 strided conv (D), fractional-strided conv (G)
  ├─ BatchNorm 사용 (G의 출력, D의 입력 제외)
  ├─ FC 레이어 제거
  ├─ G: ReLU, 마지막 tanh / D: LeakyReLU
  └─ z = 100차원 가우시안 잡음

  → 안정적 학습의 기초를 확립

Progressive GAN (Karras et al., 2017):
  "작은 해상도에서 시작하여 점진적으로 키움"

  4×4 → 8×8 → 16×16 → ... → 1024×1024
  각 해상도에서 레이어를 추가하며 학습
  → 고해상도 학습의 안정성 크게 향상
  → 처음으로 1024×1024 사실적 얼굴 생성

StyleGAN (Karras et al., 2019):
  "스타일 제어가 가능한 생성"

  구조:
  z → Mapping Network(8 FC) → w (스타일 벡터)
  w → AdaIN(Adaptive Instance Norm) → 각 레이어에 주입

  AdaIN: y = γ(w) × (x - μ)/σ + β(w)
  → 스타일 벡터가 정규화의 γ, β를 결정

  스타일 혼합:
  초기 레이어 w₁ (포즈, 형태) + 후기 레이어 w₂ (색상, 텍스처)
  → 두 스타일의 조합 가능!

  | 레이어 | 제어 대상 | 예시 |
  |--------|----------|------|
  | 4-8 (coarse) | 포즈, 얼굴 형태 | 정면/측면 |
  | 16-32 (middle) | 눈, 코, 입 | 안경 유무 |
  | 64-1024 (fine) | 색상, 텍스처 | 피부색, 머리색 |

StyleGAN2/3 개선:
  ├─ v2: 아티팩트 제거, Weight Demodulation
  ├─ v3: 회전/이동에 대한 등변성 (Alias-free)
  └─ FID 개선: FFHQ에서 2.8 → 1.9
```

> **핵심 직관**: StyleGAN의 Mapping Network는 **"잡음 공간(z)을 의미 공간(w)으로 변환"**합니다. z 공간은 가우시안이라 구조가 없지만, w 공간은 학습을 통해 "성별", "나이", "안경" 등의 의미적 축을 가지게 됩니다. 이 분리가 스타일 제어를 가능하게 합니다.

## 3. 조건부 GAN

```
Conditional GAN (cGAN, Mirza & Osindero, 2014):
  조건 정보를 G와 D에 추가

  G(z, c) → 이미지
  D(x, c) → 진짜/가짜

  c: 클래스 레이블, 텍스트, 이미지 등

Pix2Pix (Isola et al., 2017):
  이미지 → 이미지 변환

  입력: 스케치 → 출력: 사진
  입력: 낮 → 출력: 밤
  입력: 세그멘테이션 맵 → 출력: 사진

  PatchGAN 판별기:
  전체 이미지가 아닌 N×N 패치별로 진위 판별
  → 텍스처/스타일의 지역적 일관성에 집중
  → 저수준 디테일 개선

CycleGAN (Zhu et al., 2017):
  비쌍(unpaired) 이미지 변환

  쌍이 있는 데이터: (스케치₁, 사진₁), (스케치₂, 사진₂)
  쌍이 없는 데이터: {말 이미지들}, {얼룩말 이미지들}

  Cycle Consistency:
  x → G(x) → F(G(x)) ≈ x
  "말→얼룩말→말"이 원래와 같아야 함!
  → 비쌍 데이터에서도 의미 있는 변환 학습

  응용: 화풍 변환, 계절 변환, 도메인 적응
```

## 4. GAN 평가 지표

```
FID (Fréchet Inception Distance):
  가장 널리 사용되는 GAN 평가 지표

  Inception v3의 특징 공간에서:
  실제 이미지: (μ_r, Σ_r)
  생성 이미지: (μ_g, Σ_g)

  FID = ||μ_r - μ_g||² + Tr(Σ_r + Σ_g - 2(Σ_r Σ_g)^{1/2})
  → 낮을수록 좋음 (0 = 동일 분포)

  장점: 품질과 다양성을 모두 측정
  단점: Inception 모델에 의존, 최소 50K 샘플 필요

IS (Inception Score):
  IS = exp(E_x[KL(p(y|x) || p(y))])

  ├─ p(y|x): 개별 이미지의 분류 확신 → 높아야 (품질)
  └─ p(y): 전체 이미지의 클래스 분포 → 균등해야 (다양성)

  한계: 모드 붕괴 감지 불완전, 실제 데이터와 비교 안 함

  | 지표 | 측정 대상 | 낮을수록 | 높을수록 |
  |------|----------|---------|---------|
  | FID | 분포 유사도 | ✓ 좋음 | |
  | IS | 품질+다양성 | | ✓ 좋음 |
  | KID | FID의 편향 보정 | ✓ 좋음 | |
```

## 5. GAN의 한계와 Diffusion으로의 전환

```
GAN의 근본적 한계:

  1. 학습 불안정:
     G-D 균형 유지가 어려움
     모드 붕괴: 소수 이미지만 반복 생성
     → 많은 하이퍼파라미터 튜닝 필요

  2. 다양성 부족:
     실제 분포의 일부만 학습하는 경향
     → 생성된 이미지의 다양성이 제한적

  3. 텍스트 조건부 생성의 어려움:
     GAN으로 "고양이가 모자를 쓴 그림"을 생성하기 어려움
     → Diffusion Model이 이 영역을 장악

  4. 고해상도 학습의 어려움:
     해상도가 올라갈수록 학습이 불안정
     → Progressive GAN, StyleGAN의 기법으로 완화

왜 Diffusion이 GAN을 대체했나:
  ├─ 학습 안정성: MSE 기반 → 안정적 수렴
  ├─ 다양성: 전체 분포를 커버
  ├─ 텍스트 조건: CLIP과 자연스럽게 결합
  ├─ 이론적 보장: 로그 우도 기반 학습
  └─ 품질: FID에서도 GAN을 능가

GAN이 여전히 강한 영역:
  ├─ 실시간 생성: 1회 포워드로 생성 (Diffusion은 수십 스텝)
  ├─ 비디오 생성: 시간적 일관성 유지에 유리
  ├─ 이미지 편집: StyleGAN의 잠재 공간 조작
  └─ 초해상도: SRGAN, Real-ESRGAN
```

## 6. GAN의 실전 응용

```
현재 활용되는 GAN 응용:

  초해상도 (Super-Resolution):
  ├─ SRGAN, ESRGAN, Real-ESRGAN
  ├─ 저해상도 → 고해상도 (4×)
  └─ 영상/사진 복원에 실무적으로 사용

  이미지 편집:
  ├─ GAN Inversion: 이미지 → 잠재 벡터 → 편집 → 이미지
  ├─ StyleGAN 편집: 나이 변환, 표정 변화
  └─ e4e, PTI 등 역변환 기법

  데이터 증강:
  ├─ 의료: 희귀 질환 이미지 생성
  ├─ 자율주행: 악천후 조건 합성
  └─ 소수 클래스 오버샘플링

  Deepfake와 탐지:
  ├─ 얼굴 교체, 표정 전이
  ├─ 윤리적 문제: 허위 정보, 사기
  └─ 탐지: GAN 생성 이미지의 특징적 아티팩트 감지
     → responsible-ai에서 다루는 주제

  | 응용 | 모델 | 상태 |
  |------|------|------|
  | 얼굴 생성 | StyleGAN3 | 사실적 |
  | 초해상도 | Real-ESRGAN | 실용적 |
  | 이미지 변환 | CycleGAN | 활용 중 |
  | 텍스트→이미지 | DALL-E 등 | Diffusion으로 이동 |
```

## 핵심 정리

- **GAN**은 생성기와 판별기의 적대적 학습으로 이미지를 생성하며, 최적 평형에서 생성 분포가 실제 분포와 일치합니다
- **StyleGAN**은 Mapping Network로 의미적 스타일 공간을 학습하여, 포즈/표정/색상 등을 독립적으로 제어할 수 있습니다
- **Pix2Pix**(쌍 데이터)와 **CycleGAN**(비쌍 데이터)은 이미지-이미지 변환의 표준이며, Cycle Consistency가 비지도 변환을 가능하게 합니다
- **FID**가 GAN 평가의 표준 지표이며, 실제와 생성 분포의 Inception 특징 공간에서의 거리를 측정합니다
- GAN은 **학습 불안정, 모드 붕괴, 텍스트 조건부 생성의 어려움**으로 Diffusion에 주류를 넘겼지만, 실시간 생성과 초해상도에서 여전히 강점을 가집니다
