# 실험 플랫폼과 실전

## 왜 실험 플랫폼이 필요한가

ed-01부터 ed-09까지 배운 통계적·방법론적 지식을 실제 제품에 적용하려면, 수천 개의 동시 실험을 안정적으로 운영할 수 있는 플랫폼이 필요합니다. Google, Microsoft, Netflix 같은 기업은 연간 수만 건의 실험을 수행하며, 이를 가능하게 하는 것은 견고한 실험 플랫폼 아키텍처, 신뢰할 수 있는 지표 체계, 그리고 실험을 중심에 놓는 조직 문화입니다.

---

## 1. 실험 플랫폼 아키텍처

현대 실험 플랫폼의 핵심 구성 요소입니다.

| 구성 요소 | 역할 | 주요 기능 |
|-----------|------|-----------|
| **배정 서비스** | 사용자를 실험/변형에 배정 | 해싱 기반 결정론적 배정 |
| **설정 관리** | 실험 파라미터 저장/조회 | 실험 생성, 수정, 종료 |
| **데이터 파이프라인** | 이벤트 수집, 집계 | 로그 수집, 지표 계산 |
| **분석 엔진** | 통계 검정, 결과 보고 | 자동화된 분석 리포트 |
| **거버넌스** | 품질 관리, 리뷰 | 실험 리뷰 위원회 |

### 결정론적 배정 (Deterministic Assignment)

해싱 기반 배정은 동일 사용자가 항상 같은 변형에 배정되도록 보장합니다.

$$\text{variant} = \text{hash}(\text{user\_id} \| \text{experiment\_id}) \mod 100$$

```python
import hashlib

def assign_variant(user_id, experiment_id, n_variants=2):
    """해싱 기반 결정론적 변형 배정"""
    key = f"{user_id}:{experiment_id}"
    hash_val = int(hashlib.md5(key.encode()).hexdigest(), 16)
    bucket = hash_val % 100

    # 50-50 배정
    variant_boundaries = [100 // n_variants * i for i in range(1, n_variants)]
    for i, boundary in enumerate(variant_boundaries):
        if bucket < boundary:
            return i
    return n_variants - 1

# 배정 확인
user_ids = [f"user_{i}" for i in range(10000)]
assignments = [assign_variant(uid, "exp_button_color") for uid in user_ids]

import numpy as np
unique, counts = np.unique(assignments, return_counts=True)
for v, c in zip(unique, counts):
    print(f"변형 {v}: {c}명 ({c/len(assignments):.1%})")
```

> **핵심 직관**: 해싱 기반 배정은 상태를 저장하지 않고도 일관된 배정을 보장합니다. 사용자 ID와 실험 ID의 조합으로 결정되므로, 서로 다른 서버에서도 동일한 결과를 반환합니다.

---

## 2. 실험 간 상호작용 관리

여러 실험이 동시에 실행될 때 실험 간 상호작용을 관리해야 합니다.

| 전략 | 설명 | 장단점 |
|------|------|--------|
| **직교 배정** | 독립적 해싱으로 실험 간 독립성 보장 | 분석 용이, 상호작용 무시 |
| **배타적 배정** | 같은 트래픽에 두 실험 동시 실행 불가 | 상호작용 방지, 트래픽 부족 |
| **계층 배정** | 실험을 계층(layer)으로 분리 | Google 방식, 유연함 |

### 계층(Layer) 아키텍처

```
트래픽 100%
  ├── Layer 1 (UI 실험): [실험 A, 실험 B, 실험 C]
  ├── Layer 2 (알고리즘 실험): [실험 D, 실험 E]
  └── Layer 3 (가격 실험): [실험 F]
```

같은 계층 내 실험은 트래픽을 분할하고, 다른 계층의 실험은 직교(독립)합니다.

```python
import hashlib

def layer_assignment(user_id, layer_id, experiment_id, n_variants=2):
    """계층 기반 실험 배정"""
    # 계층별 독립적 해싱
    layer_key = f"{user_id}:{layer_id}"
    layer_hash = int(hashlib.sha256(layer_key.encode()).hexdigest(), 16)
    layer_bucket = layer_hash % 100

    # 실험 내 변형 배정
    exp_key = f"{user_id}:{experiment_id}"
    exp_hash = int(hashlib.md5(exp_key.encode()).hexdigest(), 16)
    variant = exp_hash % n_variants

    return layer_bucket, variant

# 두 계층의 독립성 확인
import numpy as np

n_users = 10000
layer1_buckets = []
layer2_buckets = []

for i in range(n_users):
    b1, _ = layer_assignment(f"user_{i}", "ui_layer", "exp_A")
    b2, _ = layer_assignment(f"user_{i}", "algo_layer", "exp_D")
    layer1_buckets.append(b1)
    layer2_buckets.append(b2)

corr = np.corrcoef(layer1_buckets, layer2_buckets)[0, 1]
print(f"계층 간 상관: {corr:.4f} (0에 가까워야 함)")
```

> **핵심 직관**: 계층 아키텍처는 동일한 사용자가 여러 실험에 동시에 참여하면서도, 실험 간 독립성을 통계적으로 보장합니다.

---

## 3. 지표 설계

좋은 지표는 실험의 성패를 결정합니다.

### 지표 분류 체계

| 지표 유형 | 역할 | 예시 | 특성 |
|-----------|------|------|------|
| **OEC (Overall Evaluation Criterion)** | 의사결정 기준 | 사용자당 세션 수 | 방향성 명확 |
| **가드레일 지표** | 악화되면 안 되는 지표 | 에러율, 지연시간 | 하한 설정 |
| **보조 지표** | 메커니즘 이해 | 클릭률, 스크롤 깊이 | 진단 목적 |
| **장기 지표** | 장기적 건강성 | 재방문율, LTV | 측정 어려움 |

### OEC 설계 원칙

$$\text{좋은 OEC} = \text{민감도} \times \text{방향성} \times \text{장기 가치 대리}$$

| 원칙 | 설명 | 나쁜 예 → 좋은 예 |
|------|------|------------------|
| 민감도 | 작은 변화에도 반응 | 월 매출 → 세션당 매출 |
| 방향성 | 높으면 좋은가 명확 | 세션 시간(모호) → 작업 완료율 |
| 조작 불가 | 의도적 왜곡 어려움 | 클릭 수 → 의미 있는 클릭 |

```python
import numpy as np
from scipy import stats

def metric_sensitivity_comparison(n=10000, effect=0.02):
    """지표 민감도 비교: 어떤 지표가 효과를 더 잘 탐지하는가"""
    np.random.seed(42)

    # 지표 1: 사용자당 클릭 수 (분산 높음)
    clicks_c = np.random.poisson(5, n)
    clicks_t = np.random.poisson(5 * (1 + effect), n)
    t1, p1 = stats.ttest_ind(clicks_t, clicks_c)

    # 지표 2: 클릭 여부 (이진, 분산 낮음)
    click_binary_c = (clicks_c > 0).astype(float)
    click_binary_t = (clicks_t > 0).astype(float)
    t2, p2 = stats.ttest_ind(click_binary_t, click_binary_c)

    # 지표 3: log(클릭 + 1) (분산 감소)
    log_clicks_c = np.log1p(clicks_c)
    log_clicks_t = np.log1p(clicks_t)
    t3, p3 = stats.ttest_ind(log_clicks_t, log_clicks_c)

    print(f"클릭 수:        t={t1:.3f}, p={p1:.4f}")
    print(f"클릭 여부:      t={t2:.3f}, p={p2:.4f}")
    print(f"log(클릭+1):    t={t3:.3f}, p={p3:.4f}")

metric_sensitivity_comparison()
```

> **핵심 직관**: 가장 "자연스러운" 지표가 반드시 가장 좋은 실험 지표는 아닙니다. 변환(로그, 윈저화)을 통해 민감도를 높일 수 있으며, ed-03의 분산 감소 기법과 결합하면 효과가 극대화됩니다.

---

## 4. 데이터 품질과 진단

실험 결과를 신뢰하려면 데이터 품질 검증이 필수입니다.

### SRM (Sample Ratio Mismatch) 검정

배정 비율이 기대와 일치하는지 검정합니다.

$$\chi^2 = \sum_v \frac{(O_v - E_v)^2}{E_v}$$

```python
import numpy as np
from scipy import stats

def srm_check(observed_counts, expected_ratios):
    """SRM(표본 비율 불일치) 검정"""
    total = sum(observed_counts)
    expected_counts = [total * r for r in expected_ratios]

    chi2, p_value = stats.chisquare(observed_counts, expected_counts)

    print(f"관측: {observed_counts}")
    print(f"기대: {[int(e) for e in expected_counts]}")
    print(f"χ² = {chi2:.2f}, p = {p_value:.6f}")

    if p_value < 0.001:
        print("경고: SRM 감지! 실험 결과를 신뢰할 수 없습니다.")
    else:
        print("SRM 없음: 배정 비율 정상")

# 예시 1: 정상
print("=== 정상 케이스 ===")
srm_check([4987, 5013], [0.5, 0.5])

# 예시 2: SRM 존재
print("\n=== SRM 케이스 ===")
srm_check([4500, 5500], [0.5, 0.5])
```

### 주요 진단 항목

| 진단 | 확인 내용 | 문제 시 행동 |
|------|-----------|--------------|
| SRM | 배정 비율 정상 여부 | 실험 중단, 원인 파악 |
| AA 검정 | 처치 전 지표 균형 | 공변량 불균형 확인 |
| 노벨티 효과 | 시간에 따른 효과 변화 | 장기 실험 또는 보정 |
| 시간대 효과 | 요일/시간별 효과 차이 | 전체 주기 포함 확인 |

> **핵심 직관**: SRM은 실험 인프라의 근본적 문제를 나타내며, SRM이 감지되면 어떤 분석 결과도 신뢰할 수 없습니다. 이는 모든 분석의 전제 조건입니다.

---

## 5. 자동화된 분석 파이프라인

대규모 실험 운영에서는 분석의 자동화가 필수입니다.

| 파이프라인 단계 | 자동화 내용 | 구현 요소 |
|----------------|-------------|-----------|
| 데이터 수집 | 이벤트 로그 → 분석 테이블 | ETL, 스트리밍 |
| 지표 계산 | 사용자별 지표 집계 | SQL, Spark |
| 통계 검정 | 자동 검정 + 보정 | ed-02~ed-04 적용 |
| 보고서 생성 | 대시보드, 알림 | 시각화, 자동 해석 |
| 의사결정 지원 | 권고 사항 생성 | 기대 손실 계산 |

```python
import numpy as np
from scipy import stats

class ExperimentAnalyzer:
    """실험 분석 자동화 프레임워크 (간소화)"""

    def __init__(self, y_treat, y_control, alpha=0.05):
        self.y_t = y_treat
        self.y_c = y_control
        self.alpha = alpha

    def basic_stats(self):
        """기본 통계량"""
        return {
            'n_treat': len(self.y_t),
            'n_control': len(self.y_c),
            'mean_treat': self.y_t.mean(),
            'mean_control': self.y_c.mean(),
            'effect': self.y_t.mean() - self.y_c.mean(),
        }

    def frequentist_test(self):
        """빈도주의 검정"""
        t_stat, p_val = stats.ttest_ind(self.y_t, self.y_c)
        diff = self.y_t.mean() - self.y_c.mean()
        se = np.sqrt(self.y_t.var()/len(self.y_t) +
                     self.y_c.var()/len(self.y_c))
        ci = (diff - 1.96*se, diff + 1.96*se)
        return {'t_stat': t_stat, 'p_value': p_val, 'ci': ci}

    def bayesian_analysis(self, n_samples=50000):
        """베이지안 분석 (연속 결과)"""
        # 정규 근사
        diff_samples = np.random.normal(
            self.y_t.mean() - self.y_c.mean(),
            np.sqrt(self.y_t.var()/len(self.y_t) +
                    self.y_c.var()/len(self.y_c)),
            n_samples
        )
        return {
            'prob_positive': (diff_samples > 0).mean(),
            'expected_loss': np.maximum(-diff_samples, 0).mean(),
            'credible_interval': (np.percentile(diff_samples, 2.5),
                                  np.percentile(diff_samples, 97.5))
        }

    def full_report(self):
        """전체 보고서"""
        basic = self.basic_stats()
        freq = self.frequentist_test()
        bayes = self.bayesian_analysis()

        print("=" * 50)
        print("실험 분석 보고서")
        print("=" * 50)
        print(f"표본 크기: 처치={basic['n_treat']}, 통제={basic['n_control']}")
        print(f"평균: 처치={basic['mean_treat']:.4f}, 통제={basic['mean_control']:.4f}")
        print(f"효과: {basic['effect']:.4f}")
        print(f"\n[빈도주의]")
        print(f"  p-값: {freq['p_value']:.4f}")
        print(f"  95% CI: [{freq['ci'][0]:.4f}, {freq['ci'][1]:.4f}]")
        print(f"\n[베이지안]")
        print(f"  P(효과>0): {bayes['prob_positive']:.3f}")
        print(f"  기대 손실: {bayes['expected_loss']:.5f}")
        print(f"  95% CrI: [{bayes['credible_interval'][0]:.4f}, "
              f"{bayes['credible_interval'][1]:.4f}]")

# 사용
np.random.seed(42)
analyzer = ExperimentAnalyzer(
    y_treat=np.random.normal(10.3, 3, 5000),
    y_control=np.random.normal(10.0, 3, 5000)
)
analyzer.full_report()
```

> **핵심 직관**: 자동화된 파이프라인은 분석의 일관성을 보장하고, 연구자의 자유도(researcher degrees of freedom)를 줄여 결과의 신뢰성을 높입니다.

---

## 6. 실험 문화 구축

기술적 인프라만큼 중요한 것이 조직의 실험 문화입니다.

| 문화 요소 | 성숙한 조직 | 미성숙한 조직 |
|-----------|-------------|---------------|
| 의사결정 | 데이터 기반 | 직감/권위 기반 |
| 실패 인식 | 학습의 원천 | 비난의 대상 |
| 실험 범위 | 모든 변경에 실험 | 선택적 실험 |
| 지표 합의 | OEC 사전 합의 | 사후 지표 선택 |
| 결과 공유 | 조직 전체 투명 | 팀 내 제한 |

### 실험 성숙도 모델

| 단계 | 특징 | 연간 실험 수 |
|------|------|-------------|
| 1. 개별 실험 | 임시적, 수동 분석 | < 10 |
| 2. 반복 실험 | 기본 도구, 일부 자동화 | 10-100 |
| 3. 체계적 실험 | 플랫폼 도입, 표준 프로세스 | 100-1,000 |
| 4. 대규모 실험 | 완전 자동화, 문화 내재화 | 1,000-10,000 |
| 5. 실험 주도 | 모든 결정이 실험 기반 | 10,000+ |

```python
# 실험 속도와 가치의 관계 모델링
import numpy as np

def experiment_velocity_value(n_experiments, success_rate=0.15,
                               avg_lift=0.02, revenue=1e8):
    """연간 실험 횟수에 따른 누적 가치 추정"""
    n_successes = int(n_experiments * success_rate)
    # 복리 효과: 각 성공 실험이 기저에 누적
    cumulative_lift = (1 + avg_lift) ** n_successes - 1
    value = revenue * cumulative_lift
    return value, n_successes

for n_exp in [10, 50, 100, 500, 1000]:
    value, n_win = experiment_velocity_value(n_exp)
    print(f"연간 {n_exp:>5}개 실험: {n_win:>3}개 성공, "
          f"매출 증가: {value/1e8:.1%} (기저 대비)")
```

> **핵심 직관**: 실험의 가치는 개별 실험의 효과보다 실험 속도(velocity)에서 나옵니다. 연간 1,000개 실험을 수행하면 복리 효과로 막대한 누적 가치가 창출됩니다.

---

## 7. 실험의 한계와 보완

실험이 만능은 아닙니다. 한계를 인식하고 보완 전략을 갖추어야 합니다.

| 한계 | 설명 | 보완 전략 |
|------|------|-----------|
| 장기 효과 | 실험 기간 내 관측 불가 | 대리 지표, 장기 추적 |
| 작은 효과 | 거대 표본 필요 | ed-03 분산 감소 |
| 윤리적 제약 | 실험 불가 상황 존재 | ci-05 관찰 연구 기법 |
| 외적 타당도 | 다른 맥락으로 일반화 어려움 | 다시장/다국가 복제 |
| 네트워크 효과 | ed-07 간섭 문제 | 클러스터 랜덤화 |
| 복합 효과 | 여러 변경의 누적 | ed-05 팩토리얼 설계 |

실험할 수 없는 상황에서는 ci-05부터 배운 관찰 연구 방법론(매칭, IV, DiD, RDD)이 보완적 도구가 됩니다.

```python
# 실험과 관찰 연구의 결합: 삼각측정(Triangulation)
def triangulation_example():
    """삼각측정: 여러 방법론의 결과가 수렴하는지 확인"""
    results = {
        'A/B 테스트 (단기)': {'effect': 0.05, 'ci': (0.02, 0.08)},
        'DiD (장기)': {'effect': 0.04, 'ci': (0.01, 0.07)},
        'RDD (경계)': {'effect': 0.06, 'ci': (0.01, 0.11)},
    }

    print("방법론별 효과 추정:")
    for method, result in results.items():
        ci = result['ci']
        print(f"  {method:25s}: {result['effect']:.2f} [{ci[0]:.2f}, {ci[1]:.2f}]")

    effects = [r['effect'] for r in results.values()]
    print(f"\n평균 효과: {np.mean(effects):.3f}")
    print(f"방법 간 표준편차: {np.std(effects):.3f}")
    print("→ 수렴: 결과의 강건성 확인" if np.std(effects) < 0.02
          else "→ 발산: 추가 조사 필요")

triangulation_example()
```

> **핵심 직관**: 가장 강력한 인과 추론은 실험과 관찰 연구가 동일한 결론을 가리킬 때 달성됩니다. 단일 방법론에 의존하지 않는 삼각측정(triangulation)이 과학적 엄밀성의 완성입니다.

---

## 핵심 정리

- **해싱 기반 결정론적 배정과 계층 아키텍처는 수천 개의 동시 실험을 독립적으로 운영하는 기반입니다**
- **OEC(핵심 평가 기준)는 민감도, 방향성, 장기 가치 대리성을 갖추어야 하며, 사전에 합의해야 합니다**
- **SRM(표본 비율 불일치) 검정은 모든 분석의 전제 조건이며, 실패 시 결과를 신뢰할 수 없습니다**
- **실험의 누적 가치는 개별 효과보다 실험 속도(velocity)에서 나오며, 성공률 15%의 복리 효과가 막대합니다**
- **실험의 한계(장기 효과, 윤리적 제약 등)는 관찰 연구와의 삼각측정으로 보완하며, 다중 방법론의 수렴이 강건한 인과 추론의 근거입니다**
