# A/B 테스트 방법론

## 왜 A/B 테스트를 체계적으로 이해해야 하는가

A/B 테스트는 산업 현장에서 가장 널리 사용되는 실험 방법이지만, 놀라울 만큼 많은 실무자가 검정력 분석 없이 실험을 시작하거나 중간에 결과를 확인하며 조기 종료하는 실수를 범합니다. ed-01에서 배운 무작위 배정의 원리를 올바르게 적용하려면, 가설 설정부터 표본 크기 결정, 결과 해석까지의 전체 파이프라인을 이해해야 합니다.

---

## 1. 가설 설정

A/B 테스트는 통계적 가설 검정에 기반합니다. si-05에서 다룬 가설 검정의 프레임워크를 실험에 적용합니다.

| 구분 | 기호 | 의미 | 예시 |
|------|------|------|------|
| 귀무가설 | $H_0$ | 처치 효과 없음 | $\mu_T - \mu_C = 0$ |
| 대립가설 | $H_1$ | 처치 효과 존재 | $\mu_T - \mu_C \neq 0$ |
| 단측 대립 | $H_1^+$ | 양의 방향 효과 | $\mu_T - \mu_C > 0$ |

검정 통계량은 두 집단의 평균 차이를 표준 오차로 나눈 값입니다.

$$Z = \frac{\bar{Y}_T - \bar{Y}_C}{\sqrt{\frac{s_T^2}{n_T} + \frac{s_C^2}{n_C}}}$$

> **핵심 직관**: 가설은 실험 시작 전에 명확히 정의해야 합니다. 데이터를 본 후 가설을 수정하면 p-해킹(p-hacking)에 해당합니다.

버튼 색상 A/B 테스트에서 "클릭률이 달라질 것이다"(양측)와 "클릭률이 높아질 것이다"(단측)는 다른 가설입니다.

---

## 2. 표본 크기 결정

적절한 표본 크기는 실험의 성패를 좌우합니다. 표본 크기가 너무 작으면 실제 효과를 탐지하지 못하고, 너무 크면 자원을 낭비합니다.

양측 검정에서 필요한 표본 크기 공식은 다음과 같습니다.

$$n = \frac{(z_{\alpha/2} + z_\beta)^2 \cdot 2\sigma^2}{\delta^2}$$

여기서 $\delta = \mu_T - \mu_C$는 최소 탐지 효과(MDE), $\sigma^2$는 결과 변수의 분산, $\alpha$는 유의 수준, $\beta$는 제2종 오류 확률입니다.

| 파라미터 | 일반적 설정 | 영향 |
|----------|-------------|------|
| $\alpha$ (유의 수준) | 0.05 | 낮출수록 $n$ 증가 |
| $1-\beta$ (검정력) | 0.80 | 높일수록 $n$ 증가 |
| $\delta$ (MDE) | 비즈니스 맥락 의존 | 작을수록 $n$ 증가 |
| $\sigma^2$ (분산) | 과거 데이터 기반 | 클수록 $n$ 증가 |

```python
from scipy import stats
import numpy as np

def sample_size_two_sample(mde, sigma, alpha=0.05, power=0.80):
    """양측 검정에서 필요한 그룹당 표본 크기 계산"""
    z_alpha = stats.norm.ppf(1 - alpha / 2)
    z_beta = stats.norm.ppf(power)
    n = (z_alpha + z_beta) ** 2 * 2 * sigma ** 2 / mde ** 2
    return int(np.ceil(n))

# 클릭률 실험: 기준 CTR 5%, MDE 0.5%p
baseline_ctr = 0.05
mde = 0.005
sigma = np.sqrt(baseline_ctr * (1 - baseline_ctr))

n_per_group = sample_size_two_sample(mde, sigma)
print(f"그룹당 필요 표본 크기: {n_per_group:,}")
# 그룹당 필요 표본 크기: 23,910
```

> **핵심 직관**: MDE를 절반으로 줄이면 필요 표본 크기는 4배로 증가합니다. 비즈니스적으로 의미 있는 최소 효과 크기를 먼저 정의하는 것이 핵심입니다.

---

## 3. 검정력 분석

검정력(power)은 실제 효과가 존재할 때 이를 올바르게 탐지할 확률입니다.

$$\text{Power} = 1 - \beta = P(\text{Reject } H_0 \mid H_1 \text{ is true})$$

검정력은 네 가지 요소의 함수입니다.

$$\text{Power} = f(n, \delta, \sigma, \alpha)$$

```python
from scipy import stats
import numpy as np

def compute_power(n_per_group, mde, sigma, alpha=0.05):
    """주어진 표본 크기에서 검정력 계산"""
    se = sigma * np.sqrt(2 / n_per_group)
    z_alpha = stats.norm.ppf(1 - alpha / 2)
    z_stat = mde / se
    power = 1 - stats.norm.cdf(z_alpha - z_stat) + stats.norm.cdf(-z_alpha - z_stat)
    return power

# 표본 크기별 검정력 곡선
baseline_ctr = 0.05
mde = 0.005
sigma = np.sqrt(baseline_ctr * (1 - baseline_ctr))

for n in [5000, 10000, 15000, 20000, 25000]:
    pwr = compute_power(n, mde, sigma)
    print(f"n = {n:>6,}: Power = {pwr:.3f}")
```

| 표본 크기(그룹당) | 검정력 | 판정 |
|-------------------|--------|------|
| 5,000 | 0.29 | 부족 |
| 10,000 | 0.52 | 부족 |
| 15,000 | 0.70 | 경계 |
| 20,000 | 0.82 | 적절 |
| 25,000 | 0.90 | 충분 |

> **핵심 직관**: 검정력이 80% 미만인 실험은 실제 효과가 있어도 5번 중 1번 이상 놓치게 됩니다. 실험 시작 전 반드시 검정력 분석을 수행해야 합니다.

---

## 4. 실전 A/B 테스트 파이프라인

실무에서 A/B 테스트는 다음의 체계적 단계를 따릅니다.

| 단계 | 핵심 활동 | 주의사항 |
|------|-----------|----------|
| 1. 설계 | 가설 정의, MDE 설정, 표본 크기 계산 | 사전 등록(pre-registration) |
| 2. 배정 | 무작위 배정, AA 테스트 확인 | 배정 비율 검증 |
| 3. 수행 | 데이터 수집, 모니터링 | 피킹(peeking) 금지 |
| 4. 분석 | 통계 검정, 효과 크기 추정 | 사전 정의된 분석 계획 준수 |
| 5. 의사결정 | 출시/미출시/추가 실험 | 통계적 + 실무적 유의성 구분 |

**AA 테스트**는 동일한 처치를 두 집단에 적용하여 실험 인프라의 정상 작동을 확인하는 사전 검증입니다.

```python
import numpy as np
from scipy import stats

# AA 테스트: 두 동일 집단 간 차이가 없어야 함
np.random.seed(42)
n = 10000
group_a = np.random.normal(100, 15, n)
group_b = np.random.normal(100, 15, n)

t_stat, p_value = stats.ttest_ind(group_a, group_b)
print(f"AA 테스트 결과: t = {t_stat:.3f}, p = {p_value:.3f}")
# p > 0.05 → 인프라 정상 작동 확인
```

> **핵심 직관**: 실험을 시작하기 전에 AA 테스트로 시스템의 정상 작동을 확인하지 않으면, 결과의 신뢰성 자체를 보장할 수 없습니다.

---

## 5. 실전 함정: 흔한 실수들

### 5.1 피킹 문제 (Peeking Problem)

실험 중간에 결과를 반복 확인하면 유의 수준 $\alpha$가 팽창합니다.

$$\alpha_{\text{effective}} = 1 - (1 - \alpha)^k \gg \alpha$$

여기서 $k$는 확인 횟수입니다. 매일 확인하며 30일 실험을 하면, 명목 $\alpha = 0.05$라도 실제 위양성 비율은 약 0.40에 달할 수 있습니다.

해결책은 ed-04에서 다루는 순차적 검정(sequential testing)입니다.

### 5.2 다중 비교 문제

여러 지표를 동시에 검정하면 최소 하나에서 위양성이 발생할 확률이 급증합니다.

$$P(\text{최소 1개 위양성}) = 1 - (1 - \alpha)^m$$

| 검정 횟수($m$) | 위양성 확률 |
|----------------|-------------|
| 1 | 5.0% |
| 5 | 22.6% |
| 10 | 40.1% |
| 20 | 64.2% |

```python
# Bonferroni 보정
alpha = 0.05
m = 10  # 검정 횟수
alpha_corrected = alpha / m
print(f"Bonferroni 보정 유의 수준: {alpha_corrected:.4f}")
# 0.0050 — 매우 보수적
```

### 5.3 비율 지표의 함정

비율 지표(예: 전환율)는 분모의 변화에 주의해야 합니다. 버튼 색상 A/B 테스트에서 처치 집단의 페이지 방문 자체가 줄어든다면, 전환율 상승이 실제 개선을 의미하지 않을 수 있습니다.

> **핵심 직관**: A/B 테스트의 가장 위험한 함정은 '통계적으로 유의하다'를 '비즈니스적으로 의미 있다'와 동일시하는 것입니다.

---

## 6. 효과 크기와 실무적 유의성

통계적 유의성과 실무적 유의성은 구분해야 합니다.

| 구분 | 의미 | 기준 |
|------|------|------|
| 통계적 유의성 | 관측된 차이가 우연이 아닌 확률 | $p < \alpha$ |
| 실무적 유의성 | 비즈니스에 의미 있는 효과 크기 | MDE 이상 |

Cohen's $d$는 표준화된 효과 크기 지표입니다.

$$d = \frac{\bar{Y}_T - \bar{Y}_C}{s_p}, \quad s_p = \sqrt{\frac{s_T^2 + s_C^2}{2}}$$

| Cohen's $d$ | 효과 크기 | 해석 |
|-------------|-----------|------|
| 0.2 | 작음 | 미세한 차이 |
| 0.5 | 중간 | 눈에 띄는 차이 |
| 0.8 | 큼 | 명확한 차이 |

```python
import numpy as np

# 효과 크기 계산
y_treat = np.random.normal(10.3, 3, 5000)
y_control = np.random.normal(10.0, 3, 5000)

pooled_std = np.sqrt((y_treat.var() + y_control.var()) / 2)
cohens_d = (y_treat.mean() - y_control.mean()) / pooled_std
print(f"Cohen's d = {cohens_d:.3f}")
```

> **핵심 직관**: 표본이 충분히 크면 어떤 미세한 차이도 통계적으로 유의해집니다. 중요한 것은 효과의 크기가 행동을 바꿀 만큼 의미 있는가입니다.

---

## 7. 신뢰구간 기반 해석

$p$-값에만 의존하는 이분법적 판단보다 신뢰구간 기반 해석이 더 유용합니다.

$$\text{CI}_{1-\alpha} = \hat{\tau} \pm z_{\alpha/2} \cdot \text{SE}(\hat{\tau})$$

신뢰구간은 세 가지 정보를 동시에 전달합니다.

| 신뢰구간 패턴 | 해석 |
|---------------|------|
| $[+, +]$ (0 미포함, 양수) | 통계적으로 유의한 양의 효과 |
| $[-, +]$ (0 포함) | 통계적으로 유의하지 않음 |
| $[-, -]$ (0 미포함, 음수) | 통계적으로 유의한 음의 효과 |
| 구간 폭이 넓음 | 정밀도 부족, 추가 데이터 필요 |

```python
from scipy import stats
import numpy as np

np.random.seed(42)
y_t = np.random.normal(0.52, 1, 3000)
y_c = np.random.normal(0.50, 1, 3000)

diff = y_t.mean() - y_c.mean()
se = np.sqrt(y_t.var()/len(y_t) + y_c.var()/len(y_c))
ci = (diff - 1.96 * se, diff + 1.96 * se)

print(f"효과 추정: {diff:.4f}")
print(f"95% CI: [{ci[0]:.4f}, {ci[1]:.4f}]")
print(f"MDE(0.02) 포함 여부: {ci[0] <= 0.02 <= ci[1]}")
```

> **핵심 직관**: 신뢰구간은 "효과가 있는가?"를 넘어 "효과가 얼마나 클 수 있는가?"를 보여줍니다. 의사결정에 필요한 것은 이분법이 아닌 크기와 불확실성의 범위입니다.

---

## 핵심 정리

- **가설은 실험 시작 전에 사전 등록하고, 데이터를 본 후 수정하면 p-해킹에 해당합니다**
- **표본 크기는 MDE, 분산, 유의 수준, 검정력의 함수이며, MDE 절반 → 표본 4배 증가입니다**
- **피킹(반복 확인)은 유의 수준을 팽창시키며, 이를 방지하려면 순차적 검정을 사용해야 합니다**
- **통계적 유의성과 실무적 유의성은 다르며, 효과 크기(Cohen's d)로 실질적 의미를 평가해야 합니다**
- **p-값보다 신뢰구간이 의사결정에 더 풍부한 정보를 제공하며, 효과의 방향·크기·불확실성을 동시에 전달합니다**
