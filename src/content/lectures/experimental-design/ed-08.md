# 이질적 처치 효과 분석

## 왜 평균을 넘어서야 하는가

ed-01에서 정의한 평균 처치 효과(ATE)는 모집단 전체의 평균적인 효과를 요약하지만, 모든 사용자가 동일한 효과를 경험하는 것은 아닙니다. 버튼 색상 A/B 테스트에서 전체 ATE가 0이더라도, 젊은 사용자에게는 양의 효과가, 고령 사용자에게는 음의 효과가 있을 수 있습니다. 이질적 처치 효과(HTE, Heterogeneous Treatment Effects)를 분석하면 "누구에게 효과가 있는가?"를 파악하여 의사결정을 개인화할 수 있습니다.

---

## 1. 이질적 처치 효과의 정의

**조건부 평균 처치 효과(CATE)**는 공변량 $\mathbf{X}$에 조건부인 처치 효과입니다.

$$\tau(\mathbf{x}) = E[Y(1) - Y(0) \mid \mathbf{X} = \mathbf{x}]$$

| 효과 유형 | 정의 | 해석 |
|-----------|------|------|
| ATE | $E[Y(1) - Y(0)]$ | 모집단 평균 효과 |
| CATE | $E[Y(1) - Y(0) \mid \mathbf{X}]$ | 서브그룹별 효과 |
| ITE | $Y_i(1) - Y_i(0)$ | 개인별 효과 (비관측) |

CATE와 ATE의 관계는 다음과 같습니다.

$$\text{ATE} = E[\tau(\mathbf{X})] = \int \tau(\mathbf{x}) f(\mathbf{x}) d\mathbf{x}$$

> **핵심 직관**: ATE가 0이라도 CATE의 분포가 넓으면, 처치의 혜택을 받는 하위 집단이 존재합니다. 개인화의 가치는 $\text{Var}(\tau(\mathbf{X}))$에 비례합니다.

---

## 2. 서브그룹 분석의 함정

가장 직관적인 HTE 분석은 사전 정의된 서브그룹별로 효과를 추정하는 것입니다. 그러나 여기에는 심각한 함정이 있습니다.

### 다중 비교 문제

$K$개 서브그룹을 분석하면 ed-05에서 다룬 다중 비교 문제가 발생합니다.

$$P(\text{적어도 하나의 위양성}) = 1 - (1-\alpha)^K$$

### 사후적 서브그룹 탐색 (HARKing)

데이터를 보고 서브그룹을 선택하면 과적합됩니다.

```python
import numpy as np
from scipy import stats

def subgroup_mining_demo(n=5000, n_subgroups=20):
    """서브그룹 마이닝의 위험성 데모"""
    np.random.seed(42)

    # 실제 효과 없음 (H0 하에서)
    z = np.random.binomial(1, 0.5, n)
    y = np.random.normal(0, 1, n)

    # 20개 무작위 서브그룹에서 효과 검정
    significant = 0
    for s in range(n_subgroups):
        features = np.random.normal(0, 1, n)
        mask = features > 0  # 임의의 서브그룹
        y_sub = y[mask]
        z_sub = z[mask]

        t, p = stats.ttest_ind(y_sub[z_sub==1], y_sub[z_sub==0])
        if p < 0.05:
            significant += 1

    print(f"{n_subgroups}개 서브그룹 검정 중 {significant}개 '유의' (기대값: {n_subgroups*0.05:.0f})")

subgroup_mining_demo()
```

| 접근법 | 위험 | 대응 |
|--------|------|------|
| 사전 정의 서브그룹 | 다중 비교 | Bonferroni/BH 보정 |
| 사후 탐색 | HARKing, 과적합 | 검증 데이터 분할 |
| 연속형 변수 이분화 | 정보 손실 | 연속형 유지 |

> **핵심 직관**: 서브그룹 분석에서 "유의미한 차이를 찾았다"는 것과 "실제로 차이가 있다"는 것은 완전히 다릅니다. 사후적 탐색은 반드시 독립 데이터로 검증해야 합니다.

---

## 3. 인과 포레스트 (Causal Forest)

인과 포레스트는 Athey & Imbens(2018)가 제안한, CATE를 비모수적으로 추정하는 기계학습 방법입니다.

### 핵심 아이디어

랜덤 포레스트의 분할 기준을 "예측 정확도 최대화"에서 "처치 효과 이질성 최대화"로 변경합니다.

분할 기준: 처치 효과의 분산을 최대화하는 분할을 선택합니다.

$$\max_{c, j} \left[ \hat{\tau}(\mathbf{x} \in \text{left})^2 \cdot |\text{left}| + \hat{\tau}(\mathbf{x} \in \text{right})^2 \cdot |\text{right}| \right]$$

### Honest estimation (정직 추정)

과적합을 방지하기 위해 데이터를 분할합니다.

| 데이터 부분 | 용도 |
|-------------|------|
| 분할 표본 (50%) | 트리 구조(분할) 결정 |
| 추정 표본 (50%) | 리프 내 처치 효과 추정 |

```python
import numpy as np
from sklearn.ensemble import RandomForestRegressor

def simple_causal_forest(n=5000, n_trees=100):
    """인과 포레스트의 핵심 아이디어 (간소화 구현)"""
    np.random.seed(42)

    # 데이터 생성: CATE = x1 > 0일 때 1.0, 아닐 때 0.0
    X = np.random.normal(0, 1, (n, 5))
    z = np.random.binomial(1, 0.5, n)
    true_cate = (X[:, 0] > 0).astype(float)
    y = true_cate * z + np.random.normal(0, 0.5, n)

    # T-learner: 처치/통제 각각에 모델 학습
    X_treat = X[z == 1]
    y_treat = y[z == 1]
    X_control = X[z == 0]
    y_control = y[z == 0]

    model_t = RandomForestRegressor(n_estimators=n_trees, random_state=42)
    model_c = RandomForestRegressor(n_estimators=n_trees, random_state=42)
    model_t.fit(X_treat, y_treat)
    model_c.fit(X_control, y_control)

    # CATE 추정
    cate_hat = model_t.predict(X) - model_c.predict(X)

    # 성능 평가
    from scipy.stats import pearsonr
    corr, _ = pearsonr(true_cate, cate_hat)
    print(f"진짜 CATE와의 상관: {corr:.3f}")
    print(f"X1 > 0 그룹 평균 CATE: {cate_hat[X[:,0] > 0].mean():.3f}")
    print(f"X1 <= 0 그룹 평균 CATE: {cate_hat[X[:,0] <= 0].mean():.3f}")

simple_causal_forest()
```

> **핵심 직관**: 인과 포레스트는 "어떤 공변량 조합이 처치 효과를 가장 크게 변화시키는가?"를 데이터로부터 자동으로 발견합니다. 기존의 사전 정의 서브그룹 분석과 달리, 다차원 공변량 공간에서의 이질성을 유연하게 포착합니다.

---

## 4. 메타 학습자 (Meta-Learners)

CATE 추정을 위한 메타 학습 전략은 기존 기계학습 모델을 조합하여 인과 효과를 추정합니다.

### S-Learner (Single model)

하나의 모델로 처치 변수를 공변량에 포함합니다.

$$\hat{\mu}(\mathbf{x}, z) = \hat{f}(\mathbf{x}, z), \quad \hat{\tau}(\mathbf{x}) = \hat{f}(\mathbf{x}, 1) - \hat{f}(\mathbf{x}, 0)$$

### T-Learner (Two models)

처치/통제 집단에 별도 모델을 학습합니다.

$$\hat{\tau}(\mathbf{x}) = \hat{\mu}_1(\mathbf{x}) - \hat{\mu}_0(\mathbf{x})$$

### X-Learner

이질성이 큰 경우 효율적입니다.

| 단계 | 처치 집단 | 통제 집단 |
|------|-----------|-----------|
| 1단계 | $\hat{\mu}_1(\mathbf{x})$ 학습 | $\hat{\mu}_0(\mathbf{x})$ 학습 |
| 2단계 | $\tilde{D}_i^1 = Y_i^1 - \hat{\mu}_0(\mathbf{x}_i)$ | $\tilde{D}_i^0 = \hat{\mu}_1(\mathbf{x}_i) - Y_i^0$ |
| 3단계 | $\hat{\tau}_1(\mathbf{x})$ 학습 | $\hat{\tau}_0(\mathbf{x})$ 학습 |
| 최종 | $\hat{\tau}(\mathbf{x}) = g(\mathbf{x})\hat{\tau}_0(\mathbf{x}) + (1-g(\mathbf{x}))\hat{\tau}_1(\mathbf{x})$ |

```python
import numpy as np
from sklearn.ensemble import GradientBoostingRegressor

def meta_learners_comparison(n=3000):
    """S-Learner vs T-Learner 비교"""
    np.random.seed(42)

    X = np.random.normal(0, 1, (n, 3))
    z = np.random.binomial(1, 0.5, n)
    true_cate = 0.5 * X[:, 0] + 0.3 * X[:, 1]  # 선형 CATE
    y = 2 + true_cate * z + X[:, 2] + np.random.normal(0, 0.5, n)

    # S-Learner
    X_s = np.column_stack([X, z])
    model_s = GradientBoostingRegressor(n_estimators=100, random_state=42)
    model_s.fit(X_s, y)
    cate_s = model_s.predict(np.column_stack([X, np.ones(n)])) - \
             model_s.predict(np.column_stack([X, np.zeros(n)]))

    # T-Learner
    model_t1 = GradientBoostingRegressor(n_estimators=100, random_state=42)
    model_t0 = GradientBoostingRegressor(n_estimators=100, random_state=42)
    model_t1.fit(X[z==1], y[z==1])
    model_t0.fit(X[z==0], y[z==0])
    cate_t = model_t1.predict(X) - model_t0.predict(X)

    # 평가
    from scipy.stats import pearsonr
    corr_s, _ = pearsonr(true_cate, cate_s)
    corr_t, _ = pearsonr(true_cate, cate_t)
    print(f"S-Learner 상관: {corr_s:.3f}")
    print(f"T-Learner 상관: {corr_t:.3f}")

meta_learners_comparison()
```

| 학습자 | 장점 | 단점 | 적합한 상황 |
|--------|------|------|-------------|
| S-Learner | 단순, 정규화 내재 | 효과를 무시할 수 있음 | 이질성 작을 때 |
| T-Learner | 유연, 비대칭 가능 | 분산 큼 | 이질성 클 때 |
| X-Learner | 비대칭 표본에 강건 | 구현 복잡 | 처치/통제 비율 불균형 |
| DR-Learner | 이중 강건성 | 두 모델 필요 | 일반적으로 권장 |

> **핵심 직관**: 메타 학습자는 "인과 효과 추정"을 "예측 문제의 조합"으로 변환합니다. 어떤 기계학습 모델이든 기저 학습자(base learner)로 사용할 수 있어 유연합니다.

---

## 5. 이중 강건 학습자 (Doubly Robust Learner)

DR-Learner는 ci-05에서 배운 이중 강건 추정의 CATE 버전입니다.

**유사 결과(pseudo-outcome)** 구성:

$$\tilde{Y}_i = \hat{\mu}_1(\mathbf{x}_i) - \hat{\mu}_0(\mathbf{x}_i) + \frac{Z_i(Y_i - \hat{\mu}_1(\mathbf{x}_i))}{e(\mathbf{x}_i)} - \frac{(1-Z_i)(Y_i - \hat{\mu}_0(\mathbf{x}_i))}{1 - e(\mathbf{x}_i)}$$

여기서 $e(\mathbf{x}) = P(Z=1 \mid \mathbf{X}=\mathbf{x})$는 성향 점수입니다. 무작위 실험에서는 $e(\mathbf{x}) = 0.5$입니다.

그 후 $\hat{\tau}(\mathbf{x})$를 $\tilde{Y}$를 목표 변수로 회귀합니다.

$$\hat{\tau} = \arg\min_\tau E[(\tilde{Y} - \tau(\mathbf{X}))^2]$$

```python
import numpy as np
from sklearn.ensemble import GradientBoostingRegressor

def dr_learner(n=5000):
    """이중 강건 학습자 구현"""
    np.random.seed(42)

    X = np.random.normal(0, 1, (n, 3))
    z = np.random.binomial(1, 0.5, n)
    true_cate = np.sin(X[:, 0]) + 0.5 * X[:, 1]
    y = 2 + true_cate * z + 0.5 * X[:, 2] + np.random.normal(0, 0.5, n)

    # 1단계: 결과 모델 학습 (교차 적합)
    from sklearn.model_selection import cross_val_predict
    X_with_z = np.column_stack([X, z])

    model_1 = GradientBoostingRegressor(n_estimators=100, random_state=42)
    model_0 = GradientBoostingRegressor(n_estimators=100, random_state=42)
    model_1.fit(X[z==1], y[z==1])
    model_0.fit(X[z==0], y[z==0])

    mu1_hat = model_1.predict(X)
    mu0_hat = model_0.predict(X)

    # 2단계: 유사 결과 구성 (RCT이므로 e = 0.5)
    e = 0.5
    pseudo_y = (mu1_hat - mu0_hat) + \
               z * (y - mu1_hat) / e - \
               (1 - z) * (y - mu0_hat) / (1 - e)

    # 3단계: CATE 모델 학습
    cate_model = GradientBoostingRegressor(n_estimators=100, random_state=42)
    cate_model.fit(X, pseudo_y)
    cate_hat = cate_model.predict(X)

    from scipy.stats import pearsonr
    corr, _ = pearsonr(true_cate, cate_hat)
    print(f"DR-Learner CATE 상관: {corr:.3f}")
    print(f"평균 CATE: {cate_hat.mean():.3f} (진짜: {true_cate.mean():.3f})")

dr_learner()
```

> **핵심 직관**: DR-Learner는 결과 모델 또는 성향 점수 모델 중 하나만 올바르면 일관된 CATE 추정을 제공합니다. 이는 모델 설정 오류에 대한 보험입니다.

---

## 6. CATE 추정의 평가

CATE 추정의 성능 평가는 독특한 도전입니다. 개별 ITE가 관측되지 않기 때문입니다.

### GATES (Group Average Treatment Effects)

추정된 CATE를 분위수로 나누어 각 분위의 ATE를 추정합니다.

$$\hat{\tau}_q = E[\bar{Y}_T - \bar{Y}_C \mid \hat{\tau}(\mathbf{X}) \in Q_q]$$

```python
import numpy as np
from scipy import stats

def gates_evaluation(n=10000):
    """GATES로 CATE 추정 평가"""
    np.random.seed(42)

    X = np.random.normal(0, 1, (n, 3))
    z = np.random.binomial(1, 0.5, n)
    true_cate = X[:, 0]  # 간단한 선형 CATE
    y = true_cate * z + np.random.normal(0, 1, n)

    # CATE 추정 (여기서는 간단히 처치-통제 차이의 회귀)
    cate_hat = X[:, 0] + np.random.normal(0, 0.3, n)  # 노이즈 추가

    # GATES: 5분위별 평균 효과
    quantiles = np.percentile(cate_hat, [20, 40, 60, 80])
    groups = np.digitize(cate_hat, quantiles)

    print("분위 | 평균 CATE(추정) | 평균 CATE(실제) | 관측 ATE")
    for q in range(5):
        mask = groups == q
        avg_cate_hat = cate_hat[mask].mean()
        avg_true_cate = true_cate[mask].mean()
        y_t = y[mask & (z==1)]
        y_c = y[mask & (z==0)]
        obs_ate = y_t.mean() - y_c.mean() if len(y_t) > 0 and len(y_c) > 0 else np.nan
        print(f"  Q{q+1}  | {avg_cate_hat:>+.3f}         | {avg_true_cate:>+.3f}         | {obs_ate:>+.3f}")

gates_evaluation()
```

| 평가 방법 | 측정 대상 | 장점 |
|-----------|-----------|------|
| GATES | 분위별 ATE 패턴 | 단조성 확인 가능 |
| CLAN | 분위별 공변량 특성 | 해석 가능성 |
| RATE | 순위 가중 ATE | 개인화 가치 측정 |
| 교차 검증 MSE | 유사 결과 예측 오차 | 모델 선택 |

> **핵심 직관**: GATES에서 하위 분위에서 상위 분위로 갈수록 ATE가 단조 증가하면, CATE 추정이 이질성을 올바르게 포착하고 있다는 증거입니다.

---

## 7. 개인화 정책과 의사결정

CATE 추정을 기반으로 최적의 개인화 처치 정책을 수립합니다.

$$\pi^*(\mathbf{x}) = \mathbb{1}[\hat{\tau}(\mathbf{x}) > c]$$

여기서 $c$는 처치 비용 또는 비즈니스 임계값입니다.

| 정책 유형 | 처치 대상 | 예상 가치 |
|-----------|-----------|-----------|
| 전체 처치 | 모든 사용자 | $E[\tau(\mathbf{X})] = \text{ATE}$ |
| 개인화 처치 | $\hat{\tau}(\mathbf{x}) > 0$인 사용자만 | $E[\tau(\mathbf{X}) \mid \tau(\mathbf{X}) > 0]$ |
| 임계값 처치 | $\hat{\tau}(\mathbf{x}) > c$인 사용자만 | $E[\tau(\mathbf{X}) \mid \tau(\mathbf{X}) > c]$ |

```python
import numpy as np

def personalization_value(n=10000):
    """개인화 정책의 가치 계산"""
    np.random.seed(42)

    X = np.random.normal(0, 1, (n, 3))
    true_cate = 0.5 * X[:, 0] + 0.3 * X[:, 1] - 0.2

    # 전체 처치 가치
    value_all = true_cate.mean()

    # 개인화 처치 가치 (CATE > 0인 사용자만)
    positive_mask = true_cate > 0
    value_personalized = true_cate[positive_mask].sum() / n

    # 이상적 가치 (진짜 CATE로 개인화)
    value_ideal = np.maximum(true_cate, 0).mean()

    print(f"전체 처치 가치: {value_all:.3f}")
    print(f"개인화 처치 가치: {value_personalized:.3f}")
    print(f"이상적 가치: {value_ideal:.3f}")
    print(f"개인화 이득: {value_personalized - value_all:.3f}")
    print(f"처치 대상 비율: {positive_mask.mean():.1%}")

personalization_value()
```

ed-06의 문맥적 밴딧과 결합하면, CATE 추정을 실시간으로 업데이트하며 개인화된 처치를 배정하는 시스템을 구축할 수 있습니다.

> **핵심 직관**: 개인화의 가치는 "CATE의 분산"에 비례합니다. 모든 사용자에게 비슷한 효과가 있다면 개인화의 이점이 없지만, 이질성이 크면 개인화로 큰 가치를 창출할 수 있습니다.

---

## 핵심 정리

- **CATE(조건부 평균 처치 효과)는 공변량에 따라 달라지는 처치 효과이며, 개인화 의사결정의 기반입니다**
- **사후적 서브그룹 탐색(HARKing)은 위양성을 만들며, 반드시 독립 데이터로 검증해야 합니다**
- **인과 포레스트는 처치 효과 이질성을 최대화하는 분할을 학습하며, 정직 추정(honest estimation)으로 과적합을 방지합니다**
- **DR-Learner는 결과 모델과 성향 점수 중 하나만 올바르면 일관된 CATE 추정을 제공하는 이중 강건 방법입니다**
- **개인화의 경제적 가치는 CATE 분산에 비례하며, GATES 분석으로 추정의 품질을 평가할 수 있습니다**
