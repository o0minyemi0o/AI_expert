# 베이지안 실험 설계

## 왜 베이지안 관점이 필요한가

ed-02에서 다룬 전통적 A/B 테스트는 빈도주의(frequentist) 프레임워크에 기반하며, $p$-값과 신뢰구간으로 결과를 해석합니다. 그러나 실무에서 의사결정자가 실제로 알고 싶은 것은 "처치가 효과적일 확률은 얼마인가?"입니다. 베이지안 실험 설계는 이 직관적 질문에 직접 답하며, 사전 지식의 체계적 활용, 자연스러운 순차적 분석, 의사결정 이론과의 결합을 가능하게 합니다.

---

## 1. 베이지안 추론의 기초

베이즈 정리는 사전 분포를 데이터로 업데이트하여 사후 분포를 구합니다.

$$p(\theta \mid \text{data}) = \frac{p(\text{data} \mid \theta) \cdot p(\theta)}{p(\text{data})} \propto \text{likelihood} \times \text{prior}$$

| 구성 요소 | 기호 | 역할 |
|-----------|------|------|
| 사전 분포 | $p(\theta)$ | 실험 전 믿음 |
| 우도 | $p(\text{data} \mid \theta)$ | 데이터가 주는 증거 |
| 사후 분포 | $p(\theta \mid \text{data})$ | 업데이트된 믿음 |
| 주변 우도 | $p(\text{data})$ | 정규화 상수 |

> **핵심 직관**: 베이지안 추론은 "데이터를 본 후 파라미터에 대한 불확실성이 어떻게 변하는가?"를 직접 계산합니다. si-05의 빈도주의 검정과 달리, 가설의 사후 확률을 직접 구할 수 있습니다.

---

## 2. 베이지안 A/B 테스트

### 이항 결과(전환율)의 경우

전환율 $p_A$, $p_B$에 대한 베타-이항 모형을 사용합니다.

**사전 분포:**
$$p_A \sim \text{Beta}(\alpha_0, \beta_0), \quad p_B \sim \text{Beta}(\alpha_0, \beta_0)$$

**데이터 관측 후 사후 분포:**
$$p_A \mid \text{data} \sim \text{Beta}(\alpha_0 + s_A, \beta_0 + n_A - s_A)$$
$$p_B \mid \text{data} \sim \text{Beta}(\alpha_0 + s_B, \beta_0 + n_B - s_B)$$

여기서 $s_A$는 집단 A의 전환 수, $n_A$는 총 표본 수입니다.

**핵심 지표: B가 A보다 나을 확률**

$$P(p_B > p_A \mid \text{data}) = \int \int \mathbb{1}[p_B > p_A] \cdot p(p_A, p_B \mid \text{data}) \, dp_A \, dp_B$$

```python
import numpy as np
from scipy import stats

def bayesian_ab_test(n_a, s_a, n_b, s_b, prior_alpha=1, prior_beta=1,
                      n_samples=100000):
    """베이지안 A/B 테스트: B가 A보다 나을 확률"""
    # 사후 분포에서 샘플링
    post_a = np.random.beta(prior_alpha + s_a, prior_beta + n_a - s_a, n_samples)
    post_b = np.random.beta(prior_alpha + s_b, prior_beta + n_b - s_b, n_samples)

    # B > A 확률
    prob_b_wins = (post_b > post_a).mean()
    # 효과 크기 분포
    lift = (post_b - post_a) / post_a
    expected_lift = lift.mean()
    ci_90 = np.percentile(lift, [5, 95])

    print(f"P(B > A) = {prob_b_wins:.3f}")
    print(f"기대 리프트: {expected_lift:.3%}")
    print(f"90% 신용구간: [{ci_90[0]:.3%}, {ci_90[1]:.3%}]")
    return prob_b_wins

# 예: A(통제) 5000명 중 250전환, B(처치) 5000명 중 280전환
bayesian_ab_test(n_a=5000, s_a=250, n_b=5000, s_b=280)
```

| 빈도주의 vs 베이지안 해석 | |
|---|---|
| "$p < 0.05$이므로 유의하다" | "B가 A보다 나을 확률이 96%이다" |
| "95% CI: [0.1%, 1.1%]" | "효과의 90% 신용구간: [0.1%, 1.2%]" |
| "효과가 없다고 할 수 없다" | "효과가 있을 확률이 96%이다" |

> **핵심 직관**: 베이지안 결과는 의사결정자의 언어로 직접 소통됩니다. "이 변경이 효과적일 확률이 96%"는 "$p = 0.03$"보다 훨씬 직관적입니다.

---

## 3. 사전 분포의 설정

사전 분포의 선택은 베이지안 분석에서 가장 중요하면서도 논쟁적인 부분입니다.

| 사전 분포 유형 | 예시 | 적합한 상황 |
|----------------|------|-------------|
| **무정보 사전** | $\text{Beta}(1, 1)$ | 사전 지식 없음 |
| **약한 정보 사전** | $\text{Beta}(5, 95)$ (CTR ~5%) | 과거 실험 범위 알려짐 |
| **정보 사전** | 과거 실험의 사후 분포 | 반복 실험 |
| **회의적 사전** | 효과 0 중심의 좁은 분포 | 보수적 의사결정 |

효과 크기 $\delta = p_B - p_A$에 대한 사전 분포를 직접 설정할 수도 있습니다.

$$\delta \sim \text{Normal}(0, \sigma_\delta^2)$$

```python
import numpy as np
from scipy import stats

def prior_sensitivity_analysis(n_a=5000, s_a=250, n_b=5000, s_b=280):
    """사전 분포 민감도 분석"""
    priors = [
        ("무정보", 1, 1),
        ("약한 정보 (CTR~5%)", 5, 95),
        ("강한 정보 (CTR~5%)", 50, 950),
        ("회의적 (CTR~1%)", 10, 990),
    ]

    for name, alpha, beta in priors:
        post_a = np.random.beta(alpha + s_a, beta + n_a - s_a, 100000)
        post_b = np.random.beta(alpha + s_b, beta + n_b - s_b, 100000)
        prob = (post_b > post_a).mean()
        print(f"{name:25s}: P(B>A) = {prob:.3f}")

prior_sensitivity_analysis()
```

> **핵심 직관**: 데이터가 충분하면 사전 분포의 영향은 미미해집니다(사후 분포가 우도에 지배됨). 그러나 데이터가 적을 때 사전 분포는 결과에 큰 영향을 미치므로, 민감도 분석이 필수입니다.

---

## 4. 신용구간과 사후 예측

### 신용구간 (Credible Interval)

베이지안 신용구간은 빈도주의 신뢰구간과 해석이 다릅니다.

| | 신뢰구간 (CI) | 신용구간 (CrI) |
|---|---|---|
| 해석 | 반복 실험 시 95%가 참값 포함 | 참값이 이 구간에 있을 확률 95% |
| 고정/랜덤 | 구간이 랜덤, 참값은 고정 | 참값이 랜덤(베이지안 관점) |
| 직관성 | 오해하기 쉬움 | 직관적 |

### HPD (Highest Posterior Density) 구간

가장 높은 사후 밀도를 가진 구간으로, 가장 짧은 신용구간입니다.

$$\text{HPD}_\alpha = \{θ : p(θ \mid \text{data}) \geq c_\alpha\}$$

```python
import numpy as np

def hpd_interval(samples, alpha=0.05):
    """HPD 구간 계산"""
    sorted_samples = np.sort(samples)
    n = len(sorted_samples)
    n_include = int(np.ceil((1 - alpha) * n))

    widths = sorted_samples[n_include:] - sorted_samples[:n-n_include]
    min_idx = np.argmin(widths)

    return sorted_samples[min_idx], sorted_samples[min_idx + n_include]

# 예시: 비대칭 사후 분포
np.random.seed(42)
posterior_samples = np.random.beta(30, 270, 100000)  # CTR ~10%

equal_tail = np.percentile(posterior_samples, [2.5, 97.5])
hpd = hpd_interval(posterior_samples)

print(f"동등 꼬리 95% CrI: [{equal_tail[0]:.4f}, {equal_tail[1]:.4f}]")
print(f"HPD 95% CrI:       [{hpd[0]:.4f}, {hpd[1]:.4f}]")
print(f"HPD 폭: {hpd[1]-hpd[0]:.4f}, 동등꼬리 폭: {equal_tail[1]-equal_tail[0]:.4f}")
```

> **핵심 직관**: 베이지안 신용구간은 "파라미터가 이 구간에 있을 확률"이라는 직접적인 확률적 해석을 제공합니다. 빈도주의 신뢰구간의 반복 샘플링 해석보다 의사결정에 더 적합합니다.

---

## 5. 베이지안 의사결정 이론

베이지안 프레임워크는 의사결정 이론과 자연스럽게 결합됩니다.

### 기대 손실 최소화

행동 $a$의 기대 손실은 다음과 같습니다.

$$\text{Expected Loss}(a) = \int L(\theta, a) \cdot p(\theta \mid \text{data}) \, d\theta$$

최적 행동은 기대 손실을 최소화합니다.

$$a^* = \arg\min_a \text{Expected Loss}(a)$$

### A/B 테스트의 손실 함수

| 행동 | 손실 (B가 실제로 더 좋을 때) | 손실 (A가 실제로 더 좋을 때) |
|------|---|---|
| B 출시 | 0 | $p_A - p_B$ (기회비용) |
| A 유지 | $p_B - p_A$ (기회비용) | 0 |

```python
import numpy as np

def expected_loss_decision(n_a=5000, s_a=250, n_b=5000, s_b=280,
                            n_samples=100000):
    """기대 손실 기반 의사결정"""
    np.random.seed(42)

    post_a = np.random.beta(1 + s_a, 1 + n_a - s_a, n_samples)
    post_b = np.random.beta(1 + s_b, 1 + n_b - s_b, n_samples)

    # B를 출시했을 때의 기대 손실
    loss_choose_b = np.maximum(post_a - post_b, 0).mean()

    # A를 유지했을 때의 기대 손실
    loss_choose_a = np.maximum(post_b - post_a, 0).mean()

    print(f"B 출시 시 기대 손실: {loss_choose_b:.5f}")
    print(f"A 유지 시 기대 손실: {loss_choose_a:.5f}")

    if loss_choose_b < loss_choose_a:
        print("의사결정: B 출시 (기대 손실 최소)")
    else:
        print("의사결정: A 유지 (기대 손실 최소)")

    # 실험 계속의 가치 (정보의 기대 가치)
    # 현재 최적 행동의 기대 손실이 임계값 이상이면 추가 데이터 필요
    min_loss = min(loss_choose_b, loss_choose_a)
    print(f"최소 기대 손실: {min_loss:.5f}")
    print(f"손실 임계값 0.001 이하 → {'결정 가능' if min_loss < 0.001 else '추가 데이터 필요'}")

expected_loss_decision()
```

> **핵심 직관**: 기대 손실 프레임워크는 "통계적 유의성"이 아닌 "잘못된 결정의 비용"을 기준으로 판단합니다. 비즈니스 맥락에서 더 합리적인 의사결정 기준입니다.

---

## 6. 순차 베이지안 분석

베이지안 분석은 본질적으로 순차적입니다. ed-04의 피킹 문제가 구조적으로 발생하지 않습니다.

$$p(\theta \mid D_1, D_2) \propto p(D_2 \mid \theta) \cdot p(\theta \mid D_1)$$

"어제까지의 사후 분포"가 "오늘의 사전 분포"가 됩니다.

```python
import numpy as np

def sequential_bayesian_update(daily_data, prior_alpha=1, prior_beta=1):
    """일별 순차 베이지안 업데이트"""
    alpha_a, beta_a = prior_alpha, prior_beta
    alpha_b, beta_b = prior_alpha, prior_beta

    print("일차 | P(B>A) | 기대 손실(B출시) | 판정")
    print("-" * 55)

    for day, (n_a, s_a, n_b, s_b) in enumerate(daily_data, 1):
        # 사후 분포 업데이트
        alpha_a += s_a
        beta_a += n_a - s_a
        alpha_b += s_b
        beta_b += n_b - s_b

        # 사후 샘플링
        post_a = np.random.beta(alpha_a, beta_a, 50000)
        post_b = np.random.beta(alpha_b, beta_b, 50000)

        prob_b_wins = (post_b > post_a).mean()
        exp_loss = np.maximum(post_a - post_b, 0).mean()

        status = "결정 가능" if exp_loss < 0.001 else "계속"
        print(f"  {day:>2}  | {prob_b_wins:.3f} | {exp_loss:.5f}         | {status}")

# 7일간의 일별 데이터 (n_a, s_a, n_b, s_b)
np.random.seed(42)
daily = [(1000, 50, 1000, 58),
         (1000, 48, 1000, 55),
         (1000, 52, 1000, 60),
         (1000, 49, 1000, 57),
         (1000, 51, 1000, 59),
         (1000, 47, 1000, 56),
         (1000, 53, 1000, 61)]

sequential_bayesian_update(daily)
```

| 빈도주의 순차 분석 | 베이지안 순차 분석 |
|---|---|
| 알파 소비 함수 필요 | 자연스럽게 순차적 |
| 피킹 문제 | 피킹 문제 없음 |
| 사전 정보 활용 불가 | 사전 분포 활용 |
| p-값 기반 종료 | 기대 손실 기반 종료 |

> **핵심 직관**: 베이지안 업데이트는 "새 데이터 → 새 사후 분포"의 자연스러운 흐름이므로, 빈도주의에서 필요한 다중 검정 보정이 불필요합니다. 단, 사전 분포의 영향에 대한 투명성이 필요합니다.

---

## 7. 빈도주의 vs 베이지안: 실무 선택 가이드

| 차원 | 빈도주의 | 베이지안 |
|------|----------|----------|
| 해석 직관성 | 낮음 (p-값 오해) | 높음 (확률 직접 해석) |
| 사전 정보 활용 | 불가 | 체계적 활용 |
| 피킹 | 조정 필요 | 자연스러움 |
| 의사결정 통합 | 별도 프레임워크 | 기대 손실로 통합 |
| 계산 비용 | 낮음 | 중~높음 (MCMC) |
| 규제 수용성 | 높음 | 증가 추세 |
| 팀 학습 곡선 | 낮음 | 높음 |

```python
import numpy as np

def compare_approaches(n_a=5000, s_a=250, n_b=5000, s_b=280):
    """빈도주의 vs 베이지안 비교"""
    from scipy import stats

    # 빈도주의: z-검정
    p_a = s_a / n_a
    p_b = s_b / n_b
    se = np.sqrt(p_a*(1-p_a)/n_a + p_b*(1-p_b)/n_b)
    z = (p_b - p_a) / se
    p_val = 2 * (1 - stats.norm.cdf(abs(z)))

    print("=== 빈도주의 ===")
    print(f"z-통계량: {z:.3f}")
    print(f"p-값: {p_val:.4f}")
    print(f"95% CI: [{p_b-p_a-1.96*se:.4f}, {p_b-p_a+1.96*se:.4f}]")

    # 베이지안
    post_a = np.random.beta(1+s_a, 1+n_a-s_a, 100000)
    post_b = np.random.beta(1+s_b, 1+n_b-s_b, 100000)

    print("\n=== 베이지안 ===")
    print(f"P(B > A): {(post_b > post_a).mean():.3f}")
    lift = post_b - post_a
    print(f"기대 효과: {lift.mean():.4f}")
    print(f"95% CrI: [{np.percentile(lift, 2.5):.4f}, {np.percentile(lift, 97.5):.4f}]")
    print(f"기대 손실(B 출시): {np.maximum(post_a-post_b, 0).mean():.5f}")

compare_approaches()
```

ed-10에서 다루는 실험 플랫폼에서는 빈도주의와 베이지안 결과를 병렬로 보고하는 것이 점점 일반적인 관행이 되고 있습니다.

> **핵심 직관**: 베이지안과 빈도주의는 적대적 관계가 아닌 보완적 관계입니다. 데이터가 충분하면 결론은 수렴하며, 차이는 주로 해석의 프레임워크와 의사결정 통합 방식에 있습니다.

---

## 핵심 정리

- **베이지안 A/B 테스트는 "B가 A보다 나을 확률"을 직접 계산하여, p-값보다 직관적인 의사결정을 지원합니다**
- **사전 분포는 과거 실험과 도메인 지식을 체계적으로 반영하며, 데이터가 충분하면 사후 분포에 대한 영향이 감소합니다**
- **기대 손실 최소화는 통계적 유의성이 아닌 비즈니스 비용을 기준으로 최적 행동을 선택하는 의사결정 프레임워크입니다**
- **베이지안 순차 분석은 본질적으로 피킹에 강건하며, 별도의 다중 검정 보정이 필요하지 않습니다**
- **베이지안과 빈도주의는 보완적이며, 실무에서는 두 접근법의 결과를 병렬로 보고하는 것이 권장됩니다**
