# 순차적 검정

## 왜 순차적 검정이 필요한가

ed-02에서 다룬 피킹 문제는 실무에서 가장 흔하면서도 심각한 함정입니다. 고정 표본 검정은 사전에 정해진 표본 크기에 도달한 후 단 한 번만 분석하도록 설계되었지만, 현실에서는 매일 대시보드를 확인하고 빠른 의사결정을 원합니다. 순차적 검정(sequential testing)은 이 긴장을 해소하여, 반복 확인하면서도 유의 수준을 보증하는 통계적 프레임워크를 제공합니다.

---

## 1. 피킹 문제의 수학적 이해

고정 표본 검정에서 유의 수준 $\alpha = 0.05$는 **단 한 번** 검정할 때의 위양성 확률입니다. $k$번 확인하면 실제 위양성 확률은 급격히 증가합니다.

$$\alpha_{\text{eff}} \approx 1 - (1 - \alpha)^k$$

이를 시뮬레이션으로 확인합니다.

```python
import numpy as np
from scipy import stats

def simulate_peeking(n_sims=10000, n_max=10000, n_peeks=20, alpha=0.05):
    """피킹이 위양성률에 미치는 영향 시뮬레이션"""
    false_positives = 0
    peek_points = np.linspace(500, n_max, n_peeks, dtype=int)

    for _ in range(n_sims):
        # H0 하에서 데이터 생성 (효과 없음)
        y_t = np.random.normal(0, 1, n_max)
        y_c = np.random.normal(0, 1, n_max)

        for n in peek_points:
            t_stat, p_val = stats.ttest_ind(y_t[:n], y_c[:n])
            if p_val < alpha:
                false_positives += 1
                break

    return false_positives / n_sims

fpr = simulate_peeking(n_sims=5000)
print(f"20번 피킹 시 실제 위양성률: {fpr:.3f}")
# 약 0.15~0.20 (명목 0.05보다 3~4배 높음)
```

| 피킹 횟수 | 명목 $\alpha$ | 실제 위양성률 |
|-----------|---------------|---------------|
| 1 | 0.05 | 0.05 |
| 5 | 0.05 | ~0.14 |
| 10 | 0.05 | ~0.19 |
| 20 | 0.05 | ~0.25 |
| 연속 모니터링 | 0.05 | ~0.40+ |

> **핵심 직관**: 피킹은 "여러 번 주사위를 던져 원하는 눈이 나오면 멈추는" 것과 같습니다. 시행 횟수가 늘면 원하는 결과를 얻을 확률이 올라갑니다.

---

## 2. 그룹 순차 검정 (Group Sequential Testing)

그룹 순차 검정은 사전에 정해진 중간 분석 시점에서 검정하되, 유의 수준을 분할하여 전체 $\alpha$를 보증합니다.

### O'Brien-Fleming 경계

가장 보수적인 초기 경계를 설정하여, 후반부에서는 고정 표본 검정과 거의 동일한 임계값을 사용합니다.

$$z_k = \frac{c}{\sqrt{t_k}}, \quad t_k = \frac{k}{K}$$

여기서 $K$는 총 분석 횟수, $k$는 현재 분석 시점, $c$는 전체 $\alpha$를 맞추는 상수입니다.

| 분석 시점 ($k/K$) | O'Brien-Fleming | Pocock |
|-------------------|-----------------|--------|
| 0.25 | 4.05 | 2.36 |
| 0.50 | 2.86 | 2.36 |
| 0.75 | 2.34 | 2.36 |
| 1.00 | 2.02 | 2.36 |

```python
import numpy as np
from scipy import stats

def obrien_fleming_boundary(n_analyses, alpha=0.05):
    """O'Brien-Fleming 경계 근사 계산"""
    boundaries = []
    for k in range(1, n_analyses + 1):
        t_k = k / n_analyses
        z_k = stats.norm.ppf(1 - alpha / 2) / np.sqrt(t_k)
        boundaries.append(z_k)
    return boundaries

K = 4
bounds = obrien_fleming_boundary(K)
for k, b in enumerate(bounds, 1):
    info_frac = k / K
    print(f"분석 {k} (정보 분율 {info_frac:.2f}): z 경계 = {b:.3f}")
```

> **핵심 직관**: O'Brien-Fleming 경계는 초기에 매우 높은 기준을 요구하여 성급한 종료를 방지하고, 최종 분석에서는 거의 $z_{0.025} \approx 1.96$에 수렴합니다.

---

## 3. 알파 소비 함수 (Alpha Spending Function)

Lan-DeMets 알파 소비 함수는 정보 분율의 연속 함수로 유의 수준을 분배합니다.

$$\alpha^*(t) = \text{(정보 분율 } t \text{까지 소비된 누적 } \alpha\text{)}$$

O'Brien-Fleming형 소비 함수:

$$\alpha^*(t) = 2 - 2\Phi\left(\frac{z_{\alpha/2}}{\sqrt{t}}\right)$$

Pocock형 소비 함수:

$$\alpha^*(t) = \alpha \ln(1 + (e-1)t)$$

```python
import numpy as np
from scipy import stats

def obf_spending(t, alpha=0.05):
    """O'Brien-Fleming형 알파 소비 함수"""
    return 2 - 2 * stats.norm.cdf(stats.norm.ppf(1 - alpha/2) / np.sqrt(t))

def pocock_spending(t, alpha=0.05):
    """Pocock형 알파 소비 함수"""
    return alpha * np.log(1 + (np.e - 1) * t)

info_fracs = [0.25, 0.5, 0.75, 1.0]
print("정보 분율 | OBF 소비 | Pocock 소비")
for t in info_fracs:
    print(f"  {t:.2f}     | {obf_spending(t):.5f}  | {pocock_spending(t):.5f}")
```

| 특성 | O'Brien-Fleming형 | Pocock형 |
|------|-------------------|----------|
| 초기 종료 가능성 | 낮음 (큰 효과만) | 높음 |
| 최종 임계값 | 고정 검정과 유사 | 더 높음 |
| 검정력 손실 | 거의 없음 | 약간 있음 |
| 실무 선호도 | 높음 | 중간 |

> **핵심 직관**: 알파 소비 함수는 유의 수준이라는 "예산"을 실험 진행에 따라 어떻게 "지출"할지 결정하는 전략입니다.

---

## 4. 항상-유효 신뢰구간 (Always-Valid Confidence Intervals)

항상-유효 CI는 어느 시점에서 확인하더라도 커버리지가 보장되는 신뢰구간입니다.

$$P\left(\forall t \geq 1: \tau \in \text{CI}_t \right) \geq 1 - \alpha$$

이는 고정 표본 CI의 조건과 본질적으로 다릅니다.

| 유형 | 보장 | 수학적 조건 |
|------|------|-------------|
| 고정 CI | 특정 시점 $t^*$에서 커버리지 | $P(\tau \in \text{CI}_{t^*}) \geq 1-\alpha$ |
| 항상-유효 CI | **모든** 시점에서 동시 커버리지 | $P(\forall t: \tau \in \text{CI}_t) \geq 1-\alpha$ |

혼합 순차 확률비 검정(mSPRT) 기반 CI는 다음과 같이 구성됩니다.

$$\text{CI}_t = \hat{\tau}_t \pm \sqrt{\frac{2\hat{\sigma}^2}{n_t} \left(\log\frac{1}{\alpha} + \frac{d}{2}\log\frac{n_t}{n_0}\right)}$$

```python
import numpy as np

def always_valid_ci(y_treat, y_control, alpha=0.05, n0=100):
    """혼합 순차 비율 검정 기반 항상-유효 CI (근사)"""
    n_t = len(y_treat)
    n_c = len(y_control)
    n = min(n_t, n_c)

    tau_hat = y_treat[:n].mean() - y_control[:n].mean()
    sigma2 = (y_treat[:n].var() + y_control[:n].var()) / 2

    # mSPRT 기반 반폭
    d = 1  # 혼합 분포 차원
    half_width = np.sqrt(
        2 * sigma2 / n * (np.log(1 / alpha) + d / 2 * np.log(n / n0))
    )
    return tau_hat, tau_hat - half_width, tau_hat + half_width

np.random.seed(42)
n_max = 10000
y_t = np.random.normal(0.3, 1, n_max)
y_c = np.random.normal(0, 1, n_max)

for n in [500, 1000, 2000, 5000, 10000]:
    est, lo, hi = always_valid_ci(y_t[:n], y_c[:n])
    print(f"n={n:>5}: ATE={est:.3f}, AV-CI=[{lo:.3f}, {hi:.3f}]")
```

> **핵심 직관**: 항상-유효 CI는 고정 CI보다 넓지만, 그 대가로 "언제 봐도 유효한" 보장을 제공합니다. 연속 모니터링이 필요한 실무 환경에 이상적입니다.

---

## 5. 조기 종료 규칙

순차적 검정에서 조기 종료는 두 가지 방향으로 발생합니다.

| 종료 유형 | 조건 | 의미 |
|-----------|------|------|
| **효능 종료(Efficacy)** | 검정 통계량 > 상위 경계 | 처치 효과 확인, 출시 |
| **무용 종료(Futility)** | 검정 통계량 < 하위 경계 | 효과 없음 확인, 중단 |

무용 경계의 계산은 조건부 검정력(conditional power)에 기반합니다.

$$\text{CP}(t) = P(\text{최종 기각} \mid \text{현재까지 데이터})$$

```python
import numpy as np
from scipy import stats

def conditional_power(z_current, info_frac, z_alpha=1.96):
    """현재 시점의 조건부 검정력 계산"""
    t = info_frac
    z_final_needed = (z_alpha - z_current * np.sqrt(t)) / np.sqrt(1 - t)
    cp = 1 - stats.norm.cdf(z_final_needed)
    return cp

# 정보 분율 50%에서 다양한 z 통계량의 조건부 검정력
for z in [0.0, 0.5, 1.0, 1.5, 2.0, 2.5]:
    cp = conditional_power(z, info_frac=0.5)
    print(f"z = {z:.1f}: 조건부 검정력 = {cp:.3f}")
```

| 조건부 검정력 | 권장 행동 |
|---------------|-----------|
| < 10% | 무용 종료 고려 |
| 10-50% | 계속 진행 |
| > 50% | 유망, 계속 진행 |
| 경계 초과 | 효능 종료 |

버튼 색상 A/B 테스트에서 중간 분석 시 조건부 검정력이 5%라면, 실험을 계속해도 유의한 결과를 얻을 가능성이 극히 낮으므로 자원을 절약하기 위해 조기 종료할 수 있습니다.

> **핵심 직관**: 무용 종료는 "희망이 없는 실험을 빨리 끝내는" 전략으로, 실험 자원을 더 유망한 가설에 재배분할 수 있게 합니다.

---

## 6. 실무 구현: 순차 검정 프레임워크

실무에서 순차적 검정을 구현하는 전체 파이프라인입니다.

```python
import numpy as np
from scipy import stats

class SequentialTest:
    """간단한 그룹 순차 검정 구현"""

    def __init__(self, n_analyses, alpha=0.05, spending='obf'):
        self.K = n_analyses
        self.alpha = alpha
        self.spending = spending
        self.results = []

    def _spending_function(self, t):
        if self.spending == 'obf':
            return 2 - 2 * stats.norm.cdf(
                stats.norm.ppf(1 - self.alpha/2) / np.sqrt(t)
            )
        else:  # pocock
            return self.alpha * np.log(1 + (np.e - 1) * t)

    def analyze(self, k, y_treat, y_control):
        """k번째 중간 분석 수행"""
        t = k / self.K
        alpha_spent = self._spending_function(t)

        # 이전까지 소비된 알파 차감
        if self.results:
            alpha_spent -= self._spending_function((k-1) / self.K)

        z_boundary = stats.norm.ppf(1 - alpha_spent / 2)
        z_stat = (y_treat.mean() - y_control.mean()) / \
                 np.sqrt(y_treat.var()/len(y_treat) + y_control.var()/len(y_control))

        decision = "계속" if abs(z_stat) < z_boundary else "종료"
        self.results.append({
            'k': k, 't': t, 'z_stat': z_stat,
            'z_boundary': z_boundary, 'decision': decision
        })
        return decision, z_stat, z_boundary

# 사용 예시
np.random.seed(42)
seq_test = SequentialTest(n_analyses=4, alpha=0.05)
n_total = 20000
effect = 0.15

for k in range(1, 5):
    n_k = (n_total // 4) * k
    y_t = np.random.normal(effect, 1, n_k)
    y_c = np.random.normal(0, 1, n_k)
    decision, z, boundary = seq_test.analyze(k, y_t, y_c)
    print(f"분석 {k}: z={z:.3f}, 경계={boundary:.3f}, 결정={decision}")
```

> **핵심 직관**: 순차적 검정 프레임워크는 통계적 엄밀성을 유지하면서 빠른 의사결정을 가능하게 하는 실무 도구입니다. ed-06의 다중 밴딧과는 달리 가설 검정의 프레임워크 내에서 작동합니다.

---

## 7. 고정 검정 vs 순차 검정 비교

| 차원 | 고정 표본 검정 | 순차 검정 |
|------|---------------|-----------|
| 표본 크기 | 사전 고정 | 유동적 (상한 존재) |
| 중간 확인 | 불가 (유의 수준 팽창) | 가능 (경계 조정) |
| 유의 수준 | 단일 임계값 | 시간별 경계 |
| 기대 표본 크기 | 항상 $n$ | 효과 존재 시 $< n$ |
| 구현 난이도 | 낮음 | 중간~높음 |
| 적합한 상황 | 일회성 실험 | 연속 모니터링 |

순차적 검정의 주요 비용은 최대 표본 크기가 고정 검정보다 약 3-5% 증가한다는 점이지만, 효과가 클 때 조기 종료로 절약하는 자원이 이를 상쇄합니다.

> **핵심 직관**: 순차적 검정은 "통계적 엄밀성"과 "실무적 유연성" 사이의 최적 균형점입니다. 대부분의 온라인 실험 플랫폼은 이를 기본으로 제공합니다.

---

## 핵심 정리

- **피킹(반복 확인)은 유의 수준을 명목 5%에서 최대 40% 이상까지 팽창시키며, 이는 수학적으로 증명된 문제입니다**
- **그룹 순차 검정은 O'Brien-Fleming 또는 Pocock 경계로 중간 분석을 허용하면서 전체 유의 수준을 보증합니다**
- **알파 소비 함수는 유의 수준 예산을 실험 진행에 따라 전략적으로 배분하는 연속적 프레임워크입니다**
- **항상-유효 신뢰구간은 어느 시점에서 확인하더라도 커버리지를 보장하여, 연속 모니터링 환경에 적합합니다**
- **조기 종료는 효능(효과 확인)과 무용(효과 부재 확인) 두 방향 모두 가능하며, 조건부 검정력으로 판단합니다**
