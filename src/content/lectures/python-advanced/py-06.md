# 메모리 모델과 가비지 컬렉션

## 왜 메모리 모델을 이해해야 하는가

대규모 데이터나 ML 모델을 다룰 때, "왜 메모리가 해제되지 않는가", "왜 이 객체가 아직 살아있는가"라는 질문에 답하려면 Python의 메모리 관리 메커니즘을 알아야 합니다. **레퍼런스 카운팅**, **세대별 GC**, **`__slots__`**, **weakref**는 실전 최적화에서 반복적으로 등장하는 개념입니다.

---

## 1. 모든 것은 객체이고, 변수는 이름표이다

Python에서 변수는 값을 저장하는 "상자"가 아닙니다. 힙에 있는 객체를 가리키는 **이름표(reference)**입니다.

```python
a = [1, 2, 3]
b = a  # 같은 리스트 객체를 가리키는 새 이름표

b.append(4)
print(a)  # [1, 2, 3, 4] — 같은 객체이므로 a도 변경됨

print(id(a) == id(b))  # True
print(a is b)          # True
```

### 객체의 구조

모든 Python 객체는 C 레벨에서 다음을 포함합니다:

| 필드 | 크기 | 역할 |
|------|------|------|
| `ob_refcnt` | 8 bytes | 레퍼런스 카운트 |
| `ob_type` | 8 bytes | 타입 객체에 대한 포인터 |
| 객체 데이터 | 가변 | 실제 값 |

```python
import sys

# 빈 객체도 기본 오버헤드가 있음
print(sys.getsizeof(object()))  # 16 bytes
print(sys.getsizeof(42))        # 28 bytes (정수)
print(sys.getsizeof("hello"))   # 54 bytes (문자열)
print(sys.getsizeof([]))        # 56 bytes (빈 리스트)
print(sys.getsizeof({}))        # 64 bytes (빈 딕셔너리)
```

> **핵심 직관**: Python의 모든 값은 힙에 할당된 객체이며, 변수는 이 객체에 대한 포인터입니다. 정수 `42`도 28바이트의 객체입니다.

---

## 2. 레퍼런스 카운팅

Python의 **1차 메모리 관리**는 레퍼런스 카운팅(reference counting)입니다.

```python
import sys

a = [1, 2, 3]
print(sys.getrefcount(a))  # 2 (a + getrefcount 인자)

b = a
print(sys.getrefcount(a))  # 3

c = [a, a, a]
print(sys.getrefcount(a))  # 6

del b
print(sys.getrefcount(a))  # 5

c = None
print(sys.getrefcount(a))  # 2 (리스트의 3개 참조 제거)
```

### 레퍼런스 카운트가 증가하는 경우

1. 변수에 할당: `b = a`
2. 컨테이너에 추가: `lst.append(a)`
3. 함수 인자로 전달: `func(a)`
4. 속성으로 설정: `obj.attr = a`

### 레퍼런스 카운트가 감소하는 경우

1. 변수 삭제: `del b`
2. 변수 재할당: `b = other`
3. 컨테이너에서 제거: `lst.remove(a)`
4. 스코프 종료: 함수 반환

**레퍼런스 카운트가 0이 되면 즉시 `__del__` 호출 후 메모리 해제**됩니다. 이것이 Python의 결정론적(deterministic) 메모리 관리입니다.

---

## 3. 순환 참조 문제

레퍼런스 카운팅만으로는 해결할 수 없는 문제가 있습니다.

```python
class Node:
    def __init__(self, name):
        self.name = name
        self.next = None
    def __del__(self):
        print(f"Deleting {self.name}")

# 순환 참조 생성
a = Node("A")
b = Node("B")
a.next = b  # A → B
b.next = a  # B → A (순환!)

del a  # A의 refcount: 2→1 (b.next가 아직 참조)
del b  # B의 refcount: 2→1 (a.next가 아직 참조)
# 둘 다 refcount > 0이지만, 외부에서 접근 불가능!
```

`a`와 `b`는 서로를 참조하므로 레퍼런스 카운트가 0이 되지 않습니다. 하지만 외부에서는 접근할 수 없는 **쓰레기(garbage)**입니다.

---

## 4. 세대별 가비지 컬렉션

Python의 **2차 메모리 관리**인 세대별 GC(generational garbage collector)가 순환 참조를 처리합니다.

### 세대 구조

| 세대 | 설명 | GC 빈도 |
|------|------|---------|
| 0세대 | 새로 생성된 객체 | 가장 잦음 |
| 1세대 | 0세대 GC에서 살아남은 객체 | 중간 |
| 2세대 | 1세대 GC에서 살아남은 객체 | 가장 드묾 |

```python
import gc

# GC 상태 확인
print(gc.get_threshold())  # (700, 10, 10) — 기본 임계값

# 0세대: 할당 - 해제 > 700이면 GC
# 1세대: 0세대 GC가 10번 실행되면 1세대 GC
# 2세대: 1세대 GC가 10번 실행되면 2세대 GC
```

### GC 동작 원리

1. 컨테이너 객체(리스트, 딕셔너리, 클래스 인스턴스 등)만 추적
2. 각 객체의 "임시 레퍼런스 카운트"를 계산
3. 내부 참조를 제거한 후에도 도달 가능한 객체만 살림
4. 도달 불가능한 객체(순환 참조 쓰레기)를 수거

```python
import gc

# 수동 GC 실행
collected = gc.collect()
print(f"Collected {collected} objects")

# GC 통계
print(gc.get_stats())

# 순환 참조 탐지
gc.set_debug(gc.DEBUG_SAVEALL)
gc.collect()
print(gc.garbage)  # 수거된 순환 참조 객체들
```

> **핵심 직관**: 레퍼런스 카운팅은 "즉시 정리"를, 세대별 GC는 "순환 참조 정리"를 담당합니다. 대부분의 객체는 레퍼런스 카운팅으로 정리되고, GC는 보충 역할입니다.

---

## 5. `__slots__`: 메모리 최적화

기본적으로 Python 객체는 `__dict__`(딕셔너리)에 속성을 저장합니다. `__slots__`를 사용하면 고정 크기 배열로 대체합니다.

```python
import sys

class PointDict:
    def __init__(self, x, y):
        self.x = x
        self.y = y

class PointSlots:
    __slots__ = ("x", "y")
    def __init__(self, x, y):
        self.x = x
        self.y = y

# 메모리 비교
d = PointDict(1, 2)
s = PointSlots(1, 2)

print(sys.getsizeof(d) + sys.getsizeof(d.__dict__))  # ~152 bytes
print(sys.getsizeof(s))                                # ~48 bytes
```

### `__slots__`의 효과

| 항목 | `__dict__` | `__slots__` |
|------|-----------|------------|
| 인스턴스 크기 | ~152 bytes | ~48 bytes |
| 속성 접근 속도 | 해시 조회 | 인덱스 접근 (더 빠름) |
| 동적 속성 추가 | 가능 | **불가능** |
| 100만 인스턴스 | ~152 MB | ~48 MB |

### 주의사항

```python
class PointSlots:
    __slots__ = ("x", "y")

p = PointSlots(1, 2)
p.z = 3  # AttributeError: 'PointSlots' has no attribute 'z'
```

`__slots__`는 동적 속성 추가를 차단합니다. 유연성을 포기하고 메모리를 절약하는 트레이드오프입니다.

---

## 6. weakref: 약한 참조

약한 참조(weak reference)는 레퍼런스 카운트를 **증가시키지 않는** 참조입니다.

```python
import weakref

class BigData:
    def __init__(self, name):
        self.name = name
    def __repr__(self):
        return f"BigData({self.name})"

# 강한 참조
data = BigData("important")
cache = weakref.ref(data)  # 약한 참조

print(cache())   # BigData(important) — 아직 살아있음
del data         # 레퍼런스 카운트 0 → 즉시 해제
print(cache())   # None — 이미 해제됨
```

### WeakValueDictionary: 캐시 구현

```python
import weakref

class ExpensiveObject:
    def __init__(self, key):
        self.key = key
        self.data = list(range(10000))  # 비용 큰 데이터

cache = weakref.WeakValueDictionary()

def get_object(key):
    obj = cache.get(key)
    if obj is not None:
        return obj
    obj = ExpensiveObject(key)
    cache[key] = obj
    return obj

a = get_object("key1")  # 새로 생성
b = get_object("key1")  # 캐시에서 반환 (a와 같은 객체)
print(a is b)  # True

del a, b  # 외부 참조 모두 제거
# → cache에서도 자동으로 사라짐 (약한 참조이므로)
```

> **핵심 직관**: 약한 참조는 "있으면 쓰고, 없으면 말고"의 의미입니다. 캐시처럼 **보조적인 참조**에 사용하여, 본체가 사라지면 자연스럽게 정리되도록 합니다.

---

## 7. 메모리 프로파일링

### tracemalloc: 메모리 할당 추적

```python
import tracemalloc

tracemalloc.start()

# 메모리를 사용하는 코드
data = [list(range(1000)) for _ in range(1000)]

snapshot = tracemalloc.take_snapshot()
top_stats = snapshot.statistics("lineno")

print("Top 5 memory allocations:")
for stat in top_stats[:5]:
    print(stat)
```

### objgraph: 객체 참조 그래프

```python
import objgraph

class Leaky:
    pass

# 순환 참조 생성
a = Leaky()
b = Leaky()
a.ref = b
b.ref = a

# 가장 많이 증가한 타입
objgraph.show_growth()

# 특정 객체의 참조 그래프
objgraph.show_refs([a], filename="refs.png")
objgraph.show_backrefs([a], filename="backrefs.png")
```

### 메모리 누수 탐지 패턴

```python
import gc

# 1단계: GC 수동 실행
gc.collect()

# 2단계: 특정 타입의 객체 수 확인
before = len(gc.get_objects())

# 의심되는 코드 실행
for _ in range(1000):
    do_something()

gc.collect()
after = len(gc.get_objects())
print(f"Object count change: {after - before}")
```

---

## 8. 인턴닝과 최적화

Python은 자주 사용되는 값을 미리 캐시합니다.

```python
# 작은 정수 인턴닝 (-5 ~ 256)
a = 256
b = 256
print(a is b)  # True (같은 객체)

a = 257
b = 257
print(a is b)  # False (다른 객체) — 인터프리터에 따라 다를 수 있음

# 문자열 인턴닝
a = "hello"
b = "hello"
print(a is b)  # True (컴파일 타임 상수)

a = "hello world"
b = "hello world"
print(a is b)  # True 또는 False (구현에 따라 다름)
```

| 최적화 | 대상 | 효과 |
|--------|------|------|
| 소정수 캐시 | -5 ~ 256 | 같은 정수 객체 공유 |
| 문자열 인턴 | 식별자 형태 문자열 | 같은 문자열 객체 공유 |
| peephole | 컴파일 타임 상수 | 바이트코드 최적화 |

---

## 9. ML에서의 의미

### GPU 메모리 관리

PyTorch에서 `torch.cuda.empty_cache()`는 Python의 GC와 CUDA 메모리 풀의 관계를 이해해야 합니다. Python 측에서 텐서 참조를 해제해도 CUDA 캐시에 남아있을 수 있습니다.

```python
import torch
import gc

# GPU 메모리 누수 패턴
del large_tensor
gc.collect()
torch.cuda.empty_cache()  # CUDA 캐시도 명시적으로 해제
```

### 대규모 데이터셋

수백만 개의 데이터 포인트를 객체로 만들 때 `__slots__`로 인스턴스당 100바이트 이상 절약할 수 있습니다.

### 모델 캐시

모델 추론 서버에서 weakref 기반 캐시를 사용하면, 메모리 압박 시 자동으로 불필요한 모델이 해제됩니다.

---

## 핵심 정리

1. Python의 변수는 힙 객체에 대한 **이름표(참조)**이며, 모든 값은 `ob_refcnt`를 가진 객체이다.
2. **레퍼런스 카운팅**이 1차 메모리 관리이며, 카운트가 0이 되면 **즉시** 해제된다.
3. **세대별 GC**가 순환 참조를 처리하며, 0/1/2세대로 나뉘어 세대가 높을수록 덜 자주 수거한다.
4. **`__slots__`**는 `__dict__`를 제거하여 인스턴스당 메모리를 ~3배 절약하지만, 동적 속성 추가가 불가능하다.
5. **weakref**는 레퍼런스 카운트를 증가시키지 않는 참조로, 캐시 구현에 이상적이다.
