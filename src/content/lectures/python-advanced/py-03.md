# 제너레이터와 코루틴

## 왜 제너레이터를 배워야 하는가

대량의 데이터를 처리할 때 리스트에 모두 올리면 메모리가 부족해집니다. **제너레이터(generator)**는 값을 **하나씩 게으르게(lazy)** 생산하여, 메모리를 거의 쓰지 않으면서 무한한 시퀀스도 다룰 수 있게 합니다. 여기에 `send()`와 `yield from`을 더하면 **코루틴(coroutine)**—양방향 통신이 가능한 일시 정지 함수—이 됩니다. 이것이 Python `asyncio`의 기반입니다.

---

## 1. 제너레이터의 본질

제너레이터 함수는 `yield`를 포함하는 함수입니다. 호출하면 함수 본문을 실행하지 않고, **제너레이터 객체**를 반환합니다.

```python
def count_up(n):
    i = 0
    while i < n:
        yield i
        i += 1

gen = count_up(3)
print(type(gen))  # <class 'generator'>
print(next(gen))  # 0
print(next(gen))  # 1
print(next(gen))  # 2
# next(gen) → StopIteration
```

### 실행 흐름

```
next(gen) 호출
  → 함수 본문 실행 시작
  → yield i에서 값을 반환하고 **일시 정지**
  → 호출자에게 제어권 반환

next(gen) 다시 호출
  → yield 다음 줄부터 실행 **재개**
  → 다음 yield에서 다시 일시 정지
```

> **핵심 직관**: 제너레이터는 **실행을 중단하고 재개할 수 있는 함수**입니다. 이 "중단과 재개"가 코루틴과 비동기 프로그래밍의 근본 메커니즘입니다.

---

## 2. 제너레이터 vs 리스트: 메모리

```python
import sys

# 리스트: 모든 값을 메모리에 보관
lst = [i ** 2 for i in range(1_000_000)]
print(sys.getsizeof(lst))  # ~8.4 MB

# 제너레이터: 값을 하나씩 생산
gen = (i ** 2 for i in range(1_000_000))
print(sys.getsizeof(gen))  # ~200 bytes (고정)
```

제너레이터는 **어떤 크기의 시퀀스든 메모리 사용량이 일정**합니다. 100만 개든 10억 개든 같습니다.

---

## 3. 제너레이터 파이프라인

여러 제너레이터를 연결하면 Unix 파이프처럼 데이터가 한 단계씩 흐릅니다.

```python
def read_lines(filename):
    """1단계: 파일에서 줄을 하나씩 읽기"""
    with open(filename) as f:
        for line in f:
            yield line.strip()

def filter_comments(lines):
    """2단계: 주석 제거"""
    for line in lines:
        if not line.startswith("#"):
            yield line

def parse_numbers(lines):
    """3단계: 숫자로 변환"""
    for line in lines:
        try:
            yield float(line)
        except ValueError:
            pass

# 파이프라인 조립
lines = read_lines("data.txt")
clean = filter_comments(lines)
numbers = parse_numbers(clean)

# 메모리에는 한 줄씩만 존재
total = sum(numbers)
```

파일이 100GB여도 메모리는 한 줄 분량만 사용합니다. 각 단계는 독립적이므로 테스트와 재사용이 쉽습니다.

---

## 4. send()와 양방향 통신

`yield`는 값을 **내보내기만** 하는 것이 아닙니다. `send()`로 값을 **받을 수도** 있습니다.

```python
def accumulator():
    total = 0
    while True:
        value = yield total  # 값을 내보내고, send()로 받음
        if value is None:
            break
        total += value

acc = accumulator()
next(acc)          # 제너레이터 시작 (첫 yield까지 실행)
print(acc.send(10))  # 10 → total=10, yield 10
print(acc.send(20))  # 20 → total=30, yield 30
print(acc.send(5))   # 5  → total=35, yield 35
```

### 실행 흐름

```
next(acc)       → yield total에서 정지 (total=0 반환)
acc.send(10)    → value=10 할당, total=10, yield total에서 정지 (10 반환)
acc.send(20)    → value=20 할당, total=30, yield total에서 정지 (30 반환)
```

> **핵심 직관**: `yield`는 **양방향 포트**입니다. 오른쪽의 표현식(`yield total`)이 바깥으로 나가고, `send()`의 인자가 안으로 들어옵니다. `next(gen)`은 `gen.send(None)`과 같습니다.

---

## 5. throw()와 close()

외부에서 제너레이터 내부로 예외를 던지거나 종료할 수 있습니다.

```python
def careful_generator():
    try:
        while True:
            value = yield
            print(f"Received: {value}")
    except GeneratorExit:
        print("Generator closed")
    except ValueError as e:
        print(f"Error handled: {e}")

gen = careful_generator()
next(gen)
gen.send(42)         # Received: 42
gen.throw(ValueError, "bad value")  # Error handled: bad value
gen.close()          # Generator closed
```

| 메서드 | 동작 |
|--------|------|
| `next(gen)` | 다음 yield까지 실행 |
| `gen.send(value)` | yield에 값을 보내고 다음 yield까지 실행 |
| `gen.throw(exc)` | yield 위치에서 예외 발생 |
| `gen.close()` | GeneratorExit 예외를 발생시켜 종료 |

---

## 6. yield from: 서브제너레이터 위임

`yield from`은 다른 이터러블에게 제어를 **위임**합니다.

### 단순 위임

```python
def inner():
    yield 1
    yield 2
    return "done"

def outer():
    # yield from 없이
    for item in inner():
        yield item

    # yield from 사용 (동일하지만 더 강력)
    result = yield from inner()
    print(f"Inner returned: {result}")  # Inner returned: done
```

### yield from의 진짜 힘: 양방향 전달

`yield from`은 단순 반복이 아닙니다. `send()`, `throw()`, `close()`를 **서브제너레이터에 자동 전달**합니다.

```python
def worker():
    total = 0
    while True:
        value = yield total
        if value is None:
            return total  # return 값이 yield from의 결과
        total += value

def manager():
    result = yield from worker()
    print(f"Worker finished: {result}")
    yield result

gen = manager()
next(gen)
gen.send(10)  # worker의 yield로 전달
gen.send(20)  # worker의 yield로 전달
gen.send(None)  # worker 종료 → "Worker finished: 30"
```

`yield from` 없이 이를 구현하려면 `send`, `throw`, `close`, `StopIteration`, `return` 값 처리 등을 모두 수동으로 해야 합니다. PEP 380의 의사 코드는 40줄이 넘습니다.

> **핵심 직관**: `yield from`은 제너레이터 사이에 **투명한 파이프**를 만듭니다. 바깥의 호출자와 안쪽의 서브제너레이터가 직접 소통하는 것처럼 동작합니다.

---

## 7. 코루틴 패턴: 이벤트 처리

`send()`를 활용한 코루틴은 이벤트 기반 처리에 유용합니다.

```python
from functools import wraps

def coroutine(func):
    """코루틴 자동 시작 데코레이터"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        gen = func(*args, **kwargs)
        next(gen)  # 첫 yield까지 실행 (priming)
        return gen
    return wrapper

@coroutine
def averager():
    """실시간 평균 계산 코루틴"""
    total = 0.0
    count = 0
    average = None
    while True:
        value = yield average
        total += value
        count += 1
        average = total / count

avg = averager()  # 이미 primed
print(avg.send(10))   # 10.0
print(avg.send(20))   # 15.0
print(avg.send(30))   # 20.0
```

이 패턴은 스트리밍 데이터의 온라인 통계 계산에 이상적입니다. 상태를 클래스 없이 함수 하나로 캡슐화합니다.

---

## 8. 제너레이터 기반 코루틴 → async/await

Python의 비동기 프로그래밍은 제너레이터 코루틴에서 발전했습니다.

```python
# Python 3.4 시절: 제너레이터 기반
import asyncio

@asyncio.coroutine
def old_style():
    yield from asyncio.sleep(1)
    return "done"

# Python 3.5+: 네이티브 코루틴
async def new_style():
    await asyncio.sleep(1)
    return "done"
```

| 개념 | 제너레이터 | async/await |
|------|-----------|-------------|
| 정의 | `def` + `yield` | `async def` + `await` |
| 위임 | `yield from` | `await` |
| 이벤트 루프 | 수동 구현 필요 | `asyncio` 내장 |
| 용도 | 범용 | I/O 비동기 특화 |

`await`는 내부적으로 `yield from`과 같은 메커니즘입니다. 코루틴이 `await`에서 일시 정지하고, 이벤트 루프가 다른 코루틴을 실행합니다.

---

## 9. itertools와 제너레이터 조합

표준 라이브러리의 `itertools`는 제너레이터 파이프라인의 구성 요소를 제공합니다.

```python
import itertools

# 무한 시퀀스에서 조건부 추출
def fibonacci():
    a, b = 0, 1
    while True:
        yield a
        a, b = b, a + b

# 처음 10개
first_10 = list(itertools.islice(fibonacci(), 10))
# [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]

# 1000 이하인 것만
under_1000 = list(itertools.takewhile(lambda x: x < 1000, fibonacci()))

# 여러 이터러블 연결
chained = itertools.chain(range(3), range(10, 13))
# 0, 1, 2, 10, 11, 12

# 그룹화
data = [("A", 1), ("A", 2), ("B", 3), ("B", 4)]
for key, group in itertools.groupby(data, key=lambda x: x[0]):
    print(key, list(group))
# A [('A', 1), ('A', 2)]
# B [('B', 3), ('B', 4)]
```

---

## 10. ML에서의 의미

### 데이터 로더

PyTorch의 `DataLoader`는 내부적으로 제너레이터 패턴을 사용합니다. 대규모 데이터셋을 배치 단위로 게으르게 로드합니다.

```python
def batch_generator(data, batch_size):
    for i in range(0, len(data), batch_size):
        yield data[i:i + batch_size]

for batch in batch_generator(huge_dataset, batch_size=32):
    model.train_step(batch)
```

### 데이터 전처리 파이프라인

Hugging Face의 `datasets` 라이브러리는 `map()`, `filter()` 등이 제너레이터 기반으로 동작하여 디스크의 데이터를 스트리밍 처리합니다.

### 학습 루프

학습 에폭, 스케줄러 등도 제너레이터로 표현할 수 있어 코드가 깔끔해집니다.

---

## 핵심 정리

1. **제너레이터**는 `yield`로 값을 하나씩 생산하는 게으른 시퀀스이며, 메모리 사용량이 시퀀스 크기와 무관하다.
2. **`send()`**로 제너레이터에 값을 보낼 수 있으며, 이것이 **코루틴**의 기반이다.
3. **`yield from`**은 서브제너레이터에 대한 투명한 위임으로, `send`/`throw`/`close`를 자동 전달한다.
4. **제너레이터 파이프라인**은 메모리 효율적인 데이터 처리의 핵심이며, Unix 파이프와 같은 구조이다.
5. `async/await`는 제너레이터 코루틴의 **문법적 설탕**으로, `await`는 `yield from`의 비동기 특화 버전이다.
