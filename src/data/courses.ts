import type { Course } from "@/types/curriculum";

export const courses: Course[] = [
  // ===== CODING FUNDAMENTALS =====
  {
    id: "python-advanced",
    categoryId: "coding",
    title: "Advanced Python Patterns",
    shortTitle: "Python",
    description:
      "Metaclasses, descriptors, advanced decorators, generator pipelines, async/await internals, and the Python type system in depth.",
    objectives: [
      "Master metaclasses and descriptor protocol",
      "Build complex decorator patterns (parameterized, stacked)",
      "Design generator-based data pipelines",
      "Understand async/await event loop internals",
      "Leverage advanced type hints and protocols",
    ],
    prerequisites: [],
    difficulty: "advanced",
    estimatedHours: 40,
    lectureCount: 12,
    tags: ["python", "metaclasses", "async", "generators", "type-system"],
    order: 1,
  },
  {
    id: "software-engineering",
    categoryId: "coding",
    title: "Software Engineering for ML",
    shortTitle: "SW Eng",
    description:
      "Design patterns for ML codebases, testing strategies for data-dependent code, CI/CD for ML pipelines, and code quality at scale.",
    objectives: [
      "Apply SOLID principles to ML code",
      "Design testable ML pipelines",
      "Set up CI/CD for model training and deployment",
      "Implement configuration management for experiments",
      "Master code review practices for ML teams",
    ],
    prerequisites: ["python-advanced"],
    difficulty: "advanced",
    estimatedHours: 35,
    lectureCount: 10,
    tags: ["design-patterns", "testing", "ci-cd", "code-quality"],
    order: 2,
  },
  {
    id: "systems-programming",
    categoryId: "coding",
    title: "Systems Concepts for AI",
    shortTitle: "Systems",
    description:
      "Memory management, CPU/GPU architecture, concurrency models, and distributed systems fundamentals essential for AI infrastructure.",
    objectives: [
      "Understand memory hierarchy and cache optimization",
      "Master threading, multiprocessing, and async I/O",
      "Grasp GPU execution model and CUDA basics",
      "Learn distributed systems consensus and replication",
      "Profile and optimize Python performance bottlenecks",
    ],
    prerequisites: ["python-advanced"],
    difficulty: "advanced",
    estimatedHours: 35,
    lectureCount: 10,
    tags: ["memory", "concurrency", "gpu", "distributed-systems"],
    order: 3,
  },

  // ===== MATHEMATICS FOR AI =====
  {
    id: "linear-algebra",
    categoryId: "mathematics",
    title: "Linear Algebra for ML",
    shortTitle: "LinAlg",
    description:
      "Eigendecomposition, SVD, matrix calculus, tensor algebra, and their applications in machine learning algorithms.",
    objectives: [
      "Master eigenvalue decomposition and spectral theorem",
      "Apply SVD to dimensionality reduction and recommender systems",
      "Compute matrix derivatives using matrix calculus",
      "Understand tensor operations and Einstein notation",
      "Connect linear algebra to PCA, least squares, and neural networks",
    ],
    prerequisites: [],
    difficulty: "advanced",
    estimatedHours: 45,
    lectureCount: 14,
    tags: ["eigenvalues", "svd", "matrix-calculus", "tensors"],
    order: 1,
  },
  {
    id: "calculus-optimization",
    categoryId: "mathematics",
    title: "Calculus & Optimization Theory",
    shortTitle: "Optim",
    description:
      "Multivariate calculus, convex optimization, Lagrangian duality, KKT conditions, and their role in ML training.",
    objectives: [
      "Master multivariate chain rule and Jacobians",
      "Understand convexity, strong convexity, and smoothness",
      "Apply Lagrangian multipliers and KKT conditions",
      "Analyze convergence of gradient-based methods",
      "Study duality theory and its applications",
    ],
    prerequisites: ["linear-algebra"],
    difficulty: "expert",
    estimatedHours: 50,
    lectureCount: 15,
    tags: ["calculus", "convex-optimization", "lagrangian", "duality"],
    order: 2,
  },
  {
    id: "probability-theory",
    categoryId: "mathematics",
    title: "Probability & Information Theory",
    shortTitle: "Prob",
    description:
      "Measure-theoretic foundations, Bayesian inference, exponential families, information theory, and concentration inequalities.",
    objectives: [
      "Understand measure-theoretic probability foundations",
      "Master Bayesian inference and conjugate priors",
      "Study exponential families and sufficient statistics",
      "Apply KL divergence, mutual information, and entropy",
      "Prove and apply concentration inequalities",
    ],
    prerequisites: ["linear-algebra"],
    difficulty: "expert",
    estimatedHours: 50,
    lectureCount: 15,
    tags: ["bayesian", "information-theory", "measure-theory", "exponential-families"],
    order: 3,
  },
  {
    id: "numerical-methods",
    categoryId: "mathematics",
    title: "Numerical Methods & Computation",
    shortTitle: "Numerical",
    description:
      "Floating-point arithmetic, numerical stability, automatic differentiation, and approximation theory for ML practitioners.",
    objectives: [
      "Analyze floating-point representation and error propagation",
      "Implement forward and reverse mode automatic differentiation",
      "Understand numerical stability in linear algebra operations",
      "Apply quadrature and Monte Carlo integration",
      "Study iterative methods for large-scale linear systems",
    ],
    prerequisites: ["linear-algebra", "calculus-optimization"],
    difficulty: "expert",
    estimatedHours: 35,
    lectureCount: 10,
    tags: ["floating-point", "autodiff", "stability", "approximation"],
    order: 4,
  },

  // ===== STATISTICS & DATA ANALYSIS =====
  {
    id: "statistical-inference",
    categoryId: "statistics",
    title: "Advanced Statistical Inference",
    shortTitle: "Inference",
    description:
      "Maximum likelihood, Bayesian estimation, hypothesis testing, confidence regions, and asymptotic theory.",
    objectives: [
      "Derive and apply MLE with regularity conditions",
      "Implement Bayesian estimation with MCMC",
      "Understand Neyman-Pearson framework and power analysis",
      "Construct confidence intervals and regions",
      "Apply asymptotic normality and delta method",
    ],
    prerequisites: ["probability-theory"],
    difficulty: "expert",
    estimatedHours: 40,
    lectureCount: 12,
    tags: ["mle", "bayesian", "hypothesis-testing", "mcmc"],
    order: 1,
  },
  {
    id: "causal-inference",
    categoryId: "statistics",
    title: "Causal Inference",
    shortTitle: "Causal",
    description:
      "Structural causal models, do-calculus, potential outcomes, instrumental variables, and causal discovery algorithms.",
    objectives: [
      "Formalize causality with DAGs and SCMs",
      "Apply do-calculus for causal effect identification",
      "Understand Rubin's potential outcomes framework",
      "Use instrumental variables and regression discontinuity",
      "Implement causal discovery from observational data",
    ],
    prerequisites: ["statistical-inference"],
    difficulty: "research",
    estimatedHours: 40,
    lectureCount: 12,
    tags: ["do-calculus", "dag", "potential-outcomes", "iv"],
    order: 2,
  },
  {
    id: "experimental-design",
    categoryId: "statistics",
    title: "Experimental Design at Scale",
    shortTitle: "ExpDesign",
    description:
      "A/B testing methodology, multi-armed bandits, network interference, sequential testing, and variance reduction techniques.",
    objectives: [
      "Design rigorous A/B tests with proper power analysis",
      "Handle network effects and interference in experiments",
      "Apply multi-armed bandit algorithms (UCB, Thompson)",
      "Implement sequential testing and always-valid confidence intervals",
      "Use variance reduction: CUPED, stratification, regression adjustment",
    ],
    prerequisites: ["statistical-inference"],
    difficulty: "expert",
    estimatedHours: 35,
    lectureCount: 10,
    tags: ["ab-testing", "bandits", "sequential-testing", "cuped"],
    order: 3,
  },
  {
    id: "time-series",
    categoryId: "statistics",
    title: "Time Series Analysis",
    shortTitle: "TimeSeries",
    description:
      "ARIMA, state space models, spectral analysis, and modern forecasting methods including neural approaches.",
    objectives: [
      "Model and diagnose ARIMA/SARIMA processes",
      "Implement state space models with Kalman filtering",
      "Apply spectral analysis and frequency domain methods",
      "Compare classical vs neural forecasting methods",
      "Handle non-stationarity, seasonality, and structural breaks",
    ],
    prerequisites: ["statistical-inference"],
    difficulty: "expert",
    estimatedHours: 40,
    lectureCount: 12,
    tags: ["arima", "kalman-filter", "spectral", "forecasting"],
    order: 4,
  },

  // ===== SQL & DATA ENGINEERING =====
  {
    id: "advanced-sql",
    categoryId: "sql-data-eng",
    title: "Advanced SQL Mastery",
    shortTitle: "SQL",
    description:
      "Window functions, recursive CTEs, query optimization, execution plans, and advanced SQL patterns for data analysis.",
    objectives: [
      "Master window functions (ROW_NUMBER, LEAD/LAG, NTILE)",
      "Write complex recursive CTEs for hierarchical data",
      "Read and optimize query execution plans",
      "Apply advanced joins, lateral joins, and set operations",
      "Design efficient analytical queries at scale",
    ],
    prerequisites: [],
    difficulty: "advanced",
    estimatedHours: 30,
    lectureCount: 10,
    tags: ["window-functions", "cte", "query-optimization", "joins"],
    order: 1,
  },
  {
    id: "database-internals",
    categoryId: "sql-data-eng",
    title: "Database Internals",
    shortTitle: "DB Internals",
    description:
      "B-tree indexing, LSM trees, query planners, transaction isolation levels, MVCC, and distributed database architectures.",
    objectives: [
      "Understand B-tree and LSM-tree storage engines",
      "Analyze query planner cost models and statistics",
      "Master transaction isolation (Read Committed → Serializable)",
      "Understand MVCC and lock-based concurrency control",
      "Compare distributed DB architectures (Spanner, CockroachDB)",
    ],
    prerequisites: ["advanced-sql"],
    difficulty: "expert",
    estimatedHours: 35,
    lectureCount: 10,
    tags: ["b-tree", "lsm", "mvcc", "isolation", "distributed-db"],
    order: 2,
  },
  {
    id: "data-pipelines",
    categoryId: "sql-data-eng",
    title: "Data Pipeline Architecture",
    shortTitle: "Pipelines",
    description:
      "ETL/ELT patterns, stream processing with Kafka, data quality frameworks, orchestration with Airflow, and lakehouse architecture.",
    objectives: [
      "Design batch and streaming data pipelines",
      "Implement event-driven architectures with Kafka",
      "Build data quality checks and monitoring",
      "Orchestrate complex DAGs with Airflow/Prefect",
      "Understand lakehouse architecture (Delta Lake, Iceberg)",
    ],
    prerequisites: ["advanced-sql"],
    difficulty: "expert",
    estimatedHours: 40,
    lectureCount: 12,
    tags: ["etl", "kafka", "airflow", "data-quality", "lakehouse"],
    order: 3,
  },

  // ===== ALGORITHMS & DATA STRUCTURES =====
  {
    id: "advanced-data-structures",
    categoryId: "algorithms",
    title: "Advanced Data Structures",
    shortTitle: "AdvDS",
    description:
      "Segment trees, tries, bloom filters, skip lists, persistent data structures, and cache-oblivious algorithms.",
    objectives: [
      "Implement segment trees with lazy propagation",
      "Build and apply trie variants (compressed, ternary)",
      "Use probabilistic data structures (Bloom, Count-Min, HyperLogLog)",
      "Understand persistent and functional data structures",
      "Analyze cache-oblivious data structure performance",
    ],
    prerequisites: [],
    difficulty: "advanced",
    estimatedHours: 35,
    lectureCount: 10,
    tags: ["segment-tree", "trie", "bloom-filter", "skip-list"],
    order: 1,
  },
  {
    id: "graph-algorithms",
    categoryId: "algorithms",
    title: "Graph Algorithms & Networks",
    shortTitle: "Graphs",
    description:
      "Shortest paths, network flow, matching, spectral graph theory, and community detection in large-scale networks.",
    objectives: [
      "Implement Dijkstra, Bellman-Ford, and Johnson's algorithm",
      "Solve max-flow/min-cut problems (Ford-Fulkerson, Push-Relabel)",
      "Apply spectral graph theory to clustering",
      "Detect communities with Louvain and label propagation",
      "Handle billion-edge graphs with streaming/sketching",
    ],
    prerequisites: ["advanced-data-structures"],
    difficulty: "expert",
    estimatedHours: 40,
    lectureCount: 12,
    tags: ["shortest-path", "network-flow", "spectral", "community-detection"],
    order: 2,
  },
  {
    id: "algorithm-design",
    categoryId: "algorithms",
    title: "Algorithm Design & Complexity",
    shortTitle: "AlgoDesign",
    description:
      "Dynamic programming mastery, approximation algorithms, randomized algorithms, amortized analysis, and complexity classes.",
    objectives: [
      "Solve complex DP problems with optimization techniques",
      "Design approximation algorithms with guarantees",
      "Apply randomized algorithms (Las Vegas, Monte Carlo)",
      "Perform amortized analysis (aggregate, accounting, potential)",
      "Understand P, NP, NP-hard, and reduction techniques",
    ],
    prerequisites: ["advanced-data-structures"],
    difficulty: "expert",
    estimatedHours: 45,
    lectureCount: 14,
    tags: ["dynamic-programming", "approximation", "randomized", "complexity"],
    order: 3,
  },

  // ===== MACHINE LEARNING =====
  {
    id: "classical-ml",
    categoryId: "machine-learning",
    title: "Classical Machine Learning",
    shortTitle: "ClassicML",
    description:
      "SVMs with kernel theory, ensemble methods (boosting, bagging), Gaussian processes, and probabilistic graphical models.",
    objectives: [
      "Derive SVM dual formulation and kernel trick",
      "Understand boosting theory (AdaBoost, Gradient Boosting)",
      "Implement Gaussian Process regression and classification",
      "Build and reason about probabilistic graphical models",
      "Apply model selection, cross-validation, and bias-variance tradeoff",
    ],
    prerequisites: ["linear-algebra", "probability-theory", "calculus-optimization"],
    difficulty: "expert",
    estimatedHours: 45,
    lectureCount: 14,
    tags: ["svm", "ensemble", "gaussian-process", "pgm", "kernel"],
    order: 1,
  },
  {
    id: "deep-learning",
    categoryId: "machine-learning",
    title: "Deep Learning Architectures",
    shortTitle: "DL",
    description:
      "Transformer internals, attention mechanisms, diffusion models, normalization techniques, and neural architecture design principles.",
    objectives: [
      "Implement Transformer from scratch with all variants",
      "Understand self-attention, multi-head, and cross-attention",
      "Study diffusion model theory (DDPM, score-based)",
      "Master normalization (BatchNorm, LayerNorm, RMSNorm)",
      "Design efficient architectures (MoE, Flash Attention, KV cache)",
    ],
    prerequisites: ["classical-ml", "calculus-optimization"],
    difficulty: "expert",
    estimatedHours: 50,
    lectureCount: 16,
    tags: ["transformer", "attention", "diffusion", "architecture"],
    order: 2,
  },
  {
    id: "optimization-theory",
    categoryId: "machine-learning",
    title: "Optimization for Deep Learning",
    shortTitle: "DL Optim",
    description:
      "SGD variants, learning rate schedules, loss landscape geometry, adaptive methods, and second-order optimization.",
    objectives: [
      "Analyze convergence of SGD, Adam, AdaFactor",
      "Design learning rate schedules (cosine, warmup, cyclical)",
      "Understand loss landscape geometry and sharpness-aware minimization",
      "Apply gradient clipping, accumulation, and mixed precision",
      "Study second-order methods (L-BFGS, natural gradient, K-FAC)",
    ],
    prerequisites: ["calculus-optimization", "deep-learning"],
    difficulty: "research",
    estimatedHours: 35,
    lectureCount: 10,
    tags: ["sgd", "adam", "loss-landscape", "sharpness", "second-order"],
    order: 3,
  },
  {
    id: "generalization-theory",
    categoryId: "machine-learning",
    title: "Generalization & Learning Theory",
    shortTitle: "Theory",
    description:
      "VC dimension, PAC learning, Rademacher complexity, double descent, neural tangent kernels, and implicit regularization.",
    objectives: [
      "Prove generalization bounds using VC dimension",
      "Understand PAC learning framework and sample complexity",
      "Analyze double descent and interpolation phenomena",
      "Study neural tangent kernel theory in infinite width limit",
      "Reason about implicit regularization of gradient descent",
    ],
    prerequisites: ["classical-ml", "probability-theory"],
    difficulty: "research",
    estimatedHours: 40,
    lectureCount: 12,
    tags: ["vc-dimension", "pac", "double-descent", "ntk", "regularization"],
    order: 4,
  },

  {
    id: "model-selection",
    categoryId: "machine-learning",
    title: "AI 문제 해결 가이드",
    shortTitle: "ModelSelect",
    description:
      "데이터 유형과 문제 상황에 따른 최적 모델 선택 전략. 통계적 방법, 고전 ML, 딥러닝을 비교하고 실전 의사결정 프레임워크를 제공합니다.",
    objectives: [
      "문제 유형별 최적 모델을 선택하는 의사결정 프레임워크 구축",
      "정형/이미지/텍스트/시계열/그래프 데이터별 모델 비교",
      "통계적 방법 vs 고전 ML vs 딥러닝의 트레이드오프 이해",
      "앙상블, 클러스터링, 차원 축소 등 고전 ML 기법의 실전 선택 기준",
      "비용, 지연시간, 해석가능성 등 실전 제약 조건을 반영한 모델 의사결정",
    ],
    prerequisites: ["classical-ml", "deep-learning"],
    difficulty: "expert",
    estimatedHours: 55,
    lectureCount: 19,
    tags: ["model-selection", "tabular", "ensemble", "clustering", "practical-ml"],
    order: 5,
  },

  // ===== AI ENGINEERING & MLOPS =====
  {
    id: "mlops",
    categoryId: "ai-engineering",
    title: "MLOps 실전",
    shortTitle: "MLOps",
    description:
      "ML 시스템 아키텍처, 데이터 파이프라인, 실험 관리, 모델 서빙, CI/CD, 모니터링, 피처 스토어까지 ML 운영의 전 주기.",
    objectives: [
      "ML 시스템 아키텍처 설계 (배치/실시간 서빙)",
      "데이터 파이프라인과 피처 스토어 구축",
      "실험 관리와 모델 레지스트리 운영",
      "모델 서빙 최적화와 추론 지연시간 관리",
      "모니터링, 드리프트 탐지, CI/CD for ML 구축",
    ],
    prerequisites: ["deep-learning"],
    difficulty: "expert",
    estimatedHours: 40,
    lectureCount: 12,
    tags: ["mlops", "serving", "pipeline", "monitoring", "feature-store"],
    order: 1,
  },
  {
    id: "llm-engineering",
    categoryId: "ai-engineering",
    title: "LLM 엔지니어링",
    shortTitle: "LLM Eng",
    description:
      "프롬프트 엔지니어링, RAG, 파인튜닝(LoRA/RLHF), 에이전트, 추론 최적화, 가드레일까지 LLM 애플리케이션의 설계와 운영.",
    objectives: [
      "프롬프트 엔지니어링과 구조화된 출력 설계",
      "RAG 파이프라인 설계 (벡터 DB, 청킹, Reranking)",
      "SFT, LoRA/QLoRA, RLHF/DPO 파인튜닝",
      "에이전트 아키텍처와 도구 사용 설계",
      "LLM 추론 최적화와 분산 서빙",
    ],
    prerequisites: ["deep-learning", "mlops"],
    difficulty: "expert",
    estimatedHours: 50,
    lectureCount: 14,
    tags: ["llm", "rag", "fine-tuning", "agents", "prompt-engineering"],
    order: 2,
  },
  {
    id: "responsible-ai",
    categoryId: "ai-engineering",
    title: "책임있는 AI",
    shortTitle: "ResponsibleAI",
    description:
      "알고리즘 공정성, 해석가능성, 프라이버시 보존, 적대적 강건성, 모델 거버넌스까지 신뢰할 수 있는 AI 시스템 구축.",
    objectives: [
      "공정성 정의와 측정 (DP, EO, 개인 공정성)",
      "SHAP, LIME 등 사후 설명 기법 적용",
      "차분 프라이버시와 연합 학습 이해",
      "적대적 강건성과 방어 전략 설계",
      "모델 거버넌스와 윤리적 AI 체계 구축",
    ],
    prerequisites: ["deep-learning"],
    difficulty: "expert",
    estimatedHours: 35,
    lectureCount: 10,
    tags: ["fairness", "interpretability", "privacy", "adversarial", "governance"],
    order: 3,
  },

  // ===== INTERVIEW PREPARATION =====
  {
    id: "coding-interview",
    categoryId: "interview",
    title: "코딩 인터뷰",
    shortTitle: "CodingInt",
    description:
      "배열/해시맵, 트리/그래프, DP, 그리디 등 핵심 알고리즘 패턴과 ML 코딩 문제까지 체계적 면접 준비.",
    objectives: [
      "핵심 알고리즘 패턴(투 포인터, 슬라이딩 윈도우, DP) 체계적 학습",
      "트리/그래프 탐색과 백트래킹 문제 해결",
      "ML 특화 코딩 문제(NumPy 구현, 역전파) 대비",
      "시스템 코딩 문제(LRU 캐시, 스트리밍) 구현",
      "모의 면접을 통한 시간 관리와 커뮤니케이션 훈련",
    ],
    prerequisites: ["python-advanced"],
    difficulty: "advanced",
    estimatedHours: 40,
    lectureCount: 12,
    tags: ["array", "tree", "dp", "greedy", "ml-coding"],
    order: 1,
  },
  {
    id: "system-design-ml",
    categoryId: "interview",
    title: "ML 시스템 설계",
    shortTitle: "SysDesign",
    description:
      "추천, 검색, 광고, 사기 탐지 등 실전 ML 시스템 설계 면접 준비. 아키텍처, 트레이드오프, 스케일링 전략.",
    objectives: [
      "ML 시스템 설계 면접의 체계적 프레임워크 구축",
      "추천/검색/광고 등 핵심 시스템 아키텍처 설계",
      "데이터 파이프라인과 모델 서빙 아키텍처 설계",
      "트레이드오프 분석과 스케일링 전략 수립",
      "모의 설계 면접을 통한 실전 대비",
    ],
    prerequisites: ["mlops", "deep-learning"],
    difficulty: "expert",
    estimatedHours: 40,
    lectureCount: 12,
    tags: ["system-design", "recommendation", "search", "fraud-detection", "serving"],
    order: 2,
  },

  // ===== SPECIALIZATION TRACKS =====
  {
    id: "nlp-llm",
    categoryId: "specialization",
    title: "NLP & Large Language Models",
    shortTitle: "NLP/LLM",
    description:
      "LLM fine-tuning (LoRA, QLoRA), RLHF/DPO alignment, prompt engineering, RAG architectures, and LLM evaluation.",
    objectives: [
      "Fine-tune LLMs with LoRA, QLoRA, and full fine-tuning",
      "Implement RLHF and DPO for model alignment",
      "Design advanced RAG pipelines (hybrid search, reranking)",
      "Master prompt engineering and in-context learning",
      "Evaluate LLMs with holistic benchmarks and human eval",
    ],
    prerequisites: ["deep-learning", "training-at-scale"],
    difficulty: "expert",
    estimatedHours: 45,
    lectureCount: 14,
    tags: ["llm", "fine-tuning", "rlhf", "rag", "prompt-engineering"],
    order: 1,
  },
  {
    id: "computer-vision",
    categoryId: "specialization",
    title: "Advanced Computer Vision",
    shortTitle: "CV",
    description:
      "Object detection, segmentation, generative models, self-supervised visual learning, and video understanding.",
    objectives: [
      "Implement modern detection architectures (DETR, YOLO variants)",
      "Master segmentation (SAM, Mask R-CNN, semantic/panoptic)",
      "Study image generation (Stable Diffusion, ControlNet)",
      "Apply self-supervised learning (DINO, MAE, CLIP)",
      "Process video with temporal models and optical flow",
    ],
    prerequisites: ["deep-learning"],
    difficulty: "expert",
    estimatedHours: 45,
    lectureCount: 14,
    tags: ["detection", "segmentation", "diffusion", "self-supervised", "video"],
    order: 2,
  },
  {
    id: "reinforcement-learning",
    categoryId: "specialization",
    title: "Reinforcement Learning",
    shortTitle: "RL",
    description:
      "Policy gradient methods, Q-learning, model-based RL, multi-agent systems, and the connection to RLHF.",
    objectives: [
      "Implement REINFORCE and PPO from scratch",
      "Master DQN variants (Double, Dueling, Rainbow)",
      "Study model-based RL (Dreamer, MuZero)",
      "Design multi-agent RL systems",
      "Connect RL theory to RLHF for language model alignment",
    ],
    prerequisites: ["deep-learning", "calculus-optimization"],
    difficulty: "research",
    estimatedHours: 45,
    lectureCount: 14,
    tags: ["policy-gradient", "q-learning", "model-based", "multi-agent", "rlhf"],
    order: 3,
  },
  {
    id: "multimodal-ai",
    categoryId: "specialization",
    title: "Multimodal AI Systems",
    shortTitle: "Multimodal",
    description:
      "Vision-language models, audio processing, cross-modal alignment, and unified multimodal architectures.",
    objectives: [
      "Understand CLIP, LLaVA, and multimodal LLM architectures",
      "Implement cross-modal alignment and contrastive learning",
      "Process audio with Whisper and speech synthesis models",
      "Design unified multimodal pipelines",
      "Evaluate multimodal systems across modalities",
    ],
    prerequisites: ["deep-learning", "nlp-llm", "computer-vision"],
    difficulty: "research",
    estimatedHours: 40,
    lectureCount: 12,
    tags: ["vision-language", "clip", "audio", "cross-modal", "multimodal"],
    order: 4,
  },
];

export function getCourseById(id: string) {
  return courses.find((c) => c.id === id);
}

export function getCoursesByCategory(categoryId: string) {
  return courses.filter((c) => c.categoryId === categoryId);
}
